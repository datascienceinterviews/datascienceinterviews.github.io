<!DOCTYPE html><html class=no-js lang=en> <head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities." name=description><meta content="Kuldeep Singh Sidhu" name=author><link href=https://singhsidhukuldeep.github.io/Cheat-Sheets/PyTorch/ rel=canonical><link href=../PySpark/ rel=prev><link href=../Python/ rel=next><link href=https://repository-images.githubusercontent.com/275878203/13719500-bb75-11ea-8f3a-be2ffb87a6a2 rel=icon><meta content="mkdocs-1.6.1, mkdocs-material-9.5.50" name=generator><title>PyTorch - Data Science Interview preparation</title><link href=../../assets/stylesheets/main.a40c8224.min.css rel=stylesheet><link href=../../assets/stylesheets/palette.06af60db.min.css rel=stylesheet><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback" rel=stylesheet><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link href=../../stylesheets/extra.css rel=stylesheet><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-EVGNTG49J7"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-EVGNTG49J7",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-EVGNTG49J7",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../assets/javascripts/glightbox.min.js></script></head> <body data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=default dir=ltr> <input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox> <input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a class=md-skip href=#pytorch-cheat-sheet>1. Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <!-- Add announcement here, including arbitrary HTML --> <style>
    @keyframes shake {
      0%, 100% { transform: translateX(0); }
      10%, 30%, 50%, 70%, 90% { transform: translateX(-2px); }
      20%, 40%, 60%, 80% { transform: translateX(2px); }
    }
    @keyframes glow {
      0%, 100% { text-shadow: 0 0 5px rgba(255, 165, 0, 0.5); }
      50% { text-shadow: 0 0 20px rgba(255, 165, 0, 0.8), 0 0 30px rgba(255, 140, 0, 0.6); }
    }
    .shake-text {
      display: inline-block;
      animation: shake 3s ease-in-out infinite;
    }
    .glow-link {
      animation: glow 2s ease-in-out infinite;
      font-weight: bold;
    }
  </style> <span class=shake-text>üöÄ <a class=glow-link href=/flashcards>Flashcards</a> feature is live!</span> <meta content=ca-pub-4988388949365963 name=google-adsense-account> <script async crossorigin=anonymous src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4988388949365963"></script> </div> </aside> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav aria-label=Header class="md-header__inner md-grid"> <a aria-label="Data Science Interview preparation" class="md-header__button md-logo" data-md-component=logo href=../.. title="Data Science Interview preparation"> <svg viewbox="0 0 576 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"></path></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science Interview preparation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> PyTorch </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input aria-label="Switch to light mode" class=md-option data-md-color-accent=indigo data-md-color-media=(prefers-color-scheme) data-md-color-primary=indigo data-md-color-scheme=default id=__palette_0 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_1 hidden title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg> </label> <input aria-label="Switch to dark mode" class=md-option data-md-color-accent=purple data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary=deep-purple data-md-color-scheme=default id=__palette_1 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_2 hidden title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg> </label> <input aria-label="Switch to system preference" class=md-option data-md-color-accent=purple data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary=deep-purple data-md-color-scheme=slate id=__palette_2 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_0 hidden title="Switch to system preference"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input aria-label=Search autocapitalize=off autocomplete=off autocorrect=off class=md-search__input data-md-component=search-query name=query placeholder=Search required spellcheck=false type=text> <label class="md-search__icon md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav aria-label=Search class=md-search__options> <a aria-label=Share class="md-search__icon md-icon" data-clipboard data-clipboard-text data-md-component=search-share href=javascript:void(0) tabindex=-1 title=Share> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg> </a> <button aria-label=Clear class="md-search__icon md-icon" tabindex=-1 title=Clear type=reset> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix tabindex=0> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a class=md-source data-md-component=source href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=Navigation class="md-nav md-nav--primary" data-md-level=0> <label class=md-nav__title for=__drawer> <a aria-label="Data Science Interview preparation" class="md-nav__button md-logo" data-md-component=logo href=../.. title="Data Science Interview preparation"> <svg viewbox="0 0 576 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"></path></svg> </a> Data Science Interview preparation </label> <div class=md-nav__source> <a class=md-source data-md-component=source href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"></path></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../..> <span class=md-ellipsis> üè° Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_2 type=checkbox> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> üë®üèø‚Äçüè´ Interview Questions </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_2_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> üë®üèø‚Äçüè´ Interview Questions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../flashcards/ class=md-nav__link> <span class=md-ellipsis> üìá Flashcards </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/data-structures-algorithms/ class=md-nav__link> <span class=md-ellipsis> DSA (Data Structures &amp; Algorithms) </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Machine-Learning/ class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/System-design/ class=md-nav__link> <span class=md-ellipsis> System Design </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Natural-Language-Processing/ class=md-nav__link> <span class=md-ellipsis> Natural Language Processing (NLP) </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Probability/ class=md-nav__link> <span class=md-ellipsis> Probability </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/AB-testing/ class=md-nav__link> <span class=md-ellipsis> A/B Testing </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/SQL-Interview-Questions/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Scikit-Learn/ class=md-nav__link> <span class=md-ellipsis> Scikit-Learn </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/LangChain/ class=md-nav__link> <span class=md-ellipsis> LangChain </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/LangGraph/ class=md-nav__link> <span class=md-ellipsis> LangGraph </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Interview-Question-Resources/ class=md-nav__link> <span class=md-ellipsis> Interview Question Resources </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input checked class="md-nav__toggle md-toggle" id=__nav_3 type=checkbox> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> üìù Cheat Sheets </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=true aria-labelledby=__nav_3_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> üìù Cheat Sheets </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../Django/ class=md-nav__link> <span class=md-ellipsis> Django </span> </a> </li> <li class=md-nav__item> <a href=../Flask/ class=md-nav__link> <span class=md-ellipsis> Flask </span> </a> </li> <li class=md-nav__item> <a href=../Hypothesis-Tests/ class=md-nav__link> <span class=md-ellipsis> Hypothesis Tests </span> </a> </li> <li class=md-nav__item> <a href=../Keras/ class=md-nav__link> <span class=md-ellipsis> Keras </span> </a> </li> <li class=md-nav__item> <a href=../LangChain-LangGraph/ class=md-nav__link> <span class=md-ellipsis> LangChain &amp; LangGraph </span> </a> </li> <li class=md-nav__item> <a href=../NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../PySpark/ class=md-nav__link> <span class=md-ellipsis> PySpark </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id=__toc type=checkbox> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> PyTorch </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> PyTorch </span> </a> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#getting-started>1.1 <span class=md-ellipsis> Getting Started </span> </a> <nav aria-label="Getting Started" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#installation>1.1.1 <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#importing-pytorch>1.1.2 <span class=md-ellipsis> Importing PyTorch </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#tensors>1.2 <span class=md-ellipsis> Tensors </span> </a> <nav aria-label=Tensors class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#tensor-creation-flow>1.2.1 <span class=md-ellipsis> Tensor Creation Flow </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#creating-tensors>1.2.2 <span class=md-ellipsis> Creating Tensors </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#tensor-attributes>1.2.3 <span class=md-ellipsis> Tensor Attributes </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#tensor-operations>1.2.4 <span class=md-ellipsis> Tensor Operations </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#data-types>1.2.5 <span class=md-ellipsis> Data Types </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#device-management>1.2.6 <span class=md-ellipsis> Device Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#neural-networks>1.3 <span class=md-ellipsis> Neural Networks </span> </a> <nav aria-label="Neural Networks" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#neural-network-architecture>1.3.1 <span class=md-ellipsis> Neural Network Architecture </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#defining-a-model>1.3.2 <span class=md-ellipsis> Defining a Model </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#layers>1.3.3 <span class=md-ellipsis> Layers </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#activation-functions>1.3.4 <span class=md-ellipsis> Activation Functions </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#loss-functions>1.3.5 <span class=md-ellipsis> Loss Functions </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#optimizers>1.3.6 <span class=md-ellipsis> Optimizers </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#optimizer-configuration>1.3.7 <span class=md-ellipsis> Optimizer Configuration </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#learning-rate-schedulers>1.3.8 <span class=md-ellipsis> Learning Rate Schedulers </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#metrics>1.3.9 <span class=md-ellipsis> Metrics </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#training>1.4 <span class=md-ellipsis> Training </span> </a> <nav aria-label=Training class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#training-pipeline>1.4.1 <span class=md-ellipsis> Training Pipeline </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#training-loop>1.4.2 <span class=md-ellipsis> Training Loop </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#custom-datasets-and-dataloaders>1.4.3 <span class=md-ellipsis> Custom Datasets and DataLoaders </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#transforms>1.4.4 <span class=md-ellipsis> Transforms </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#mixed-precision-training>1.4.5 <span class=md-ellipsis> Mixed Precision Training </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#evaluation>1.5 <span class=md-ellipsis> Evaluation </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#prediction-and-inference>1.6 <span class=md-ellipsis> Prediction and Inference </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#saving-and-loading-models>1.7 <span class=md-ellipsis> Saving and Loading Models </span> </a> <nav aria-label="Saving and Loading Models" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#save-model-state-dictionary-recommended>1.7.1 <span class=md-ellipsis> Save Model State Dictionary (Recommended) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#load-model-state-dictionary>1.7.2 <span class=md-ellipsis> Load Model State Dictionary </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#save-entire-model-not-recommended>1.7.3 <span class=md-ellipsis> Save Entire Model (Not Recommended) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#model-versioning-and-management>1.7.4 <span class=md-ellipsis> Model Versioning and Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#cuda-gpu-support>1.8 <span class=md-ellipsis> CUDA (GPU Support) </span> </a> <nav aria-label="CUDA (GPU Support)" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#check-cuda-availability>1.8.1 <span class=md-ellipsis> Check CUDA Availability </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#set-device>1.8.2 <span class=md-ellipsis> Set Device </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#move-tensors-to-gpu>1.8.3 <span class=md-ellipsis> Move Tensors to GPU </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#cuda-best-practices>1.8.4 <span class=md-ellipsis> CUDA Best Practices </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#distributed-training>1.9 <span class=md-ellipsis> Distributed Training </span> </a> <nav aria-label="Distributed Training" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#dataparallel-simple-but-limited>1.9.1 <span class=md-ellipsis> DataParallel (Simple but limited) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#distributeddataparallel-recommended>1.9.2 <span class=md-ellipsis> DistributedDataParallel (Recommended) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#multi-node-ddp>1.9.3 <span class=md-ellipsis> Multi-Node DDP </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#ddp-with-mixed-precision>1.9.4 <span class=md-ellipsis> DDP with Mixed Precision </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#autograd-automatic-differentiation>1.10 <span class=md-ellipsis> Autograd (Automatic Differentiation) </span> </a> <nav aria-label="Autograd (Automatic Differentiation)" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#computational-graph>1.10.1 <span class=md-ellipsis> Computational Graph </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#tracking-gradients>1.10.2 <span class=md-ellipsis> Tracking Gradients </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#controlling-gradient-tracking>1.10.3 <span class=md-ellipsis> Controlling Gradient Tracking </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#computing-higher-order-derivatives>1.10.4 <span class=md-ellipsis> Computing Higher-Order Derivatives </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#gradient-for-non-scalar-outputs>1.10.5 <span class=md-ellipsis> Gradient for Non-Scalar Outputs </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#custom-autograd-functions>1.10.6 <span class=md-ellipsis> Custom Autograd Functions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#data-augmentation>1.11 <span class=md-ellipsis> Data Augmentation </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#learning-rate-schedulers_1>1.12 <span class=md-ellipsis> Learning Rate Schedulers </span> </a> <nav aria-label="Learning Rate Schedulers" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#common-schedulers>1.12.1 <span class=md-ellipsis> Common Schedulers </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#usage-in-training-loop>1.12.2 <span class=md-ellipsis> Usage in Training Loop </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#tensorboard-integration>1.13 <span class=md-ellipsis> TensorBoard Integration </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#onnx-export>1.14 <span class=md-ellipsis> ONNX Export </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#torchscript>1.15 <span class=md-ellipsis> TorchScript </span> </a> <nav aria-label=TorchScript class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#tracing-recommended-for-most-models>1.15.1 <span class=md-ellipsis> Tracing (Recommended for most models) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#scripting-for-models-with-control-flow>1.15.2 <span class=md-ellipsis> Scripting (For models with control flow) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#performance-comparison>1.15.3 <span class=md-ellipsis> Performance Comparison </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#deployment>1.16 <span class=md-ellipsis> Deployment </span> </a> <nav aria-label=Deployment class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#serving-with-flask>1.16.1 <span class=md-ellipsis> Serving with Flask </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#test-api>1.16.2 <span class=md-ellipsis> Test API </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#docker-deployment>1.16.3 <span class=md-ellipsis> Docker Deployment </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#serving-with-torchserve>1.16.4 <span class=md-ellipsis> Serving with TorchServe </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#distributed-training_1>1.17 <span class=md-ellipsis> Distributed Training </span> </a> <nav aria-label="Distributed Training" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#dataparallel>1.17.1 <span class=md-ellipsis> DataParallel </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#distributeddataparallel-ddp>1.17.2 <span class=md-ellipsis> DistributedDataParallel (DDP) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#gradient-clipping>1.17.3 <span class=md-ellipsis> Gradient Clipping </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#weight-decay>1.17.4 <span class=md-ellipsis> Weight Decay </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#early-stopping>1.17.5 <span class=md-ellipsis> Early Stopping </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#learning-rate-finders>1.17.6 <span class=md-ellipsis> Learning Rate Finders </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#gradient-accumulation>1.17.7 <span class=md-ellipsis> Gradient Accumulation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#common-neural-network-architectures>1.18 <span class=md-ellipsis> Common Neural Network Architectures </span> </a> <nav aria-label="Common Neural Network Architectures" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#convolutional-neural-network-cnn>1.18.1 <span class=md-ellipsis> Convolutional Neural Network (CNN) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#resnet-style-residual-block>1.18.2 <span class=md-ellipsis> ResNet-style Residual Block </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#recurrent-neural-network-lstm>1.18.3 <span class=md-ellipsis> Recurrent Neural Network (LSTM) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#transformer-encoder>1.18.4 <span class=md-ellipsis> Transformer Encoder </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#autoencoder>1.18.5 <span class=md-ellipsis> Autoencoder </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#common-issues-and-debugging>1.19 <span class=md-ellipsis> Common Issues and Debugging </span> </a> <nav aria-label="Common Issues and Debugging" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#debugging-tools>1.19.1 <span class=md-ellipsis> Debugging Tools </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#common-issues-and-solutions>1.19.2 <span class=md-ellipsis> Common Issues and Solutions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#best-practices>1.20 <span class=md-ellipsis> Best Practices </span> </a> <nav aria-label="Best Practices" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#code-organization>1.20.1 <span class=md-ellipsis> Code Organization </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#performance-optimization>1.20.2 <span class=md-ellipsis> Performance Optimization </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#reproducibility>1.20.3 <span class=md-ellipsis> Reproducibility </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#model-initialization>1.20.4 <span class=md-ellipsis> Model Initialization </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#logging-and-monitoring>1.20.5 <span class=md-ellipsis> Logging and Monitoring </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#model-deployment-checklist>1.20.6 <span class=md-ellipsis> Model Deployment Checklist </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#development-tips>1.20.7 <span class=md-ellipsis> Development Tips </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#quick-reference>1.21 <span class=md-ellipsis> Quick Reference </span> </a> <nav aria-label="Quick Reference" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#essential-operations>1.21.1 <span class=md-ellipsis> Essential Operations </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#training-template>1.21.2 <span class=md-ellipsis> Training Template </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#common-layer-patterns>1.21.3 <span class=md-ellipsis> Common Layer Patterns </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#useful-commands>1.21.4 <span class=md-ellipsis> Useful Commands </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#performance-tips>1.21.5 <span class=md-ellipsis> Performance Tips </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../RegEx/ class=md-nav__link> <span class=md-ellipsis> Regular Expressions (RegEx) </span> </a> </li> <li class=md-nav__item> <a href=../Sk-learn/ class=md-nav__link> <span class=md-ellipsis> Scikit Learn </span> </a> </li> <li class=md-nav__item> <a href=../SQL/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../tensorflow/ class=md-nav__link> <span class=md-ellipsis> TensorFlow </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_4 type=checkbox> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> ‚Äçüéì ML Topics </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_4_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> ‚Äçüéì ML Topics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Machine-Learning/ARIMA/ class=md-nav__link> <span class=md-ellipsis> ARIMA </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Activation%20functions/ class=md-nav__link> <span class=md-ellipsis> Activation functions </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Collaborative%20Filtering/ class=md-nav__link> <span class=md-ellipsis> Collaborative Filtering </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Confusion%20Matrix/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/DBSCAN/ class=md-nav__link> <span class=md-ellipsis> DBSCAN </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Decision%20Trees/ class=md-nav__link> <span class=md-ellipsis> Decision Trees </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Gradient%20Boosting/ class=md-nav__link> <span class=md-ellipsis> Gradient Boosting </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/K-means%20clustering/ class=md-nav__link> <span class=md-ellipsis> K-means clustering </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Linear%20Regression/ class=md-nav__link> <span class=md-ellipsis> Linear Regression </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Logistic%20Regression/ class=md-nav__link> <span class=md-ellipsis> Logistic Regression </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Loss%20Function%20MAE%2C%20RMSE/ class=md-nav__link> <span class=md-ellipsis> Loss Function MAE, RMSE </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Neural%20Networks/ class=md-nav__link> <span class=md-ellipsis> Neural Networks </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Normal%20Distribution/ class=md-nav__link> <span class=md-ellipsis> Normal Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Normalization%20Regularisation/ class=md-nav__link> <span class=md-ellipsis> Normalization Regularisation </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Overfitting%2C%20Underfitting/ class=md-nav__link> <span class=md-ellipsis> Overfitting, Underfitting </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/PCA/ class=md-nav__link> <span class=md-ellipsis> PCA </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Random%20Forest/ class=md-nav__link> <span class=md-ellipsis> Random Forest </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Support%20Vector%20Machines/ class=md-nav__link> <span class=md-ellipsis> Support Vector Machines </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Unbalanced%2C%20Skewed%20data/ class=md-nav__link> <span class=md-ellipsis> Unbalanced, Skewed data </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/kNN/ class=md-nav__link> <span class=md-ellipsis> kNN </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" id=__nav_5 type=checkbox> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> üë®üèæ‚Äçüíª Online Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=false aria-labelledby=__nav_5_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> üë®üèæ‚Äçüíª Online Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Online-Material/Online-Material-for-Learning/ class=md-nav__link> <span class=md-ellipsis> Online Study Material </span> </a> </li> <li class=md-nav__item> <a href=../../Online-Material/popular-resources/ class=md-nav__link> <span class=md-ellipsis> Popular Blogs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../Contribute/ class=md-nav__link> <span class=md-ellipsis> ü§ù Contribute </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label="Table of contents" class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#getting-started>1.1 <span class=md-ellipsis> Getting Started </span> </a> <nav aria-label="Getting Started" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#installation>1.1.1 <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#importing-pytorch>1.1.2 <span class=md-ellipsis> Importing PyTorch </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#tensors>1.2 <span class=md-ellipsis> Tensors </span> </a> <nav aria-label=Tensors class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#tensor-creation-flow>1.2.1 <span class=md-ellipsis> Tensor Creation Flow </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#creating-tensors>1.2.2 <span class=md-ellipsis> Creating Tensors </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#tensor-attributes>1.2.3 <span class=md-ellipsis> Tensor Attributes </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#tensor-operations>1.2.4 <span class=md-ellipsis> Tensor Operations </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#data-types>1.2.5 <span class=md-ellipsis> Data Types </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#device-management>1.2.6 <span class=md-ellipsis> Device Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#neural-networks>1.3 <span class=md-ellipsis> Neural Networks </span> </a> <nav aria-label="Neural Networks" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#neural-network-architecture>1.3.1 <span class=md-ellipsis> Neural Network Architecture </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#defining-a-model>1.3.2 <span class=md-ellipsis> Defining a Model </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#layers>1.3.3 <span class=md-ellipsis> Layers </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#activation-functions>1.3.4 <span class=md-ellipsis> Activation Functions </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#loss-functions>1.3.5 <span class=md-ellipsis> Loss Functions </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#optimizers>1.3.6 <span class=md-ellipsis> Optimizers </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#optimizer-configuration>1.3.7 <span class=md-ellipsis> Optimizer Configuration </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#learning-rate-schedulers>1.3.8 <span class=md-ellipsis> Learning Rate Schedulers </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#metrics>1.3.9 <span class=md-ellipsis> Metrics </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#training>1.4 <span class=md-ellipsis> Training </span> </a> <nav aria-label=Training class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#training-pipeline>1.4.1 <span class=md-ellipsis> Training Pipeline </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#training-loop>1.4.2 <span class=md-ellipsis> Training Loop </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#custom-datasets-and-dataloaders>1.4.3 <span class=md-ellipsis> Custom Datasets and DataLoaders </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#transforms>1.4.4 <span class=md-ellipsis> Transforms </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#mixed-precision-training>1.4.5 <span class=md-ellipsis> Mixed Precision Training </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#evaluation>1.5 <span class=md-ellipsis> Evaluation </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#prediction-and-inference>1.6 <span class=md-ellipsis> Prediction and Inference </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#saving-and-loading-models>1.7 <span class=md-ellipsis> Saving and Loading Models </span> </a> <nav aria-label="Saving and Loading Models" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#save-model-state-dictionary-recommended>1.7.1 <span class=md-ellipsis> Save Model State Dictionary (Recommended) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#load-model-state-dictionary>1.7.2 <span class=md-ellipsis> Load Model State Dictionary </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#save-entire-model-not-recommended>1.7.3 <span class=md-ellipsis> Save Entire Model (Not Recommended) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#model-versioning-and-management>1.7.4 <span class=md-ellipsis> Model Versioning and Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#cuda-gpu-support>1.8 <span class=md-ellipsis> CUDA (GPU Support) </span> </a> <nav aria-label="CUDA (GPU Support)" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#check-cuda-availability>1.8.1 <span class=md-ellipsis> Check CUDA Availability </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#set-device>1.8.2 <span class=md-ellipsis> Set Device </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#move-tensors-to-gpu>1.8.3 <span class=md-ellipsis> Move Tensors to GPU </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#cuda-best-practices>1.8.4 <span class=md-ellipsis> CUDA Best Practices </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#distributed-training>1.9 <span class=md-ellipsis> Distributed Training </span> </a> <nav aria-label="Distributed Training" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#dataparallel-simple-but-limited>1.9.1 <span class=md-ellipsis> DataParallel (Simple but limited) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#distributeddataparallel-recommended>1.9.2 <span class=md-ellipsis> DistributedDataParallel (Recommended) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#multi-node-ddp>1.9.3 <span class=md-ellipsis> Multi-Node DDP </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#ddp-with-mixed-precision>1.9.4 <span class=md-ellipsis> DDP with Mixed Precision </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#autograd-automatic-differentiation>1.10 <span class=md-ellipsis> Autograd (Automatic Differentiation) </span> </a> <nav aria-label="Autograd (Automatic Differentiation)" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#computational-graph>1.10.1 <span class=md-ellipsis> Computational Graph </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#tracking-gradients>1.10.2 <span class=md-ellipsis> Tracking Gradients </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#controlling-gradient-tracking>1.10.3 <span class=md-ellipsis> Controlling Gradient Tracking </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#computing-higher-order-derivatives>1.10.4 <span class=md-ellipsis> Computing Higher-Order Derivatives </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#gradient-for-non-scalar-outputs>1.10.5 <span class=md-ellipsis> Gradient for Non-Scalar Outputs </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#custom-autograd-functions>1.10.6 <span class=md-ellipsis> Custom Autograd Functions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#data-augmentation>1.11 <span class=md-ellipsis> Data Augmentation </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#learning-rate-schedulers_1>1.12 <span class=md-ellipsis> Learning Rate Schedulers </span> </a> <nav aria-label="Learning Rate Schedulers" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#common-schedulers>1.12.1 <span class=md-ellipsis> Common Schedulers </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#usage-in-training-loop>1.12.2 <span class=md-ellipsis> Usage in Training Loop </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#tensorboard-integration>1.13 <span class=md-ellipsis> TensorBoard Integration </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#onnx-export>1.14 <span class=md-ellipsis> ONNX Export </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#torchscript>1.15 <span class=md-ellipsis> TorchScript </span> </a> <nav aria-label=TorchScript class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#tracing-recommended-for-most-models>1.15.1 <span class=md-ellipsis> Tracing (Recommended for most models) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#scripting-for-models-with-control-flow>1.15.2 <span class=md-ellipsis> Scripting (For models with control flow) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#performance-comparison>1.15.3 <span class=md-ellipsis> Performance Comparison </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#deployment>1.16 <span class=md-ellipsis> Deployment </span> </a> <nav aria-label=Deployment class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#serving-with-flask>1.16.1 <span class=md-ellipsis> Serving with Flask </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#test-api>1.16.2 <span class=md-ellipsis> Test API </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#docker-deployment>1.16.3 <span class=md-ellipsis> Docker Deployment </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#serving-with-torchserve>1.16.4 <span class=md-ellipsis> Serving with TorchServe </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#distributed-training_1>1.17 <span class=md-ellipsis> Distributed Training </span> </a> <nav aria-label="Distributed Training" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#dataparallel>1.17.1 <span class=md-ellipsis> DataParallel </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#distributeddataparallel-ddp>1.17.2 <span class=md-ellipsis> DistributedDataParallel (DDP) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#gradient-clipping>1.17.3 <span class=md-ellipsis> Gradient Clipping </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#weight-decay>1.17.4 <span class=md-ellipsis> Weight Decay </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#early-stopping>1.17.5 <span class=md-ellipsis> Early Stopping </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#learning-rate-finders>1.17.6 <span class=md-ellipsis> Learning Rate Finders </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#gradient-accumulation>1.17.7 <span class=md-ellipsis> Gradient Accumulation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#common-neural-network-architectures>1.18 <span class=md-ellipsis> Common Neural Network Architectures </span> </a> <nav aria-label="Common Neural Network Architectures" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#convolutional-neural-network-cnn>1.18.1 <span class=md-ellipsis> Convolutional Neural Network (CNN) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#resnet-style-residual-block>1.18.2 <span class=md-ellipsis> ResNet-style Residual Block </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#recurrent-neural-network-lstm>1.18.3 <span class=md-ellipsis> Recurrent Neural Network (LSTM) </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#transformer-encoder>1.18.4 <span class=md-ellipsis> Transformer Encoder </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#autoencoder>1.18.5 <span class=md-ellipsis> Autoencoder </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#common-issues-and-debugging>1.19 <span class=md-ellipsis> Common Issues and Debugging </span> </a> <nav aria-label="Common Issues and Debugging" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#debugging-tools>1.19.1 <span class=md-ellipsis> Debugging Tools </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#common-issues-and-solutions>1.19.2 <span class=md-ellipsis> Common Issues and Solutions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#best-practices>1.20 <span class=md-ellipsis> Best Practices </span> </a> <nav aria-label="Best Practices" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#code-organization>1.20.1 <span class=md-ellipsis> Code Organization </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#performance-optimization>1.20.2 <span class=md-ellipsis> Performance Optimization </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#reproducibility>1.20.3 <span class=md-ellipsis> Reproducibility </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#model-initialization>1.20.4 <span class=md-ellipsis> Model Initialization </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#logging-and-monitoring>1.20.5 <span class=md-ellipsis> Logging and Monitoring </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#model-deployment-checklist>1.20.6 <span class=md-ellipsis> Model Deployment Checklist </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#development-tips>1.20.7 <span class=md-ellipsis> Development Tips </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=#quick-reference>1.21 <span class=md-ellipsis> Quick Reference </span> </a> <nav aria-label="Quick Reference" class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a class=md-nav__link href=#essential-operations>1.21.1 <span class=md-ellipsis> Essential Operations </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#training-template>1.21.2 <span class=md-ellipsis> Training Template </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#common-layer-patterns>1.21.3 <span class=md-ellipsis> Common Layer Patterns </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#useful-commands>1.21.4 <span class=md-ellipsis> Useful Commands </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#performance-tips>1.21.5 <span class=md-ellipsis> Performance Tips </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a class="md-content__button md-icon" href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/edit/master/docs/Cheat-Sheets/PyTorch.md title="Edit this page"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg> </a> <a class="md-content__button md-icon" href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/raw/master/docs/Cheat-Sheets/PyTorch.md title="View source of this page"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg> </a> <h1 id=pytorch-cheat-sheet><span class="enumerate-headings-plugin enumerate-heading-plugin">1.</span> PyTorch Cheat Sheet</h1> <div class=toc> <ul> <li><a href=#pytorch-cheat-sheet>1. PyTorch Cheat Sheet</a><ul> <li><a href=#getting-started>1.1 Getting Started</a><ul> <li><a href=#installation>1.1.1 Installation</a></li> <li><a href=#importing-pytorch>1.1.2 Importing PyTorch</a></li> </ul> </li> <li><a href=#tensors>1.2 Tensors</a><ul> <li><a href=#tensor-creation-flow>1.2.1 Tensor Creation Flow</a></li> <li><a href=#creating-tensors>1.2.2 Creating Tensors</a></li> <li><a href=#tensor-attributes>1.2.3 Tensor Attributes</a></li> <li><a href=#tensor-operations>1.2.4 Tensor Operations</a></li> <li><a href=#data-types>1.2.5 Data Types</a></li> <li><a href=#device-management>1.2.6 Device Management</a></li> </ul> </li> <li><a href=#neural-networks>1.3 Neural Networks</a><ul> <li><a href=#neural-network-architecture>1.3.1 Neural Network Architecture</a></li> <li><a href=#defining-a-model>1.3.2 Defining a Model</a></li> <li><a href=#layers>1.3.3 Layers</a></li> <li><a href=#activation-functions>1.3.4 Activation Functions</a></li> <li><a href=#loss-functions>1.3.5 Loss Functions</a></li> <li><a href=#optimizers>1.3.6 Optimizers</a></li> <li><a href=#optimizer-configuration>1.3.7 Optimizer Configuration</a></li> <li><a href=#learning-rate-schedulers>1.3.8 Learning Rate Schedulers</a></li> <li><a href=#metrics>1.3.9 Metrics</a></li> </ul> </li> <li><a href=#training>1.4 Training</a><ul> <li><a href=#training-pipeline>1.4.1 Training Pipeline</a></li> <li><a href=#training-loop>1.4.2 Training Loop</a></li> <li><a href=#custom-datasets-and-dataloaders>1.4.3 Custom Datasets and DataLoaders</a></li> <li><a href=#transforms>1.4.4 Transforms</a></li> <li><a href=#mixed-precision-training>1.4.5 Mixed Precision Training</a></li> </ul> </li> <li><a href=#evaluation>1.5 Evaluation</a></li> <li><a href=#prediction-and-inference>1.6 Prediction and Inference</a></li> <li><a href=#saving-and-loading-models>1.7 Saving and Loading Models</a><ul> <li><a href=#save-model-state-dictionary-recommended>1.7.1 Save Model State Dictionary (Recommended)</a></li> <li><a href=#load-model-state-dictionary>1.7.2 Load Model State Dictionary</a></li> <li><a href=#save-entire-model-not-recommended>1.7.3 Save Entire Model (Not Recommended)</a></li> <li><a href=#model-versioning-and-management>1.7.4 Model Versioning and Management</a></li> </ul> </li> <li><a href=#cuda-gpu-support>1.8 CUDA (GPU Support)</a><ul> <li><a href=#check-cuda-availability>1.8.1 Check CUDA Availability</a></li> <li><a href=#set-device>1.8.2 Set Device</a></li> <li><a href=#move-tensors-to-gpu>1.8.3 Move Tensors to GPU</a></li> <li><a href=#cuda-best-practices>1.8.4 CUDA Best Practices</a></li> </ul> </li> <li><a href=#distributed-training>1.9 Distributed Training</a><ul> <li><a href=#dataparallel-simple-but-limited>1.9.1 DataParallel (Simple but limited)</a></li> <li><a href=#distributeddataparallel-recommended>1.9.2 DistributedDataParallel (Recommended)</a></li> <li><a href=#multi-node-ddp>1.9.3 Multi-Node DDP</a></li> <li><a href=#ddp-with-mixed-precision>1.9.4 DDP with Mixed Precision</a></li> </ul> </li> <li><a href=#autograd-automatic-differentiation>1.10 Autograd (Automatic Differentiation)</a><ul> <li><a href=#computational-graph>1.10.1 Computational Graph</a></li> <li><a href=#tracking-gradients>1.10.2 Tracking Gradients</a></li> <li><a href=#controlling-gradient-tracking>1.10.3 Controlling Gradient Tracking</a></li> <li><a href=#computing-higher-order-derivatives>1.10.4 Computing Higher-Order Derivatives</a></li> <li><a href=#gradient-for-non-scalar-outputs>1.10.5 Gradient for Non-Scalar Outputs</a></li> <li><a href=#custom-autograd-functions>1.10.6 Custom Autograd Functions</a></li> </ul> </li> <li><a href=#data-augmentation>1.11 Data Augmentation</a></li> <li><a href=#learning-rate-schedulers_1>1.12 Learning Rate Schedulers</a><ul> <li><a href=#common-schedulers>1.12.1 Common Schedulers</a></li> <li><a href=#usage-in-training-loop>1.12.2 Usage in Training Loop</a></li> </ul> </li> <li><a href=#tensorboard-integration>1.13 TensorBoard Integration</a></li> <li><a href=#onnx-export>1.14 ONNX Export</a></li> <li><a href=#torchscript>1.15 TorchScript</a><ul> <li><a href=#tracing-recommended-for-most-models>1.15.1 Tracing (Recommended for most models)</a></li> <li><a href=#scripting-for-models-with-control-flow>1.15.2 Scripting (For models with control flow)</a></li> <li><a href=#performance-comparison>1.15.3 Performance Comparison</a></li> </ul> </li> <li><a href=#deployment>1.16 Deployment</a><ul> <li><a href=#serving-with-flask>1.16.1 Serving with Flask</a></li> <li><a href=#test-api>1.16.2 Test API</a></li> <li><a href=#docker-deployment>1.16.3 Docker Deployment</a></li> <li><a href=#serving-with-torchserve>1.16.4 Serving with TorchServe</a></li> </ul> </li> <li><a href=#distributed-training_1>1.17 Distributed Training</a><ul> <li><a href=#dataparallel>1.17.1 DataParallel</a></li> <li><a href=#distributeddataparallel-ddp>1.17.2 DistributedDataParallel (DDP)</a></li> <li><a href=#gradient-clipping>1.17.3 Gradient Clipping</a></li> <li><a href=#weight-decay>1.17.4 Weight Decay</a></li> <li><a href=#early-stopping>1.17.5 Early Stopping</a></li> <li><a href=#learning-rate-finders>1.17.6 Learning Rate Finders</a></li> <li><a href=#gradient-accumulation>1.17.7 Gradient Accumulation</a></li> </ul> </li> <li><a href=#common-neural-network-architectures>1.18 Common Neural Network Architectures</a><ul> <li><a href=#convolutional-neural-network-cnn>1.18.1 Convolutional Neural Network (CNN)</a></li> <li><a href=#resnet-style-residual-block>1.18.2 ResNet-style Residual Block</a></li> <li><a href=#recurrent-neural-network-lstm>1.18.3 Recurrent Neural Network (LSTM)</a></li> <li><a href=#transformer-encoder>1.18.4 Transformer Encoder</a></li> <li><a href=#autoencoder>1.18.5 Autoencoder</a></li> </ul> </li> <li><a href=#common-issues-and-debugging>1.19 Common Issues and Debugging</a><ul> <li><a href=#debugging-tools>1.19.1 Debugging Tools</a></li> <li><a href=#common-issues-and-solutions>1.19.2 Common Issues and Solutions</a></li> </ul> </li> <li><a href=#best-practices>1.20 Best Practices</a><ul> <li><a href=#code-organization>1.20.1 Code Organization</a></li> <li><a href=#performance-optimization>1.20.2 Performance Optimization</a></li> <li><a href=#reproducibility>1.20.3 Reproducibility</a></li> <li><a href=#model-initialization>1.20.4 Model Initialization</a></li> <li><a href=#logging-and-monitoring>1.20.5 Logging and Monitoring</a></li> <li><a href=#model-deployment-checklist>1.20.6 Model Deployment Checklist</a></li> <li><a href=#development-tips>1.20.7 Development Tips</a></li> </ul> </li> <li><a href=#quick-reference>1.21 Quick Reference</a><ul> <li><a href=#essential-operations>1.21.1 Essential Operations</a></li> <li><a href=#training-template>1.21.2 Training Template</a></li> <li><a href=#common-layer-patterns>1.21.3 Common Layer Patterns</a></li> <li><a href=#useful-commands>1.21.4 Useful Commands</a></li> <li><a href=#performance-tips>1.21.5 Performance Tips</a></li> </ul> </li> </ul> </li> </ul> </div> <p>This cheat sheet provides an exhaustive overview of the PyTorch deep learning library, covering essential concepts, code snippets, and best practices for efficient model building, training, and deployment. It aims to be a one-stop reference for common tasks.</p> <h2 id=getting-started><span class="enumerate-headings-plugin enumerate-heading-plugin">1.1</span> Getting Started</h2> <h3 id=installation><span class="enumerate-headings-plugin enumerate-heading-plugin">1.1.1</span> Installation</h3> <div class=highlight><pre><span></span><code><span class=c1># CPU-only version</span>
pip<span class=w> </span>install<span class=w> </span>torch<span class=w> </span>torchvision<span class=w> </span>torchaudio

<span class=c1># CUDA 11.8 support</span>
pip<span class=w> </span>install<span class=w> </span>torch<span class=w> </span>torchvision<span class=w> </span>torchaudio<span class=w> </span>--index-url<span class=w> </span>https://download.pytorch.org/whl/cu118

<span class=c1># CUDA 12.1 support</span>
pip<span class=w> </span>install<span class=w> </span>torch<span class=w> </span>torchvision<span class=w> </span>torchaudio<span class=w> </span>--index-url<span class=w> </span>https://download.pytorch.org/whl/cu121
</code></pre></div> <p>Replace <code>cu121</code> with your CUDA version. Check the <a href=https://pytorch.org/get-started/locally/ >PyTorch website</a> for the most up-to-date installation instructions.</p> <h3 id=importing-pytorch><span class="enumerate-headings-plugin enumerate-heading-plugin">1.1.2</span> Importing PyTorch</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.optim</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>optim</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data</span><span class=w> </span><span class=kn>import</span> <span class=n>Dataset</span><span class=p>,</span> <span class=n>DataLoader</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torchvision</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torchvision.transforms</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>transforms</span>

<span class=c1># Check version</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"PyTorch version: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>__version__</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"CUDA available: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"CUDA version: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>version</span><span class=o>.</span><span class=n>cuda</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</code></pre></div> <h2 id=tensors><span class="enumerate-headings-plugin enumerate-heading-plugin">1.2</span> Tensors</h2> <h3 id=tensor-creation-flow><span class="enumerate-headings-plugin enumerate-heading-plugin">1.2.1</span> Tensor Creation Flow</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ     Tensor Creation Methods            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                                ‚îÇ
        ‚Üì                                ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  From   ‚îÇ                    ‚îÇ  From   ‚îÇ
    ‚îÇ  Data   ‚îÇ                    ‚îÇ Scratch ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                              ‚îÇ
         ‚Üì                              ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ .tensor()‚îÇ                   ‚îÇ .zeros() ‚îÇ
   ‚îÇ .from_   ‚îÇ                   ‚îÇ .ones()  ‚îÇ
   ‚îÇ  numpy() ‚îÇ                   ‚îÇ .rand()  ‚îÇ
   ‚îÇ .as_     ‚îÇ                   ‚îÇ .randn() ‚îÇ
   ‚îÇ  tensor()‚îÇ                   ‚îÇ .empty() ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h3 id=creating-tensors><span class="enumerate-headings-plugin enumerate-heading-plugin">1.2.2</span> Creating Tensors</h3> <p>From a List:</p> <div class=highlight><pre><span></span><code><span class=c1># Direct creation from list</span>
<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>]</span>
<span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>  <span class=c1># tensor([1, 2, 3, 4, 5])</span>

<span class=c1># 2D tensor</span>
<span class=n>data_2d</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>]]</span>
<span class=n>tensor_2d</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>data_2d</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>tensor_2d</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([2, 3])</span>
</code></pre></div> <p>From a NumPy Array:</p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Convert NumPy to tensor (shares memory)</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
<span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=c1># Changes in NumPy array affect tensor</span>
<span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>100</span>
<span class=nb>print</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>  <span class=c1># tensor([100, 2, 3, 4, 5])</span>

<span class=c1># Create independent copy</span>
<span class=n>tensor_copy</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</code></pre></div> <p>Zeros, Ones, and Filled Tensors:</p> <div class=highlight><pre><span></span><code><span class=c1># Create tensor filled with zeros</span>
<span class=n>zeros</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>zeros</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([3, 4])</span>

<span class=c1># Create tensor filled with ones</span>
<span class=n>ones</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>

<span class=c1># Create tensor filled with specific value</span>
<span class=n>full</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>full</span><span class=p>((</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>),</span> <span class=n>fill_value</span><span class=o>=</span><span class=mi>7</span><span class=p>)</span>

<span class=c1># Create tensor like another tensor</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>]])</span>
<span class=n>zeros_like</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
<span class=n>ones_like</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

<span class=c1># Empty tensor (uninitialized memory)</span>
<span class=n>empty</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</code></pre></div> <p>Ranges:</p> <div class=highlight><pre><span></span><code><span class=c1># Create range of integers</span>
<span class=n>arange</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>start</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>step</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>arange</span><span class=p>)</span>  <span class=c1># tensor([0, 2, 4, 6, 8])</span>

<span class=c1># Create linearly spaced values</span>
<span class=n>linspace</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>start</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>linspace</span><span class=p>)</span>  <span class=c1># tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])</span>

<span class=c1># Logarithmically spaced values</span>
<span class=n>logspace</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>logspace</span><span class=p>(</span><span class=n>start</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>logspace</span><span class=p>)</span>  <span class=c1># tensor([1., 3.1623, 10., 31.6228, 100.])</span>
</code></pre></div> <p>Random Number Generation:</p> <div class=highlight><pre><span></span><code><span class=c1># Set random seed for reproducibility</span>
<span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=c1># Uniform distribution [0, 1)</span>
<span class=n>rand</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>

<span class=c1># Standard normal distribution (mean=0, std=1)</span>
<span class=n>randn</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>

<span class=c1># Random integers in range [low, high)</span>
<span class=n>randint</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>low</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>high</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>

<span class=c1># Random permutation</span>
<span class=n>perm</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randperm</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>  <span class=c1># tensor([2, 5, 1, 9, 0, 3, 7, 4, 6, 8])</span>

<span class=c1># Random sampling from normal distribution</span>
<span class=n>normal</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</code></pre></div> <h3 id=tensor-attributes><span class="enumerate-headings-plugin enumerate-heading-plugin">1.2.3</span> Tensor Attributes</h3> <div class=highlight><pre><span></span><code><span class=n>tensor</span><span class=o>.</span><span class=n>shape</span>       <span class=c1># Shape of the tensor</span>
<span class=n>tensor</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>      <span class=c1># Same as shape</span>
<span class=n>tensor</span><span class=o>.</span><span class=n>ndim</span>        <span class=c1># Number of dimensions</span>
<span class=n>tensor</span><span class=o>.</span><span class=n>dtype</span>       <span class=c1># Data type of the tensor</span>
<span class=n>tensor</span><span class=o>.</span><span class=n>device</span>      <span class=c1># Device where the tensor is stored (CPU or GPU)</span>
<span class=n>tensor</span><span class=o>.</span><span class=n>requires_grad</span> <span class=c1># Whether gradients are tracked</span>
<span class=n>tensor</span><span class=o>.</span><span class=n>layout</span>      <span class=c1># Memory layout (torch.strided, torch.sparse_coo)</span>
</code></pre></div> <h3 id=tensor-operations><span class="enumerate-headings-plugin enumerate-heading-plugin">1.2.4</span> Tensor Operations</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ    Tensor Operation Types        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                        ‚îÇ
         ‚Üì                        ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇArithmetic‚îÇ            ‚îÇ Shape   ‚îÇ
    ‚îÇOperations‚îÇ            ‚îÇOperations‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ +, -, *,‚îÇ             ‚îÇ reshape ‚îÇ
    ‚îÇ /, **, @‚îÇ             ‚îÇ view    ‚îÇ
    ‚îÇ add_()  ‚îÇ             ‚îÇ squeeze ‚îÇ
    ‚îÇ sub_()  ‚îÇ             ‚îÇ unsqueeze‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p>Arithmetic Operations:</p> <div class=highlight><pre><span></span><code><span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>])</span>
<span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>4.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>6.0</span><span class=p>])</span>

<span class=c1># Element-wise operations</span>
<span class=n>c</span> <span class=o>=</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span>       <span class=c1># tensor([5., 7., 9.])</span>
<span class=n>d</span> <span class=o>=</span> <span class=n>a</span> <span class=o>-</span> <span class=n>b</span>       <span class=c1># tensor([-3., -3., -3.])</span>
<span class=n>e</span> <span class=o>=</span> <span class=n>a</span> <span class=o>*</span> <span class=n>b</span>       <span class=c1># tensor([4., 10., 18.])</span>
<span class=n>f</span> <span class=o>=</span> <span class=n>a</span> <span class=o>/</span> <span class=n>b</span>       <span class=c1># tensor([0.25, 0.4, 0.5])</span>
<span class=n>g</span> <span class=o>=</span> <span class=n>a</span> <span class=o>**</span> <span class=mi>2</span>      <span class=c1># tensor([1., 4., 9.])</span>

<span class=c1># In-place operations (modify original tensor)</span>
<span class=n>a</span><span class=o>.</span><span class=n>add_</span><span class=p>(</span><span class=n>b</span><span class=p>)</span>       <span class=c1># a = tensor([5., 7., 9.])</span>
<span class=n>a</span><span class=o>.</span><span class=n>sub_</span><span class=p>(</span><span class=n>b</span><span class=p>)</span>       <span class=c1># Subtract in-place</span>
<span class=n>a</span><span class=o>.</span><span class=n>mul_</span><span class=p>(</span><span class=n>b</span><span class=p>)</span>       <span class=c1># Multiply in-place</span>
<span class=n>a</span><span class=o>.</span><span class=n>div_</span><span class=p>(</span><span class=n>b</span><span class=p>)</span>       <span class=c1># Divide in-place</span>

<span class=c1># Functional form</span>
<span class=n>result</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
<span class=n>result</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>

<span class=c1># Scalar operations</span>
<span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>])</span>
<span class=n>scaled</span> <span class=o>=</span> <span class=n>a</span> <span class=o>*</span> <span class=mi>2</span>  <span class=c1># tensor([2., 4., 6.])</span>
<span class=n>shifted</span> <span class=o>=</span> <span class=n>a</span> <span class=o>+</span> <span class=mi>5</span>  <span class=c1># tensor([6., 7., 8.])</span>
</code></pre></div> <p>Slicing and Indexing:</p> <div class=highlight><pre><span></span><code><span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>]])</span>

<span class=c1># Basic indexing</span>
<span class=n>first_row</span> <span class=o>=</span> <span class=n>tensor</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>           <span class=c1># tensor([1, 2, 3])</span>
<span class=n>second_col</span> <span class=o>=</span> <span class=n>tensor</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span>       <span class=c1># tensor([2, 5])</span>
<span class=n>element</span> <span class=o>=</span> <span class=n>tensor</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>          <span class=c1># tensor(2)</span>

<span class=c1># Slicing</span>
<span class=n>sliced</span> <span class=o>=</span> <span class=n>tensor</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>:</span><span class=mi>3</span><span class=p>]</span>       <span class=c1># tensor([[2, 3], [5, 6]])</span>

<span class=c1># Boolean indexing</span>
<span class=n>mask</span> <span class=o>=</span> <span class=n>tensor</span> <span class=o>&gt;</span> <span class=mi>3</span>
<span class=n>filtered</span> <span class=o>=</span> <span class=n>tensor</span><span class=p>[</span><span class=n>mask</span><span class=p>]</span>         <span class=c1># tensor([4, 5, 6])</span>

<span class=c1># Advanced indexing</span>
<span class=n>indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>
<span class=n>selected</span> <span class=o>=</span> <span class=n>tensor</span><span class=p>[:,</span> <span class=n>indices</span><span class=p>]</span>   <span class=c1># Select columns</span>

<span class=c1># Fancy indexing</span>
<span class=n>rows</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
<span class=n>cols</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span>
<span class=n>elements</span> <span class=o>=</span> <span class=n>tensor</span><span class=p>[</span><span class=n>rows</span><span class=p>,</span> <span class=n>cols</span><span class=p>]</span>   <span class=c1># tensor([2, 6])</span>
</code></pre></div> <p>Reshaping:</p> <div class=highlight><pre><span></span><code><span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>12</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span>  <span class=c1># tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])</span>

<span class=c1># Reshape to 2D</span>
<span class=n>reshaped</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>reshaped</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([3, 4])</span>

<span class=c1># View (shares memory with original)</span>
<span class=n>viewed</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>  <span class=c1># Same as reshape but requires contiguous tensor</span>

<span class=c1># Transpose (2D tensors)</span>
<span class=n>tensor_2d</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>]])</span>
<span class=n>transposed</span> <span class=o>=</span> <span class=n>tensor_2d</span><span class=o>.</span><span class=n>T</span>
<span class=nb>print</span><span class=p>(</span><span class=n>transposed</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([3, 2])</span>

<span class=c1># Permute dimensions (generalized transpose)</span>
<span class=n>tensor_3d</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=n>permuted</span> <span class=o>=</span> <span class=n>tensor_3d</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># New shape: (4, 2, 3)</span>

<span class=c1># Flatten to 1D</span>
<span class=n>flattened</span> <span class=o>=</span> <span class=n>tensor_2d</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=n>flattened</span><span class=p>)</span>  <span class=c1># tensor([1, 2, 3, 4, 5, 6])</span>

<span class=c1># Squeeze (remove dimensions of size 1)</span>
<span class=n>tensor_with_ones</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=n>squeezed</span> <span class=o>=</span> <span class=n>tensor_with_ones</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span>  <span class=c1># Shape: (3, 4)</span>

<span class=c1># Unsqueeze (add dimension of size 1)</span>
<span class=n>tensor_1d</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>])</span>
<span class=n>unsqueezed</span> <span class=o>=</span> <span class=n>tensor_1d</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Shape: (1, 3)</span>
<span class=n>unsqueezed</span> <span class=o>=</span> <span class=n>tensor_1d</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># Shape: (3, 1)</span>

<span class=c1># Contiguous (ensure tensor is contiguous in memory)</span>
<span class=n>contiguous</span> <span class=o>=</span> <span class=n>transposed</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</code></pre></div> <p>Concatenation and Stacking:</p> <div class=highlight><pre><span></span><code><span class=n>tensor1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>]])</span>
<span class=n>tensor2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>]])</span>

<span class=c1># Concatenate along existing dimension</span>
<span class=n>cat_rows</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>tensor1</span><span class=p>,</span> <span class=n>tensor2</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Shape: (4, 2)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>cat_rows</span><span class=p>)</span>
<span class=c1># tensor([[1, 2],</span>
<span class=c1>#         [3, 4],</span>
<span class=c1>#         [5, 6],</span>
<span class=c1>#         [7, 8]])</span>

<span class=n>cat_cols</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>tensor1</span><span class=p>,</span> <span class=n>tensor2</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># Shape: (2, 4)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>cat_cols</span><span class=p>)</span>
<span class=c1># tensor([[1, 2, 5, 6],</span>
<span class=c1>#         [3, 4, 7, 8]])</span>

<span class=c1># Stack creates new dimension</span>
<span class=n>stacked</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>tensor1</span><span class=p>,</span> <span class=n>tensor2</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Shape: (2, 2, 2)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>stacked</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([2, 2, 2])</span>

<span class=c1># Split tensor into chunks</span>
<span class=n>tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>10</span><span class=p>)</span>
<span class=n>chunks</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>chunk</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># Split into 3 chunks</span>
<span class=nb>print</span><span class=p>(</span><span class=n>chunks</span><span class=p>)</span>  <span class=c1># (tensor([0, 1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9]))</span>

<span class=c1># Split with specific sizes</span>
<span class=n>split</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>  <span class=c1># Sizes: 2, 3, 5</span>
</code></pre></div> <p>Matrix Multiplication:</p> <div class=highlight><pre><span></span><code><span class=c1># Matrix multiplication</span>
<span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>

<span class=c1># Three equivalent ways</span>
<span class=n>c</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>     <span class=c1># Functional form</span>
<span class=n>d</span> <span class=o>=</span> <span class=n>a</span> <span class=o>@</span> <span class=n>b</span>                  <span class=c1># Operator form (preferred)</span>
<span class=n>e</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mm</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>         <span class=c1># Explicit matrix multiplication</span>

<span class=nb>print</span><span class=p>(</span><span class=n>c</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># torch.Size([3, 5])</span>

<span class=c1># Batch matrix multiplication</span>
<span class=n>batch1</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>  <span class=c1># 10 matrices of shape (3, 4)</span>
<span class=n>batch2</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>  <span class=c1># 10 matrices of shape (4, 5)</span>
<span class=n>batch_result</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bmm</span><span class=p>(</span><span class=n>batch1</span><span class=p>,</span> <span class=n>batch2</span><span class=p>)</span>  <span class=c1># Shape: (10, 3, 5)</span>

<span class=c1># Element-wise multiplication (Hadamard product)</span>
<span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>])</span>
<span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span>
<span class=n>c</span> <span class=o>=</span> <span class=n>a</span> <span class=o>*</span> <span class=n>b</span>  <span class=c1># tensor([4, 10, 18])</span>

<span class=c1># Dot product (1D tensors)</span>
<span class=n>dot_product</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>  <span class=c1># tensor(32)</span>

<span class=c1># Outer product</span>
<span class=n>outer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>outer</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>  <span class=c1># Shape: (3, 3)</span>

<span class=c1># Matrix-vector multiplication</span>
<span class=n>matrix</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=n>vector</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>4</span><span class=p>)</span>
<span class=n>result</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>mv</span><span class=p>(</span><span class=n>matrix</span><span class=p>,</span> <span class=n>vector</span><span class=p>)</span>  <span class=c1># Shape: (3,)</span>
</code></pre></div> <h3 id=data-types><span class="enumerate-headings-plugin enumerate-heading-plugin">1.2.5</span> Data Types</h3> <ul> <li><code>torch.float32</code> or <code>torch.float</code>: 32-bit floating point</li> <li><code>torch.float64</code> or <code>torch.double</code>: 64-bit floating point</li> <li><code>torch.float16</code> or <code>torch.half</code>: 16-bit floating point</li> <li><code>torch.bfloat16</code>: BFloat16 floating point (useful for mixed precision)</li> <li><code>torch.int8</code>: 8-bit integer (signed)</li> <li><code>torch.int16</code> or <code>torch.short</code>: 16-bit integer (signed)</li> <li><code>torch.int32</code> or <code>torch.int</code>: 32-bit integer (signed)</li> <li><code>torch.int64</code> or <code>torch.long</code>: 64-bit integer (signed)</li> <li><code>torch.uint8</code>: 8-bit integer (unsigned)</li> <li><code>torch.bool</code>: Boolean</li> </ul> <h3 id=device-management><span class="enumerate-headings-plugin enumerate-heading-plugin">1.2.6</span> Device Management</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Device Management     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ             ‚îÇ
        ‚Üì             ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  CPU  ‚îÇ    ‚îÇ  GPU   ‚îÇ
    ‚îÇ tensor‚îÇ‚Üê‚îÄ‚îÄ‚Üí‚îÇ tensor ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ             ‚îÇ
        ‚Üì             ‚Üì
    .cpu()        .cuda()
    .to('cpu')    .to('cuda')
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># Check device availability</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"CUDA available: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"CUDA device count: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"CUDA device name: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Set default device</span>
<span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>"cuda"</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>"cpu"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Using device: </span><span class=si>{</span><span class=n>device</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Create tensor on specific device</span>
<span class=n>tensor_gpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>tensor_gpu</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>  <span class=c1># cuda:0 or cpu</span>

<span class=c1># Move tensor between devices</span>
<span class=n>tensor_cpu</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=n>tensor_gpu</span> <span class=o>=</span> <span class=n>tensor_cpu</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>      <span class=c1># Move to GPU</span>
<span class=n>tensor_gpu</span> <span class=o>=</span> <span class=n>tensor_cpu</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>          <span class=c1># Alternative</span>
<span class=n>tensor_cpu_back</span> <span class=o>=</span> <span class=n>tensor_gpu</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span>      <span class=c1># Move back to CPU</span>

<span class=c1># Check tensor device</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Tensor is on CUDA: </span><span class=si>{</span><span class=n>tensor_gpu</span><span class=o>.</span><span class=n>is_cuda</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Multiple GPU support</span>
<span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>
    <span class=n>tensor_gpu0</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>'cuda:0'</span><span class=p>)</span>
    <span class=n>tensor_gpu1</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>'cuda:1'</span><span class=p>)</span>

<span class=c1># Set active GPU</span>
<span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>set_device</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Use GPU 0</span>
</code></pre></div> <h2 id=neural-networks><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3</span> Neural Networks</h2> <h3 id=neural-network-architecture><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.1</span> Neural Network Architecture</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Input   ‚îÇ
    ‚îÇ  Layer   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Hidden  ‚îÇ
    ‚îÇ  Layer 1 ‚îÇ‚îÄ‚îÄ‚Üí Activation (ReLU)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Hidden  ‚îÇ
    ‚îÇ  Layer 2 ‚îÇ‚îÄ‚îÄ‚Üí Activation (ReLU)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Output  ‚îÇ
    ‚îÇ  Layer   ‚îÇ‚îÄ‚îÄ‚Üí Softmax/Sigmoid
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h3 id=defining-a-model><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.2</span> Defining a Model</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>

<span class=c1># Simple feedforward network</span>
<span class=k>class</span><span class=w> </span><span class=nc>SimpleNet</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_size</span><span class=p>,</span> <span class=n>hidden_size</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>SimpleNet</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_size</span><span class=p>,</span> <span class=n>hidden_size</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_size</span><span class=p>,</span> <span class=n>hidden_size</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_size</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.2</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Flatten input if needed</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc3</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># No activation for logits</span>
        <span class=k>return</span> <span class=n>x</span>

<span class=c1># Instantiate model</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNet</span><span class=p>(</span><span class=n>input_size</span><span class=o>=</span><span class=mi>784</span><span class=p>,</span> <span class=n>hidden_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>

<span class=c1># Count parameters</span>
<span class=n>total_params</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>
<span class=n>trainable_params</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>()</span> <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Total parameters: </span><span class=si>{</span><span class=n>total_params</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Trainable parameters: </span><span class=si>{</span><span class=n>trainable_params</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</code></pre></div> <h3 id=layers><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.3</span> Layers</h3> <ul> <li><code>nn.Linear</code>: Fully connected layer.</li> <li><code>nn.Conv1d</code>: 1D convolution layer.</li> <li><code>nn.Conv2d</code>: 2D convolution layer.</li> <li><code>nn.Conv3d</code>: 3D convolution layer.</li> <li><code>nn.ConvTranspose2d</code>: Transposed convolution layer (deconvolution).</li> <li><code>nn.MaxPool1d</code>, <code>nn.MaxPool2d</code>, <code>nn.MaxPool3d</code>: Max pooling layers.</li> <li><code>nn.AvgPool1d</code>, <code>nn.AvgPool2d</code>, <code>nn.AvgPool3d</code>: Average pooling layers.</li> <li><code>nn.AdaptiveAvgPool2d</code>: Adaptive average pooling layer.</li> <li><code>nn.ReLU</code>: ReLU activation function.</li> <li><code>nn.Sigmoid</code>: Sigmoid activation function.</li> <li><code>nn.Tanh</code>: Tanh activation function.</li> <li><code>nn.BatchNorm1d</code>, <code>nn.BatchNorm2d</code>, <code>nn.BatchNorm3d</code>: Batch normalization layers.</li> <li><code>nn.LayerNorm</code>: Layer normalization layer.</li> <li><code>nn.Dropout</code>: Dropout layer.</li> <li><code>nn.Embedding</code>: Embedding layer.</li> <li><code>nn.LSTM</code>: LSTM layer.</li> <li><code>nn.GRU</code>: GRU layer.</li> <li><code>nn.Transformer</code>: Transformer layer.</li> <li><code>nn.TransformerEncoder</code>, <code>nn.TransformerDecoder</code>: Transformer encoder and decoder layers.</li> <li><code>nn.MultiheadAttention</code>: Multi-head attention layer.</li> </ul> <h3 id=activation-functions><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.4</span> Activation Functions</h3> <ul> <li><code>torch.relu</code>: Rectified Linear Unit.</li> <li><code>torch.sigmoid</code>: Sigmoid function.</li> <li><code>torch.tanh</code>: Hyperbolic tangent function.</li> <li><code>torch.softmax</code>: Softmax function (for multi-class classification).</li> <li><code>torch.elu</code>: Exponential Linear Unit.</li> <li><code>torch.selu</code>: Scaled Exponential Linear Unit.</li> <li><code>torch.leaky_relu</code>: Leaky Rectified Linear Unit.</li> <li><code>torch.gelu</code>: Gaussian Error Linear Unit (GELU).</li> <li><code>torch.silu</code>: SiLU (Sigmoid Linear Unit) or Swish.</li> </ul> <h3 id=loss-functions><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.5</span> Loss Functions</h3> <ul> <li><code>nn.CrossEntropyLoss</code>: Cross-entropy loss (for multi-class classification).</li> <li><code>nn.BCELoss</code>: Binary cross-entropy loss (for binary classification).</li> <li><code>nn.BCEWithLogitsLoss</code>: Binary cross-entropy with logits (more stable).</li> <li><code>nn.MSELoss</code>: Mean squared error loss (for regression).</li> <li><code>nn.L1Loss</code>: Mean absolute error loss (for regression).</li> <li><code>nn.SmoothL1Loss</code>: Huber loss (for robust regression).</li> <li><code>nn.CTCLoss</code>: Connectionist Temporal Classification loss (for sequence labeling).</li> <li><code>nn.TripletMarginLoss</code>: Triplet margin loss (for learning embeddings).</li> <li><code>nn.CosineEmbeddingLoss</code>: Cosine embedding loss.</li> </ul> <h3 id=optimizers><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.6</span> Optimizers</h3> <ul> <li><code>optim.SGD</code>: Stochastic Gradient Descent.</li> <li><code>optim.Adam</code>: Adaptive Moment Estimation.</li> <li><code>optim.RMSprop</code>: Root Mean Square Propagation.</li> <li><code>optim.Adagrad</code>: Adaptive Gradient Algorithm.</li> <li><code>optim.Adadelta</code>: Adaptive Delta.</li> <li><code>optim.AdamW</code>: Adam with weight decay regularization.</li> <li><code>optim.SparseAdam</code>: Adam optimizer for sparse tensors.</li> </ul> <h3 id=optimizer-configuration><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.7</span> Optimizer Configuration</h3> <div class=highlight><pre><span></span><code><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>betas</span><span class=o>=</span><span class=p>(</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.999</span><span class=p>),</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-08</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>amsgrad</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</code></pre></div> <h3 id=learning-rate-schedulers><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.8</span> Learning Rate Schedulers</h3> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>torch.optim.lr_scheduler</span><span class=w> </span><span class=kn>import</span> <span class=n>StepLR</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>StepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>step_size</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>

<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>100</span><span class=p>):</span>
    <span class=c1># Training loop</span>
    <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</code></pre></div> <p>Common Schedulers:</p> <ul> <li><code>StepLR</code>: Decays the learning rate by a factor every few steps.</li> <li><code>MultiStepLR</code>: Decays the learning rate at specified milestones.</li> <li><code>ExponentialLR</code>: Decays the learning rate exponentially.</li> <li><code>CosineAnnealingLR</code>: Uses a cosine annealing schedule.</li> <li><code>ReduceLROnPlateau</code>: Reduces the learning rate when a metric has stopped improving.</li> <li><code>CyclicLR</code>: Sets the learning rate cyclically.</li> <li><code>OneCycleLR</code>: Sets the learning rate according to the 1cycle policy.</li> <li><code>CosineAnnealingWarmRestarts</code>: Cosine annealing with warm restarts.</li> </ul> <h3 id=metrics><span class="enumerate-headings-plugin enumerate-heading-plugin">1.3.9</span> Metrics</h3> <ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1-Score</li> <li>AUC (Area Under the Curve)</li> <li>IoU (Intersection over Union)</li> </ul> <h2 id=training><span class="enumerate-headings-plugin enumerate-heading-plugin">1.4</span> Training</h2> <h3 id=training-pipeline><span class="enumerate-headings-plugin enumerate-heading-plugin">1.4.1</span> Training Pipeline</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         Training Pipeline               ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  1. Load Data (DataLoader)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  2. Zero Gradients            ‚îÇ
    ‚îÇ     optimizer.zero_grad()     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  3. Forward Pass              ‚îÇ
    ‚îÇ     outputs = model(inputs)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  4. Compute Loss              ‚îÇ
    ‚îÇ     loss = criterion(...)     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  5. Backward Pass             ‚îÇ
    ‚îÇ     loss.backward()           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  6. Update Weights            ‚îÇ
    ‚îÇ     optimizer.step()          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚îî‚îÄ‚îÄ‚Üí Repeat for all batches
</code></pre></div> <h3 id=training-loop><span class="enumerate-headings-plugin enumerate-heading-plugin">1.4.2</span> Training Loop</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.optim</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>optim</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data</span><span class=w> </span><span class=kn>import</span> <span class=n>DataLoader</span><span class=p>,</span> <span class=n>TensorDataset</span>

<span class=c1># Sample data</span>
<span class=n>X_train</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>784</span><span class=p>)</span>
<span class=n>y_train</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=p>(</span><span class=mi>1000</span><span class=p>,))</span>
<span class=n>X_val</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>200</span><span class=p>,</span> <span class=mi>784</span><span class=p>)</span>
<span class=n>y_val</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=p>(</span><span class=mi>200</span><span class=p>,))</span>

<span class=c1># Create datasets and dataloaders</span>
<span class=n>train_dataset</span> <span class=o>=</span> <span class=n>TensorDataset</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>
<span class=n>val_dataset</span> <span class=o>=</span> <span class=n>TensorDataset</span><span class=p>(</span><span class=n>X_val</span><span class=p>,</span> <span class=n>y_val</span><span class=p>)</span>
<span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>val_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>val_dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=c1># Model, loss, optimizer</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNet</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>"cuda"</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>"cpu"</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
<span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>

<span class=c1># Training loop</span>
<span class=n>num_epochs</span> <span class=o>=</span> <span class=mi>10</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=c1># Training phase</span>
    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
    <span class=n>train_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
    <span class=n>train_correct</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=n>train_total</span> <span class=o>=</span> <span class=mi>0</span>

    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
        <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

        <span class=c1># Zero the gradients</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Backward pass and optimization</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

        <span class=c1># Statistics</span>
        <span class=n>train_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span> <span class=o>*</span> <span class=n>inputs</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
        <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
        <span class=n>train_total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
        <span class=n>train_correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>

    <span class=c1># Calculate average training metrics</span>
    <span class=n>train_loss</span> <span class=o>=</span> <span class=n>train_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span>
    <span class=n>train_acc</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>train_correct</span> <span class=o>/</span> <span class=n>train_total</span>

    <span class=c1># Validation phase</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=n>val_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
    <span class=n>val_correct</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=n>val_total</span> <span class=o>=</span> <span class=mi>0</span>

    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>val_loader</span><span class=p>:</span>
            <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

            <span class=n>val_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span> <span class=o>*</span> <span class=n>inputs</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
            <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
            <span class=n>val_total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
            <span class=n>val_correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>

    <span class=n>val_loss</span> <span class=o>=</span> <span class=n>val_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>val_loader</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span>
    <span class=n>val_acc</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>val_correct</span> <span class=o>/</span> <span class=n>val_total</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>'Epoch [</span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s1>] '</span>
          <span class=sa>f</span><span class=s1>'Train Loss: </span><span class=si>{</span><span class=n>train_loss</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>, Train Acc: </span><span class=si>{</span><span class=n>train_acc</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>% | '</span>
          <span class=sa>f</span><span class=s1>'Val Loss: </span><span class=si>{</span><span class=n>val_loss</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>, Val Acc: </span><span class=si>{</span><span class=n>val_acc</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>%'</span><span class=p>)</span>
</code></pre></div> <h3 id=custom-datasets-and-dataloaders><span class="enumerate-headings-plugin enumerate-heading-plugin">1.4.3</span> Custom Datasets and DataLoaders</h3> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data</span><span class=w> </span><span class=kn>import</span> <span class=n>Dataset</span><span class=p>,</span> <span class=n>DataLoader</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>

<span class=c1># Custom Dataset</span>
<span class=k>class</span><span class=w> </span><span class=nc>CustomDataset</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        Args:</span>
<span class=sd>            data: Input data (numpy array or list)</span>
<span class=sd>            labels: Target labels (numpy array or list)</span>
<span class=sd>            transform: Optional transform to be applied</span>
<span class=sd>        """</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>data</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>FloatTensor</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>labels</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>LongTensor</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>transform</span> <span class=o>=</span> <span class=n>transform</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
        <span class=n>sample</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
        <span class=n>label</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>labels</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>

        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>transform</span><span class=p>:</span>
            <span class=n>sample</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>sample</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>sample</span><span class=p>,</span> <span class=n>label</span>

<span class=c1># CSV Dataset example</span>
<span class=k>class</span><span class=w> </span><span class=nc>CSVDataset</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>csv_file</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>csv_file</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>transform</span> <span class=o>=</span> <span class=n>transform</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__len__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
        <span class=c1># Assuming last column is label</span>
        <span class=n>features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>'float32'</span><span class=p>)</span>
        <span class=n>label</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span>

        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>transform</span><span class=p>:</span>
            <span class=n>features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>features</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>FloatTensor</span><span class=p>(</span><span class=n>features</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>LongTensor</span><span class=p>([</span><span class=n>label</span><span class=p>])</span>

<span class=c1># Create dataset and dataloader</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>CustomDataset</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

<span class=c1># DataLoader parameters</span>
<span class=n>dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>dataset</span><span class=p>,</span>
    <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>         <span class=c1># Number of samples per batch</span>
    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>          <span class=c1># Shuffle data at every epoch</span>
    <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>         <span class=c1># Number of subprocesses for data loading</span>
    <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>       <span class=c1># Pin memory for faster data transfer to CUDA</span>
    <span class=n>drop_last</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>       <span class=c1># Drop last incomplete batch</span>
    <span class=n>persistent_workers</span><span class=o>=</span><span class=kc>True</span> <span class=c1># Keep workers alive between epochs</span>
<span class=p>)</span>

<span class=c1># Iterate through batches</span>
<span class=k>for</span> <span class=n>batch_idx</span><span class=p>,</span> <span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Batch </span><span class=si>{</span><span class=n>batch_idx</span><span class=si>}</span><span class=s2>: inputs shape </span><span class=si>{</span><span class=n>inputs</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>, labels shape </span><span class=si>{</span><span class=n>labels</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</code></pre></div> <h3 id=transforms><span class="enumerate-headings-plugin enumerate-heading-plugin">1.4.4</span> Transforms</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torchvision.transforms</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>transforms</span>

<span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>Resize</span><span class=p>((</span><span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>((</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>),</span> <span class=p>(</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>))</span>
<span class=p>])</span>

<span class=n>trainset</span> <span class=o>=</span> <span class=n>torchvision</span><span class=o>.</span><span class=n>datasets</span><span class=o>.</span><span class=n>ImageFolder</span><span class=p>(</span><span class=n>root</span><span class=o>=</span><span class=s1>'./data/train'</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>transform</span><span class=p>)</span>
<span class=n>trainloader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span><span class=n>trainset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
                                          <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <p>Common Augmentations:</p> <ul> <li><code>transforms.RandomHorizontalFlip</code>: Horizontally flips the image.</li> <li><code>transforms.RandomVerticalFlip</code>: Vertically flips the image.</li> <li><code>transforms.RandomRotation</code>: Rotates the image by a random angle.</li> <li><code>transforms.RandomAffine</code>: Applies random affine transformations.</li> <li><code>transforms.RandomPerspective</code>: Performs perspective transformation of the given image randomly with a given magnitude.</li> <li><code>transforms.RandomCrop</code>: Crops a random portion of the image.</li> <li><code>transforms.CenterCrop</code>: Crops the image from the center.</li> <li><code>transforms.ColorJitter</code>: Randomly changes the brightness, contrast, saturation, and hue of an image.</li> <li><code>transforms.RandomGrayscale</code>: Converts the image to grayscale with a certain probability.</li> <li><code>transforms.RandomErasing</code>: Randomly erases a rectangular region in the image.</li> </ul> <h3 id=mixed-precision-training><span class="enumerate-headings-plugin enumerate-heading-plugin">1.4.5</span> Mixed Precision Training</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Mixed Precision Training Flow    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Forward Pass (FP16)       ‚îÇ
    ‚îÇ  with autocast()           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Compute Loss (FP16)       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Scale Loss                ‚îÇ
    ‚îÇ  scaler.scale(loss)        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Backward Pass (FP32)      ‚îÇ
    ‚îÇ  scaled_loss.backward()    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Unscale &amp; Update          ‚îÇ
    ‚îÇ  scaler.step(optimizer)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.cuda.amp</span><span class=w> </span><span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>

<span class=c1># Initialize GradScaler</span>
<span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>

<span class=c1># Training loop with mixed precision</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
        <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Forward pass with autocast</span>
        <span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Backward pass with scaled gradients</span>
        <span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Unscale gradients and perform optimizer step</span>
        <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>

        <span class=c1># Update scaler for next iteration</span>
        <span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>

<span class=c1># Benefits:</span>
<span class=c1># - 2-3x faster training</span>
<span class=c1># - ~50% memory reduction</span>
<span class=c1># - Maintains model accuracy</span>
</code></pre></div> <h2 id=evaluation><span class="enumerate-headings-plugin enumerate-heading-plugin">1.5</span> Evaluation</h2> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Evaluation Mode          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  model.eval()   ‚îÇ‚îÄ‚îÄ‚Üí Disable dropout
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     Freeze batch norm
             ‚îÇ
             ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  torch.no_grad()    ‚îÇ‚îÄ‚îÄ‚Üí Disable gradient
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     computation
             ‚îÇ
             ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Forward Pass       ‚îÇ
    ‚îÇ  Compute Metrics    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>classification_report</span><span class=p>,</span> <span class=n>confusion_matrix</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>def</span><span class=w> </span><span class=nf>evaluate_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Comprehensive model evaluation"""</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>

    <span class=n>all_preds</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=n>all_labels</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=n>total_loss</span> <span class=o>=</span> <span class=mf>0.0</span>

    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
            <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

            <span class=c1># Forward pass</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

            <span class=c1># Get predictions</span>
            <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

            <span class=c1># Store results</span>
            <span class=n>all_preds</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>predicted</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
            <span class=n>all_labels</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>labels</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
            <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span> <span class=o>*</span> <span class=n>inputs</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

    <span class=c1># Calculate metrics</span>
    <span class=n>avg_loss</span> <span class=o>=</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>test_loader</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span>
    <span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>all_preds</span><span class=p>)</span> <span class=o>==</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>all_labels</span><span class=p>))</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>all_labels</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Test Loss: </span><span class=si>{</span><span class=n>avg_loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Test Accuracy: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%"</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Classification Report:"</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>all_labels</span><span class=p>,</span> <span class=n>all_preds</span><span class=p>))</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Confusion Matrix:"</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>confusion_matrix</span><span class=p>(</span><span class=n>all_labels</span><span class=p>,</span> <span class=n>all_preds</span><span class=p>))</span>

    <span class=k>return</span> <span class=n>accuracy</span><span class=p>,</span> <span class=n>avg_loss</span>

<span class=c1># Quick evaluation</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
<span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
<span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
    <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
        <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
        <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
        <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
        <span class=n>correct</span> <span class=o>+=</span> <span class=p>(</span><span class=n>predicted</span> <span class=o>==</span> <span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>

<span class=n>accuracy</span> <span class=o>=</span> <span class=mi>100</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>'Test Accuracy: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>%'</span><span class=p>)</span>
</code></pre></div> <h2 id=prediction-and-inference><span class="enumerate-headings-plugin enumerate-heading-plugin">1.6</span> Prediction and Inference</h2> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>

<span class=c1># Single prediction</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
    <span class=c1># Prepare input</span>
    <span class=n>input_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

    <span class=c1># Get prediction</span>
    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>input_tensor</span><span class=p>)</span>

    <span class=c1># For classification</span>
    <span class=n>probabilities</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>confidence</span><span class=p>,</span> <span class=n>predicted_class</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>probabilities</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>'Predicted class: </span><span class=si>{</span><span class=n>predicted_class</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>}</span><span class=s1>'</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>'Confidence: </span><span class=si>{</span><span class=n>confidence</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>'</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>'All probabilities: </span><span class=si>{</span><span class=n>probabilities</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span><span class=si>}</span><span class=s1>'</span><span class=p>)</span>

<span class=c1># Batch prediction</span>
<span class=k>def</span><span class=w> </span><span class=nf>predict_batch</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Make predictions for a batch of inputs"""</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=n>inputs</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>probabilities</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
        <span class=n>confidences</span><span class=p>,</span> <span class=n>predictions</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>probabilities</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>predictions</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>(),</span> <span class=n>confidences</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>

<span class=c1># Example usage</span>
<span class=n>batch_inputs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span>
<span class=n>predictions</span><span class=p>,</span> <span class=n>confidences</span> <span class=o>=</span> <span class=n>predict_batch</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>batch_inputs</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span>

<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>pred</span><span class=p>,</span> <span class=n>conf</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>confidences</span><span class=p>)):</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Sample </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>: Class </span><span class=si>{</span><span class=n>pred</span><span class=si>}</span><span class=s2>, Confidence </span><span class=si>{</span><span class=n>conf</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Top-k predictions</span>
<span class=k>def</span><span class=w> </span><span class=nf>get_top_k_predictions</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_tensor</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Get top-k predictions with probabilities"""</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>input_tensor</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>))</span>
        <span class=n>probabilities</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
        <span class=n>top_probs</span><span class=p>,</span> <span class=n>top_classes</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>probabilities</span><span class=p>,</span> <span class=n>k</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>top_classes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>(),</span> <span class=n>top_probs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>

<span class=c1># Usage</span>
<span class=n>input_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span>
<span class=n>classes</span><span class=p>,</span> <span class=n>probs</span> <span class=o>=</span> <span class=n>get_top_k_predictions</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_tensor</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>"Top 5 predictions:"</span><span class=p>)</span>
<span class=k>for</span> <span class=bp>cls</span><span class=p>,</span> <span class=n>prob</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>classes</span><span class=p>,</span> <span class=n>probs</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Class </span><span class=si>{</span><span class=bp>cls</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>prob</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</code></pre></div> <h2 id=saving-and-loading-models><span class="enumerate-headings-plugin enumerate-heading-plugin">1.7</span> Saving and Loading Models</h2> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ    Model Saving Strategies       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ          ‚îÇ
        ‚Üì          ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Full   ‚îÇ  ‚îÇ State Dict   ‚îÇ
    ‚îÇ Model  ‚îÇ  ‚îÇ (Preferred)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h3 id=save-model-state-dictionary-recommended><span class="enumerate-headings-plugin enumerate-heading-plugin">1.7.1</span> Save Model State Dictionary (Recommended)</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>os</span>

<span class=c1># Save only state dictionary (recommended)</span>
<span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=s1>'model_weights.pth'</span><span class=p>)</span>

<span class=c1># Save checkpoint with additional info</span>
<span class=n>checkpoint</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>'epoch'</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
    <span class=s1>'model_state_dict'</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
    <span class=s1>'optimizer_state_dict'</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
    <span class=s1>'loss'</span><span class=p>:</span> <span class=n>loss</span><span class=p>,</span>
    <span class=s1>'accuracy'</span><span class=p>:</span> <span class=n>accuracy</span>
<span class=p>}</span>
<span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>,</span> <span class=s1>'checkpoint.pth'</span><span class=p>)</span>

<span class=c1># Save best model</span>
<span class=n>best_acc</span> <span class=o>=</span> <span class=mf>0.0</span>
<span class=k>if</span> <span class=n>val_acc</span> <span class=o>&gt;</span> <span class=n>best_acc</span><span class=p>:</span>
    <span class=n>best_acc</span> <span class=o>=</span> <span class=n>val_acc</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
        <span class=s1>'epoch'</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
        <span class=s1>'model_state_dict'</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
        <span class=s1>'optimizer_state_dict'</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
        <span class=s1>'best_acc'</span><span class=p>:</span> <span class=n>best_acc</span>
    <span class=p>},</span> <span class=s1>'best_model.pth'</span><span class=p>)</span>
</code></pre></div> <h3 id=load-model-state-dictionary><span class="enumerate-headings-plugin enumerate-heading-plugin">1.7.2</span> Load Model State Dictionary</h3> <div class=highlight><pre><span></span><code><span class=c1># Load state dictionary</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNet</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>'model_weights.pth'</span><span class=p>))</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>

<span class=c1># Load checkpoint</span>
<span class=n>checkpoint</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>'checkpoint.pth'</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>'model_state_dict'</span><span class=p>])</span>
<span class=n>optimizer</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>'optimizer_state_dict'</span><span class=p>])</span>
<span class=n>epoch</span> <span class=o>=</span> <span class=n>checkpoint</span><span class=p>[</span><span class=s1>'epoch'</span><span class=p>]</span>
<span class=n>loss</span> <span class=o>=</span> <span class=n>checkpoint</span><span class=p>[</span><span class=s1>'loss'</span><span class=p>]</span>

<span class=c1># Resume training</span>
<span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>

<span class=c1># Load for inference on different device</span>
<span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>'cpu'</span><span class=p>)</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNet</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>'model_weights.pth'</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=n>device</span><span class=p>))</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</code></pre></div> <h3 id=save-entire-model-not-recommended><span class="enumerate-headings-plugin enumerate-heading-plugin">1.7.3</span> Save Entire Model (Not Recommended)</h3> <div class=highlight><pre><span></span><code><span class=c1># Save entire model</span>
<span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s1>'full_model.pth'</span><span class=p>)</span>

<span class=c1># Load entire model</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>'full_model.pth'</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>

<span class=c1># Note: This is less flexible and may break with PyTorch version changes</span>
</code></pre></div> <h3 id=model-versioning-and-management><span class="enumerate-headings-plugin enumerate-heading-plugin">1.7.4</span> Model Versioning and Management</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>os</span>
<span class=kn>from</span><span class=w> </span><span class=nn>datetime</span><span class=w> </span><span class=kn>import</span> <span class=n>datetime</span>

<span class=k>def</span><span class=w> </span><span class=nf>save_model_with_metadata</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>epoch</span><span class=p>,</span> <span class=n>metrics</span><span class=p>,</span> <span class=n>save_dir</span><span class=o>=</span><span class=s1>'models'</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Save model with comprehensive metadata"""</span>
    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>save_dir</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

    <span class=n>timestamp</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s1>'%Y%m</span><span class=si>%d</span><span class=s1>_%H%M%S'</span><span class=p>)</span>
    <span class=n>filename</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>'model_epoch</span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s1>_</span><span class=si>{</span><span class=n>timestamp</span><span class=si>}</span><span class=s1>.pth'</span>
    <span class=n>filepath</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>save_dir</span><span class=p>,</span> <span class=n>filename</span><span class=p>)</span>

    <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
        <span class=s1>'epoch'</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
        <span class=s1>'model_state_dict'</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
        <span class=s1>'optimizer_state_dict'</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
        <span class=s1>'metrics'</span><span class=p>:</span> <span class=n>metrics</span><span class=p>,</span>
        <span class=s1>'timestamp'</span><span class=p>:</span> <span class=n>timestamp</span><span class=p>,</span>
        <span class=s1>'pytorch_version'</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>__version__</span>
    <span class=p>},</span> <span class=n>filepath</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Model saved to </span><span class=si>{</span><span class=n>filepath</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>filepath</span>

<span class=c1># Usage</span>
<span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span><span class=s1>'train_loss'</span><span class=p>:</span> <span class=mf>0.5</span><span class=p>,</span> <span class=s1>'train_acc'</span><span class=p>:</span> <span class=mf>0.85</span><span class=p>,</span> <span class=s1>'val_loss'</span><span class=p>:</span> <span class=mf>0.6</span><span class=p>,</span> <span class=s1>'val_acc'</span><span class=p>:</span> <span class=mf>0.82</span><span class=p>}</span>
<span class=n>save_model_with_metadata</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>epoch</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>metrics</span><span class=o>=</span><span class=n>metrics</span><span class=p>)</span>
</code></pre></div> <h2 id=cuda-gpu-support><span class="enumerate-headings-plugin enumerate-heading-plugin">1.8</span> CUDA (GPU Support)</h2> <h3 id=check-cuda-availability><span class="enumerate-headings-plugin enumerate-heading-plugin">1.8.1</span> Check CUDA Availability</h3> <div class=highlight><pre><span></span><code><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span>
</code></pre></div> <h3 id=set-device><span class="enumerate-headings-plugin enumerate-heading-plugin">1.8.2</span> Set Device</h3> <div class=highlight><pre><span></span><code><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>"cuda"</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>"cpu"</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</code></pre></div> <h3 id=move-tensors-to-gpu><span class="enumerate-headings-plugin enumerate-heading-plugin">1.8.3</span> Move Tensors to GPU</h3> <div class=highlight><pre><span></span><code><span class=n>tensor</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</code></pre></div> <h3 id=cuda-best-practices><span class="enumerate-headings-plugin enumerate-heading-plugin">1.8.4</span> CUDA Best Practices</h3> <ul> <li>Use pinned memory for data transfer: <code>torch.utils.data.DataLoader(..., pin_memory=True)</code></li> <li>Use asynchronous data transfer: <code>torch.cuda.Stream()</code></li> <li>Use mixed precision training: <code>torch.cuda.amp.autocast()</code> and <code>torch.cuda.amp.GradScaler()</code></li> <li>Use <code>torch.backends.cudnn.benchmark = True</code> for faster convolutions when input sizes are fixed.</li> </ul> <h2 id=distributed-training><span class="enumerate-headings-plugin enumerate-heading-plugin">1.9</span> Distributed Training</h2> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Distributed Training Methods        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                       ‚îÇ
        ‚Üì                       ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇDataParallel‚îÇ       ‚îÇDistributedData‚îÇ
    ‚îÇ    (DP)    ‚îÇ       ‚îÇParallel (DDP) ‚îÇ
    ‚îÇ            ‚îÇ       ‚îÇ                ‚îÇ
    ‚îÇ ‚Ä¢ Single   ‚îÇ       ‚îÇ ‚Ä¢ Multi-node ‚îÇ
    ‚îÇ   node     ‚îÇ       ‚îÇ ‚Ä¢ Faster     ‚îÇ
    ‚îÇ ‚Ä¢ Easier   ‚îÇ       ‚îÇ ‚Ä¢ Scalable   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h3 id=dataparallel-simple-but-limited><span class="enumerate-headings-plugin enumerate-heading-plugin">1.9.1</span> DataParallel (Simple but limited)</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>

<span class=c1># Check available GPUs</span>
<span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Using </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span><span class=si>}</span><span class=s2> GPUs"</span><span class=p>)</span>

    <span class=c1># Wrap model with DataParallel</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
    <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>'cuda'</span><span class=p>)</span>

    <span class=c1># Training works the same way</span>
    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
        <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>'cuda'</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>'cuda'</span><span class=p>)</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

<span class=c1># Note: DataParallel splits batches across GPUs but has limitations:</span>
<span class=c1># - Single process (GIL bottleneck)</span>
<span class=c1># - Slower than DDP</span>
<span class=c1># - Uneven GPU utilization</span>
</code></pre></div> <h3 id=distributeddataparallel-recommended><span class="enumerate-headings-plugin enumerate-heading-plugin">1.9.2</span> DistributedDataParallel (Recommended)</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.distributed</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>dist</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.multiprocessing</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>mp</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.nn.parallel</span><span class=w> </span><span class=kn>import</span> <span class=n>DistributedDataParallel</span> <span class=k>as</span> <span class=n>DDP</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data.distributed</span><span class=w> </span><span class=kn>import</span> <span class=n>DistributedSampler</span>
<span class=kn>import</span><span class=w> </span><span class=nn>os</span>

<span class=k>def</span><span class=w> </span><span class=nf>setup</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Initialize the distributed environment"""</span>
    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>'MASTER_ADDR'</span><span class=p>]</span> <span class=o>=</span> <span class=s1>'localhost'</span>
    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>'MASTER_PORT'</span><span class=p>]</span> <span class=o>=</span> <span class=s1>'12355'</span>

    <span class=c1># Initialize process group</span>
    <span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span>
        <span class=n>backend</span><span class=o>=</span><span class=s1>'nccl'</span><span class=p>,</span>      <span class=c1># Use 'gloo' for CPU, 'nccl' for GPU</span>
        <span class=n>init_method</span><span class=o>=</span><span class=s1>'env://'</span><span class=p>,</span>
        <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span>
        <span class=n>world_size</span><span class=o>=</span><span class=n>world_size</span>
    <span class=p>)</span>

    <span class=c1># Set device</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>set_device</span><span class=p>(</span><span class=n>rank</span><span class=p>)</span>

<span class=k>def</span><span class=w> </span><span class=nf>cleanup</span><span class=p>():</span>
<span class=w>    </span><span class=sd>"""Clean up the distributed environment"""</span>
    <span class=n>dist</span><span class=o>.</span><span class=n>destroy_process_group</span><span class=p>()</span>

<span class=k>def</span><span class=w> </span><span class=nf>train</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>,</span> <span class=n>epochs</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Training function for each process"""</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Running DDP on rank </span><span class=si>{</span><span class=n>rank</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
    <span class=n>setup</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>

    <span class=c1># Create model and move to GPU</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNet</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>rank</span><span class=p>)</span>
    <span class=n>ddp_model</span> <span class=o>=</span> <span class=n>DDP</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=n>rank</span><span class=p>])</span>

    <span class=c1># Create dataset and sampler</span>
    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>YourDataset</span><span class=p>()</span>
    <span class=n>train_sampler</span> <span class=o>=</span> <span class=n>DistributedSampler</span><span class=p>(</span>
        <span class=n>train_dataset</span><span class=p>,</span>
        <span class=n>num_replicas</span><span class=o>=</span><span class=n>world_size</span><span class=p>,</span>
        <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span>
        <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span>
    <span class=p>)</span>

    <span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
        <span class=n>train_dataset</span><span class=p>,</span>
        <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
        <span class=n>sampler</span><span class=o>=</span><span class=n>train_sampler</span><span class=p>,</span>
        <span class=n>num_workers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
        <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span>
    <span class=p>)</span>

    <span class=c1># Optimizer and loss</span>
    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>ddp_model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
    <span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>rank</span><span class=p>)</span>

    <span class=c1># Training loop</span>
    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
        <span class=c1># Set epoch for sampler (important for shuffling)</span>
        <span class=n>train_sampler</span><span class=o>.</span><span class=n>set_epoch</span><span class=p>(</span><span class=n>epoch</span><span class=p>)</span>

        <span class=n>ddp_model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
        <span class=n>epoch_loss</span> <span class=o>=</span> <span class=mf>0.0</span>

        <span class=k>for</span> <span class=n>batch_idx</span><span class=p>,</span> <span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
            <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>rank</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>rank</span><span class=p>)</span>

            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>ddp_model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

            <span class=n>epoch_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>

        <span class=c1># Average loss across all processes</span>
        <span class=n>avg_loss</span> <span class=o>=</span> <span class=n>epoch_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>rank</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>  <span class=c1># Only print from main process</span>
            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>epochs</span><span class=si>}</span><span class=s2>, Loss: </span><span class=si>{</span><span class=n>avg_loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

        <span class=c1># Save checkpoint from main process</span>
        <span class=k>if</span> <span class=n>rank</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>checkpoint</span> <span class=o>=</span> <span class=p>{</span>
                <span class=s1>'epoch'</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
                <span class=s1>'model_state_dict'</span><span class=p>:</span> <span class=n>ddp_model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
                <span class=s1>'optimizer_state_dict'</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
                <span class=s1>'loss'</span><span class=p>:</span> <span class=n>avg_loss</span>
            <span class=p>}</span>
            <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>,</span> <span class=sa>f</span><span class=s1>'checkpoint_epoch_</span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s1>.pth'</span><span class=p>)</span>

    <span class=n>cleanup</span><span class=p>()</span>

<span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
<span class=w>    </span><span class=sd>"""Main function to spawn processes"""</span>
    <span class=n>world_size</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span>

    <span class=k>if</span> <span class=n>world_size</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>"Need at least 2 GPUs for DDP"</span><span class=p>)</span>
        <span class=k>return</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Training on </span><span class=si>{</span><span class=n>world_size</span><span class=si>}</span><span class=s2> GPUs"</span><span class=p>)</span>

    <span class=c1># Spawn processes</span>
    <span class=n>mp</span><span class=o>.</span><span class=n>spawn</span><span class=p>(</span>
        <span class=n>train</span><span class=p>,</span>
        <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>world_size</span><span class=p>,</span> <span class=mi>10</span><span class=p>),</span>  <span class=c1># world_size, epochs</span>
        <span class=n>nprocs</span><span class=o>=</span><span class=n>world_size</span><span class=p>,</span>
        <span class=n>join</span><span class=o>=</span><span class=kc>True</span>
    <span class=p>)</span>

<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>"__main__"</span><span class=p>:</span>
    <span class=n>main</span><span class=p>()</span>
</code></pre></div> <h3 id=multi-node-ddp><span class="enumerate-headings-plugin enumerate-heading-plugin">1.9.3</span> Multi-Node DDP</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch.distributed</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>dist</span>

<span class=c1># On each node, set these environment variables:</span>
<span class=c1># MASTER_ADDR: IP address of rank 0 node</span>
<span class=c1># MASTER_PORT: Free port on rank 0 node</span>
<span class=c1># WORLD_SIZE: Total number of processes across all nodes</span>
<span class=c1># RANK: Global rank of this process</span>

<span class=k>def</span><span class=w> </span><span class=nf>setup_multinode</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Setup for multi-node training"""</span>
    <span class=c1># These should be set via environment variables</span>
    <span class=n>master_addr</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>'MASTER_ADDR'</span><span class=p>,</span> <span class=s1>'localhost'</span><span class=p>)</span>
    <span class=n>master_port</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>'MASTER_PORT'</span><span class=p>,</span> <span class=s1>'12355'</span><span class=p>)</span>

    <span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span>
        <span class=n>backend</span><span class=o>=</span><span class=s1>'nccl'</span><span class=p>,</span>
        <span class=n>init_method</span><span class=o>=</span><span class=sa>f</span><span class=s1>'tcp://</span><span class=si>{</span><span class=n>master_addr</span><span class=si>}</span><span class=s1>:</span><span class=si>{</span><span class=n>master_port</span><span class=si>}</span><span class=s1>'</span><span class=p>,</span>
        <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span>
        <span class=n>world_size</span><span class=o>=</span><span class=n>world_size</span>
    <span class=p>)</span>

<span class=c1># Launch on node 0 (4 GPUs):</span>
<span class=c1># MASTER_ADDR=node0 MASTER_PORT=12355 WORLD_SIZE=8 RANK=0 python train.py</span>

<span class=c1># Launch on node 1 (4 GPUs):</span>
<span class=c1># MASTER_ADDR=node0 MASTER_PORT=12355 WORLD_SIZE=8 RANK=4 python train.py</span>
</code></pre></div> <h3 id=ddp-with-mixed-precision><span class="enumerate-headings-plugin enumerate-heading-plugin">1.9.4</span> DDP with Mixed Precision</h3> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>torch.cuda.amp</span><span class=w> </span><span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>

<span class=k>def</span><span class=w> </span><span class=nf>train_with_amp</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>):</span>
    <span class=n>setup</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>

    <span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNet</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>rank</span><span class=p>)</span>
    <span class=n>ddp_model</span> <span class=o>=</span> <span class=n>DDP</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=n>rank</span><span class=p>])</span>

    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>ddp_model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
    <span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>

    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
        <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>rank</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>rank</span><span class=p>)</span>

        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=c1># Mixed precision forward pass</span>
        <span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>ddp_model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

        <span class=c1># Scaled backward pass</span>
        <span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
        <span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>

    <span class=n>cleanup</span><span class=p>()</span>
</code></pre></div> <h2 id=autograd-automatic-differentiation><span class="enumerate-headings-plugin enumerate-heading-plugin">1.10</span> Autograd (Automatic Differentiation)</h2> <h3 id=computational-graph><span class="enumerate-headings-plugin enumerate-heading-plugin">1.10.1</span> Computational Graph</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Computational Graph          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚Üì Forward
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   x   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ  y=x+2‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇz=y*y*3‚îÇ
    ‚îÇ(leaf) ‚îÇ     ‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üë                            ‚îÇ
        ‚îÇ                            ‚Üì
        ‚îÇ       Backward         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇout.mean‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h3 id=tracking-gradients><span class="enumerate-headings-plugin enumerate-heading-plugin">1.10.2</span> Tracking Gradients</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>

<span class=c1># Create tensor with gradient tracking</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"x: </span><span class=si>{</span><span class=n>x</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"requires_grad: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>requires_grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Perform operations</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=mi>2</span>
<span class=n>z</span> <span class=o>=</span> <span class=n>y</span> <span class=o>*</span> <span class=n>y</span> <span class=o>*</span> <span class=mi>3</span>
<span class=n>out</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>out: </span><span class=si>{</span><span class=n>out</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Compute gradients</span>
<span class=n>out</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

<span class=c1># Access gradients</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>x.grad: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Gradient of out with respect to x: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Gradient accumulation (multiple backward passes)</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
    <span class=n>y</span> <span class=o>=</span> <span class=p>(</span><span class=n>x</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>y</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Iteration </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>, x.grad: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Zero gradients manually</span>
<span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=o>.</span><span class=n>zero_</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"After zeroing: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</code></pre></div> <h3 id=controlling-gradient-tracking><span class="enumerate-headings-plugin enumerate-heading-plugin">1.10.3</span> Controlling Gradient Tracking</h3> <div class=highlight><pre><span></span><code><span class=c1># Disable gradient tracking (for inference)</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
    <span class=n>y</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=mi>2</span>
    <span class=n>z</span> <span class=o>=</span> <span class=n>y</span> <span class=o>*</span> <span class=n>y</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"z.requires_grad: </span><span class=si>{</span><span class=n>z</span><span class=o>.</span><span class=n>requires_grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>  <span class=c1># False</span>

<span class=c1># Alternative: use inference mode (faster than no_grad)</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
    <span class=n>y</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=mi>2</span>
    <span class=n>z</span> <span class=o>=</span> <span class=n>y</span> <span class=o>*</span> <span class=n>y</span>

<span class=c1># Temporarily disable gradient</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>set_grad_enabled</span><span class=p>(</span><span class=kc>False</span><span class=p>):</span>
    <span class=n>y</span> <span class=o>=</span> <span class=n>x</span> <span class=o>*</span> <span class=mi>2</span>

<span class=c1># Detach tensor from computation graph</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>  <span class=c1># y shares data with x but has no gradient</span>
<span class=n>z</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>  <span class=c1># Create independent copy without gradient</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"x.requires_grad: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>requires_grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>  <span class=c1># True</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"y.requires_grad: </span><span class=si>{</span><span class=n>y</span><span class=o>.</span><span class=n>requires_grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>  <span class=c1># False</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"z.requires_grad: </span><span class=si>{</span><span class=n>z</span><span class=o>.</span><span class=n>requires_grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>  <span class=c1># False</span>
</code></pre></div> <h3 id=computing-higher-order-derivatives><span class="enumerate-headings-plugin enumerate-heading-plugin">1.10.4</span> Computing Higher-Order Derivatives</h3> <div class=highlight><pre><span></span><code><span class=c1># Second derivative</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>2.0</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span> <span class=o>**</span> <span class=mi>3</span>

<span class=c1># First derivative</span>
<span class=n>first_grad</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>autograd</span><span class=o>.</span><span class=n>grad</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>create_graph</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"First derivative (3x^2): </span><span class=si>{</span><span class=n>first_grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>  <span class=c1># 12.0</span>

<span class=c1># Second derivative</span>
<span class=n>second_grad</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>autograd</span><span class=o>.</span><span class=n>grad</span><span class=p>(</span><span class=n>first_grad</span><span class=p>,</span> <span class=n>x</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Second derivative (6x): </span><span class=si>{</span><span class=n>second_grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>  <span class=c1># 12.0</span>
</code></pre></div> <h3 id=gradient-for-non-scalar-outputs><span class="enumerate-headings-plugin enumerate-heading-plugin">1.10.5</span> Gradient for Non-Scalar Outputs</h3> <div class=highlight><pre><span></span><code><span class=c1># For non-scalar outputs, provide gradient argument</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span> <span class=o>*</span> <span class=mi>2</span>

<span class=c1># Create gradient tensor matching y's shape</span>
<span class=n>grad_output</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
<span class=n>y</span><span class=o>.</span><span class=n>backward</span><span class=p>(</span><span class=n>grad_output</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"x.grad: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</code></pre></div> <h3 id=custom-autograd-functions><span class="enumerate-headings-plugin enumerate-heading-plugin">1.10.6</span> Custom Autograd Functions</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>

<span class=k>class</span><span class=w> </span><span class=nc>CustomReLU</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>autograd</span><span class=o>.</span><span class=n>Function</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""</span>
<span class=sd>    Custom ReLU implementation with autograd support</span>
<span class=sd>    """</span>
    <span class=nd>@staticmethod</span>
    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=nb>input</span><span class=p>):</span>
        <span class=c1># Save input for backward pass</span>
        <span class=n>ctx</span><span class=o>.</span><span class=n>save_for_backward</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
        <span class=c1># Apply ReLU: max(0, x)</span>
        <span class=k>return</span> <span class=nb>input</span><span class=o>.</span><span class=n>clamp</span><span class=p>(</span><span class=nb>min</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>

    <span class=nd>@staticmethod</span>
    <span class=k>def</span><span class=w> </span><span class=nf>backward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>grad_output</span><span class=p>):</span>
        <span class=c1># Retrieve saved input</span>
        <span class=nb>input</span><span class=p>,</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>.</span><span class=n>saved_tensors</span>
        <span class=c1># Compute gradient</span>
        <span class=n>grad_input</span> <span class=o>=</span> <span class=n>grad_output</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
        <span class=n>grad_input</span><span class=p>[</span><span class=nb>input</span> <span class=o>&lt;</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># Gradient is 0 where input &lt; 0</span>
        <span class=k>return</span> <span class=n>grad_input</span>

<span class=c1># Use custom function</span>
<span class=n>custom_relu</span> <span class=o>=</span> <span class=n>CustomReLU</span><span class=o>.</span><span class=n>apply</span>

<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>custom_relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
<span class=n>loss</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
<span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Input: </span><span class=si>{</span><span class=n>x</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Output: </span><span class=si>{</span><span class=n>y</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Gradient: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Custom function with multiple inputs/outputs</span>
<span class=k>class</span><span class=w> </span><span class=nc>CustomMultiply</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>autograd</span><span class=o>.</span><span class=n>Function</span><span class=p>):</span>
    <span class=nd>@staticmethod</span>
    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>input1</span><span class=p>,</span> <span class=n>input2</span><span class=p>,</span> <span class=n>constant</span><span class=p>):</span>
        <span class=n>ctx</span><span class=o>.</span><span class=n>save_for_backward</span><span class=p>(</span><span class=n>input1</span><span class=p>,</span> <span class=n>input2</span><span class=p>)</span>
        <span class=n>ctx</span><span class=o>.</span><span class=n>constant</span> <span class=o>=</span> <span class=n>constant</span>
        <span class=k>return</span> <span class=n>input1</span> <span class=o>*</span> <span class=n>input2</span> <span class=o>*</span> <span class=n>constant</span>

    <span class=nd>@staticmethod</span>
    <span class=k>def</span><span class=w> </span><span class=nf>backward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>grad_output</span><span class=p>):</span>
        <span class=n>input1</span><span class=p>,</span> <span class=n>input2</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>.</span><span class=n>saved_tensors</span>
        <span class=n>constant</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>.</span><span class=n>constant</span>

        <span class=n>grad_input1</span> <span class=o>=</span> <span class=n>grad_output</span> <span class=o>*</span> <span class=n>input2</span> <span class=o>*</span> <span class=n>constant</span>
        <span class=n>grad_input2</span> <span class=o>=</span> <span class=n>grad_output</span> <span class=o>*</span> <span class=n>input1</span> <span class=o>*</span> <span class=n>constant</span>
        <span class=c1># Return gradient for each input (constant has no gradient)</span>
        <span class=k>return</span> <span class=n>grad_input1</span><span class=p>,</span> <span class=n>grad_input2</span><span class=p>,</span> <span class=kc>None</span>

<span class=c1># Usage</span>
<span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>2.0</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>b</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>3.0</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>c</span> <span class=o>=</span> <span class=n>CustomMultiply</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>)</span>
<span class=n>c</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"a.grad: </span><span class=si>{</span><span class=n>a</span><span class=o>.</span><span class=n>grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>  <span class=c1># 15.0 (3 * 5)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"b.grad: </span><span class=si>{</span><span class=n>b</span><span class=o>.</span><span class=n>grad</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>  <span class=c1># 10.0 (2 * 5)</span>
</code></pre></div> <h2 id=data-augmentation><span class="enumerate-headings-plugin enumerate-heading-plugin">1.11</span> Data Augmentation</h2> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torchvision.transforms</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>transforms</span>

<span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=mi>224</span><span class=p>),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomHorizontalFlip</span><span class=p>(),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomRotation</span><span class=p>(</span><span class=n>degrees</span><span class=o>=</span><span class=mi>15</span><span class=p>),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>ColorJitter</span><span class=p>(</span><span class=n>brightness</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>contrast</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>saturation</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>hue</span><span class=o>=</span><span class=mf>0.1</span><span class=p>),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>((</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>),</span> <span class=p>(</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>))</span>
<span class=p>])</span>
</code></pre></div> <p>Common Augmentations:</p> <ul> <li><code>transforms.RandomHorizontalFlip</code>: Horizontally flips the image.</li> <li><code>transforms.RandomVerticalFlip</code>: Vertically flips the image.</li> <li><code>transforms.RandomRotation</code>: Rotates the image by a random angle.</li> <li><code>transforms.RandomAffine</code>: Applies random affine transformations.</li> <li><code>transforms.RandomPerspective</code>: Performs perspective transformation of the given image randomly with a given magnitude.</li> <li><code>transforms.RandomCrop</code>: Crops a random portion of the image.</li> <li><code>transforms.CenterCrop</code>: Crops the image from the center.</li> <li><code>transforms.ColorJitter</code>: Randomly changes the brightness, contrast, saturation, and hue of an image.</li> <li><code>transforms.RandomGrayscale</code>: Converts the image to grayscale with a certain probability.</li> <li><code>transforms.RandomErasing</code>: Randomly erases a rectangular region in the image.</li> <li><code>transforms.RandomResizedCrop</code>: Crops a random portion of the image and resizes it.</li> </ul> <h2 id=learning-rate-schedulers_1><span class="enumerate-headings-plugin enumerate-heading-plugin">1.12</span> Learning Rate Schedulers</h2> <div class=highlight><pre><span></span><code>    Learning Rate Schedules Visualization

    StepLR:                CosineAnnealing:
    lr ‚îÇ                    lr ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îú‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ    ‚ïÆ‚ïÆ
       ‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ       ‚îÇ    ‚ï≤ ‚ïØ‚îê
       ‚îÇ                       ‚îÇ       ‚ïØ‚îê‚ï≤
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
              epochs                    epochs
</code></pre></div> <h3 id=common-schedulers><span class="enumerate-headings-plugin enumerate-heading-plugin">1.12.1</span> Common Schedulers</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.optim</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>optim</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.optim</span><span class=w> </span><span class=kn>import</span> <span class=n>lr_scheduler</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNet</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>

<span class=c1># 1. StepLR: Decay LR by gamma every step_size epochs</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>StepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>step_size</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
<span class=c1># LR: 0.001 ‚Üí 0.0001 (epoch 30) ‚Üí 0.00001 (epoch 60)</span>

<span class=c1># 2. MultiStepLR: Decay at specific milestones</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>MultiStepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>milestones</span><span class=o>=</span><span class=p>[</span><span class=mi>30</span><span class=p>,</span> <span class=mi>60</span><span class=p>,</span> <span class=mi>90</span><span class=p>],</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>

<span class=c1># 3. ExponentialLR: Exponential decay</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>ExponentialLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.95</span><span class=p>)</span>
<span class=c1># LR = initial_lr * (gamma ** epoch)</span>

<span class=c1># 4. CosineAnnealingLR: Cosine annealing</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>CosineAnnealingLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>T_max</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>eta_min</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>

<span class=c1># 5. ReduceLROnPlateau: Reduce when metric plateaus</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>ReduceLROnPlateau</span><span class=p>(</span>
    <span class=n>optimizer</span><span class=p>,</span> 
    <span class=n>mode</span><span class=o>=</span><span class=s1>'min'</span><span class=p>,</span>        <span class=c1># 'min' for loss, 'max' for accuracy</span>
    <span class=n>factor</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>        <span class=c1># Multiply LR by factor</span>
    <span class=n>patience</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>       <span class=c1># Wait 10 epochs before reducing</span>
    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>min_lr</span><span class=o>=</span><span class=mf>1e-6</span>
<span class=p>)</span>

<span class=c1># 6. CyclicLR: Cycle between two boundaries</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>CyclicLR</span><span class=p>(</span>
    <span class=n>optimizer</span><span class=p>,</span>
    <span class=n>base_lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span>
    <span class=n>max_lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>
    <span class=n>step_size_up</span><span class=o>=</span><span class=mi>2000</span><span class=p>,</span>
    <span class=n>mode</span><span class=o>=</span><span class=s1>'triangular'</span>
<span class=p>)</span>

<span class=c1># 7. OneCycleLR: 1cycle policy (very effective)</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>OneCycleLR</span><span class=p>(</span>
    <span class=n>optimizer</span><span class=p>,</span>
    <span class=n>max_lr</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>
    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
    <span class=n>steps_per_epoch</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=p>)</span>
<span class=p>)</span>

<span class=c1># 8. CosineAnnealingWarmRestarts: Cosine with restarts</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>CosineAnnealingWarmRestarts</span><span class=p>(</span>
    <span class=n>optimizer</span><span class=p>,</span>
    <span class=n>T_0</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>      <span class=c1># First restart after 10 epochs</span>
    <span class=n>T_mult</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>    <span class=c1># Double period after each restart</span>
    <span class=n>eta_min</span><span class=o>=</span><span class=mi>0</span>
<span class=p>)</span>

<span class=c1># 9. LambdaLR: Custom schedule</span>
<span class=n>scheduler</span> <span class=o>=</span> <span class=n>lr_scheduler</span><span class=o>.</span><span class=n>LambdaLR</span><span class=p>(</span>
    <span class=n>optimizer</span><span class=p>,</span>
    <span class=n>lr_lambda</span><span class=o>=</span><span class=k>lambda</span> <span class=n>epoch</span><span class=p>:</span> <span class=mf>0.95</span> <span class=o>**</span> <span class=n>epoch</span>
<span class=p>)</span>
</code></pre></div> <h3 id=usage-in-training-loop><span class="enumerate-headings-plugin enumerate-heading-plugin">1.12.2</span> Usage in Training Loop</h3> <div class=highlight><pre><span></span><code><span class=c1># For most schedulers</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=c1># Training</span>
    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

    <span class=c1># Step scheduler after each epoch</span>
    <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

    <span class=c1># Print current learning rate</span>
    <span class=n>current_lr</span> <span class=o>=</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>'lr'</span><span class=p>]</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>, LR: </span><span class=si>{</span><span class=n>current_lr</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># For ReduceLROnPlateau (needs validation metric)</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=c1># Training</span>
    <span class=n>train_loss</span> <span class=o>=</span> <span class=n>train_one_epoch</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>)</span>

    <span class=c1># Validation</span>
    <span class=n>val_loss</span> <span class=o>=</span> <span class=n>validate</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>val_loader</span><span class=p>)</span>

    <span class=c1># Step with validation loss</span>
    <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>val_loss</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>, Train Loss: </span><span class=si>{</span><span class=n>train_loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>, Val Loss: </span><span class=si>{</span><span class=n>val_loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># For OneCycleLR (step after each batch)</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
        <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>  <span class=c1># Step after each batch</span>

<span class=c1># Get learning rate history</span>
<span class=n>lr_history</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>100</span><span class=p>):</span>
    <span class=n>lr_history</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>'lr'</span><span class=p>])</span>
    <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

<span class=c1># Plot learning rate schedule</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>lr_history</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>'Epoch'</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>'Learning Rate'</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>'Learning Rate Schedule'</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <h2 id=tensorboard-integration><span class="enumerate-headings-plugin enumerate-heading-plugin">1.13</span> TensorBoard Integration</h2> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.tensorboard</span><span class=w> </span><span class=kn>import</span> <span class=n>SummaryWriter</span>

<span class=n>writer</span> <span class=o>=</span> <span class=n>SummaryWriter</span><span class=p>(</span><span class=s2>"runs/experiment_1"</span><span class=p>)</span>

<span class=c1># Log scalar values</span>
<span class=n>writer</span><span class=o>.</span><span class=n>add_scalar</span><span class=p>(</span><span class=s1>'Loss/train'</span><span class=p>,</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span> <span class=n>epoch</span><span class=p>)</span>
<span class=n>writer</span><span class=o>.</span><span class=n>add_scalar</span><span class=p>(</span><span class=s1>'Accuracy/train'</span><span class=p>,</span> <span class=n>accuracy</span><span class=p>,</span> <span class=n>epoch</span><span class=p>)</span>

<span class=c1># Log model graph</span>
<span class=n>writer</span><span class=o>.</span><span class=n>add_graph</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>images</span><span class=p>)</span>

<span class=c1># Log images</span>
<span class=n>writer</span><span class=o>.</span><span class=n>add_image</span><span class=p>(</span><span class=s1>'Image'</span><span class=p>,</span> <span class=n>img_grid</span><span class=p>,</span> <span class=n>epoch</span><span class=p>)</span>

<span class=c1># Log histograms</span>
<span class=n>writer</span><span class=o>.</span><span class=n>add_histogram</span><span class=p>(</span><span class=s1>'fc1.weight'</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>fc1</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>epoch</span><span class=p>)</span>

<span class=c1># Log embeddings</span>
<span class=n>writer</span><span class=o>.</span><span class=n>add_embedding</span><span class=p>(</span><span class=n>features</span><span class=p>,</span> <span class=n>metadata</span><span class=o>=</span><span class=n>labels</span><span class=p>,</span> <span class=n>tag</span><span class=o>=</span><span class=s1>'my_embedding'</span><span class=p>)</span>

<span class=n>writer</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</code></pre></div> <p>Run TensorBoard:</p> <div class=highlight><pre><span></span><code>tensorboard<span class=w> </span>--logdir<span class=o>=</span>runs
</code></pre></div> <h2 id=onnx-export><span class="enumerate-headings-plugin enumerate-heading-plugin">1.14</span> ONNX Export</h2> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   ONNX Export Pipeline          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  PyTorch Model (.pth)         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  torch.onnx.export()          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  ONNX Model (.onnx)           ‚îÇ
    ‚îÇ  (Cross-platform inference)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>onnx</span>
<span class=kn>import</span><span class=w> </span><span class=nn>onnxruntime</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>ort</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Export model to ONNX</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
<span class=n>dummy_input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

<span class=c1># Export with dynamic axes for variable batch size</span>
<span class=n>torch</span><span class=o>.</span><span class=n>onnx</span><span class=o>.</span><span class=n>export</span><span class=p>(</span>
    <span class=n>model</span><span class=p>,</span>
    <span class=n>dummy_input</span><span class=p>,</span>
    <span class=s2>"model.onnx"</span><span class=p>,</span>
    <span class=n>export_params</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>opset_version</span><span class=o>=</span><span class=mi>14</span><span class=p>,</span>          <span class=c1># ONNX opset version</span>
    <span class=n>do_constant_folding</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>  <span class=c1># Optimize constant folding</span>
    <span class=n>input_names</span><span class=o>=</span><span class=p>[</span><span class=s1>'input'</span><span class=p>],</span>
    <span class=n>output_names</span><span class=o>=</span><span class=p>[</span><span class=s1>'output'</span><span class=p>],</span>
    <span class=n>dynamic_axes</span><span class=o>=</span><span class=p>{</span>
        <span class=s1>'input'</span><span class=p>:</span> <span class=p>{</span><span class=mi>0</span><span class=p>:</span> <span class=s1>'batch_size'</span><span class=p>},</span>   <span class=c1># Variable batch size</span>
        <span class=s1>'output'</span><span class=p>:</span> <span class=p>{</span><span class=mi>0</span><span class=p>:</span> <span class=s1>'batch_size'</span><span class=p>}</span>
    <span class=p>},</span>
    <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>"ONNX model exported successfully!"</span><span class=p>)</span>

<span class=c1># Verify ONNX model</span>
<span class=n>onnx_model</span> <span class=o>=</span> <span class=n>onnx</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>"model.onnx"</span><span class=p>)</span>
<span class=n>onnx</span><span class=o>.</span><span class=n>checker</span><span class=o>.</span><span class=n>check_model</span><span class=p>(</span><span class=n>onnx_model</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"ONNX model is valid!"</span><span class=p>)</span>

<span class=c1># Print model info</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>ONNX Model Info:"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Inputs: </span><span class=si>{</span><span class=p>[(</span><span class=n>i</span><span class=o>.</span><span class=n>name</span><span class=p>,</span><span class=w> </span><span class=n>i</span><span class=o>.</span><span class=n>type</span><span class=p>)</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>i</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>onnx_model</span><span class=o>.</span><span class=n>graph</span><span class=o>.</span><span class=n>input</span><span class=p>]</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Outputs: </span><span class=si>{</span><span class=p>[(</span><span class=n>o</span><span class=o>.</span><span class=n>name</span><span class=p>,</span><span class=w> </span><span class=n>o</span><span class=o>.</span><span class=n>type</span><span class=p>)</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>o</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>onnx_model</span><span class=o>.</span><span class=n>graph</span><span class=o>.</span><span class=n>output</span><span class=p>]</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Test ONNX model with ONNX Runtime</span>
<span class=n>ort_session</span> <span class=o>=</span> <span class=n>ort</span><span class=o>.</span><span class=n>InferenceSession</span><span class=p>(</span><span class=s2>"model.onnx"</span><span class=p>)</span>

<span class=c1># Prepare input</span>
<span class=n>test_input</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>

<span class=c1># Run inference</span>
<span class=n>ort_inputs</span> <span class=o>=</span> <span class=p>{</span><span class=n>ort_session</span><span class=o>.</span><span class=n>get_inputs</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>name</span><span class=p>:</span> <span class=n>test_input</span><span class=p>}</span>
<span class=n>ort_outputs</span> <span class=o>=</span> <span class=n>ort_session</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=n>ort_inputs</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>ONNX Runtime output shape: </span><span class=si>{</span><span class=n>ort_outputs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Compare PyTorch and ONNX outputs</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
    <span class=n>pytorch_output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>test_input</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>))</span>
    <span class=n>pytorch_output</span> <span class=o>=</span> <span class=n>pytorch_output</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>

<span class=n>difference</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>pytorch_output</span> <span class=o>-</span> <span class=n>ort_outputs</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Max difference between PyTorch and ONNX: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>difference</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Mean difference: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>difference</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Optimize ONNX model</span>
<span class=kn>from</span><span class=w> </span><span class=nn>onnxruntime.quantization</span><span class=w> </span><span class=kn>import</span> <span class=n>quantize_dynamic</span><span class=p>,</span> <span class=n>QuantType</span>

<span class=c1># Dynamic quantization (INT8)</span>
<span class=n>quantize_dynamic</span><span class=p>(</span>
    <span class=s2>"model.onnx"</span><span class=p>,</span>
    <span class=s2>"model_quantized.onnx"</span><span class=p>,</span>
    <span class=n>weight_type</span><span class=o>=</span><span class=n>QuantType</span><span class=o>.</span><span class=n>QInt8</span>
<span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Quantized ONNX model created!"</span><span class=p>)</span>

<span class=c1># Compare model sizes</span>
<span class=kn>import</span><span class=w> </span><span class=nn>os</span>
<span class=n>original_size</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>getsize</span><span class=p>(</span><span class=s2>"model.onnx"</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1024</span> <span class=o>*</span> <span class=mi>1024</span><span class=p>)</span>
<span class=n>quantized_size</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>getsize</span><span class=p>(</span><span class=s2>"model_quantized.onnx"</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1024</span> <span class=o>*</span> <span class=mi>1024</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Original model size: </span><span class=si>{</span><span class=n>original_size</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> MB"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Quantized model size: </span><span class=si>{</span><span class=n>quantized_size</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> MB"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Size reduction: </span><span class=si>{</span><span class=p>(</span><span class=mi>1</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>quantized_size</span><span class=o>/</span><span class=n>original_size</span><span class=p>)</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>100</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%"</span><span class=p>)</span>
</code></pre></div> <h2 id=torchscript><span class="enumerate-headings-plugin enumerate-heading-plugin">1.15</span> TorchScript</h2> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   TorchScript Methods        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ             ‚îÇ
        ‚Üì             ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Tracing‚îÇ   ‚îÇ Scripting‚îÇ
    ‚îÇ (Record ‚îÇ   ‚îÇ (Analyze ‚îÇ
    ‚îÇ  ops)   ‚îÇ   ‚îÇ  source) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h3 id=tracing-recommended-for-most-models><span class="enumerate-headings-plugin enumerate-heading-plugin">1.15.1</span> Tracing (Recommended for most models)</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>

<span class=c1># Set model to evaluation mode</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>

<span class=c1># Create example input</span>
<span class=n>example_input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

<span class=c1># Trace the model</span>
<span class=n>traced_model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>trace</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>example_input</span><span class=p>)</span>

<span class=c1># Save traced model</span>
<span class=n>traced_model</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>"model_traced.pt"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"Traced model saved!"</span><span class=p>)</span>

<span class=c1># Load traced model</span>
<span class=n>loaded_model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>"model_traced.pt"</span><span class=p>)</span>
<span class=n>loaded_model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>

<span class=c1># Test traced model</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
    <span class=n>test_input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
    <span class=n>output</span> <span class=o>=</span> <span class=n>loaded_model</span><span class=p>(</span><span class=n>test_input</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Output shape: </span><span class=si>{</span><span class=n>output</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Optimize for mobile deployment</span>
<span class=n>optimized_model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>optimize_for_inference</span><span class=p>(</span><span class=n>traced_model</span><span class=p>)</span>
<span class=n>optimized_model</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>"model_optimized.pt"</span><span class=p>)</span>
</code></pre></div> <h3 id=scripting-for-models-with-control-flow><span class="enumerate-headings-plugin enumerate-heading-plugin">1.15.2</span> Scripting (For models with control flow)</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>

<span class=c1># Script entire model</span>
<span class=k>class</span><span class=w> </span><span class=nc>ScriptableModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>128</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>

        <span class=c1># Control flow is preserved</span>
        <span class=k>if</span> <span class=n>x</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=mi>10</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>x</span>

<span class=n>model</span> <span class=o>=</span> <span class=n>ScriptableModel</span><span class=p>()</span>
<span class=n>scripted_model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>script</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
<span class=n>scripted_model</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>"model_scripted.pt"</span><span class=p>)</span>

<span class=c1># Script individual functions</span>
<span class=nd>@torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>script</span>
<span class=k>def</span><span class=w> </span><span class=nf>custom_function</span><span class=p>(</span><span class=n>x</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>:</span>
<span class=w>    </span><span class=sd>"""Custom function with type annotations"""</span>
    <span class=k>if</span> <span class=n>x</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>&gt;</span> <span class=n>y</span><span class=o>.</span><span class=n>sum</span><span class=p>():</span>
        <span class=k>return</span> <span class=n>x</span> <span class=o>+</span> <span class=n>y</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=k>return</span> <span class=n>x</span> <span class=o>-</span> <span class=n>y</span>

<span class=c1># Use scripted function</span>
<span class=n>result</span> <span class=o>=</span> <span class=n>custom_function</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>

<span class=c1># Combine tracing and scripting</span>
<span class=k>class</span><span class=w> </span><span class=nc>HybridModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>conv</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>

    <span class=nd>@torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>script_method</span>
    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># This method will be scripted</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>])</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

<span class=c1># Mobile deployment</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.mobile_optimizer</span><span class=w> </span><span class=kn>import</span> <span class=n>optimize_for_mobile</span>

<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
<span class=n>traced</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>trace</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>example_input</span><span class=p>)</span>
<span class=n>optimized</span> <span class=o>=</span> <span class=n>optimize_for_mobile</span><span class=p>(</span><span class=n>traced</span><span class=p>)</span>
<span class=n>optimized</span><span class=o>.</span><span class=n>_save_for_lite_interpreter</span><span class=p>(</span><span class=s2>"model_mobile.ptl"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>"Mobile model saved!"</span><span class=p>)</span>
</code></pre></div> <h3 id=performance-comparison><span class="enumerate-headings-plugin enumerate-heading-plugin">1.15.3</span> Performance Comparison</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>time</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch</span>

<span class=c1># Benchmark function</span>
<span class=k>def</span><span class=w> </span><span class=nf>benchmark</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_tensor</span><span class=p>,</span> <span class=n>num_runs</span><span class=o>=</span><span class=mi>100</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=c1># Warmup</span>
        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
            <span class=n>_</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>input_tensor</span><span class=p>)</span>

        <span class=c1># Benchmark</span>
        <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_runs</span><span class=p>):</span>
            <span class=n>_</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>input_tensor</span><span class=p>)</span>
        <span class=n>end</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>

    <span class=n>avg_time</span> <span class=o>=</span> <span class=p>(</span><span class=n>end</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span> <span class=o>/</span> <span class=n>num_runs</span> <span class=o>*</span> <span class=mi>1000</span>  <span class=c1># ms</span>
    <span class=k>return</span> <span class=n>avg_time</span>

<span class=c1># Compare models</span>
<span class=n>input_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

<span class=n>original_time</span> <span class=o>=</span> <span class=n>benchmark</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_tensor</span><span class=p>)</span>
<span class=n>traced_time</span> <span class=o>=</span> <span class=n>benchmark</span><span class=p>(</span><span class=n>traced_model</span><span class=p>,</span> <span class=n>input_tensor</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Original model: </span><span class=si>{</span><span class=n>original_time</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ms"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Traced model: </span><span class=si>{</span><span class=n>traced_time</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ms"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Speedup: </span><span class=si>{</span><span class=n>original_time</span><span class=o>/</span><span class=n>traced_time</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>x"</span><span class=p>)</span>
</code></pre></div> <h2 id=deployment><span class="enumerate-headings-plugin enumerate-heading-plugin">1.16</span> Deployment</h2> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ     Deployment Pipeline            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  1. Train Model                   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  2. Save Model (.pth/.onnx)      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  3. Create API (Flask/FastAPI)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  4. Containerize (Docker)        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  5. Deploy (Cloud/On-Premise)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h3 id=serving-with-flask><span class="enumerate-headings-plugin enumerate-heading-plugin">1.16.1</span> Serving with Flask</h3> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>flask</span><span class=w> </span><span class=kn>import</span> <span class=n>Flask</span><span class=p>,</span> <span class=n>request</span><span class=p>,</span> <span class=n>jsonify</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torchvision</span><span class=w> </span><span class=kn>import</span> <span class=n>transforms</span>
<span class=kn>from</span><span class=w> </span><span class=nn>PIL</span><span class=w> </span><span class=kn>import</span> <span class=n>Image</span>
<span class=kn>import</span><span class=w> </span><span class=nn>io</span>
<span class=kn>import</span><span class=w> </span><span class=nn>logging</span>

<span class=c1># Configure logging</span>
<span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span><span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>)</span>
<span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

<span class=c1># Initialize Flask app</span>
<span class=n>app</span> <span class=o>=</span> <span class=n>Flask</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

<span class=c1># Load model</span>
<span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>'cuda'</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>'cpu'</span><span class=p>)</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNet</span><span class=p>(</span><span class=mi>784</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>'model_weights.pth'</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=n>device</span><span class=p>))</span>
<span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
<span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Model loaded successfully on </span><span class=si>{</span><span class=n>device</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Define image transformations</span>
<span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>Resize</span><span class=p>(</span><span class=mi>256</span><span class=p>),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>CenterCrop</span><span class=p>(</span><span class=mi>224</span><span class=p>),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
    <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>],</span> 
                       <span class=n>std</span><span class=o>=</span><span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>])</span>
<span class=p>])</span>

<span class=k>def</span><span class=w> </span><span class=nf>transform_image</span><span class=p>(</span><span class=n>image_bytes</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Transform image bytes to tensor"""</span>
    <span class=k>try</span><span class=p>:</span>
        <span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>io</span><span class=o>.</span><span class=n>BytesIO</span><span class=p>(</span><span class=n>image_bytes</span><span class=p>))</span><span class=o>.</span><span class=n>convert</span><span class=p>(</span><span class=s1>'RGB'</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>transform</span><span class=p>(</span><span class=n>image</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Error transforming image: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
        <span class=k>raise</span>

<span class=nd>@app</span><span class=o>.</span><span class=n>route</span><span class=p>(</span><span class=s1>'/health'</span><span class=p>,</span> <span class=n>methods</span><span class=o>=</span><span class=p>[</span><span class=s1>'GET'</span><span class=p>])</span>
<span class=k>def</span><span class=w> </span><span class=nf>health_check</span><span class=p>():</span>
<span class=w>    </span><span class=sd>"""Health check endpoint"""</span>
    <span class=k>return</span> <span class=n>jsonify</span><span class=p>({</span><span class=s1>'status'</span><span class=p>:</span> <span class=s1>'healthy'</span><span class=p>,</span> <span class=s1>'device'</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>device</span><span class=p>)})</span>

<span class=nd>@app</span><span class=o>.</span><span class=n>route</span><span class=p>(</span><span class=s1>'/predict'</span><span class=p>,</span> <span class=n>methods</span><span class=o>=</span><span class=p>[</span><span class=s1>'POST'</span><span class=p>])</span>
<span class=k>def</span><span class=w> </span><span class=nf>predict</span><span class=p>():</span>
<span class=w>    </span><span class=sd>"""Prediction endpoint"""</span>
    <span class=k>if</span> <span class=s1>'image'</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>request</span><span class=o>.</span><span class=n>files</span><span class=p>:</span>
        <span class=k>return</span> <span class=n>jsonify</span><span class=p>({</span><span class=s1>'error'</span><span class=p>:</span> <span class=s1>'No image provided'</span><span class=p>}),</span> <span class=mi>400</span>

    <span class=k>try</span><span class=p>:</span>
        <span class=c1># Read and transform image</span>
        <span class=n>image_bytes</span> <span class=o>=</span> <span class=n>request</span><span class=o>.</span><span class=n>files</span><span class=p>[</span><span class=s1>'image'</span><span class=p>]</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
        <span class=n>img_tensor</span> <span class=o>=</span> <span class=n>transform_image</span><span class=p>(</span><span class=n>image_bytes</span><span class=p>)</span>
        <span class=n>img_tensor</span> <span class=o>=</span> <span class=n>img_tensor</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

        <span class=c1># Make prediction</span>
        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>img_tensor</span><span class=p>)</span>
            <span class=n>probabilities</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>confidence</span><span class=p>,</span> <span class=n>predicted_class</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>probabilities</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

            <span class=c1># Get top 3 predictions</span>
            <span class=n>top3_probs</span><span class=p>,</span> <span class=n>top3_classes</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>probabilities</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

        <span class=c1># Prepare response</span>
        <span class=n>response</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>'predicted_class'</span><span class=p>:</span> <span class=n>predicted_class</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
            <span class=s1>'confidence'</span><span class=p>:</span> <span class=n>confidence</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
            <span class=s1>'top3_predictions'</span><span class=p>:</span> <span class=p>[</span>
                <span class=p>{</span>
                    <span class=s1>'class'</span><span class=p>:</span> <span class=n>top3_classes</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
                    <span class=s1>'probability'</span><span class=p>:</span> <span class=n>top3_probs</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
                <span class=p>}</span>
                <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
            <span class=p>]</span>
        <span class=p>}</span>

        <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Prediction: </span><span class=si>{</span><span class=n>response</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>jsonify</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>

    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Error during prediction: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>jsonify</span><span class=p>({</span><span class=s1>'error'</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)}),</span> <span class=mi>500</span>

<span class=nd>@app</span><span class=o>.</span><span class=n>route</span><span class=p>(</span><span class=s1>'/batch_predict'</span><span class=p>,</span> <span class=n>methods</span><span class=o>=</span><span class=p>[</span><span class=s1>'POST'</span><span class=p>])</span>
<span class=k>def</span><span class=w> </span><span class=nf>batch_predict</span><span class=p>():</span>
<span class=w>    </span><span class=sd>"""Batch prediction endpoint"""</span>
    <span class=k>if</span> <span class=s1>'images'</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>request</span><span class=o>.</span><span class=n>files</span><span class=p>:</span>
        <span class=k>return</span> <span class=n>jsonify</span><span class=p>({</span><span class=s1>'error'</span><span class=p>:</span> <span class=s1>'No images provided'</span><span class=p>}),</span> <span class=mi>400</span>

    <span class=k>try</span><span class=p>:</span>
        <span class=n>images</span> <span class=o>=</span> <span class=n>request</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>getlist</span><span class=p>(</span><span class=s1>'images'</span><span class=p>)</span>
        <span class=n>batch_tensors</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>for</span> <span class=n>img</span> <span class=ow>in</span> <span class=n>images</span><span class=p>:</span>
            <span class=n>img_bytes</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
            <span class=n>img_tensor</span> <span class=o>=</span> <span class=n>transform_image</span><span class=p>(</span><span class=n>img_bytes</span><span class=p>)</span>
            <span class=n>batch_tensors</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>img_tensor</span><span class=p>)</span>

        <span class=c1># Stack tensors into batch</span>
        <span class=n>batch</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>batch_tensors</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

        <span class=c1># Make predictions</span>
        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
            <span class=n>probabilities</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
            <span class=n>confidences</span><span class=p>,</span> <span class=n>predictions</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>probabilities</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

        <span class=c1># Prepare response</span>
        <span class=n>results</span> <span class=o>=</span> <span class=p>[</span>
            <span class=p>{</span>
                <span class=s1>'index'</span><span class=p>:</span> <span class=n>i</span><span class=p>,</span>
                <span class=s1>'predicted_class'</span><span class=p>:</span> <span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>(),</span>
                <span class=s1>'confidence'</span><span class=p>:</span> <span class=n>confidences</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
            <span class=p>}</span>
            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>predictions</span><span class=p>))</span>
        <span class=p>]</span>

        <span class=k>return</span> <span class=n>jsonify</span><span class=p>({</span><span class=s1>'predictions'</span><span class=p>:</span> <span class=n>results</span><span class=p>})</span>

    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
        <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Error during batch prediction: </span><span class=si>{</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>jsonify</span><span class=p>({</span><span class=s1>'error'</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)}),</span> <span class=mi>500</span>

<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>'__main__'</span><span class=p>:</span>
    <span class=n>app</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>host</span><span class=o>=</span><span class=s1>'0.0.0.0'</span><span class=p>,</span> <span class=n>port</span><span class=o>=</span><span class=mi>5000</span><span class=p>,</span> <span class=n>debug</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</code></pre></div> <h3 id=test-api><span class="enumerate-headings-plugin enumerate-heading-plugin">1.16.2</span> Test API</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>requests</span>

<span class=c1># Test single prediction</span>
<span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>'test_image.jpg'</span><span class=p>,</span> <span class=s1>'rb'</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
    <span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span>
        <span class=s1>'http://localhost:5000/predict'</span><span class=p>,</span>
        <span class=n>files</span><span class=o>=</span><span class=p>{</span><span class=s1>'image'</span><span class=p>:</span> <span class=n>f</span><span class=p>}</span>
    <span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>())</span>

<span class=c1># Test batch prediction</span>
<span class=n>files</span> <span class=o>=</span> <span class=p>[</span>
    <span class=p>(</span><span class=s1>'images'</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=s1>'image1.jpg'</span><span class=p>,</span> <span class=s1>'rb'</span><span class=p>)),</span>
    <span class=p>(</span><span class=s1>'images'</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=s1>'image2.jpg'</span><span class=p>,</span> <span class=s1>'rb'</span><span class=p>)),</span>
    <span class=p>(</span><span class=s1>'images'</span><span class=p>,</span> <span class=nb>open</span><span class=p>(</span><span class=s1>'image3.jpg'</span><span class=p>,</span> <span class=s1>'rb'</span><span class=p>))</span>
<span class=p>]</span>
<span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span>
    <span class=s1>'http://localhost:5000/batch_predict'</span><span class=p>,</span>
    <span class=n>files</span><span class=o>=</span><span class=n>files</span>
<span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>())</span>
</code></pre></div> <h3 id=docker-deployment><span class="enumerate-headings-plugin enumerate-heading-plugin">1.16.3</span> Docker Deployment</h3> <div class=highlight><pre><span></span><code><span class=c># Dockerfile</span>
<span class=k>FROM</span><span class=w> </span><span class=s>python:3.9-slim</span>

<span class=k>WORKDIR</span><span class=w> </span><span class=s>/app</span>

<span class=c># Install dependencies</span>
<span class=k>COPY</span><span class=w> </span>requirements.txt<span class=w> </span>.
<span class=k>RUN</span><span class=w> </span>pip<span class=w> </span>install<span class=w> </span>--no-cache-dir<span class=w> </span>-r<span class=w> </span>requirements.txt

<span class=c># Copy model and application</span>
<span class=k>COPY</span><span class=w> </span>model_weights.pth<span class=w> </span>.
<span class=k>COPY</span><span class=w> </span>app.py<span class=w> </span>.
<span class=k>COPY</span><span class=w> </span>model.py<span class=w> </span>.

<span class=c># Expose port</span>
<span class=k>EXPOSE</span><span class=w> </span><span class=s>5000</span>

<span class=c># Set environment variables</span>
<span class=k>ENV</span><span class=w> </span><span class=nv>FLASK_APP</span><span class=o>=</span>app.py
<span class=k>ENV</span><span class=w> </span><span class=nv>MODEL_PATH</span><span class=o>=</span>model_weights.pth

<span class=c># Run application</span>
<span class=k>CMD</span><span class=w> </span><span class=p>[</span><span class=s2>"python"</span><span class=p>,</span><span class=w> </span><span class=s2>"app.py"</span><span class=p>]</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># docker-compose.yml</span>
<span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s>'3.8'</span>

<span class=nt>services</span><span class=p>:</span>
<span class=w>  </span><span class=nt>pytorch-api</span><span class=p>:</span>
<span class=w>    </span><span class=nt>build</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">.</span>
<span class=w>    </span><span class=nt>ports</span><span class=p>:</span>
<span class=w>      </span><span class="p p-Indicator">-</span><span class=w> </span><span class=s>"5000:5000"</span>
<span class=w>    </span><span class=nt>environment</span><span class=p>:</span>
<span class=w>      </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">MODEL_PATH=/app/model_weights.pth</span>
<span class=w>    </span><span class=nt>volumes</span><span class=p>:</span>
<span class=w>      </span><span class="p p-Indicator">-</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">./models:/app/models</span>
<span class=w>    </span><span class=nt>deploy</span><span class=p>:</span>
<span class=w>      </span><span class=nt>resources</span><span class=p>:</span>
<span class=w>        </span><span class=nt>limits</span><span class=p>:</span>
<span class=w>          </span><span class=nt>cpus</span><span class=p>:</span><span class=w> </span><span class=s>'2'</span>
<span class=w>          </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">4G</span>
<span class=w>    </span><span class=nt>healthcheck</span><span class=p>:</span>
<span class=w>      </span><span class=nt>test</span><span class=p>:</span><span class=w> </span><span class="p p-Indicator">[</span><span class=s>"CMD"</span><span class="p p-Indicator">,</span><span class=w> </span><span class=s>"curl"</span><span class="p p-Indicator">,</span><span class=w> </span><span class=s>"-f"</span><span class="p p-Indicator">,</span><span class=w> </span><span class=s>"http://localhost:5000/health"</span><span class="p p-Indicator">]</span>
<span class=w>      </span><span class=nt>interval</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">30s</span>
<span class=w>      </span><span class=nt>timeout</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">10s</span>
<span class=w>      </span><span class=nt>retries</span><span class=p>:</span><span class=w> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># Build and run Docker container</span>
docker<span class=w> </span>build<span class=w> </span>-t<span class=w> </span>pytorch-api:latest<span class=w> </span>.
docker<span class=w> </span>run<span class=w> </span>-p<span class=w> </span><span class=m>5000</span>:5000<span class=w> </span>pytorch-api:latest

<span class=c1># Or use docker-compose</span>
docker-compose<span class=w> </span>up<span class=w> </span>-d

<span class=c1># Scale service</span>
docker-compose<span class=w> </span>up<span class=w> </span>-d<span class=w> </span>--scale<span class=w> </span>pytorch-api<span class=o>=</span><span class=m>3</span>
</code></pre></div> <h3 id=serving-with-torchserve><span class="enumerate-headings-plugin enumerate-heading-plugin">1.16.4</span> Serving with TorchServe</h3> <div class=highlight><pre><span></span><code><span class=c1># Install TorchServe</span>
pip<span class=w> </span>install<span class=w> </span>torchserve<span class=w> </span>torch-model-archiver<span class=w> </span>torch-workflow-archiver

<span class=c1># Create handler.py</span>
cat<span class=w> </span>&gt;<span class=w> </span>handler.py<span class=w> </span><span class=s>&lt;&lt; 'EOF'</span>
<span class=s>import torch</span>
<span class=s>import torch.nn.functional as F</span>
<span class=s>from torchvision import transforms</span>
<span class=s>from ts.torch_handler.base_handler import BaseHandler</span>
<span class=s>from PIL import Image</span>
<span class=s>import io</span>

<span class=s>class ImageClassifier(BaseHandler):</span>
<span class=s>    def __init__(self):</span>
<span class=s>        super(ImageClassifier, self).__init__()</span>
<span class=s>        self.transform = transforms.Compose([</span>
<span class=s>            transforms.Resize(256),</span>
<span class=s>            transforms.CenterCrop(224),</span>
<span class=s>            transforms.ToTensor(),</span>
<span class=s>            transforms.Normalize(mean=[0.485, 0.456, 0.406],</span>
<span class=s>                               std=[0.229, 0.224, 0.225])</span>
<span class=s>        ])</span>

<span class=s>    def preprocess(self, data):</span>
<span class=s>        images = []</span>
<span class=s>        for row in data:</span>
<span class=s>            image = row.get("data") or row.get("body")</span>
<span class=s>            if isinstance(image, str):</span>
<span class=s>                image = base64.b64decode(image)</span>
<span class=s>            image = Image.open(io.BytesIO(image))</span>
<span class=s>            image = self.transform(image)</span>
<span class=s>            images.append(image)</span>
<span class=s>        return torch.stack(images).to(self.device)</span>

<span class=s>    def postprocess(self, inference_output):</span>
<span class=s>        probabilities = F.softmax(inference_output, dim=1)</span>
<span class=s>        confidences, predictions = torch.max(probabilities, 1)</span>
<span class=s>        return [</span>
<span class=s>            {</span>
<span class=s>                "class": pred.item(),</span>
<span class=s>                "confidence": conf.item()</span>
<span class=s>            }</span>
<span class=s>            for pred, conf in zip(predictions, confidences)</span>
<span class=s>        ]</span>
<span class=s>EOF</span>

<span class=c1># Create model archive</span>
torch-model-archiver<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--model-name<span class=w> </span>image_classifier<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--version<span class=w> </span><span class=m>1</span>.0<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--model-file<span class=w> </span>model.py<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--serialized-file<span class=w> </span>model_weights.pth<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--handler<span class=w> </span>handler.py<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--extra-files<span class=w> </span>index_to_name.json

<span class=c1># Create model store directory</span>
mkdir<span class=w> </span>-p<span class=w> </span>model_store
mv<span class=w> </span>image_classifier.mar<span class=w> </span>model_store/

<span class=c1># Start TorchServe</span>
torchserve<span class=w> </span>--start<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--model-store<span class=w> </span>model_store<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--models<span class=w> </span><span class=nv>image_classifier</span><span class=o>=</span>image_classifier.mar<span class=w> </span><span class=se>\</span>
<span class=w>  </span>--ncs

<span class=c1># Test inference</span>
curl<span class=w> </span>-X<span class=w> </span>POST<span class=w> </span>http://localhost:8080/predictions/image_classifier<span class=w> </span><span class=se>\</span>
<span class=w>  </span>-T<span class=w> </span>test_image.jpg

<span class=c1># Management API</span>
curl<span class=w> </span>http://localhost:8081/models

<span class=c1># Stop TorchServe</span>
torchserve<span class=w> </span>--stop
</code></pre></div> <h2 id=distributed-training_1><span class="enumerate-headings-plugin enumerate-heading-plugin">1.17</span> Distributed Training</h2> <h3 id=dataparallel><span class="enumerate-headings-plugin enumerate-heading-plugin">1.17.1</span> DataParallel</h3> <div class=highlight><pre><span></span><code><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>DataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</code></pre></div> <h3 id=distributeddataparallel-ddp><span class="enumerate-headings-plugin enumerate-heading-plugin">1.17.2</span> DistributedDataParallel (DDP)</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch.distributed</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>dist</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.multiprocessing</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>mp</span>
<span class=kn>import</span><span class=w> </span><span class=nn>os</span>

<span class=k>def</span><span class=w> </span><span class=nf>setup</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>):</span>
    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>'MASTER_ADDR'</span><span class=p>]</span> <span class=o>=</span> <span class=s1>'localhost'</span>
    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>'MASTER_PORT'</span><span class=p>]</span> <span class=o>=</span> <span class=s1>'12355'</span>
    <span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span><span class=s2>"nccl"</span><span class=p>,</span> <span class=n>rank</span><span class=o>=</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=o>=</span><span class=n>world_size</span><span class=p>)</span>

<span class=k>def</span><span class=w> </span><span class=nf>cleanup</span><span class=p>():</span>
    <span class=n>dist</span><span class=o>.</span><span class=n>destroy_process_group</span><span class=p>()</span>

<span class=k>def</span><span class=w> </span><span class=nf>train</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>):</span>
    <span class=n>setup</span><span class=p>(</span><span class=n>rank</span><span class=p>,</span> <span class=n>world_size</span><span class=p>)</span>

    <span class=n>model</span> <span class=o>=</span> <span class=n>Net</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>rank</span><span class=p>)</span>
    <span class=n>ddp_model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>parallel</span><span class=o>.</span><span class=n>DistributedDataParallel</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=n>rank</span><span class=p>])</span>

    <span class=c1># Training loop</span>
    <span class=n>cleanup</span><span class=p>()</span>

<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>"__main__"</span><span class=p>:</span>
    <span class=n>world_size</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>()</span>
    <span class=n>mp</span><span class=o>.</span><span class=n>spawn</span><span class=p>(</span><span class=n>train</span><span class=p>,</span>
             <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>world_size</span><span class=p>,),</span>
             <span class=n>nprocs</span><span class=o>=</span><span class=n>world_size</span><span class=p>,</span>
             <span class=n>join</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <h3 id=gradient-clipping><span class="enumerate-headings-plugin enumerate-heading-plugin">1.17.3</span> Gradient Clipping</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Gradient Clipping Flow     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Compute Gradients          ‚îÇ
    ‚îÇ  loss.backward()            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Check Gradient Norm        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ               ‚îÇ
        ‚Üì &gt;max_norm    ‚Üì &lt;=max_norm
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Scale  ‚îÇ     ‚îÇ   Use   ‚îÇ
    ‚îÇGradients‚îÇ     ‚îÇ  As-Is  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  optimizer.step()           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>

<span class=c1># Gradient clipping by norm (most common)</span>
<span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

    <span class=c1># Clip gradients to prevent exploding gradients</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>

    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

<span class=c1># Gradient clipping by value</span>
<span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

    <span class=c1># Clip each gradient to [-clip_value, clip_value]</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_value_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>clip_value</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>

    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

<span class=c1># Monitor gradient norms</span>
<span class=k>def</span><span class=w> </span><span class=nf>get_gradient_norm</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Calculate total gradient norm"""</span>
    <span class=n>total_norm</span> <span class=o>=</span> <span class=mf>0.0</span>
    <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
        <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>param_norm</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>grad</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
            <span class=n>total_norm</span> <span class=o>+=</span> <span class=n>param_norm</span><span class=o>.</span><span class=n>item</span><span class=p>()</span> <span class=o>**</span> <span class=mi>2</span>
    <span class=n>total_norm</span> <span class=o>=</span> <span class=n>total_norm</span> <span class=o>**</span> <span class=mf>0.5</span>
    <span class=k>return</span> <span class=n>total_norm</span>

<span class=c1># Usage in training loop</span>
<span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

    <span class=c1># Monitor gradients</span>
    <span class=n>grad_norm</span> <span class=o>=</span> <span class=n>get_gradient_norm</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Gradient norm: </span><span class=si>{</span><span class=n>grad_norm</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

    <span class=c1># Clip if needed</span>
    <span class=k>if</span> <span class=n>grad_norm</span> <span class=o>&gt;</span> <span class=mf>5.0</span><span class=p>:</span>
        <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>5.0</span><span class=p>)</span>

    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</code></pre></div> <h3 id=weight-decay><span class="enumerate-headings-plugin enumerate-heading-plugin">1.17.4</span> Weight Decay</h3> <p>Weight decay (L2 regularization) is often included directly in the optimizer:</p> <div class=highlight><pre><span></span><code><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=mf>1e-5</span><span class=p>)</span>
</code></pre></div> <h3 id=early-stopping><span class="enumerate-headings-plugin enumerate-heading-plugin">1.17.5</span> Early Stopping</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>class</span><span class=w> </span><span class=nc>EarlyStopping</span><span class=p>:</span>
<span class=w>    </span><span class=sd>"""Early stopping to stop training when validation loss doesn't improve"""</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>patience</span><span class=o>=</span><span class=mi>7</span><span class=p>,</span> <span class=n>min_delta</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>path</span><span class=o>=</span><span class=s1>'best_model.pth'</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""</span>
<span class=sd>        Args:</span>
<span class=sd>            patience: How many epochs to wait after last improvement</span>
<span class=sd>            min_delta: Minimum change to qualify as improvement</span>
<span class=sd>            verbose: Print messages</span>
<span class=sd>            path: Path to save best model</span>
<span class=sd>        """</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>patience</span> <span class=o>=</span> <span class=n>patience</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>min_delta</span> <span class=o>=</span> <span class=n>min_delta</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>verbose</span> <span class=o>=</span> <span class=n>verbose</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>path</span> <span class=o>=</span> <span class=n>path</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>counter</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>best_loss</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>early_stop</span> <span class=o>=</span> <span class=kc>False</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>val_loss_min</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>Inf</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>val_loss</span><span class=p>,</span> <span class=n>model</span><span class=p>):</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_loss</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>best_loss</span> <span class=o>=</span> <span class=n>val_loss</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>save_checkpoint</span><span class=p>(</span><span class=n>val_loss</span><span class=p>,</span> <span class=n>model</span><span class=p>)</span>
        <span class=k>elif</span> <span class=n>val_loss</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_loss</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>min_delta</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>counter</span> <span class=o>+=</span> <span class=mi>1</span>
            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>verbose</span><span class=p>:</span>
                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>'EarlyStopping counter: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>counter</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>patience</span><span class=si>}</span><span class=s1>'</span><span class=p>)</span>
            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>counter</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>patience</span><span class=p>:</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>early_stop</span> <span class=o>=</span> <span class=kc>True</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>best_loss</span> <span class=o>=</span> <span class=n>val_loss</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>save_checkpoint</span><span class=p>(</span><span class=n>val_loss</span><span class=p>,</span> <span class=n>model</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>counter</span> <span class=o>=</span> <span class=mi>0</span>

    <span class=k>def</span><span class=w> </span><span class=nf>save_checkpoint</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>val_loss</span><span class=p>,</span> <span class=n>model</span><span class=p>):</span>
<span class=w>        </span><span class=sd>"""Save model when validation loss decreases"""</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>verbose</span><span class=p>:</span>
            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>'Validation loss decreased (</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>val_loss_min</span><span class=si>:</span><span class=s1>.6f</span><span class=si>}</span><span class=s1> --&gt; </span><span class=si>{</span><span class=n>val_loss</span><span class=si>:</span><span class=s1>.6f</span><span class=si>}</span><span class=s1>). Saving model...'</span><span class=p>)</span>
        <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=bp>self</span><span class=o>.</span><span class=n>path</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>val_loss_min</span> <span class=o>=</span> <span class=n>val_loss</span>

<span class=c1># Usage in training loop</span>
<span class=n>early_stopping</span> <span class=o>=</span> <span class=n>EarlyStopping</span><span class=p>(</span><span class=n>patience</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=c1># Training phase</span>
    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
    <span class=n>train_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
        <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
        <span class=n>train_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>

    <span class=c1># Validation phase</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=n>val_loss</span> <span class=o>=</span> <span class=mf>0.0</span>
    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>val_loader</span><span class=p>:</span>
            <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
            <span class=n>val_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>

    <span class=n>avg_train_loss</span> <span class=o>=</span> <span class=n>train_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=p>)</span>
    <span class=n>avg_val_loss</span> <span class=o>=</span> <span class=n>val_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>val_loader</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>'Epoch [</span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s1>] Train Loss: </span><span class=si>{</span><span class=n>avg_train_loss</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>, Val Loss: </span><span class=si>{</span><span class=n>avg_val_loss</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>'</span><span class=p>)</span>

    <span class=c1># Check early stopping</span>
    <span class=n>early_stopping</span><span class=p>(</span><span class=n>avg_val_loss</span><span class=p>,</span> <span class=n>model</span><span class=p>)</span>

    <span class=k>if</span> <span class=n>early_stopping</span><span class=o>.</span><span class=n>early_stop</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>"Early stopping triggered!"</span><span class=p>)</span>
        <span class=k>break</span>

<span class=c1># Load best model</span>
<span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>'best_model.pth'</span><span class=p>))</span>
</code></pre></div> <h3 id=learning-rate-finders><span class="enumerate-headings-plugin enumerate-heading-plugin">1.17.6</span> Learning Rate Finders</h3> <div class=highlight><pre><span></span><code><span class=c1># Requires a separate library like `torch_lr_finder`</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch_lr_finder</span><span class=w> </span><span class=kn>import</span> <span class=n>LRFinder</span>

<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>1e-7</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span><span class=p>)</span>
<span class=n>lr_finder</span> <span class=o>=</span> <span class=n>LRFinder</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>criterion</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s2>"cuda"</span><span class=p>)</span>
<span class=n>lr_finder</span><span class=o>.</span><span class=n>range_test</span><span class=p>(</span><span class=n>trainloader</span><span class=p>,</span> <span class=n>end_lr</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_iter</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
<span class=n>lr_finder</span><span class=o>.</span><span class=n>plot</span><span class=p>()</span>
<span class=n>lr_finder</span><span class=o>.</span><span class=n>reset</span><span class=p>()</span>
</code></pre></div> <h3 id=gradient-accumulation><span class="enumerate-headings-plugin enumerate-heading-plugin">1.17.7</span> Gradient Accumulation</h3> <p>Gradient accumulation allows you to simulate larger batch sizes when you are limited by GPU memory. It works by accumulating gradients over multiple smaller batches before performing the optimization step.</p> <div class=highlight><pre><span></span><code>    Effective Batch Size = batch_size √ó accumulation_steps

    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ    Gradient Accumulation Process       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  optimizer.zero_grad()      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Batch 1: Forward + Back   ‚îÇ
    ‚îÇ  (gradients accumulate)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Batch 2: Forward + Back   ‚îÇ
    ‚îÇ  (gradients accumulate)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Batch N: Forward + Back   ‚îÇ
    ‚îÇ  (gradients accumulate)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  optimizer.step()          ‚îÇ
    ‚îÇ  (update weights)          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>

<span class=c1># Configuration</span>
<span class=n>accumulation_steps</span> <span class=o>=</span> <span class=mi>4</span>  <span class=c1># Simulate 4x larger batch size</span>

<span class=c1># Training loop with gradient accumulation</span>
<span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
<span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
    <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

    <span class=c1># Forward pass</span>
    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

    <span class=c1># Normalize loss (important!)</span>
    <span class=n>loss</span> <span class=o>=</span> <span class=n>loss</span> <span class=o>/</span> <span class=n>accumulation_steps</span>

    <span class=c1># Backward pass (gradients accumulate)</span>
    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

    <span class=c1># Update weights every accumulation_steps</span>
    <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=n>accumulation_steps</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Step </span><span class=si>{</span><span class=p>(</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span><span class=o>//</span><span class=n>accumulation_steps</span><span class=si>}</span><span class=s2>: Loss = </span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>accumulation_steps</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Handle remaining batches if dataset size not divisible by accumulation_steps</span>
<span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=n>accumulation_steps</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

<span class=c1># Example: Compare memory usage</span>
<span class=c1># Without accumulation: batch_size = 64 ‚Üí GPU memory = X GB</span>
<span class=c1># With accumulation: batch_size = 16, accumulation_steps = 4 ‚Üí GPU memory = X/4 GB</span>
<span class=c1># But effective batch size is still 64</span>
</code></pre></div> <h2 id=common-neural-network-architectures><span class="enumerate-headings-plugin enumerate-heading-plugin">1.18</span> Common Neural Network Architectures</h2> <h3 id=convolutional-neural-network-cnn><span class="enumerate-headings-plugin enumerate-heading-plugin">1.18.1</span> Convolutional Neural Network (CNN)</h3> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ      CNN Architecture Flow          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
    Input Image      ‚Üì
    (3, 224, 224)    ‚îÇ
                     ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Conv2d + BatchNorm + ReLU         ‚îÇ
    ‚îÇ  (64 filters)                      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  MaxPool2d (2x2)                  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì (Repeat blocks)
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Flatten                          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Fully Connected Layers           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Output (num_classes)             ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>

<span class=k>class</span><span class=w> </span><span class=nc>SimpleCNN</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>SimpleCNN</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=c1># Convolutional layers</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>bn1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>64</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>128</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>conv3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>bn3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>256</span><span class=p>)</span>

        <span class=c1># Pooling</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>pool</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>

        <span class=c1># Fully connected layers</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span> <span class=o>*</span> <span class=mi>28</span> <span class=o>*</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>512</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>

        <span class=c1># Dropout</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Block 1</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pool</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>))))</span>

        <span class=c1># Block 2</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pool</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>x</span><span class=p>))))</span>

        <span class=c1># Block 3</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pool</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn3</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv3</span><span class=p>(</span><span class=n>x</span><span class=p>))))</span>

        <span class=c1># Flatten</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>

        <span class=c1># Fully connected</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>x</span>

<span class=c1># Usage</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>SimpleCNN</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>

<span class=c1># Count parameters</span>
<span class=n>total_params</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Total parameters: </span><span class=si>{</span><span class=n>total_params</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</code></pre></div> <h3 id=resnet-style-residual-block><span class="enumerate-headings-plugin enumerate-heading-plugin">1.18.2</span> ResNet-style Residual Block</h3> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>ResidualBlock</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Residual block with skip connection"""</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>ResidualBlock</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> 
                               <span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>bn1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>
                               <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>

        <span class=c1># Skip connection</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>()</span>
        <span class=k>if</span> <span class=n>stride</span> <span class=o>!=</span> <span class=mi>1</span> <span class=ow>or</span> <span class=n>in_channels</span> <span class=o>!=</span> <span class=n>out_channels</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
                <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> 
                         <span class=n>stride</span><span class=o>=</span><span class=n>stride</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
                <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
            <span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=n>identity</span> <span class=o>=</span> <span class=n>x</span>

        <span class=n>out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>out</span><span class=p>))</span>

        <span class=c1># Add skip connection</span>
        <span class=n>out</span> <span class=o>+=</span> <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span><span class=p>(</span><span class=n>identity</span><span class=p>)</span>
        <span class=n>out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>out</span>

<span class=k>class</span><span class=w> </span><span class=nc>ResNet</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>ResNet</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>7</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>bn1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=mi>64</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>maxpool</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

        <span class=c1># Residual layers</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layer1</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_make_layer</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layer2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_make_layer</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layer3</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_make_layer</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>avgpool</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>AdaptiveAvgPool2d</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_make_layer</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>num_blocks</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
        <span class=n>layers</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=n>layers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ResidualBlock</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>stride</span><span class=p>))</span>
        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_blocks</span><span class=p>):</span>
            <span class=n>layers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ResidualBlock</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>))</span>
        <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=n>layers</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>maxpool</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layer1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layer2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layer3</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>avgpool</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>x</span>
</code></pre></div> <h3 id=recurrent-neural-network-lstm><span class="enumerate-headings-plugin enumerate-heading-plugin">1.18.3</span> Recurrent Neural Network (LSTM)</h3> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>LSTMClassifier</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>,</span> <span class=n>hidden_dim</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>2</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>LSTMClassifier</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>lstm</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LSTM</span><span class=p>(</span>
            <span class=n>embedding_dim</span><span class=p>,</span> 
            <span class=n>hidden_dim</span><span class=p>,</span> 
            <span class=n>num_layers</span><span class=o>=</span><span class=n>num_layers</span><span class=p>,</span>
            <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
            <span class=n>dropout</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span>
            <span class=n>bidirectional</span><span class=o>=</span><span class=kc>True</span>
        <span class=p>)</span>

        <span class=c1># *2 for bidirectional</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_dim</span> <span class=o>*</span> <span class=mi>2</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># x shape: (batch_size, seq_length)</span>
        <span class=n>embedded</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># (batch_size, seq_length, embedding_dim)</span>

        <span class=c1># LSTM output</span>
        <span class=n>lstm_out</span><span class=p>,</span> <span class=p>(</span><span class=n>hidden</span><span class=p>,</span> <span class=n>cell</span><span class=p>)</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lstm</span><span class=p>(</span><span class=n>embedded</span><span class=p>)</span>
        <span class=c1># lstm_out: (batch_size, seq_length, hidden_dim * 2)</span>

        <span class=c1># Use last output or pooling</span>
        <span class=n>output</span> <span class=o>=</span> <span class=n>lstm_out</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span>  <span class=c1># Last time step</span>
        <span class=c1># Or use mean pooling: output = torch.mean(lstm_out, dim=1)</span>

        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>output</span>

<span class=c1># Usage</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>LSTMClassifier</span><span class=p>(</span>
    <span class=n>vocab_size</span><span class=o>=</span><span class=mi>10000</span><span class=p>,</span>
    <span class=n>embedding_dim</span><span class=o>=</span><span class=mi>300</span><span class=p>,</span>
    <span class=n>hidden_dim</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
    <span class=n>num_classes</span><span class=o>=</span><span class=mi>5</span>
<span class=p>)</span>
</code></pre></div> <h3 id=transformer-encoder><span class="enumerate-headings-plugin enumerate-heading-plugin">1.18.4</span> Transformer Encoder</h3> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>TransformerClassifier</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>d_model</span><span class=p>,</span> <span class=n>nhead</span><span class=p>,</span> <span class=n>num_layers</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>TransformerClassifier</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>pos_encoder</span> <span class=o>=</span> <span class=n>PositionalEncoding</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>

        <span class=n>encoder_layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>TransformerEncoderLayer</span><span class=p>(</span>
            <span class=n>d_model</span><span class=o>=</span><span class=n>d_model</span><span class=p>,</span>
            <span class=n>nhead</span><span class=o>=</span><span class=n>nhead</span><span class=p>,</span>
            <span class=n>dim_feedforward</span><span class=o>=</span><span class=n>d_model</span> <span class=o>*</span> <span class=mi>4</span><span class=p>,</span>
            <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span>
        <span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>transformer_encoder</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>TransformerEncoder</span><span class=p>(</span>
            <span class=n>encoder_layer</span><span class=p>,</span>
            <span class=n>num_layers</span><span class=o>=</span><span class=n>num_layers</span>
        <span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>src_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
        <span class=c1># src: (batch_size, seq_length)</span>
        <span class=n>src</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>src</span><span class=p>)</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>d_model</span><span class=p>)</span>
        <span class=n>src</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pos_encoder</span><span class=p>(</span><span class=n>src</span><span class=p>)</span>

        <span class=c1># Transformer expects (seq_length, batch_size, d_model)</span>
        <span class=n>src</span> <span class=o>=</span> <span class=n>src</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>transformer_encoder</span><span class=p>(</span><span class=n>src</span><span class=p>,</span> <span class=n>src_mask</span><span class=p>)</span>

        <span class=c1># Use CLS token or mean pooling</span>
        <span class=n>output</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Average over sequence</span>
        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>output</span>

<span class=k>class</span><span class=w> </span><span class=nc>PositionalEncoding</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=p>,</span> <span class=n>max_len</span><span class=o>=</span><span class=mi>5000</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>PositionalEncoding</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=n>pe</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>max_len</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
        <span class=n>position</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>max_len</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
        <span class=n>div_term</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>d_model</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span> <span class=o>*</span> 
                           <span class=p>(</span><span class=o>-</span><span class=n>math</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mf>10000.0</span><span class=p>)</span> <span class=o>/</span> <span class=n>d_model</span><span class=p>))</span>

        <span class=n>pe</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>::</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>position</span> <span class=o>*</span> <span class=n>div_term</span><span class=p>)</span>
        <span class=n>pe</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>position</span> <span class=o>*</span> <span class=n>div_term</span><span class=p>)</span>
        <span class=n>pe</span> <span class=o>=</span> <span class=n>pe</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>register_buffer</span><span class=p>(</span><span class=s1>'pe'</span><span class=p>,</span> <span class=n>pe</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>pe</span><span class=p>[:,</span> <span class=p>:</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=p>:]</span>
</code></pre></div> <h3 id=autoencoder><span class="enumerate-headings-plugin enumerate-heading-plugin">1.18.5</span> Autoencoder</h3> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>Autoencoder</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>,</span> <span class=n>encoding_dim</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>(</span><span class=n>Autoencoder</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=c1># Encoder</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>encoder</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_dim</span><span class=p>,</span> <span class=mi>512</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>256</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=n>encoding_dim</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
        <span class=p>)</span>

        <span class=c1># Decoder</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>encoding_dim</span><span class=p>,</span> <span class=mi>256</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>512</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>input_dim</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()</span>  <span class=c1># For normalized inputs [0, 1]</span>
        <span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=n>encoded</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>encoder</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=n>decoded</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=p>(</span><span class=n>encoded</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>decoded</span>

    <span class=k>def</span><span class=w> </span><span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>encoder</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>z</span><span class=p>):</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=p>(</span><span class=n>z</span><span class=p>)</span>
</code></pre></div> <h2 id=common-issues-and-debugging><span class="enumerate-headings-plugin enumerate-heading-plugin">1.19</span> Common Issues and Debugging</h2> <div class=highlight><pre><span></span><code>    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ      Debugging Workflow              ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  1. Check Tensor Shapes/Devices   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  2. Verify Gradients Flow         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  3. Monitor Loss/Metrics          ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  4. Profile Performance           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h3 id=debugging-tools><span class="enumerate-headings-plugin enumerate-heading-plugin">1.19.1</span> Debugging Tools</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>

<span class=c1># 1. Register hooks to monitor gradients</span>
<span class=k>def</span><span class=w> </span><span class=nf>print_grad_hook</span><span class=p>(</span><span class=n>name</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=nf>hook</span><span class=p>(</span><span class=n>grad</span><span class=p>):</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2> gradient: </span><span class=si>{</span><span class=n>grad</span><span class=o>.</span><span class=n>norm</span><span class=p>()</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>hook</span>

<span class=c1># Register hooks</span>
<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
    <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
        <span class=n>param</span><span class=o>.</span><span class=n>register_hook</span><span class=p>(</span><span class=n>print_grad_hook</span><span class=p>(</span><span class=n>name</span><span class=p>))</span>

<span class=c1># 2. Check for NaN/Inf values</span>
<span class=k>def</span><span class=w> </span><span class=nf>check_nan_inf</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s2>"tensor"</span><span class=p>):</span>
    <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>isnan</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span><span class=o>.</span><span class=n>any</span><span class=p>():</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"NaN detected in </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>isinf</span><span class=p>(</span><span class=n>tensor</span><span class=p>)</span><span class=o>.</span><span class=n>any</span><span class=p>():</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Inf detected in </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># 3. Print model summary</span>
<span class=k>def</span><span class=w> </span><span class=nf>print_model_summary</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_size</span><span class=p>):</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>torchsummary</span><span class=w> </span><span class=kn>import</span> <span class=n>summary</span>
    <span class=n>summary</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_size</span><span class=p>)</span>

<span class=c1># Usage</span>
<span class=n>print_model_summary</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>))</span>

<span class=c1># 4. Visualize gradient flow</span>
<span class=k>def</span><span class=w> </span><span class=nf>plot_grad_flow</span><span class=p>(</span><span class=n>named_parameters</span><span class=p>):</span>
    <span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

    <span class=n>ave_grads</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=n>max_grads</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=n>layers</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=k>for</span> <span class=n>n</span><span class=p>,</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>named_parameters</span><span class=p>:</span>
        <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>requires_grad</span> <span class=ow>and</span> <span class=n>p</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>layers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
            <span class=n>ave_grads</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>grad</span><span class=o>.</span><span class=n>abs</span><span class=p>()</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>())</span>
            <span class=n>max_grads</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>grad</span><span class=o>.</span><span class=n>abs</span><span class=p>()</span><span class=o>.</span><span class=n>max</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>())</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>max_grads</span><span class=p>)),</span> <span class=n>max_grads</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>"max"</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>ave_grads</span><span class=p>)),</span> <span class=n>ave_grads</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>"mean"</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>ave_grads</span><span class=p>)),</span> <span class=n>layers</span><span class=p>,</span> <span class=n>rotation</span><span class=o>=</span><span class=s2>"vertical"</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># 5. Memory profiling</span>
<span class=k>def</span><span class=w> </span><span class=nf>profile_memory</span><span class=p>():</span>
    <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Allocated: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>memory_allocated</span><span class=p>()</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mi>1024</span><span class=o>**</span><span class=mi>3</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> GB"</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Cached: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>memory_reserved</span><span class=p>()</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mi>1024</span><span class=o>**</span><span class=mi>3</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> GB"</span><span class=p>)</span>

<span class=c1># 6. Torch profiler</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.profiler</span><span class=w> </span><span class=kn>import</span> <span class=n>profile</span><span class=p>,</span> <span class=n>ProfilerActivity</span>

<span class=k>with</span> <span class=n>profile</span><span class=p>(</span><span class=n>activities</span><span class=o>=</span><span class=p>[</span><span class=n>ProfilerActivity</span><span class=o>.</span><span class=n>CPU</span><span class=p>,</span> <span class=n>ProfilerActivity</span><span class=o>.</span><span class=n>CUDA</span><span class=p>])</span> <span class=k>as</span> <span class=n>prof</span><span class=p>:</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=n>prof</span><span class=o>.</span><span class=n>key_averages</span><span class=p>()</span><span class=o>.</span><span class=n>table</span><span class=p>(</span><span class=n>sort_by</span><span class=o>=</span><span class=s2>"cuda_time_total"</span><span class=p>,</span> <span class=n>row_limit</span><span class=o>=</span><span class=mi>10</span><span class=p>))</span>
</code></pre></div> <h3 id=common-issues-and-solutions><span class="enumerate-headings-plugin enumerate-heading-plugin">1.19.2</span> Common Issues and Solutions</h3> <ul> <li> <p><strong>CUDA Out of Memory:</strong></p> <ul> <li>Reduce batch size</li> <li>Use mixed precision training (<code>torch.cuda.amp</code>)</li> <li>Use gradient checkpointing</li> <li>Clear cache: <code>torch.cuda.empty_cache()</code></li> <li>Use smaller model or fewer layers</li> </ul> </li> <li> <p><strong>NaN/Inf Losses:</strong></p> <ul> <li>Reduce learning rate</li> <li>Use gradient clipping: <code>torch.nn.utils.clip_grad_norm_()</code></li> <li>Check for division by zero</li> <li>Normalize input data</li> <li>Use stable loss functions (e.g., <code>BCEWithLogitsLoss</code> instead of <code>BCELoss</code>)</li> </ul> </li> <li> <p><strong>Slow Training:</strong></p> <ul> <li>Profile code to find bottlenecks</li> <li>Use GPU acceleration</li> <li>Increase <code>num_workers</code> in DataLoader</li> <li>Use <code>pin_memory=True</code> in DataLoader</li> <li>Enable <code>torch.backends.cudnn.benchmark = True</code> for fixed input sizes</li> <li>Use mixed precision training</li> </ul> </li> <li> <p><strong>Overfitting:</strong></p> <ul> <li>Add dropout layers</li> <li>Use data augmentation</li> <li>Implement early stopping</li> <li>Reduce model complexity</li> <li>Add L2 regularization (weight decay)</li> <li>Increase training data</li> </ul> </li> <li> <p><strong>Underfitting:</strong></p> <ul> <li>Increase model capacity (more layers/neurons)</li> <li>Train for more epochs</li> <li>Reduce regularization</li> <li>Check if data preprocessing is correct</li> <li>Use better optimizer (Adam instead of SGD)</li> </ul> </li> <li> <p><strong>Incorrect Tensor Shapes:</strong> <div class=highlight><pre><span></span><code><span class=c1># Debug tensor shapes</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Input shape: </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Expected shape: (batch, channels, height, width)"</span><span class=p>)</span>

<span class=c1># Use assertions</span>
<span class=k>assert</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>3</span><span class=p>,</span> <span class=sa>f</span><span class=s2>"Expected 3 channels, got </span><span class=si>{</span><span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>"</span>
</code></pre></div></p> </li> <li> <p><strong>Device Mismatch:</strong> <div class=highlight><pre><span></span><code><span class=c1># Check device</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Model device: </span><span class=si>{</span><span class=nb>next</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=o>.</span><span class=n>device</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Input device: </span><span class=si>{</span><span class=n>inputs</span><span class=o>.</span><span class=n>device</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Move everything to same device</span>
<span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>"cuda"</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>"cpu"</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>inputs</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</code></pre></div></p> </li> <li> <p><strong>Gradients Not Flowing:</strong> <div class=highlight><pre><span></span><code><span class=c1># Check requires_grad</span>
<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: requires_grad=</span><span class=si>{</span><span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=si>}</span><span class=s2>, grad=</span><span class=si>{</span><span class=n>param</span><span class=o>.</span><span class=n>grad</span><span class=w> </span><span class=ow>is</span><span class=w> </span><span class=ow>not</span><span class=w> </span><span class=kc>None</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Check for detached tensors</span>
<span class=c1># Make sure not using .detach() or .data unintentionally</span>
</code></pre></div></p> </li> <li> <p><strong>Dead Neurons (ReLU):</strong></p> <ul> <li>Use Leaky ReLU: <code>nn.LeakyReLU(0.01)</code></li> <li>Use ELU: <code>nn.ELU()</code></li> <li>Reduce learning rate</li> <li>Better weight initialization: <code>nn.init.kaiming_normal_()</code></li> </ul> </li> <li> <p><strong>Data Loading Bottlenecks:</strong> <div class=highlight><pre><span></span><code><span class=c1># Increase workers and use prefetching</span>
<span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>dataset</span><span class=p>,</span>
    <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
    <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
    <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>prefetch_factor</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
    <span class=n>persistent_workers</span><span class=o>=</span><span class=kc>True</span>
<span class=p>)</span>
</code></pre></div></p> </li> </ul> <h2 id=best-practices><span class="enumerate-headings-plugin enumerate-heading-plugin">1.20</span> Best Practices</h2> <h3 id=code-organization><span class="enumerate-headings-plugin enumerate-heading-plugin">1.20.1</span> Code Organization</h3> <div class=highlight><pre><span></span><code><span class=c1># Organize code into modular components</span>

<span class=c1># model.py</span>
<span class=k>class</span><span class=w> </span><span class=nc>MyModel</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=c1># Define layers</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Forward pass</span>
        <span class=k>return</span> <span class=n>x</span>

<span class=c1># dataset.py</span>
<span class=k>class</span><span class=w> </span><span class=nc>MyDataset</span><span class=p>(</span><span class=n>Dataset</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>data_path</span><span class=p>):</span>
        <span class=c1># Load data</span>
        <span class=k>pass</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
        <span class=c1># Return sample</span>
        <span class=k>pass</span>

<span class=c1># train.py</span>
<span class=k>def</span><span class=w> </span><span class=nf>train_epoch</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>loader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>criterion</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
    <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>loader</span><span class=p>:</span>
        <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
        <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
    <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>loader</span><span class=p>)</span>

<span class=c1># config.py</span>
<span class=k>class</span><span class=w> </span><span class=nc>Config</span><span class=p>:</span>
    <span class=c1># Hyperparameters</span>
    <span class=n>BATCH_SIZE</span> <span class=o>=</span> <span class=mi>32</span>
    <span class=n>LEARNING_RATE</span> <span class=o>=</span> <span class=mf>0.001</span>
    <span class=n>NUM_EPOCHS</span> <span class=o>=</span> <span class=mi>100</span>
    <span class=n>DEVICE</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>"cuda"</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>"cpu"</span><span class=p>)</span>
</code></pre></div> <h3 id=performance-optimization><span class="enumerate-headings-plugin enumerate-heading-plugin">1.20.2</span> Performance Optimization</h3> <div class=highlight><pre><span></span><code><span class=c1># 1. Enable cuDNN autotuner for fixed input sizes</span>
<span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>benchmark</span> <span class=o>=</span> <span class=kc>True</span>

<span class=c1># 2. Use appropriate data types</span>
<span class=c1># Use fp16 for training when possible</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.cuda.amp</span><span class=w> </span><span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>

<span class=c1># 3. Optimize DataLoader</span>
<span class=n>train_loader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
    <span class=n>dataset</span><span class=p>,</span>
    <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
    <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>           <span class=c1># Multi-process data loading</span>
    <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>         <span class=c1># Fast data transfer to GPU</span>
    <span class=n>persistent_workers</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=c1># Keep workers alive</span>
    <span class=n>prefetch_factor</span><span class=o>=</span><span class=mi>2</span>        <span class=c1># Prefetch batches</span>
<span class=p>)</span>

<span class=c1># 4. Use in-place operations when possible</span>
<span class=n>x</span><span class=o>.</span><span class=n>add_</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># In-place</span>
<span class=n>x</span><span class=o>.</span><span class=n>relu_</span><span class=p>()</span>  <span class=c1># In-place</span>

<span class=c1># 5. Avoid unnecessary CPU-GPU transfers</span>
<span class=c1># Keep data on GPU as much as possible</span>

<span class=c1># 6. Use torch.no_grad() for inference</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
    <span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>

<span class=c1># 7. Clear unused variables</span>
<span class=k>del</span> <span class=n>intermediate_tensor</span>
<span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>empty_cache</span><span class=p>()</span>
</code></pre></div> <h3 id=reproducibility><span class="enumerate-headings-plugin enumerate-heading-plugin">1.20.3</span> Reproducibility</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>random</span>

<span class=k>def</span><span class=w> </span><span class=nf>set_seed</span><span class=p>(</span><span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Set seed for reproducibility"""</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>manual_seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>manual_seed_all</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>
    <span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=n>seed</span><span class=p>)</span>

    <span class=c1># Make cudnn deterministic</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>deterministic</span> <span class=o>=</span> <span class=kc>True</span>
    <span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>benchmark</span> <span class=o>=</span> <span class=kc>False</span>

<span class=n>set_seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</code></pre></div> <h3 id=model-initialization><span class="enumerate-headings-plugin enumerate-heading-plugin">1.20.4</span> Model Initialization</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>

<span class=k>def</span><span class=w> </span><span class=nf>init_weights</span><span class=p>(</span><span class=n>m</span><span class=p>):</span>
<span class=w>    </span><span class=sd>"""Initialize model weights"""</span>
    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_uniform_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>m</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
    <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>):</span>
        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>kaiming_normal_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mode</span><span class=o>=</span><span class=s1>'fan_out'</span><span class=p>,</span> <span class=n>nonlinearity</span><span class=o>=</span><span class=s1>'relu'</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>m</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
    <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>):</span>
        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>ones_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
        <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>m</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>

<span class=c1># Apply initialization</span>
<span class=n>model</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>init_weights</span><span class=p>)</span>
</code></pre></div> <h3 id=logging-and-monitoring><span class="enumerate-headings-plugin enumerate-heading-plugin">1.20.5</span> Logging and Monitoring</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>logging</span>
<span class=kn>from</span><span class=w> </span><span class=nn>pathlib</span><span class=w> </span><span class=kn>import</span> <span class=n>Path</span>

<span class=c1># Setup logging</span>
<span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span>
    <span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>,</span>
    <span class=nb>format</span><span class=o>=</span><span class=s1>'</span><span class=si>%(asctime)s</span><span class=s1> - </span><span class=si>%(name)s</span><span class=s1> - </span><span class=si>%(levelname)s</span><span class=s1> - </span><span class=si>%(message)s</span><span class=s1>'</span><span class=p>,</span>
    <span class=n>handlers</span><span class=o>=</span><span class=p>[</span>
        <span class=n>logging</span><span class=o>.</span><span class=n>FileHandler</span><span class=p>(</span><span class=s1>'training.log'</span><span class=p>),</span>
        <span class=n>logging</span><span class=o>.</span><span class=n>StreamHandler</span><span class=p>()</span>
    <span class=p>]</span>
<span class=p>)</span>
<span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

<span class=c1># Log training progress</span>
<span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s2>, Loss: </span><span class=si>{</span><span class=n>loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>

<span class=c1># Use TensorBoard</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.tensorboard</span><span class=w> </span><span class=kn>import</span> <span class=n>SummaryWriter</span>

<span class=n>writer</span> <span class=o>=</span> <span class=n>SummaryWriter</span><span class=p>(</span><span class=s1>'runs/experiment1'</span><span class=p>)</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=n>writer</span><span class=o>.</span><span class=n>add_scalar</span><span class=p>(</span><span class=s1>'Loss/train'</span><span class=p>,</span> <span class=n>train_loss</span><span class=p>,</span> <span class=n>epoch</span><span class=p>)</span>
    <span class=n>writer</span><span class=o>.</span><span class=n>add_scalar</span><span class=p>(</span><span class=s1>'Accuracy/train'</span><span class=p>,</span> <span class=n>train_acc</span><span class=p>,</span> <span class=n>epoch</span><span class=p>)</span>
<span class=n>writer</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</code></pre></div> <h3 id=model-deployment-checklist><span class="enumerate-headings-plugin enumerate-heading-plugin">1.20.6</span> Model Deployment Checklist</h3> <div class=highlight><pre><span></span><code><span class=c1># 1. Model validation</span>
<span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
    <span class=n>test_acc</span> <span class=o>=</span> <span class=n>evaluate</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>test_loader</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Test Accuracy: </span><span class=si>{</span><span class=n>test_acc</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%"</span><span class=p>)</span>

<span class=c1># 2. Save model with metadata</span>
<span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
    <span class=s1>'model_state_dict'</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
    <span class=s1>'optimizer_state_dict'</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
    <span class=s1>'epoch'</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
    <span class=s1>'test_accuracy'</span><span class=p>:</span> <span class=n>test_acc</span><span class=p>,</span>
    <span class=s1>'config'</span><span class=p>:</span> <span class=n>config</span><span class=p>,</span>
    <span class=s1>'pytorch_version'</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>__version__</span>
<span class=p>},</span> <span class=s1>'model_final.pth'</span><span class=p>)</span>

<span class=c1># 3. Export to ONNX for production</span>
<span class=n>torch</span><span class=o>.</span><span class=n>onnx</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>dummy_input</span><span class=p>,</span> <span class=s1>'model.onnx'</span><span class=p>)</span>

<span class=c1># 4. Test exported model</span>
<span class=n>ort_session</span> <span class=o>=</span> <span class=n>ort</span><span class=o>.</span><span class=n>InferenceSession</span><span class=p>(</span><span class=s1>'model.onnx'</span><span class=p>)</span>

<span class=c1># 5. Create API endpoint</span>
<span class=c1># See deployment section above</span>

<span class=c1># 6. Containerize with Docker</span>
<span class=c1># See Docker section above</span>

<span class=c1># 7. Set up monitoring and logging</span>
<span class=c1># Track inference time, memory usage, error rates</span>

<span class=c1># 8. Implement versioning</span>
<span class=c1># Use model registry (MLflow, DVC, etc.)</span>
</code></pre></div> <h3 id=development-tips><span class="enumerate-headings-plugin enumerate-heading-plugin">1.20.7</span> Development Tips</h3> <ul> <li><strong>Virtual Environments:</strong> Use <code>conda</code> or <code>venv</code> to isolate dependencies</li> <li><strong>Code Style:</strong> Follow PEP 8, use <code>black</code> for formatting</li> <li><strong>Version Control:</strong> Use Git, commit frequently with meaningful messages</li> <li><strong>Testing:</strong> Write unit tests for data loading, model forward pass, etc.</li> <li><strong>Documentation:</strong> Add docstrings to classes and functions</li> <li><strong>GPU Memory:</strong> Monitor with <code>nvidia-smi</code> or <code>torch.cuda.memory_summary()</code></li> <li><strong>Hyperparameter Tuning:</strong> Use Optuna, Ray Tune, or Weights &amp; Biases</li> <li><strong>Model Compression:</strong> Quantization, pruning, knowledge distillation</li> <li><strong>Regular Updates:</strong> Keep PyTorch and dependencies up to date</li> <li><strong>Experiment Tracking:</strong> Use MLflow, Weights &amp; Biases, or TensorBoard</li> </ul> <h2 id=quick-reference><span class="enumerate-headings-plugin enumerate-heading-plugin">1.21</span> Quick Reference</h2> <h3 id=essential-operations><span class="enumerate-headings-plugin enumerate-heading-plugin">1.21.1</span> Essential Operations</h3> <div class=highlight><pre><span></span><code><span class=c1># Tensor creation</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>])</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>

<span class=c1># Tensor operations</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=mi>12</span><span class=p>)</span>           <span class=c1># Reshape</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>      <span class=c1># Transpose</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>       <span class=c1># Add dimension</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>squeeze</span><span class=p>()</span>          <span class=c1># Remove dimensions of size 1</span>

<span class=c1># Move to device</span>
<span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>"cuda"</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>"cpu"</span><span class=p>)</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

<span class=c1># Gradient tracking</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=mf>1.0</span><span class=p>],</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>x</span> <span class=o>**</span> <span class=mi>2</span>
<span class=n>y</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=p>)</span>  <span class=c1># dy/dx</span>

<span class=c1># No gradient context</span>
<span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
    <span class=n>y</span> <span class=o>=</span> <span class=n>x</span> <span class=o>*</span> <span class=mi>2</span>
</code></pre></div> <h3 id=training-template><span class="enumerate-headings-plugin enumerate-heading-plugin">1.21.2</span> Training Template</h3> <div class=highlight><pre><span></span><code><span class=c1># Setup</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>MyModel</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
<span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
<span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>

<span class=c1># Training loop</span>
<span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
    <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
        <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>labels</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

    <span class=c1># Validation</span>
    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
        <span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>val_loader</span><span class=p>:</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
            <span class=c1># Calculate metrics</span>
</code></pre></div> <h3 id=common-layer-patterns><span class="enumerate-headings-plugin enumerate-heading-plugin">1.21.3</span> Common Layer Patterns</h3> <div class=highlight><pre><span></span><code><span class=c1># Conv block</span>
<span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(</span><span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
<span class=p>)</span>

<span class=c1># Dense block</span>
<span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>in_features</span><span class=p>,</span> <span class=n>out_features</span><span class=p>),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
    <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span>
<span class=p>)</span>

<span class=c1># Residual connection</span>
<span class=n>out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
<span class=n>out</span> <span class=o>=</span> <span class=n>out</span> <span class=o>+</span> <span class=n>x</span>  <span class=c1># Skip connection</span>
</code></pre></div> <h3 id=useful-commands><span class="enumerate-headings-plugin enumerate-heading-plugin">1.21.4</span> Useful Commands</h3> <div class=highlight><pre><span></span><code><span class=c1># Model info</span>
<span class=nb>print</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
<span class=n>total_params</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>

<span class=c1># Save/Load</span>
<span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span> <span class=s1>'model.pth'</span><span class=p>)</span>
<span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>'model.pth'</span><span class=p>))</span>

<span class=c1># Learning rate</span>
<span class=k>for</span> <span class=n>param_group</span> <span class=ow>in</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>param_group</span><span class=p>[</span><span class=s1>'lr'</span><span class=p>])</span>
    <span class=n>param_group</span><span class=p>[</span><span class=s1>'lr'</span><span class=p>]</span> <span class=o>=</span> <span class=mf>0.0001</span>  <span class=c1># Update LR</span>

<span class=c1># Freeze layers</span>
<span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
    <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>False</span>

<span class=c1># GPU memory</span>
<span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"GPU: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Memory: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>memory_allocated</span><span class=p>()</span><span class=o>/</span><span class=mf>1e9</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>GB"</span><span class=p>)</span>
</code></pre></div> <h3 id=performance-tips><span class="enumerate-headings-plugin enumerate-heading-plugin">1.21.5</span> Performance Tips</h3> <div class=highlight><pre><span></span><code><span class=c1># Speed up training</span>
<span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>benchmark</span> <span class=o>=</span> <span class=kc>True</span>

<span class=c1># Mixed precision</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.cuda.amp</span><span class=w> </span><span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>
<span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>

<span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>

<span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
<span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
<span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>

<span class=c1># Gradient clipping</span>
<span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>

<span class=c1># DataLoader optimization</span>
<span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> 
          <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>persistent_workers</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <hr> <p><strong>Happy PyTorch Coding!</strong> üî•</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button class="md-top md-icon" data-md-component=top hidden type=button> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright ¬© 2020 - <script>document.write(/\d{4}/.exec(Date())[0])</script> ‚Ä¢ <strong>Kuldeep Singh Sidhu</strong> ‚Ä¢ <u><a href=https://choosealicense.com/licenses/agpl-3.0/ target=‚Äù_blank‚Äù>License</a></u> ‚Ä¢ <u><a href=/privacy>Privacy Policy</a></u> ‚Ä¢ <u><a href=/contact>Contact</a></u> ‚Ä¢ </div> </div> <div class=md-social> <a class=md-social__link href=https://github.com/singhsidhukuldeep/ rel=noopener target=_blank title=github.com> <svg viewbox="0 0 16 16" xmlns=http://www.w3.org/2000/svg><path d="M8 0c4.42 0 8 3.58 8 8a8.01 8.01 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27s-1.36.09-2 .27c-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8"></path></svg> </a> <a class=md-social__link href=https://linkedin.com/in/singhsidhukuldeep rel=noopener target=_blank title=linkedin.com> <svg viewbox="0 0 448 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"></path></svg> </a> <a class=md-social__link href=https://twitter.com/kuldeep_s_s rel=noopener target=_blank title=twitter.com> <svg viewbox="0 0 512 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"></path></svg> </a> <a class=md-social__link href=https://stackoverflow.com/u/7182350/ rel=noopener target=_blank title=stackoverflow.com> <svg viewbox="0 0 384 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M290.7 311 95 269.7 86.8 309l195.7 41zm51-87L188.2 95.7l-25.5 30.8 153.5 128.3zm-31.2 39.7L129.2 179l-16.7 36.5L293.7 300zM262 32l-32 24 119.3 160.3 32-24zm20.5 328h-200v39.7h200zm39.7 80H42.7V320h-40v160h359.5V320h-40z"></path></svg> </a> <a class=md-social__link href=https://huggingface.co/singhsidhukuldeep rel=noopener target=_blank title=huggingface.co> <svg fill=none height=463 viewbox="0 0 500 463" width=500 xmlns=http://www.w3.org/2000/svg> <path d="M496.592 369.699C500.563 381.093 499.61 393.227 494.315 403.778C490.503 411.48 485.05 417.441 478.379 422.769C470.331 429.099 460.324 434.48 448.253 439.65C433.852 445.77 416.274 451.52 408.226 453.63C387.63 458.958 367.829 462.334 347.762 462.493C319.066 462.756 294.34 456.004 276.762 438.753C267.656 439.861 258.443 440.494 249.178 440.494C240.389 440.494 231.706 439.967 223.076 438.912C205.445 456.057 180.825 462.756 152.234 462.493C132.168 462.334 112.366 458.958 91.7177 453.63C83.7229 451.52 66.145 445.77 51.7439 439.65C39.6723 434.48 29.6656 429.099 21.6708 422.769C14.9467 417.441 9.49334 411.48 5.68127 403.778C0.439661 393.227 -0.566304 381.093 3.45755 369.699C-0.248631 360.994 -1.20165 351.024 1.71035 339.998C3.03399 334.987 5.20476 330.344 7.95792 326.229C7.37552 324.067 6.89901 321.851 6.58134 319.424C4.56941 304.97 9.59923 291.781 19.0765 281.547C23.7357 276.43 28.7655 272.895 34.0071 270.627C30.1421 254.273 28.1302 237.445 28.1302 220.247C28.1302 98.5969 127.085 0 249.178 0C291.111 0 330.343 11.6058 363.805 31.8633C369.84 35.5561 375.77 39.5126 381.436 43.7329C384.242 45.8431 387.048 48.006 389.748 50.2744C392.501 52.49 395.201 54.8112 397.796 57.1851C405.632 64.3069 412.991 71.9562 419.715 80.133C421.992 82.8235 424.163 85.6194 426.28 88.4681C430.569 94.1128 434.54 99.9685 438.193 106.035C443.752 115.109 448.623 124.604 452.859 134.469C455.665 141.064 458.101 147.816 460.271 154.727C463.501 165.067 465.99 175.723 467.684 186.696C468.213 190.336 468.69 194.028 469.06 197.721C469.802 205.107 470.225 212.598 470.225 220.247C470.225 237.234 468.213 253.904 464.454 269.994C470.278 272.262 475.784 275.955 480.92 281.547C490.397 291.781 495.427 305.022 493.415 319.477C493.098 321.851 492.621 324.067 492.039 326.229C494.792 330.344 496.963 334.987 498.286 339.998C501.198 351.024 500.245 360.994 496.592 369.699Z" fill=white></path> <path d="M433.839 221.75C433.839 120.838 351.531 39.0323 250 39.0323C148.469 39.0323 66.1613 120.838 66.1613 221.75C66.1613 322.662 148.469 404.468 250 404.468C351.531 404.468 433.839 322.662 433.839 221.75ZM45 221.75C45 109.222 136.782 18 250 18C363.218 18 455 109.222 455 221.75C455 334.278 363.218 425.5 250 425.5C136.782 425.5 45 334.278 45 221.75Z" fill=black></path> <path d="M250 405.5C352.173 405.5 435 323.232 435 221.75C435 120.268 352.173 38 250 38C147.827 38 65 120.268 65 221.75C65 323.232 147.827 405.5 250 405.5Z" fill=white></path> <path d="M202.198 404.174C216.789 383.118 215.755 367.316 195.735 347.627C175.715 327.943 164.062 299.145 164.062 299.145C164.062 299.145 159.709 282.419 149.794 283.958C139.88 285.497 132.6 310.492 153.368 325.783C174.135 341.069 149.232 351.456 141.242 337.099C133.252 322.741 111.435 285.831 100.121 278.772C88.8117 271.713 80.8483 275.668 83.5151 290.218C86.182 304.769 133.48 340.036 128.878 347.668C124.276 355.296 108.058 338.7 108.058 338.7C108.058 338.7 57.3079 293.255 46.2587 305.097C35.2096 316.94 54.641 326.863 82.3328 343.359C110.03 359.85 112.177 364.206 108.248 370.446C104.314 376.685 43.1836 325.971 37.4417 347.47C31.705 368.969 99.8291 375.209 95.6247 390.051C91.4203 404.899 47.6372 361.958 38.6823 378.689C29.7221 395.425 100.465 415.088 101.038 415.234C123.889 421.067 181.924 433.426 202.198 404.174Z" fill=white></path> <path d="M90.9935 255C82.4744 255 74.8603 258.477 69.551 264.784C66.2675 268.69 62.8367 274.986 62.5578 284.414C58.985 283.394 55.5489 282.824 52.3391 282.824C44.183 282.824 36.8163 285.93 31.6069 291.573C24.9137 298.815 21.9407 307.715 23.2351 316.62C23.8508 320.861 25.2768 324.663 27.4079 328.182C22.9142 331.795 19.6044 336.826 18.0047 342.876C16.7524 347.619 15.4685 357.497 22.1722 367.673C21.746 368.337 21.3461 369.027 20.9725 369.733C16.9418 377.336 16.684 385.927 20.2411 393.928C25.6346 406.054 39.0368 415.608 65.0625 425.863C81.2536 432.242 96.0661 436.321 96.1976 436.357C117.603 441.874 136.962 444.677 153.721 444.677C184.525 444.677 206.578 435.301 219.27 416.811C239.697 387.036 236.776 359.803 210.346 333.552C195.717 319.026 185.993 297.607 183.967 292.906C179.884 278.986 169.086 263.513 151.138 263.513H151.133C149.622 263.513 148.096 263.633 146.592 263.869C138.73 265.097 131.858 269.595 126.949 276.361C121.65 269.814 116.504 264.606 111.847 261.667C104.827 257.243 97.813 255 90.9935 255ZM90.9935 275.917C93.6771 275.917 96.9553 277.051 100.57 279.331C111.794 286.406 133.452 323.403 141.382 337.793C144.039 342.614 148.581 344.654 152.669 344.654C160.783 344.654 167.118 336.638 153.411 326.451C132.8 311.124 140.03 286.072 149.87 284.529C150.301 284.461 150.727 284.43 151.138 284.43C160.083 284.43 164.03 299.751 164.03 299.751C164.03 299.751 175.595 328.616 195.465 348.346C215.334 368.08 216.36 383.919 201.879 405.024C192.002 419.415 173.096 421.292 153.721 421.292C133.626 421.292 112.99 417.772 101.445 414.796C100.877 414.65 30.7019 396.255 39.5946 379.48C41.089 376.661 43.5516 375.532 46.6509 375.532C59.1744 375.532 81.9535 394.054 91.746 394.054C93.935 394.054 95.5662 392.371 96.1976 390.112C100.555 374.522 32.6646 369.738 38.3633 348.189C39.3683 344.377 42.094 342.829 45.9248 342.834C62.4737 342.834 99.6021 371.756 107.385 371.756C107.979 371.756 108.405 371.584 108.637 371.218C112.536 364.964 110.74 359.872 83.257 343.343C55.7738 326.808 36.1428 317.588 47.114 305.718C48.3768 304.347 50.1659 303.741 52.3391 303.741C69.0248 303.746 108.447 339.398 108.447 339.398C108.447 339.398 119.087 350.395 125.523 350.395C127.001 350.395 128.259 349.815 129.111 348.382C133.673 340.737 86.7366 305.388 84.0898 290.804C82.2955 280.921 85.3474 275.917 90.9935 275.917Z" fill=black></path> <path d="M296.9 404.174C282.31 383.118 283.343 367.316 303.363 347.627C323.383 327.943 335.037 299.145 335.037 299.145C335.037 299.145 339.39 282.419 349.304 283.958C359.219 285.497 366.498 310.492 345.731 325.783C324.963 341.069 349.866 351.456 357.856 337.099C365.846 322.741 387.663 285.831 398.978 278.772C410.287 271.713 418.25 275.668 415.583 290.218C412.916 304.769 365.618 340.036 370.22 347.668C374.822 355.296 391.041 338.7 391.041 338.7C391.041 338.7 441.791 293.255 452.84 305.097C463.889 316.94 444.457 326.863 416.766 343.359C389.068 359.85 386.921 364.206 390.85 370.446C394.784 376.685 455.915 325.971 461.657 347.47C467.393 368.969 399.269 375.209 403.474 390.051C407.678 404.899 451.461 361.958 460.416 378.689C469.376 395.425 398.633 415.088 398.06 415.234C375.209 421.067 317.175 433.426 296.9 404.174Z" fill=white></path> <path d="M408.105 255C416.624 255 424.238 258.477 429.547 264.784C432.831 268.69 436.262 274.986 436.541 284.414C440.113 283.394 443.549 282.824 446.759 282.824C454.915 282.824 462.282 285.93 467.491 291.573C474.185 298.815 477.158 307.715 475.863 316.62C475.248 320.861 473.822 324.663 471.69 328.182C476.184 331.795 479.494 336.826 481.094 342.876C482.346 347.619 483.63 357.497 476.926 367.673C477.352 368.337 477.752 369.027 478.126 369.733C482.157 377.336 482.414 385.927 478.857 393.928C473.464 406.054 460.062 415.608 434.036 425.863C417.845 432.242 403.032 436.321 402.901 436.357C381.495 441.874 362.136 444.677 345.377 444.677C314.573 444.677 292.52 435.301 279.829 416.811C259.402 387.036 262.322 359.803 288.753 333.552C303.381 319.026 313.105 297.607 315.131 292.906C319.214 278.986 330.012 263.513 347.961 263.513H347.966C349.476 263.513 351.002 263.633 352.507 263.869C360.368 265.097 367.24 269.595 372.15 276.361C377.449 269.814 382.595 264.606 387.252 261.667C394.271 257.243 401.285 255 408.105 255ZM408.105 275.917C405.421 275.917 402.143 277.051 398.528 279.331C387.304 286.406 365.646 323.403 357.716 337.793C355.059 342.614 350.518 344.654 346.429 344.654C338.315 344.654 331.98 336.638 345.687 326.451C366.299 311.124 359.069 286.072 349.229 284.529C348.797 284.461 348.371 284.43 347.961 284.43C339.015 284.43 335.069 299.751 335.069 299.751C335.069 299.751 323.503 328.616 303.634 348.346C283.764 368.08 282.738 383.919 297.219 405.024C307.096 419.415 326.002 421.292 345.377 421.292C365.472 421.292 386.108 417.772 397.653 414.796C398.221 414.65 468.397 396.255 459.504 379.48C458.009 376.661 455.547 375.532 452.447 375.532C439.924 375.532 417.145 394.054 407.352 394.054C405.163 394.054 403.532 392.371 402.901 390.112C398.543 374.522 466.434 369.738 460.735 348.189C459.73 344.377 457.004 342.829 453.174 342.834C436.625 342.834 399.496 371.756 391.714 371.756C391.119 371.756 390.693 371.584 390.461 371.218C386.562 364.964 388.358 359.872 415.841 343.343C443.325 326.808 462.956 317.588 451.984 305.718C450.722 304.347 448.932 303.741 446.759 303.741C430.074 303.746 390.651 339.398 390.651 339.398C390.651 339.398 380.011 350.395 373.576 350.395C372.097 350.395 370.84 349.815 369.987 348.382C365.425 340.737 412.362 305.388 415.009 290.804C416.803 280.921 413.751 275.917 408.105 275.917Z" fill=black></path> <path d="M319.277 228.901C319.277 205.236 288.585 241.304 250.637 241.465C212.692 241.306 182 205.238 182 228.901C182 244.591 189.507 270.109 209.669 285.591C213.681 271.787 235.726 260.729 238.877 262.317C243.364 264.578 243.112 270.844 250.637 276.365C258.163 270.844 257.911 264.58 262.398 262.317C265.551 260.729 287.594 271.787 291.605 285.591C311.767 270.109 319.275 244.591 319.275 228.903L319.277 228.901Z" fill=#0E1116></path> <path d="M262.4 262.315C257.913 264.576 258.165 270.842 250.639 276.363C243.114 270.842 243.366 264.578 238.879 262.315C235.726 260.727 213.683 271.785 209.672 285.589C219.866 293.417 233.297 298.678 250.627 298.806C250.631 298.806 250.635 298.806 250.641 298.806C250.646 298.806 250.65 298.806 250.656 298.806C267.986 298.68 281.417 293.417 291.611 285.589C287.6 271.785 265.555 260.727 262.404 262.315H262.4Z" fill=#FF323D></path> <path d="M373 196C382.389 196 390 188.389 390 179C390 169.611 382.389 162 373 162C363.611 162 356 169.611 356 179C356 188.389 363.611 196 373 196Z" fill=black></path> <path d="M128 196C137.389 196 145 188.389 145 179C145 169.611 137.389 162 128 162C118.611 162 111 169.611 111 179C111 188.389 118.611 196 128 196Z" fill=black></path> <path d="M313.06 171.596C319.796 173.968 322.476 187.779 329.281 184.171C342.167 177.337 347.06 161.377 340.208 148.524C333.356 135.671 317.354 130.792 304.467 137.626C291.58 144.46 286.688 160.419 293.54 173.272C296.774 179.339 307.039 169.475 313.06 171.596Z" fill=#0E1116></path> <path d="M188.554 171.596C181.818 173.968 179.138 187.779 172.334 184.171C159.447 177.337 154.555 161.377 161.407 148.524C168.259 135.671 184.26 130.792 197.147 137.626C210.034 144.46 214.926 160.419 208.074 173.272C204.84 179.339 194.575 169.475 188.554 171.596Z" fill=#0E1116></path> </svg> </a> <a class=md-social__link href=http://kuldeepsinghsidhu.com rel=noopener target=_blank title=kuldeepsinghsidhu.com> <svg viewbox="0 0 16 16" xmlns=http://www.w3.org/2000/svg><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0M5.78 8.75a9.64 9.64 0 0 0 1.363 4.177q.383.64.857 1.215c.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a10 10 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.51 6.51 0 0 0 4.666 5.5q-.184-.271-.352-.552c-.715-1.192-1.437-2.874-1.581-4.948m-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948q.18-.295.353-.552a6.51 6.51 0 0 0-4.666 5.5m10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948q-.18.296-.353.552a6.51 6.51 0 0 0 4.666-5.5Zm2.733-1.5a6.51 6.51 0 0 0-4.666-5.5q.184.272.353.552c.714 1.192 1.436 2.874 1.58 4.948Z"></path></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "search.highlight", "search.share", "search.suggest", "content.tooltips", "navigation.instant.progress", "navigation.path", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.60a45f97.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../javascripts/xfile.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>