{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Crack Data Science Interviews","text":"<ul> <li>  Interview Questions <p>These are currently most commonly asked interview questions. </p> <p>Questions can be removed if they are no longer popular in interview circles and added as new question banks are released.</p> <ul> <li>DSA (Data Structures &amp; Algorithms)</li> <li>System Design</li> <li>Natural Language Processing (NLP)</li> <li>Probability</li> <li>ML-Algorithms</li> </ul> </li> <li> Cheat Sheets <p>Distilled down important concepts for your quick reference</p> <ul> <li>Cheat-Sheets/Django</li> <li>Cheat-Sheets/Flask</li> <li>Cheat-Sheets/Hypothesis-Tests</li> <li>Cheat-Sheets/Keras</li> <li>Cheat-Sheets/NumPy</li> <li>Cheat-Sheets/Pandas</li> <li>Cheat-Sheets/PySpark</li> <li>Cheat-Sheets/PyTorch</li> <li>Cheat-Sheets/Python</li> <li>Cheat-Sheets/RegEx</li> <li>Cheat-Sheets/Sk-learn</li> <li>Cheat-Sheets/SQL</li> <li>Cheat-Sheets/tensorflow</li> </ul> </li> <li> ML Algorithms <p>From scratch implementation and documentation of all ML algorithms</p> <ul> <li>ARIMA</li> <li>Activation functions</li> <li>Collaborative Filtering</li> <li>Confusion Matrix</li> <li>DBSCAN</li> <li>Decision Trees</li> <li>Gradient Boosting</li> <li>K-means clustering</li> <li>Linear Regression</li> <li>Logistic Regression</li> <li>Loss Function MAE, RMSE</li> <li>Neural Networks</li> <li>Normal Distribution</li> <li>Normalization Regularisation</li> <li>Overfitting, Underfitting</li> <li>PCA</li> <li>Random Forest</li> <li>Support Vector Machines</li> <li>Unbalanced, Skewed data</li> <li>kNN</li> </ul> </li> <li> Online Resources <p>Most popular and commonly reffered online resources</p> <ul> <li>Online Study Material</li> <li>Popular Blogs</li> </ul> </li> </ul> <p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews. You can also improve topics and articles.</p> Current Platform Status  Done Under Development To Do About <ul> <li>Cheat-Sheets/Django</li> <li>Cheat-Sheets/Flask</li> <li>Cheat-Sheets/Hypothesis-Tests</li> <li>Cheat-Sheets/Keras</li> <li>Cheat-Sheets/NumPy</li> <li>Cheat-Sheets/Pandas</li> <li>Cheat-Sheets/PySpark</li> <li>Cheat-Sheets/PyTorch</li> <li>Cheat-Sheets/Python</li> <li>Cheat-Sheets/RegEx</li> <li>Cheat-Sheets/Sk-learn</li> <li>Cheat-Sheets/SQL</li> <li>Cheat-Sheets/tensorflow</li> <li>Interview-Questions/DSA</li> <li>Interview-Questions/System-Design</li> <li>Interview-Questions/Natural-Language-Processing</li> <li>Interview-Questions/Probability</li> <li>Interview-Questions/ML-Algorithms</li> </ul> <p>Learn about How to contribute?  You can pick anyone, write in <code>.py</code>, <code>.md</code>, <code>.txt</code> or <code>.ipynb</code>; I will format it!</p> <ul> <li>Machine-Learning/ARIMA</li> <li>Machine-Learning/Activation-Functions</li> <li>Machine-Learning/Collaborative-Filtering</li> <li>Machine-Learning/Confusion-Matrix</li> <li>Machine-Learning/DBSCAN</li> <li>Machine-Learning/Decision-Trees</li> <li>Machine-Learning/Gradient-Boosting</li> <li>Machine-Learning/K-means-Clustering</li> <li>Machine-Learning/Linear-Regression</li> <li>Machine-Learning/Logistic-Regression</li> <li>Machine-Learning/Loss-Function-MAE-RMSE</li> <li>Machine-Learning/Neural-Networks</li> <li>Machine-Learning/Normal-Distribution</li> <li>Machine-Learning/Normalization-Regularisation</li> <li>Machine-Learning/Overfitting-Underfitting</li> <li>Machine-Learning/PCA</li> <li>Machine-Learning/Random-Forest</li> <li>Machine-Learning/Support-Vector-Machines</li> <li>Machine-Learning/Unbalanced-Skewed-Data</li> <li>Machine-Learning/kNN</li> <li>Online-Material/Online-Material-for-Learning</li> <li>Online-Material/Popular-Blogs</li> </ul> <p> Useful Commands </p> <ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Use\u00a0<code>mkdocs gh-deploy --help</code>\u00a0to get a full list of options available for the\u00a0<code>gh-deploy</code>\u00a0command.     Be aware that you will not be able to review the built site before it is pushed to GitHub. Therefore, you may want to verify any changes you make to the docs beforehand by using the\u00a0<code>build</code>\u00a0or\u00a0<code>serve</code>\u00a0commands and reviewing the built files locally.</li> <li><code>mkdocs new [dir-name]</code> - Create a new project. No need to create a new project</li> </ul> <p> Useful Documents </p> <ul> <li> <p>\ud83d\udcd1 MkDocs: </p> <ul> <li>GitHub: https://github.com/mkdocs/mkdocs</li> <li>Documentation: https://www.mkdocs.org/</li> </ul> </li> <li> <p>\ud83c\udfa8 Theme: </p> <ul> <li>GitHub: https://github.com/squidfunk/mkdocs-material</li> <li>Documentation: https://squidfunk.github.io/mkdocs-material/getting-started/</li> </ul> </li> </ul> <ul> <li>:: Project Maintainer</li> <li> All Contributors list</li> <li> AGPL-3.0 license</li> <li> Reach Out</li> </ul> <ul> <li>:: Project Maintainer</li> <li> All Contributors list</li> </ul>"},{"location":"Contribute/","title":"Contributions to singhsidhukuldeep.github.io","text":"<p>For any correspondence please check contact</p> <p>Detailed step by step contributions guide coming soon!</p> <p>For now, plese open a discussion here for anything!</p> <p>List of things to contribute!</p> <p>Thank you, Kuldeep</p>"},{"location":"Introduction/","title":"Home","text":""},{"location":"Introduction/#introduction","title":"Introduction","text":"<p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews.</p>"},{"location":"Introduction/#contribute-to-the-platform","title":"Contribute to the platform","text":"<p>Contribution in any form will be deeply appreciated. \ud83d\ude4f</p>"},{"location":"Introduction/#add-questions","title":"Add questions","text":"<p>\u2753 Add your questions here. Please ensure to provide a detailed description to allow your fellow contributors to understand your questions and answer them to your satisfaction.</p> <p></p> <p>\ud83e\udd1d Please note that as of now, you cannot directly add a question via a pull request. This will help us to maintain the quality of the content for you.</p>"},{"location":"Introduction/#add-answerstopics","title":"Add answers/topics","text":"<p>\ud83d\udcdd These are the answers/topics that need your help at the moment</p> <ul> <li> Add documentation for the project</li> <li> Online Material for Learning</li> <li> Suggested Learning Paths</li> <li> Cheat Sheets<ul> <li> Django</li> <li> Flask</li> <li> Numpy</li> <li> Pandas</li> <li> PySpark</li> <li> Python</li> <li> RegEx</li> <li> SQL</li> </ul> </li> <li> NLP Interview Questions</li> <li> Add python common DSA interview questions</li> <li> Add Major ML topics<ul> <li> Linear Regression </li> <li> Logistic Regression </li> <li> SVM </li> <li> Random Forest </li> <li> Gradient boosting </li> <li> PCA </li> <li> Collaborative Filtering </li> <li> K-means clustering </li> <li> kNN </li> <li> ARIMA </li> <li> Neural Networks </li> <li> Decision Trees </li> <li> Overfitting, Underfitting</li> <li> Unbalanced, Skewed data</li> <li> Activation functions relu/ leaky relu</li> <li> Normalization</li> <li> DBSCAN </li> <li> Normal Distribution </li> <li> Precision, Recall </li> <li> Loss Function MAE, RMSE </li> </ul> </li> <li> Add Pandas questions</li> <li> Add NumPy questions</li> <li> Add TensorFlow questions</li> <li> Add PyTorch questions</li> <li> Add list of learning resources</li> </ul>"},{"location":"Introduction/#reportsolve-issues","title":"Report/Solve Issues","text":"<p>\ud83d\udd27 To report any issues find me on LinkedIn or raise an issue on GitHub.</p> <p>\ud83d\udee0 You can also solve existing issues on GitHub and create a pull request.</p>"},{"location":"Introduction/#say-thanks","title":"Say Thanks","text":"<p>\ud83d\ude0a If this platform helped you in any way, it would be great if you could share it with others.</p> <p> </p> <pre><code>Check out this \ud83d\udc47 platform \ud83d\udc47 for data science content:\n\ud83d\udc49 https://singhsidhukuldeep.github.io/data-science-interview-prep/ \ud83d\udc48\n</code></pre> <p>You can also star the repository on GitHub    and watch-out for any updates </p>"},{"location":"Introduction/#features","title":"Features","text":"<ul> <li> <p>\ud83c\udfa8 Beautiful: The design is built on top of most popular libraries like MkDocs and material which allows the platform to be responsive and to work on all sorts of devices \u2013 from mobile phones to wide-screens. The underlying fluid layout will always adapt perfectly to the available screen space.</p> </li> <li> <p>\ud83e\uddd0 Searchable: almost magically, all the content on the website is searchable without any further ado. The built-in search \u2013 server-less \u2013 is fast and accurate in responses to any of the queries.</p> </li> <li> <p>\ud83d\ude4c Accessible:</p> <ul> <li>Easy to use: \ud83d\udc4c The website is hosted on github-pages and is free and open to use to over 40 million users of GitHub in 100+ countries.</li> <li>Easy to contribute: \ud83e\udd1d The website embodies the concept of collaboration to the latter. Allowing anyone to add/improve the content. To make contributing easy, everything is written in MarkDown and then compiled to beautiful html.</li> </ul> </li> </ul>"},{"location":"Introduction/#setup","title":"Setup","text":"<p>No setup is required for usage of the platform</p> <p>Important: It is strongly advised to use virtual environment and not change anything in <code>gh-pages</code></p>"},{"location":"Introduction/#linux-systems","title":"<code>Linux</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nsource venv/bin/activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>deactivate\n</code></pre>"},{"location":"Introduction/#windows-systems","title":"<code>Windows</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nvenv\\Scripts\\activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>venv\\Scripts\\deactivate\n</code></pre>"},{"location":"Introduction/#to-install-the-latest","title":"To install the latest","text":"<pre><code>pip3 install mkdocs\npip3 install mkdocs-material\npip3 install mkdocs-minify-plugin\npip3 install mkdocs-git-revision-date-localized-plugin\n</code></pre>"},{"location":"Introduction/#useful-commands","title":"Useful Commands","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Use\u00a0<code>mkdocs gh-deploy --help</code>\u00a0to get a full list of options available for the\u00a0<code>gh-deploy</code>\u00a0command.     Be aware that you will not be able to review the built site before it is pushed to GitHub. Therefore, you may want to verify any changes you make to the docs beforehand by using the\u00a0<code>build</code>\u00a0or\u00a0<code>serve</code>\u00a0commands and reviewing the built files locally.</li> <li><code>mkdocs new [dir-name]</code> - Create a new project. No need to create a new project</li> </ul>"},{"location":"Introduction/#useful-documents","title":"Useful Documents","text":"<ul> <li> <p>\ud83d\udcd1 MkDocs: </p> <ul> <li>GitHub: https://github.com/mkdocs/mkdocs</li> <li>Documentation: https://www.mkdocs.org/</li> </ul> </li> <li> <p>\ud83c\udfa8 Theme: </p> <ul> <li>GitHub: https://github.com/squidfunk/mkdocs-material</li> <li>Documentation: https://squidfunk.github.io/mkdocs-material/getting-started/</li> </ul> </li> </ul>"},{"location":"Introduction/#faq","title":"FAQ","text":"<ul> <li> <p>Can I filter questions based on companies? \ud83e\udd2a</p> <p>As much as this platform aims to help you with your interview preparation, it is not a short-cut to crack one. Think of this platform as a practicing field to help you sharpen your skills for your interview processes. However, for your convenience we have sorted all the questions by topics for you. \ud83e\udd13</p> <p>This doesn't mean that such feature won't be added in the future.  \"Never say Never\"</p> <p>But as of now there is neither plan nor data to do so. \ud83d\ude22</p> </li> <li> <p>Why is this platform free? \ud83e\udd17</p> <p>Currently there is no major cost involved in maintaining this platform other than time and effort that is put in by every contributor.  If you want to help you can contribute here. </p> <p>If you still want to pay for something that is free, we would request you to donate it to a charity of your choice instead. \ud83d\ude07</p> </li> </ul>"},{"location":"Introduction/#credits","title":"Credits","text":""},{"location":"Introduction/#maintained-by","title":"Maintained by","text":"<p>\ud83d\udc68\u200d\ud83c\udf93 Kuldeep Singh Sidhu </p> <p>Github: github/singhsidhukuldeep <code>https://github.com/singhsidhukuldeep</code></p> <p>Website: Kuldeep Singh Sidhu (Website) <code>http://kuldeepsinghsidhu.com</code></p> <p>LinkedIn: Kuldeep Singh Sidhu (LinkedIn) <code>https://www.linkedin.com/in/singhsidhukuldeep/</code></p>"},{"location":"Introduction/#contributors","title":"Contributors","text":"<p>\ud83d\ude0e The full list of all the contributors is available here</p>"},{"location":"Introduction/#current-status","title":"Current Status","text":""},{"location":"contact/","title":"Contact for https://singhsidhukuldeep.github.io","text":"<p>Welcome to https://singhsidhukuldeep.github.io/ </p> <p>For any information, request or official correspondence please email to: singhsidhukuldeep@gmail.com</p> <p>Mailing Address:</p> <p>Kuldeep Singh Sidhu</p> <p>Street No 4, Malviya Nagar Bathinda, Punjab, 151001 India</p>"},{"location":"contact/#follow-on-social-media","title":"Follow on Social Media","text":"Platform Link GitHub https://github.com/singhsidhukuldeep LinkedIn https://www.linkedin.com/in/singhsidhukuldeep/ Twitter (X) https://twitter.com/kuldeep_s_s HuggingFace https://huggingface.co/singhsidhukuldeep StackOverflow https://stackoverflow.com/users/7182350 Website http://kuldeepsinghsidhu.com/"},{"location":"privacy/","title":"Privacy Policy for https://singhsidhukuldeep.github.io","text":""},{"location":"privacy/#introduction","title":"Introduction","text":"<p>Welcome to https://singhsidhukuldeep.github.io/ (the \"Website\"). Your privacy is important to us, and we are committed to protecting the personal information you share with us. This Privacy Policy explains how we collect, use, and disclose your information, and our commitment to ensuring that your personal data is handled with care and security.</p> <p>This policy complies with the General Data Protection Regulation (GDPR), ePrivacy Directive (EPD), California Privacy Rights Act (CPRA), Colorado Privacy Act (CPA), Virginia Consumer Data Protection Act (VCDPA), and Brazil's Lei Geral de Prote\u00e7\u00e3o de Dados (LGPD).</p>"},{"location":"privacy/#information-we-collect","title":"Information We Collect","text":""},{"location":"privacy/#personal-information","title":"Personal Information","text":"<p>We may collect personally identifiable information about you, such as:</p> <ul> <li>Name</li> <li>Email address</li> <li>IP address</li> <li>Other information you voluntarily provide through contact forms or interactions with the Website</li> </ul>"},{"location":"privacy/#non-personal-information","title":"Non-Personal Information","text":"<p>We may also collect non-personal information such as:</p> <ul> <li>Browser type</li> <li>Language preference</li> <li>Referring site</li> <li>Date and time of each visitor request</li> <li>Aggregated data on how visitors use the Website</li> </ul>"},{"location":"privacy/#cookies-and-web-beacons","title":"Cookies and Web Beacons","text":"<p>Our Website uses cookies to enhance your experience. A cookie is a small file that is placed on your device when you visit our Website. Cookies help us to:</p> <ul> <li>Remember your preferences and settings</li> <li>Understand how you interact with our Website</li> <li>Track and analyze usage patterns</li> </ul> <p>You can disable cookies through your browser settings; however, doing so may affect your ability to access certain features of the Website.</p>"},{"location":"privacy/#google-adsense","title":"Google AdSense","text":"<p>We use Google AdSense to display advertisements on our Website. Google AdSense may use cookies and web beacons to collect information about your interaction with the ads displayed on our Website. This information may include:</p> <ul> <li>Your IP address</li> <li>The type of browser you use</li> <li>The pages you visit on our Website</li> </ul> <p>Google may use this information to show you personalized ads based on your interests and browsing history. For more information on how Google uses your data, please visit the Google Privacy &amp; Terms page.</p>"},{"location":"privacy/#legal-bases-for-processing-your-data-gdpr-compliance","title":"Legal Bases for Processing Your Data (GDPR Compliance)","text":"<p>We process your personal data under the following legal bases:</p> <ul> <li>Consent: When you have given explicit consent for us to process your data for specific purposes.</li> <li>Contract: When processing your data is necessary to fulfill a contract with you or to take steps at your request before entering into a contract.</li> <li>Legitimate Interests: When the processing is necessary for our legitimate interests, such as improving our services, provided these are not overridden by your rights.</li> <li>Compliance with Legal Obligations: When we need to process your data to comply with a legal obligation.</li> </ul>"},{"location":"privacy/#how-your-data-will-be-used-to-show-ads","title":"How Your Data Will Be Used to Show Ads","text":"<p>We work with third-party vendors, including Google, to serve ads on our Website. These vendors use cookies and similar technologies to collect and use data about your visits to this and other websites to show you ads that are more relevant to your interests.</p>"},{"location":"privacy/#types-of-data-used","title":"Types of Data Used","text":"<p>The data used to show you ads may include:</p> <ul> <li>Demographic Information: Age, gender, and other demographic details</li> <li>Location Data: Approximate geographical location based on your IP address</li> <li>Behavioral Data: Your browsing behavior, such as pages visited, links clicked, and time spent on our Website</li> <li>Interests and Preferences: Based on your browsing history, the types of ads you interact with, and your preferences across websites</li> </ul>"},{"location":"privacy/#purpose-of-data-usage","title":"Purpose of Data Usage","text":"<p>The primary purpose of collecting and using this data is to:</p> <ul> <li>Serve ads that are relevant and tailored to your interests</li> <li>Improve ad targeting and effectiveness</li> <li>Analyze and optimize the performance of ads on our Website</li> </ul>"},{"location":"privacy/#opting-out-of-personalized-ads","title":"Opting Out of Personalized Ads","text":"<p>You can opt out of personalized ads by adjusting your ad settings with Google and other third-party vendors. For more information on how to opt out of personalized ads, please visit the Google Ads Settings page and review the options available to manage your preferences.</p>"},{"location":"privacy/#data-subject-rights-gdpr-cpra-cpa-vcdpa-lgpd-compliance","title":"Data Subject Rights (GDPR, CPRA, CPA, VCDPA, LGPD Compliance)","text":"<p>Depending on your jurisdiction, you have the following rights regarding your personal data:</p>"},{"location":"privacy/#right-to-access","title":"Right to Access","text":"<p>You have the right to request access to the personal data we hold about you and to receive a copy of this data.</p>"},{"location":"privacy/#right-to-rectification","title":"Right to Rectification","text":"<p>You have the right to request that we correct any inaccuracies in the personal data we hold about you.</p>"},{"location":"privacy/#right-to-erasure-right-to-be-forgotten","title":"Right to Erasure (Right to Be Forgotten)","text":"<p>You have the right to request that we delete your personal data, subject to certain conditions and legal obligations.</p>"},{"location":"privacy/#right-to-restriction-of-processing","title":"Right to Restriction of Processing","text":"<p>You have the right to request that we restrict the processing of your personal data in certain circumstances, such as when you contest the accuracy of the data.</p>"},{"location":"privacy/#right-to-data-portability","title":"Right to Data Portability","text":"<p>You have the right to receive your personal data in a structured, commonly used, and machine-readable format and to transmit this data to another controller.</p>"},{"location":"privacy/#right-to-object","title":"Right to Object","text":"<p>You have the right to object to the processing of your personal data based on legitimate interests or for direct marketing purposes.</p>"},{"location":"privacy/#right-to-withdraw-consent","title":"Right to Withdraw Consent","text":"<p>Where we rely on your consent to process your personal data, you have the right to withdraw your consent at any time.</p>"},{"location":"privacy/#right-to-non-discrimination-cpra-compliance","title":"Right to Non-Discrimination (CPRA Compliance)","text":"<p>We will not discriminate against you for exercising any of your privacy rights under CPRA or any other applicable laws.</p>"},{"location":"privacy/#exercising-your-rights","title":"Exercising Your Rights","text":"<p>To exercise any of these rights, please contact us at:</p> <p>Email: singhsidhukuldeep@gmail.com</p> <p>We will respond to your request within the timeframes required by applicable law.</p>"},{"location":"privacy/#how-we-use-your-information","title":"How We Use Your Information","text":"<p>We use the information collected from you to:</p> <ul> <li>Improve the content and functionality of our Website</li> <li>Display relevant advertisements through Google AdSense and other ad networks</li> <li>Respond to your inquiries and provide customer support</li> <li>Analyze usage patterns and improve our services</li> </ul>"},{"location":"privacy/#data-sharing-and-disclosure","title":"Data Sharing and Disclosure","text":""},{"location":"privacy/#third-party-service-providers","title":"Third-Party Service Providers","text":"<p>We may share your personal data with third-party service providers who assist us in operating our Website, conducting our business, or servicing you, as long as these parties agree to keep this information confidential.</p>"},{"location":"privacy/#legal-obligations","title":"Legal Obligations","text":"<p>We may disclose your personal data when required by law or to comply with legal processes, such as a court order or subpoena.</p>"},{"location":"privacy/#business-transfers","title":"Business Transfers","text":"<p>In the event of a merger, acquisition, or sale of all or a portion of our assets, your personal data may be transferred to the acquiring entity.</p>"},{"location":"privacy/#data-retention","title":"Data Retention","text":"<p>We will retain your personal data only for as long as necessary to fulfill the purposes outlined in this Privacy Policy unless a longer retention period is required or permitted by law.</p>"},{"location":"privacy/#data-security","title":"Data Security","text":"<p>We take reasonable measures to protect your information from unauthorized access, alteration, disclosure, or destruction. However, no method of transmission over the internet or electronic storage is 100% secure, and we cannot guarantee absolute security.</p>"},{"location":"privacy/#cross-border-data-transfers","title":"Cross-Border Data Transfers","text":"<p>Your personal data may be transferred to, and processed in, countries other than the country in which you are resident. These countries may have data protection laws that are different from the laws of your country.</p> <p>Where we transfer your personal data to other countries, we will take appropriate measures to ensure that your personal data remains protected in accordance with this Privacy Policy and applicable data protection laws.</p>"},{"location":"privacy/#your-consent","title":"Your Consent","text":"<p>By using our Website, you consent to our Privacy Policy and agree to its terms.</p>"},{"location":"privacy/#changes-to-this-privacy-policy","title":"Changes to This Privacy Policy","text":"<p>We may update this Privacy Policy from time to time. We will notify you of any changes by posting the new Privacy Policy on this page. You are advised to review this Privacy Policy periodically for any changes.</p>"},{"location":"privacy/#contact-us","title":"Contact Us","text":"<p>If you have any questions about this Privacy Policy, or if you would like to exercise your rights under GDPR, CPRA, CPA, VCDPA, or LGPD, please contact us at:</p> <p>Email: singhsidhukuldeep@gmail.com</p> <p>Mailing Address:</p> <p>Kuldeep Singh Sidhu</p> <p>Street No 4, Malviya Nagar Bathinda, Punjab, 151001 India</p>"},{"location":"projects/","title":"Projects","text":""},{"location":"projects/#introduction","title":"Introduction","text":"<p>These are the projects that you can take inspiration from and try to improve on them. \u270d\ufe0f</p> <p></p>"},{"location":"projects/#popular-sources","title":"Popular Sources","text":""},{"location":"projects/#list-of-projects","title":"List of projects","text":""},{"location":"projects/#natural-language-processing-nlp","title":"Natural Language processing (NLP)","text":"Title Description Source Author Text Classification with Facebook fasttext Building the User Review Model with fastText (Text Classification) with response time of less than one second Kuldeep Singh Sidhu Chat-bot using ChatterBot ChatterBot is a Python library that makes it easy to generate automated responses to a user\u2019s input. Kuldeep Singh Sidhu Text Summarizer Comparing state of the art models for text summary generation Kuldeep Singh Sidhu NLP with Spacy Building NLP pipeline using Spacy Kuldeep Singh Sidhu"},{"location":"projects/#recommendation-engine","title":"Recommendation Engine","text":"Title Description Source Author Recommendation Engine with Surprise Comparing different recommendation systems algorithms like SVD, SVDpp (Matrix Factorization), KNN Baseline, KNN Basic, KNN Means, KNN ZScore), Baseline, Co Clustering Kuldeep Singh Sidhu"},{"location":"projects/#image-processing","title":"Image Processing","text":"Title Description Source Author Facial Landmarks Using Dlib, a library capable of giving you 68 points (land marks) of the face. Kuldeep Singh Sidhu"},{"location":"projects/#reinforcement-learning","title":"Reinforcement Learning","text":"Title Description Source Author Google Dopamine Dopamine is a research framework for fast prototyping of reinforcement learning algorithms. Kuldeep Singh Sidhu Tic Tac Toe Training a computer to play Tic Tac Toe using reinforcement learning algorithms. Kuldeep Singh Sidhu"},{"location":"projects/#others","title":"Others","text":"Title Description Source Author TensorFlow Eager Execution Eager Execution (EE) enables you to run operations immediately. Kuldeep Singh Sidhu"},{"location":"Cheat-Sheets/Django/","title":"Django Cheat Sheet","text":"<ul> <li>Django Cheat Sheet<ul> <li>Getting Started<ul> <li>Installation</li> <li>Create a Project</li> <li>Create an App</li> <li>Run the Development Server</li> </ul> </li> <li>Models<ul> <li>Define a Model (models.py)</li> <li>Model Fields</li> <li>Model Meta Options</li> <li>Querying the Database</li> <li>Raw SQL Queries</li> </ul> </li> <li>Views<ul> <li>Create a View (views.py)</li> <li>Class-Based Views</li> <li>Function-Based View Decorators</li> </ul> </li> <li>URLs<ul> <li>Define URL Patterns (urls.py)</li> <li>URL Reversing</li> </ul> </li> <li>Templates<ul> <li>Create a Template (mytemplate.html)</li> <li>Template Inheritance</li> <li>Template Tags and Filters</li> <li>Common Template Filters</li> </ul> </li> <li>Forms<ul> <li>Define a Form (forms.py)</li> <li>Form Fields</li> <li>Form Widgets</li> <li>Render a Form in a Template</li> <li>Process Form Data in a View</li> </ul> </li> <li>Admin Interface<ul> <li>Register a Model (admin.py)</li> <li>Customize Admin Interface</li> <li>Inline Admin</li> </ul> </li> <li>Settings (settings.py)<ul> <li>Key Settings</li> <li>Database Configuration</li> <li>Static Files Configuration</li> <li>Middleware Configuration</li> <li>Caching Configuration</li> <li>Email Configuration</li> </ul> </li> <li>Common Commands</li> <li>Django REST Framework (DRF)<ul> <li>Installation</li> <li>Serializers (serializers.py)</li> <li>Views (views.py)</li> <li>URLs (urls.py)</li> <li>Authentication and Permissions</li> <li>APIView</li> </ul> </li> <li>Security<ul> <li>CSRF Protection</li> <li>SQL Injection</li> <li>XSS (Cross-Site Scripting)</li> <li>Clickjacking</li> <li>Security Headers</li> <li>HTTPS</li> <li>Authentication</li> <li>Test Client</li> </ul> </li> <li>Deployment<ul> <li>Production Settings</li> <li>Web Server (Gunicorn)</li> <li>Process Manager (systemd)</li> <li>Static Files</li> <li>Media Files</li> <li>Database</li> <li>Environment Variables</li> </ul> </li> <li>Caching<ul> <li>Per-Site Cache</li> <li>Per-View Cache</li> <li>Template Fragment Caching</li> <li>Low-Level Cache API</li> </ul> </li> <li>Signals<ul> <li>Define a Signal (signals.py)</li> <li>Connect Signals (apps.py)</li> <li>Common Signals</li> </ul> </li> <li>Internationalization (i18n) and Localization (l10n)<ul> <li>Enable i18n and l10n</li> <li>Set the Language Code</li> <li>Translate Strings</li> <li>Mark Strings for Translation</li> <li>Translate Strings with Context</li> <li>Pluralization</li> <li>Switch Language</li> </ul> </li> <li>Custom Management Commands<ul> <li>Create a Command (management/commands/mycommand.py)</li> <li>Run the Command</li> </ul> </li> <li>Middleware<ul> <li>Create a Middleware (middleware.py)</li> <li>Activate Middleware</li> </ul> </li> <li>File Handling<ul> <li>Uploading Files</li> <li>Serving Files</li> </ul> </li> <li>Logging<ul> <li>Configure Logging (settings.py)</li> <li>Use Logging</li> </ul> </li> <li>Django Channels (Asynchronous)<ul> <li>Installation</li> <li>Configure Channels (settings.py)</li> <li>Create a Consumer (consumers.py)</li> <li>Configure Routing (routing.py)</li> <li>Update ASGI Application (asgi.py)</li> </ul> </li> <li>Django Allauth (Authentication)<ul> <li>Installation</li> <li>Configuration (settings.py)</li> <li>URLs (urls.py)</li> <li>Templates</li> </ul> </li> <li>Django Debug Toolbar<ul> <li>Installation</li> <li>Configuration (settings.py)</li> <li>URLs (urls.py)</li> </ul> </li> <li>Tips and Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of the Django web framework, covering essential commands, concepts, and code snippets for efficient Django development. It aims to be a one-stop reference for common tasks and best practices.</p>"},{"location":"Cheat-Sheets/Django/#getting-started","title":"Getting Started","text":""},{"location":"Cheat-Sheets/Django/#installation","title":"Installation","text":"<pre><code>pip install django\n</code></pre> <p>Consider using a virtual environment:</p> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Linux/macOS\nvenv\\Scripts\\activate  # On Windows\n</code></pre>"},{"location":"Cheat-Sheets/Django/#create-a-project","title":"Create a Project","text":"<pre><code>django-admin startproject myproject\ncd myproject\n</code></pre>"},{"location":"Cheat-Sheets/Django/#create-an-app","title":"Create an App","text":"<pre><code>python manage.py startapp myapp\n</code></pre>"},{"location":"Cheat-Sheets/Django/#run-the-development-server","title":"Run the Development Server","text":"<pre><code>python manage.py runserver\n</code></pre>"},{"location":"Cheat-Sheets/Django/#models","title":"Models","text":""},{"location":"Cheat-Sheets/Django/#define-a-model-modelspy","title":"Define a Model (models.py)","text":"<pre><code>from django.db import models\n\nclass MyModel(models.Model):\n    name = models.CharField(max_length=100, help_text=\"Enter the name\")\n    description = models.TextField(blank=True, null=True)\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n    is_active = models.BooleanField(default=True)\n    order = models.PositiveIntegerField(default=0)\n\n    def __str__(self):\n        return self.name\n\n    class Meta:\n        ordering = ['order', '-created_at']  # Default ordering\n        verbose_name = \"My Model Entry\"\n        verbose_name_plural = \"My Model Entries\"\n</code></pre>"},{"location":"Cheat-Sheets/Django/#model-fields","title":"Model Fields","text":"<ul> <li><code>AutoField</code>: An auto-incrementing integer field (primary key by default).</li> <li><code>BigAutoField</code>: A 64-bit integer, similar to AutoField.</li> <li><code>CharField</code>: For short to medium-length strings. <code>max_length</code> is required.</li> <li><code>TextField</code>: For long strings of unlimited length. <code>blank=True</code> allows the field to be empty in forms, <code>null=True</code> allows the field to store NULL values in the database.</li> <li><code>IntegerField</code>: For integer values.</li> <li><code>PositiveIntegerField</code>: An integer field that must be positive.</li> <li><code>SmallIntegerField</code>, <code>BigIntegerField</code>: Smaller and larger integer fields.</li> <li><code>FloatField</code>: For floating-point numbers.</li> <li><code>DecimalField</code>: For fixed-precision decimal numbers. Requires <code>max_digits</code> and <code>decimal_places</code>.</li> <li><code>BooleanField</code>: For boolean values (True/False).</li> <li><code>NullBooleanField</code>: A BooleanField that also accepts NULL.</li> <li><code>DateField</code>: For dates (YYYY-MM-DD).</li> <li><code>DateTimeField</code>: For dates and times (YYYY-MM-DD HH:MM:SS). <code>auto_now_add=True</code> sets the field to the current date/time when the object is created. <code>auto_now=True</code> updates the field every time the object is saved.</li> <li><code>TimeField</code>: For times (HH:MM:SS).</li> <li><code>DurationField</code>: Stores periods of time \u2013 modeled in Python by timedelta.</li> <li><code>EmailField</code>: A CharField that validates if the input is an email address.</li> <li><code>URLField</code>: A CharField that validates URLs.</li> <li><code>FileField</code>: For file uploads. Requires <code>upload_to</code> to specify the storage directory.</li> <li><code>ImageField</code>: For image uploads. Requires Pillow library and <code>upload_to</code>.</li> <li><code>FilePathField</code>: A CharField whose choices are limited to the filenames in a certain directory on the filesystem.</li> <li><code>SlugField</code>: A CharField intended to store a \"slug\" \u2013 a short label containing only letters, numbers, underscores or hyphens.</li> <li><code>BinaryField</code>: For storing raw binary data.</li> <li><code>ForeignKey</code>: For creating one-to-many relationships with other models. Requires <code>on_delete</code> to specify what happens when the related object is deleted (e.g., <code>models.CASCADE</code>, <code>models.SET_NULL</code>).</li> <li><code>ManyToManyField</code>: For creating many-to-many relationships.</li> <li><code>OneToOneField</code>: For creating one-to-one relationships.</li> <li><code>GenericIPAddressField</code>: For storing IPv4 or IPv6 addresses.</li> <li><code>UUIDField</code>: For storing universally unique identifiers.</li> </ul>"},{"location":"Cheat-Sheets/Django/#model-meta-options","title":"Model Meta Options","text":"<ul> <li><code>ordering</code>: Defines the default ordering of objects.</li> <li><code>verbose_name</code>: A human-readable name for the model.</li> <li><code>verbose_name_plural</code>: The plural form of the verbose name.</li> <li><code>abstract = True</code>: Makes the model an abstract base class.</li> <li><code>db_table</code>: Specifies the name of the database table.</li> <li><code>unique_together</code>: Defines a set of fields that, taken together, must be unique.</li> <li><code>index_together</code>: Defines a set of fields that should be indexed together.</li> <li><code>get_latest_by</code>: Specifies a field to use for retrieving the \"latest\" object.</li> </ul>"},{"location":"Cheat-Sheets/Django/#querying-the-database","title":"Querying the Database","text":"<pre><code>from .models import MyModel\n\n# Get all objects\nall_objects = MyModel.objects.all()\n\n# Filter objects\nfiltered_objects = MyModel.objects.filter(name__contains='keyword', is_active=True)\n\n# Get a single object by primary key\nsingle_object = MyModel.objects.get(pk=1)\n\n# Get a single object, handling DoesNotExist exception\nfrom django.shortcuts import get_object_or_404\nsingle_object = get_object_or_404(MyModel, pk=1)\n\n# Create a new object\nnew_object = MyModel.objects.create(name='New Object', description='...')\n\n# Update an existing object\nobj = MyModel.objects.get(pk=1)\nobj.name = 'Updated Name'\nobj.save()\n\n# Delete an object\nobj = MyModel.objects.get(pk=1)\nobj.delete()\n\n# Complex lookups with Q objects\nfrom django.db.models import Q\nobjects = MyModel.objects.filter(Q(name__startswith='A') | Q(description__icontains='data'))\n\n# Ordering\nordered_objects = MyModel.objects.order_by('name', '-created_at')\n\n# Limiting results\nlimited_objects = MyModel.objects.all()[:10]\n\n# Chaining queries\nchained_objects = MyModel.objects.filter(is_active=True).order_by('name')\n</code></pre>"},{"location":"Cheat-Sheets/Django/#raw-sql-queries","title":"Raw SQL Queries","text":"<pre><code>from django.db import connection\n\ndef my_raw_query():\n    with connection.cursor() as cursor:\n        cursor.execute(\"SELECT * FROM myapp_mymodel WHERE name = %s\", ['My Name'])\n        row = cursor.fetchone()\n        return row\n</code></pre>"},{"location":"Cheat-Sheets/Django/#views","title":"Views","text":""},{"location":"Cheat-Sheets/Django/#create-a-view-viewspy","title":"Create a View (views.py)","text":"<pre><code>from django.shortcuts import render, get_object_or_404\nfrom django.http import HttpResponse, JsonResponse\nfrom .models import MyModel\n\ndef my_view(request):\n    data = MyModel.objects.all()  # Get all objects from MyModel\n    context = {'data': data}\n    return render(request, 'myapp/mytemplate.html', context)\n\ndef detail_view(request, pk):\n    item = get_object_or_404(MyModel, pk=pk)\n    return render(request, 'myapp/detail.html', {'item': item})\n\ndef json_response(request):\n    data = {'message': 'Hello, world!'}\n    return JsonResponse(data)\n\ndef http_response(request):\n    return HttpResponse(\"&lt;h1&gt;Hello, world!&lt;/h1&gt;\", content_type=\"text/html\")\n</code></pre>"},{"location":"Cheat-Sheets/Django/#class-based-views","title":"Class-Based Views","text":"<pre><code>from django.views.generic import ListView, DetailView, CreateView, UpdateView, DeleteView\nfrom django.urls import reverse_lazy\nfrom .models import MyModel\n\nclass MyListView(ListView):\n    model = MyModel\n    template_name = 'myapp/mymodel_list.html'\n    context_object_name = 'data'  # Renames the object_list in the template\n    paginate_by = 10  # Enable pagination\n\nclass MyDetailView(DetailView):\n    model = MyModel\n    template_name = 'myapp/mymodel_detail.html'\n    context_object_name = 'item'\n\nclass MyCreateView(CreateView):\n    model = MyModel\n    fields = ['name', 'description', 'is_active']  # Fields to include in the form\n    template_name = 'myapp/mymodel_form.html'\n    success_url = reverse_lazy('myapp:my_list_view')  # Redirect after successful creation\n\nclass MyUpdateView(UpdateView):\n    model = MyModel\n    fields = ['name', 'description', 'is_active']\n    template_name = 'myapp/mymodel_form.html'\n    success_url = reverse_lazy('myapp:my_list_view')\n\nclass MyDeleteView(DeleteView):\n    model = MyModel\n    template_name = 'myapp/mymodel_confirm_delete.html'\n    success_url = reverse_lazy('myapp:my_list_view')\n</code></pre>"},{"location":"Cheat-Sheets/Django/#function-based-view-decorators","title":"Function-Based View Decorators","text":"<ul> <li><code>@require_http_methods([\"GET\", \"POST\"])</code>: Only allows specified HTTP methods.</li> <li><code>@require_GET</code>, <code>@require_POST</code>: Shorthand for requiring GET or POST.</li> <li><code>@login_required</code>: Requires the user to be logged in.</li> <li><code>@permission_required('myapp.change_mymodel')</code>: Requires the user to have a specific permission.</li> <li><code>@staff_member_required</code>: Requires the user to be a staff member.</li> <li><code>@cache_page(60 * 15)</code>: Caches the view output for 15 minutes (requires cache configuration).</li> </ul>"},{"location":"Cheat-Sheets/Django/#urls","title":"URLs","text":""},{"location":"Cheat-Sheets/Django/#define-url-patterns-urlspy","title":"Define URL Patterns (urls.py)","text":"<p>Project <code>urls.py</code>:</p> <pre><code>from django.contrib import admin\nfrom django.urls import path, include\n\nurlpatterns = [\n    path('admin/', admin.site.urls),\n    path('myapp/', include('myapp.urls', namespace='myapp')),  # Include app's URLs with namespace\n]\n</code></pre> <p>App <code>urls.py</code>:</p> <pre><code>from django.urls import path\nfrom . import views\n\napp_name = 'myapp'  # App namespace\n\nurlpatterns = [\n    path('', views.my_view, name='my_view'),\n    path('list/', views.MyListView.as_view(), name='my_list_view'),\n    path('detail/&lt;int:pk&gt;/', views.MyDetailView.as_view(), name='my_detail_view'),\n    path('create/', views.MyCreateView.as_view(), name='my_create_view'),\n    path('update/&lt;int:pk&gt;/', views.MyUpdateView.as_view(), name='my_update_view'),\n    path('delete/&lt;int:pk&gt;/', views.MyDeleteView.as_view(), name='my_delete_view'),\n]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#url-reversing","title":"URL Reversing","text":"<p>In templates:</p> <pre><code>&lt;a href=\"{% url 'myapp:my_detail_view' item.pk %}\"&gt;{{ item.name }}&lt;/a&gt;\n</code></pre> <p>In Python code:</p> <pre><code>from django.urls import reverse\n\nurl = reverse('myapp:my_detail_view', kwargs={'pk': 1})\n</code></pre>"},{"location":"Cheat-Sheets/Django/#templates","title":"Templates","text":""},{"location":"Cheat-Sheets/Django/#create-a-template-mytemplatehtml","title":"Create a Template (mytemplate.html)","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{% block title %}My Template{% endblock %}&lt;/title&gt;\n    {% load static %}\n    &lt;link rel=\"stylesheet\" href=\"{% static 'myapp/css/style.css' %}\"&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;header&gt;\n        &lt;h1&gt;{% block header %}My Website{% endblock %}&lt;/h1&gt;\n    &lt;/header&gt;\n\n    &lt;main&gt;\n        {% block content %}\n            &lt;h1&gt;Data from MyModel:&lt;/h1&gt;\n            &lt;ul&gt;\n                {% for item in data %}\n                    &lt;li&gt;&lt;a href=\"{% url 'myapp:my_detail_view' item.pk %}\"&gt;{{ item.name }}&lt;/a&gt; - {{ item.description }}&lt;/li&gt;\n                {% empty %}\n                    &lt;li&gt;No data available.&lt;/li&gt;\n                {% endfor %}\n            &lt;/ul&gt;\n        {% endblock %}\n    &lt;/main&gt;\n\n    &lt;footer&gt;\n        &lt;p&gt;&amp;copy; 2025 My Website&lt;/p&gt;\n    &lt;/footer&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Django/#template-inheritance","title":"Template Inheritance","text":"<p>Create a base template (<code>base.html</code>):</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{% block title %}My Website{% endblock %}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;header&gt;\n        &lt;h1&gt;{% block header %}My Website{% endblock %}&lt;/h1&gt;\n    &lt;/header&gt;\n\n    &lt;main&gt;\n        {% block content %}{% endblock %}\n    &lt;/main&gt;\n\n    &lt;footer&gt;\n        &lt;p&gt;&amp;copy; 2025 My Website&lt;/p&gt;\n    &lt;/footer&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Extend the base template (<code>mytemplate.html</code>):</p> <pre><code>{% extends 'base.html' %}\n\n{% block title %}My Custom Title{% endblock %}\n\n{% block content %}\n    &lt;h1&gt;Data from MyModel:&lt;/h1&gt;\n    &lt;ul&gt;\n        {% for item in data %}\n            &lt;li&gt;{{ item.name }} - {{ item.description }}&lt;/li&gt;\n        {% endfor %}\n    &lt;/ul&gt;\n{% endblock %}\n</code></pre>"},{"location":"Cheat-Sheets/Django/#template-tags-and-filters","title":"Template Tags and Filters","text":"<ul> <li><code>{{ variable }}</code>: Outputs a variable.</li> <li><code>{% tag %}</code>: Template logic tag (e.g., <code>for</code>, <code>if</code>).</li> <li><code>{{ variable|filter }}</code>: Applies a filter to a variable.</li> <li><code>{% load static %}</code>: Loads the <code>static</code> template tag library for serving static files.</li> <li><code>{% url 'view_name' arg1 arg2 %}</code>: Reverses a URL pattern by its name.</li> <li><code>{% csrf_token %}</code>: Adds a CSRF token to a form.</li> <li><code>{% now \"Y-m-d H:i\" %}</code>: Displays the current date and time.</li> <li><code>{% include \"template_name.html\" %}</code>: Includes another template.</li> <li><code>{% extends \"base.html\" %}</code>: Extends a base template.</li> <li><code>{% block block_name %}{% endblock %}</code>: Defines a block for template inheritance.</li> <li><code>{% if condition %}{% endif %}</code>: Conditional logic.</li> <li><code>{% for item in items %}{% endfor %}</code>: Loop through a list.</li> <li><code>{% with total=items|length %}</code>: Assign a value to a variable within the template.</li> </ul>"},{"location":"Cheat-Sheets/Django/#common-template-filters","title":"Common Template Filters","text":"<ul> <li><code>safe</code>: Marks a string as safe for HTML output.</li> <li><code>date:\"FORMAT_STRING\"</code>: Formats a date. See Django's documentation for format string options.</li> <li><code>time:\"FORMAT_STRING\"</code>: Formats a time.</li> <li><code>timesince</code>: Displays the time elapsed since a date.</li> <li><code>truncatechars:LENGTH</code>: Truncates a string to a certain length.</li> <li><code>truncatewords:NUM</code>: Truncates a string to a certain number of words.</li> <li><code>lower</code>, <code>upper</code>: Converts a string to lowercase or uppercase.</li> <li><code>title</code>: Converts a string to title case.</li> <li><code>capfirst</code>: Capitalizes the first character of a string.</li> <li><code>length</code>: Returns the length of a value.</li> <li><code>default:VALUE</code>: Provides a default value if a variable is False.</li> <li><code>filesizeformat</code>: Formats a number as a human-readable file size.</li> <li><code>stringformat:\"E\"</code>: Formats a number according to a string format specifier.</li> <li><code>linebreaks</code>: Replaces line breaks in plain text with appropriate HTML; a single newline becomes an HTML line break (<code>&lt;br&gt;</code>) and a new line surrounded by empty lines becomes a paragraph break (<code>&lt;p&gt;</code>).</li> <li><code>urlencode</code>: Encodes a string for use in a URL.</li> <li><code>json_script</code>: Safely outputs data as JSON for use in JavaScript.</li> </ul>"},{"location":"Cheat-Sheets/Django/#forms","title":"Forms","text":""},{"location":"Cheat-Sheets/Django/#define-a-form-formspy","title":"Define a Form (forms.py)","text":"<pre><code>from django import forms\nfrom .models import MyModel\n\nclass MyForm(forms.Form):\n    name = forms.CharField(label=\"Your Name\", max_length=100,\n                           widget=forms.TextInput(attrs={'class': 'form-control'}))\n    email = forms.EmailField(label=\"Your Email\",\n                            widget=forms.EmailInput(attrs={'class': 'form-control'}))\n    message = forms.CharField(widget=forms.Textarea(attrs={'class': 'form-control'}),\n                              label=\"Your Message\")\n    agree = forms.BooleanField(label=\"I agree to the terms\", required=True)\n\n    # Custom validation\n    def clean_name(self):\n        name = self.cleaned_data['name']\n        if len(name) &lt; 3:\n            raise forms.ValidationError(\"Name must be at least 3 characters long.\")\n        return name\n\nclass MyModelForm(forms.ModelForm):\n    class Meta:\n        model = MyModel\n        fields = ['name', 'description', 'is_active']\n        widgets = {\n            'description': forms.Textarea(attrs={'rows': 4, 'cols': 40}),\n        }\n        labels = {\n            'name': 'Model Name',\n            'description': 'Model Description',\n        }\n        help_texts = {\n            'name': 'Enter a descriptive name for the model.',\n        }\n        error_messages = {\n            'name': {\n                'required': 'Please enter a name.',\n            },\n        }\n</code></pre>"},{"location":"Cheat-Sheets/Django/#form-fields","title":"Form Fields","text":"<ul> <li><code>CharField</code>: For text input.</li> <li><code>IntegerField</code>: For integer input.</li> <li><code>FloatField</code>: For floating-point input.</li> <li><code>BooleanField</code>: For checkbox input.</li> <li><code>DateField</code>, <code>DateTimeField</code>: For date and time input.</li> <li><code>EmailField</code>: For email input.</li> <li><code>URLField</code>: For URL input.</li> <li><code>ChoiceField</code>: For select input. Requires <code>choices</code> argument.</li> <li><code>MultipleChoiceField</code>: For multiple select input.</li> <li><code>FileField</code>: For file upload.</li> <li><code>ImageField</code>: For image upload.</li> <li><code>ModelChoiceField</code>: For selecting a model instance from a queryset.</li> <li><code>ModelMultipleChoiceField</code>: For selecting multiple model instances.</li> <li><code>TypedChoiceField</code>: Like <code>ChoiceField</code>, but coerces values to a specific type.</li> <li><code>TypedMultipleChoiceField</code>: Like <code>MultipleChoiceField</code>, but coerces values to a specific type.</li> <li><code>RegexField</code>: A CharField that validates against a regular expression.</li> </ul>"},{"location":"Cheat-Sheets/Django/#form-widgets","title":"Form Widgets","text":"<ul> <li><code>TextInput</code>: Default text input.</li> <li><code>Textarea</code>: Multi-line text input.</li> <li><code>NumberInput</code>: For number input.</li> <li><code>EmailInput</code>: For email input.</li> <li><code>URLInput</code>: For URL input.</li> <li><code>PasswordInput</code>: For password input.</li> <li><code>HiddenInput</code>: A hidden input field.</li> <li><code>Select</code>: For single select dropdown.</li> <li><code>SelectMultiple</code>: For multiple select dropdown.</li> <li><code>RadioSelect</code>: For radio button selection.</li> <li><code>CheckboxInput</code>: For a single checkbox.</li> <li><code>CheckboxSelectMultiple</code>: For multiple checkboxes.</li> <li><code>FileInput</code>: For file uploads.</li> <li><code>ClearableFileInput</code>: A FileInput with a checkbox to clear the current file.</li> <li><code>DateInput</code>, <code>DateTimeInput</code>, <code>TimeInput</code>: For date, datetime, and time input, respectively.</li> </ul>"},{"location":"Cheat-Sheets/Django/#render-a-form-in-a-template","title":"Render a Form in a Template","text":"<pre><code>&lt;form method=\"post\"&gt;\n    {% csrf_token %}\n    {% if form.errors %}\n        &lt;div class=\"alert alert-danger\"&gt;\n            Please correct the errors below.\n        &lt;/div&gt;\n    {% endif %}\n    {{ form.as_p }}  {# Renders the form as a series of &lt;p&gt; tags #}\n    {# Or render fields individually: #}\n    {# &lt;div class=\"form-group\"&gt;\n        {{ form.name.label_tag }}\n        {{ form.name }}\n        {{ form.name.errors }}\n    &lt;/div&gt; #}\n    &lt;button type=\"submit\"&gt;Submit&lt;/button&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Django/#process-form-data-in-a-view","title":"Process Form Data in a View","text":"<pre><code>from django.shortcuts import render, redirect\nfrom .forms import MyForm, MyModelForm\n\ndef my_form_view(request):\n    if request.method == 'POST':\n        form = MyForm(request.POST)\n        if form.is_valid():\n            name = form.cleaned_data['name']\n            email = form.cleaned_data['email']\n            message = form.cleaned_data['message']\n            # Process the data (e.g., save to database, send email)\n            return redirect('success_url')  # Redirect to a success page\n        else:\n            # Form is invalid, display errors\n            return render(request, 'myapp/myform.html', {'form': form})\n    else:\n        form = MyForm()\n    return render(request, 'myapp/myform.html', {'form': form})\n\ndef my_model_form_view(request):\n    if request.method == 'POST':\n        form = MyModelForm(request.POST, request.FILES) # Include request.FILES for file uploads\n        if form.is_valid():\n            instance = form.save()  # Save the model instance\n            # Or, to process data before saving:\n            # new_instance = form.save(commit=False)\n            # new_instance.some_field = 'some_value'\n            # new_instance.save()\n            return redirect('my_list_view')\n        else:\n            return render(request, 'myapp/mymodel_form.html', {'form': form})\n    else:\n        form = MyModelForm()\n    return render(request, 'myapp/mymodel_form.html', {'form': form})\n</code></pre>"},{"location":"Cheat-Sheets/Django/#admin-interface","title":"Admin Interface","text":""},{"location":"Cheat-Sheets/Django/#register-a-model-adminpy","title":"Register a Model (admin.py)","text":"<pre><code>from django.contrib import admin\nfrom .models import MyModel\n\nadmin.site.register(MyModel)\n</code></pre>"},{"location":"Cheat-Sheets/Django/#customize-admin-interface","title":"Customize Admin Interface","text":"<pre><code>from django.contrib import admin\nfrom .models import MyModel\n\n@admin.register(MyModel)\nclass MyModelAdmin(admin.ModelAdmin):\n    list_display = ('name', 'created_at', 'is_active')  # Columns to display in list view\n    search_fields = ('name', 'description') # Enable search\n    list_filter = ('is_active', 'created_at')          # Enable filtering\n    ordering = ('name',)\n    readonly_fields = ('created_at', 'updated_at')\n    date_hierarchy = 'created_at' # Drill-down by date\n    prepopulated_fields = {'slug': ('name',)} # Automatically populate slug field\n    raw_id_fields = ('related_model',) # Use raw ID lookup for ForeignKey/ManyToManyField\n    filter_horizontal = ('many_to_many_field',) # Use horizontal filter for ManyToManyField\n    filter_vertical = ('another_many_to_many_field',) # Use vertical filter for ManyToManyField\n    fieldsets = (\n        (None, {\n            'fields': ('name', 'description')\n        }),\n        ('Advanced options', {\n            'classes': ('collapse',),\n            'fields': ('is_active', 'order'),\n        }),\n    )\n    actions = ['make_active', 'make_inactive']\n\n    def make_active(self, request, queryset):\n        queryset.update(is_active=True)\n    make_active.short_description = \"Mark selected entries as active\"\n\n    def make_inactive(self, request, queryset):\n        queryset.update(is_active=False)\n    make_inactive.short_description = \"Mark selected entries as inactive\"\n</code></pre>"},{"location":"Cheat-Sheets/Django/#inline-admin","title":"Inline Admin","text":"<pre><code>from django.contrib import admin\nfrom .models import MyModel, RelatedModel\n\nclass RelatedModelAdminInline(admin.TabularInline):  # Or admin.StackedInline\n    model = RelatedModel\n    extra = 1  # Number of empty forms to display\n    fk_name = 'mymodel' # Specify the ForeignKey field name in RelatedModel\n\n@admin.register(MyModel)\nclass MyModelAdmin(admin.ModelAdmin):\n    inlines = [RelatedModelAdminInline]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#settings-settingspy","title":"Settings (settings.py)","text":""},{"location":"Cheat-Sheets/Django/#key-settings","title":"Key Settings","text":"<ul> <li><code>DEBUG = True</code>: Enables debug mode (for development only!).</li> <li><code>SECRET_KEY</code>: A secret key for security. Never share this! Use environment variables.</li> <li><code>ALLOWED_HOSTS = ['*']</code>: List of allowed hostnames for the Django project. In production, set this to your domain name.</li> <li><code>INSTALLED_APPS</code>: List of installed Django apps.</li> <li><code>MIDDLEWARE</code>: List of enabled middleware.</li> <li><code>ROOT_URLCONF</code>: Specifies the root URL configuration module.</li> <li><code>DATABASES</code>: Database connection settings.</li> <li><code>STATIC_URL</code>: URL to serve static files.</li> <li><code>STATIC_ROOT</code>: The absolute path to the directory where <code>collectstatic</code> will collect static files for production.</li> <li><code>STATICFILES_DIRS</code>: List of directories where Django will look for static files.</li> <li><code>MEDIA_URL</code>: URL to serve media files (user-uploaded files).</li> <li><code>MEDIA_ROOT</code>: The absolute path to the directory where user-uploaded media files will be stored.</li> <li><code>TEMPLATES</code>: Template engine settings.</li> <li><code>LANGUAGE_CODE</code>: The default language code for the project.</li> <li><code>TIME_ZONE</code>: The timezone for the project.</li> <li><code>USE_I18N = True</code>: Enables internationalization.</li> <li><code>USE_L10N = True</code>: Enables localization.</li> <li><code>USE_TZ = True</code>: Enables timezone support.</li> <li><code>DEFAULT_AUTO_FIELD</code>: Default auto-field type for primary keys (Django 3.2+).</li> <li><code>SESSION_ENGINE</code>: Defines the session storage engine.</li> <li><code>CSRF_COOKIE_SECURE = True</code>: Ensures the CSRF cookie is only sent over HTTPS (production).</li> <li><code>SESSION_COOKIE_SECURE = True</code>: Ensures the session cookie is only sent over HTTPS (production).</li> <li><code>SECURE_SSL_REDIRECT = True</code>: Redirects all HTTP traffic to HTTPS (production).</li> <li><code>SECURE_HSTS_SECONDS = 31536000</code>: Enables HTTP Strict Transport Security (HSTS) (production).</li> <li><code>SECURE_HSTS_INCLUDE_SUBDOMAINS = True</code>: Includes subdomains in HSTS policy (production).</li> <li><code>SECURE_HSTS_PRELOAD = True</code>: Enables HSTS preloading (production).</li> </ul>"},{"location":"Cheat-Sheets/Django/#database-configuration","title":"Database Configuration","text":"<pre><code>DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql',  # Or 'django.db.backends.mysql', 'django.db.backends.sqlite3'\n        'NAME': 'mydatabase',\n        'USER': 'myuser',\n        'PASSWORD': 'mypassword',\n        'HOST': 'localhost',\n        'PORT': '5432',\n    }\n}\n</code></pre>"},{"location":"Cheat-Sheets/Django/#static-files-configuration","title":"Static Files Configuration","text":"<pre><code>STATIC_URL = '/static/'\nSTATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')\nSTATICFILES_DIRS = [\n    os.path.join(BASE_DIR, 'myapp/static'),\n]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#middleware-configuration","title":"Middleware Configuration","text":"<pre><code>MIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'django.middleware.cache.UpdateCacheMiddleware', # Add for caching\n    'django.middleware.cache.FetchFromCacheMiddleware', # Add for caching\n]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#caching-configuration","title":"Caching Configuration","text":"<pre><code>CACHES = {\n    'default': {\n        'BACKEND': 'django.core.cache.backends.redis.RedisCache',\n        'LOCATION': 'redis://127.0.0.1:6379',\n    }\n}\n\nCACHE_MIDDLEWARE_ALIAS = 'default'\nCACHE_MIDDLEWARE_SECONDS = 600  # Cache for 10 minutes\nCACHE_MIDDLEWARE_KEY_PREFIX = ''\n</code></pre>"},{"location":"Cheat-Sheets/Django/#email-configuration","title":"Email Configuration","text":"<pre><code>EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'\nEMAIL_HOST = 'smtp.gmail.com'\nEMAIL_PORT = 587\nEMAIL_USE_TLS = True\nEMAIL_HOST_USER = 'your_email@gmail.com'\nEMAIL_HOST_PASSWORD = 'your_password'\nDEFAULT_FROM_EMAIL = 'your_email@gmail.com'\n</code></pre>"},{"location":"Cheat-Sheets/Django/#common-commands","title":"Common Commands","text":"<ul> <li><code>python manage.py runserver</code>: Starts the development server.</li> <li><code>python manage.py shell</code>: Opens a Python shell with Django environment loaded.</li> <li><code>python manage.py createsuperuser</code>: Creates an admin user.</li> <li><code>python manage.py makemigrations</code>: Creates new migrations based on model changes.</li> <li><code>python manage.py migrate</code>: Applies migrations to the database.</li> <li><code>python manage.py collectstatic</code>: Collects static files into <code>STATIC_ROOT</code>.</li> <li><code>python manage.py test</code>: Runs the project's tests.</li> <li><code>python manage.py dbshell</code>: Opens a shell for the database.</li> <li><code>python manage.py dumpdata</code>: Exports data from the database as JSON or XML.</li> <li><code>python manage.py loaddata</code>: Loads data from a JSON or XML fixture into the database.</li> <li><code>python manage.py check</code>: Performs system checks to identify potential problems.</li> <li><code>python manage.py showmigrations</code>: Shows the status of migrations.</li> <li><code>python manage.py inspectdb</code>: Generates models from an existing database.</li> <li><code>python manage.py flush</code>: Empties the database.</li> <li><code>python manage.py changepassword &lt;username&gt;</code>: Changes a user's password.</li> </ul>"},{"location":"Cheat-Sheets/Django/#django-rest-framework-drf","title":"Django REST Framework (DRF)","text":""},{"location":"Cheat-Sheets/Django/#installation_1","title":"Installation","text":"<pre><code>pip install djangorestframework\n</code></pre> <p>Add <code>'rest_framework'</code> to <code>INSTALLED_APPS</code> in <code>settings.py</code>.</p>"},{"location":"Cheat-Sheets/Django/#serializers-serializerspy","title":"Serializers (serializers.py)","text":"<pre><code>from rest_framework import serializers\nfrom .models import MyModel\n\nclass MyModelSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = MyModel\n        fields = '__all__'  # Or specify a tuple of field names\n        # or exclude = ('field1', 'field2')\n        read_only_fields = ('created_at', 'updated_at') # Make fields read-only\n\n    # Custom field validation\n    def validate_name(self, value):\n        if len(value) &lt; 5:\n            raise serializers.ValidationError(\"Name must be at least 5 characters long.\")\n        return value\n\n    # Object-level validation\n    def validate(self, data):\n        if data['name'] == data['description']:\n            raise serializers.ValidationError(\"Name and description cannot be the same.\")\n        return data\n</code></pre>"},{"location":"Cheat-Sheets/Django/#views-viewspy","title":"Views (views.py)","text":"<pre><code>from rest_framework import generics, permissions, status\nfrom rest_framework.response import Response\nfrom .models import MyModel\nfrom .serializers import MyModelSerializer\n\nclass MyModelList(generics.ListCreateAPIView):\n    queryset = MyModel.objects.all()\n    serializer_class = MyModelSerializer\n    permission_classes = [permissions.IsAuthenticatedOrReadOnly] # Require authentication for write operations\n\n    def perform_create(self, serializer):\n        serializer.save() # Save the object\n\nclass MyModelDetail(generics.RetrieveUpdateDestroyAPIView):\n    queryset = MyModel.objects.all()\n    serializer_class = MyModelSerializer\n    permission_classes = [permissions.IsAuthenticatedOrReadOnly]\n\n    def delete(self, request, *args, **kwargs):\n        instance = self.get_object()\n        self.perform_destroy(instance)\n        return Response(status=status.HTTP_204_NO_CONTENT) # Return 204 No Content on successful deletion\n</code></pre>"},{"location":"Cheat-Sheets/Django/#urls-urlspy","title":"URLs (urls.py)","text":"<pre><code>from django.urls import path\nfrom . import views\n\nurlpatterns = [\n    path('mymodel/', views.MyModelList.as_view(), name='mymodel-list'),\n    path('mymodel/&lt;int:pk&gt;/', views.MyModelDetail.as_view(), name='mymodel-detail'),\n]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#authentication-and-permissions","title":"Authentication and Permissions","text":"<ul> <li><code>permissions.AllowAny</code>: Allows access to anyone, authenticated or not.</li> <li><code>permissions.IsAuthenticated</code>: Only allows access to authenticated users.</li> <li><code>permissions.IsAdminUser</code>: Only allows access to admin users.</li> <li><code>permissions.IsAuthenticatedOrReadOnly</code>: Allows read access to anyone, but write access only to authenticated users.</li> <li>Custom permissions: You can create custom permission classes to define more specific access control rules.</li> </ul>"},{"location":"Cheat-Sheets/Django/#apiview","title":"APIView","text":"<p>For more control, use <code>APIView</code>:</p> <pre><code>from rest_framework.views import APIView\nfrom rest_framework.response import Response\nfrom rest_framework import status\nfrom .models import MyModel\nfrom .serializers import MyModelSerializer\n\nclass MyCustomAPIView(APIView):\n    def get(self, request):\n        data = MyModel.objects.all()\n        serializer = MyModelSerializer(data, many=True)\n        return Response(serializer.data)\n\n    def post(self, request):\n        serializer = MyModelSerializer(data=request.data)\n        if serializer.is_valid():\n            serializer.save()\n            return Response(serializer.data, status=status.HTTP_201_CREATED)\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\n</code></pre>"},{"location":"Cheat-Sheets/Django/#security","title":"Security","text":""},{"location":"Cheat-Sheets/Django/#csrf-protection","title":"CSRF Protection","text":"<ul> <li>Use the <code>{% csrf_token %}</code> template tag in forms.</li> <li>Ensure <code>django.middleware.csrf.CsrfViewMiddleware</code> is in <code>MIDDLEWARE</code>.</li> </ul>"},{"location":"Cheat-Sheets/Django/#sql-injection","title":"SQL Injection","text":"<ul> <li>Use Django's ORM to avoid raw SQL queries whenever possible.</li> <li>If you must use raw SQL, use parameterized queries to escape user input.</li> </ul>"},{"location":"Cheat-Sheets/Django/#xss-cross-site-scripting","title":"XSS (Cross-Site Scripting)","text":"<ul> <li>Use the <code>safe</code> template filter with caution. Only use it on data you trust.</li> <li>Sanitize user input before displaying it.</li> </ul>"},{"location":"Cheat-Sheets/Django/#clickjacking","title":"Clickjacking","text":"<ul> <li>Ensure <code>django.middleware.clickjacking.XFrameOptionsMiddleware</code> is in <code>MIDDLEWARE</code>.</li> <li>Set <code>X_FRAME_OPTIONS = 'DENY'</code> or <code>X_FRAME_OPTIONS = 'SAMEORIGIN'</code> in <code>settings.py</code>.</li> </ul>"},{"location":"Cheat-Sheets/Django/#security-headers","title":"Security Headers","text":"<p>Use <code>django-security</code> or similar package to set security headers.</p>"},{"location":"Cheat-Sheets/Django/#https","title":"HTTPS","text":"<ul> <li>Configure your web server to use HTTPS.</li> <li>Set <code>SECURE_SSL_REDIRECT = True</code> in <code>settings.py</code> to redirect HTTP requests to HTTPS.</li> <li>Set <code>SECURE_HSTS_SECONDS</code> and <code>SECURE_HSTS_INCLUDE_SUBDOMAINS</code> for HTTP Strict Transport Security.</li> <li>Set <code>SECURE_HSTS_PRELOAD = True</code> to enable HSTS preloading.</li> </ul>"},{"location":"Cheat-Sheets/Django/#authentication","title":"Authentication","text":"<p>Use Django's built-in authentication <pre><code>import TestCase\nfrom .models import MyModel\n\nclass MyModelTest(TestCase):\n    def setUp(self):\n        MyModel.objects.create(name='Test Object', description='Test Description')\n\n    def test_model_content(self):\n        obj = MyModel.objects.get(name='Test Object')\n        self.assertEqual(obj.description, 'Test Description')\n</code></pre></p>"},{"location":"Cheat-Sheets/Django/#test-client","title":"Test Client","text":"<pre><code>from django.test import Client\n\nclass MyViewTest(TestCase):\n    def setUp(self):\n        self.client = Client()\n\n    def test_my_view(self):\n        response = self.client.get('/myapp/')\n        self.assertEqual(response.status_code, 200)\n        self.assertContains(response, 'My Template')\n</code></pre>"},{"location":"Cheat-Sheets/Django/#deployment","title":"Deployment","text":""},{"location":"Cheat-Sheets/Django/#production-settings","title":"Production Settings","text":"<p>Create a <code>production.py</code> settings file:</p> <pre><code>from .settings import *\n\nDEBUG = False\nALLOWED_HOSTS = ['yourdomain.com', 'www.yourdomain.com']\nSTATIC_ROOT = os.path.join(BASE_DIR, 'staticfiles')\n</code></pre>"},{"location":"Cheat-Sheets/Django/#web-server-gunicorn","title":"Web Server (Gunicorn)","text":"<p>Install Gunicorn:</p> <pre><code>pip install gunicorn\n</code></pre> <p>Run Gunicorn:</p> <pre><code>gunicorn myproject.wsgi:application --bind 0.0.0.0:8000\n</code></pre>"},{"location":"Cheat-Sheets/Django/#process-manager-systemd","title":"Process Manager (systemd)","text":"<p>Create a systemd service file (<code>/etc/systemd/system/myproject.service</code>):</p> <pre><code>[Unit]\nDescription=My Django Project\nAfter=network.target\n\n[Service]\nUser=myuser\nGroup=mygroup\nWorkingDirectory=/path/to/myproject\nExecStart=/path/to/venv/bin/gunicorn myproject.wsgi:application --bind 0.0.0.0:8000\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Enable and start the service:</p> <pre><code>sudo systemctl enable myproject\nsudo systemctl start myproject\n</code></pre>"},{"location":"Cheat-Sheets/Django/#static-files","title":"Static Files","text":"<ul> <li>Run <code>python manage.py collectstatic</code> to collect static files.</li> <li>Configure your web server (e.g., Nginx, Apache) to serve static files from <code>STATIC_ROOT</code>.</li> </ul>"},{"location":"Cheat-Sheets/Django/#media-files","title":"Media Files","text":"<ul> <li>Configure your web server to serve media files from <code>MEDIA_ROOT</code>.</li> <li>Consider using a cloud storage service (e.g., AWS S3) for media files.</li> </ul>"},{"location":"Cheat-Sheets/Django/#database","title":"Database","text":"<ul> <li>Use a production-ready database (e.g., PostgreSQL, MySQL).</li> <li>Configure the database connection settings in <code>settings.py</code>.</li> <li>Back up your database regularly.</li> </ul>"},{"location":"Cheat-Sheets/Django/#environment-variables","title":"Environment Variables","text":"<ul> <li>Use environment variables for sensitive settings (e.g., <code>SECRET_KEY</code>, database credentials).</li> <li>Use a package like <code>python-dotenv</code> to manage environment variables.</li> </ul>"},{"location":"Cheat-Sheets/Django/#caching","title":"Caching","text":""},{"location":"Cheat-Sheets/Django/#per-site-cache","title":"Per-Site Cache","text":"<p>Add <code>django.middleware.cache.UpdateCacheMiddleware</code> and <code>django.middleware.cache.FetchFromCacheMiddleware</code> to <code>MIDDLEWARE</code> in <code>settings.py</code>.</p> <pre><code># settings.py\nMIDDLEWARE = [\n    'django.middleware.cache.UpdateCacheMiddleware',\n    # ... other middleware ...\n    'django.middleware.cache.FetchFromCacheMiddleware',\n]\n</code></pre> <p>Configure the cache backend:</p> <pre><code># settings.py\nCACHES = {\n    'default': {\n        'BACKEND': 'django.core.cache.backends.redis.RedisCache',\n        'LOCATION': 'redis://127.0.0.1:6379',  # Example using Redis\n    }\n}\n\nCACHE_MIDDLEWARE_ALIAS = 'default'\nCACHE_MIDDLEWARE_SECONDS = 600  # Cache for 10 minutes\nCACHE_MIDDLEWARE_KEY_PREFIX = ''\n</code></pre>"},{"location":"Cheat-Sheets/Django/#per-view-cache","title":"Per-View Cache","text":"<p>Use the <code>@cache_page</code> decorator:</p> <pre><code>from django.views.decorators.cache import cache_page\n\n@cache_page(60 * 15)  # Cache for 15 minutes\ndef my_view(request):\n    # ...\n    return render(request, 'myapp/mytemplate.html', context)\n</code></pre>"},{"location":"Cheat-Sheets/Django/#template-fragment-caching","title":"Template Fragment Caching","text":"<pre><code>{% load cache %}\n\n{% cache 600 \"my_template_fragment\" %}\n    {# Expensive template code here #}\n{% endcache %}\n</code></pre>"},{"location":"Cheat-Sheets/Django/#low-level-cache-api","title":"Low-Level Cache API","text":"<pre><code>from django.core.cache import cache\n\n# Set a value\ncache.set('my_key', 'my_value', 600)  # Cache for 10 minutes\n\n# Get a value\nvalue = cache.get('my_key')\n\n# Delete a value\ncache.delete('my_key')\n</code></pre>"},{"location":"Cheat-Sheets/Django/#signals","title":"Signals","text":""},{"location":"Cheat-Sheets/Django/#define-a-signal-signalspy","title":"Define a Signal (signals.py)","text":"<pre><code>from django.db.models.signals import post_save\nfrom django.dispatch import receiver\nfrom .models import MyModel\n\n@receiver(post_save, sender=MyModel)\ndef my_model_post_save(sender, instance, created, **kwargs):\n    if created:\n        # Perform actions when a new MyModel instance is created\n        print(f\"New MyModel instance created: {instance.name}\")\n    else:\n        # Perform actions when a MyModel instance is updated\n        print(f\"MyModel instance updated: {instance.name}\")\n</code></pre>"},{"location":"Cheat-Sheets/Django/#connect-signals-appspy","title":"Connect Signals (apps.py)","text":"<pre><code>from django.apps import AppConfig\n\nclass MyappConfig(AppConfig):\n    default_auto_field = 'django.db.models.BigAutoField'\n    name = 'myapp'\n\n    def ready(self):\n        import myapp.signals  # Import the signals module\n</code></pre>"},{"location":"Cheat-Sheets/Django/#common-signals","title":"Common Signals","text":"<ul> <li><code>pre_save</code>, <code>post_save</code>: Sent before and after a model's <code>save()</code> method is called.</li> <li><code>pre_delete</code>, <code>post_delete</code>: Sent before and after a model instance is deleted.</li> <li><code>m2m_changed</code>: Sent when a ManyToManyField is changed.</li> <li><code>pre_migrate</code>, <code>post_migrate</code>: Sent before and after migrations are applied.</li> </ul>"},{"location":"Cheat-Sheets/Django/#internationalization-i18n-and-localization-l10n","title":"Internationalization (i18n) and Localization (l10n)","text":""},{"location":"Cheat-Sheets/Django/#enable-i18n-and-l10n","title":"Enable i18n and l10n","text":"<p>Set <code>USE_I18N = True</code> and <code>USE_L10N = True</code> in <code>settings.py</code>.</p>"},{"location":"Cheat-Sheets/Django/#set-the-language-code","title":"Set the Language Code","text":"<p>Set <code>LANGUAGE_CODE = 'en-us'</code> in <code>settings.py</code>.</p>"},{"location":"Cheat-Sheets/Django/#translate-strings","title":"Translate Strings","text":"<p>In Python code:</p> <pre><code>from django.utils.translation import gettext as _\n\ndef my_view(request):\n    message = _(\"Hello, world!\")\n    return render(request, 'myapp/mytemplate.html', {'message': message})\n</code></pre> <p>In templates:</p> <pre><code>{% load i18n %}\n&lt;h1&gt;{% trans \"Hello, world!\" %}&lt;/h1&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Django/#mark-strings-for-translation","title":"Mark Strings for Translation","text":"<p>Use <code>makemessages</code> command:</p> <pre><code>python manage.py makemessages -l de  # Create a translation file for German\n</code></pre>"},{"location":"Cheat-Sheets/Django/#translate-strings-with-context","title":"Translate Strings with Context","text":"<pre><code>from django.utils.translation import pgettext as _\n\nmessage = _(\"context\", \"Hello, world!\")\n</code></pre>"},{"location":"Cheat-Sheets/Django/#pluralization","title":"Pluralization","text":"<pre><code>from django.utils.translation import ngettext\n\ndef my_view(request, count):\n    message = ngettext(\n        'There is %(count)d object',\n        'There are %(count)d objects',\n        count\n    ) % {'count': count}\n    return render(request, 'myapp/mytemplate.html', {'message': message})\n</code></pre>"},{"location":"Cheat-Sheets/Django/#switch-language","title":"Switch Language","text":"<pre><code>&lt;form action=\"{% url 'set_language' %}\" method=\"post\"&gt;\n    {% csrf_token %}\n    &lt;input name=\"language\" type=\"hidden\" value=\"de\"&gt;\n    &lt;button type=\"submit\"&gt;Switch to German&lt;/button&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Django/#custom-management-commands","title":"Custom Management Commands","text":""},{"location":"Cheat-Sheets/Django/#create-a-command-managementcommandsmycommandpy","title":"Create a Command (management/commands/mycommand.py)","text":"<pre><code>from django.core.management.base import BaseCommand\n\nclass Command(BaseCommand):\n    help = 'My custom command'\n\n    def add_arguments(self, parser):\n        parser.add_argument('argument', nargs='?', type=str, help='An argument for the command')\n\n    def handle(self, *args, **options):\n        argument = options['argument']\n        self.stdout.write(self.style.SUCCESS(f'Successfully executed mycommand with argument: {argument}'))\n</code></pre>"},{"location":"Cheat-Sheets/Django/#run-the-command","title":"Run the Command","text":"<pre><code>python manage.py mycommand \"My Argument\"\n</code></pre>"},{"location":"Cheat-Sheets/Django/#middleware","title":"Middleware","text":""},{"location":"Cheat-Sheets/Django/#create-a-middleware-middlewarepy","title":"Create a Middleware (middleware.py)","text":"<pre><code>class MyMiddleware:\n    def __init__(self, get_response):\n        self.get_response = get_response\n\n    def __call__(self, request):\n        # Code to be executed for each request before the view (pre-processing)\n        print(\"Before view\")\n\n        response = self.get_response(request)\n\n        # Code to be executed for each request after the view (post-processing)\n        print(\"After view\")\n\n        return response\n</code></pre>"},{"location":"Cheat-Sheets/Django/#activate-middleware","title":"Activate Middleware","text":"<p>Add the middleware to <code>MIDDLEWARE</code> in <code>settings.py</code>:</p> <pre><code>MIDDLEWARE = [\n    # ...\n    'myapp.middleware.MyMiddleware',\n]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#file-handling","title":"File Handling","text":""},{"location":"Cheat-Sheets/Django/#uploading-files","title":"Uploading Files","text":"<p>In <code>forms.py</code>:</p> <pre><code>class UploadFileForm(forms.Form):\n    file = forms.FileField()\n</code></pre> <p>In <code>views.py</code>:</p> <pre><code>def upload_file(request):\n    if request.method == 'POST':\n        form = UploadFileForm(request.POST, request.FILES)\n        if form.is_valid():\n            uploaded_file = request.FILES['file']\n            # Process the uploaded file (e.g., save to MEDIA_ROOT)\n            with open(os.path.join(settings.MEDIA_ROOT, uploaded_file.name), 'wb+') as destination:\n                for chunk in uploaded_file.chunks():\n                    destination.write(chunk)\n            return HttpResponse(\"File uploaded successfully\")\n    else:\n        form = UploadFileForm()\n    return render(request, 'myapp/upload.html', {'form': form})\n</code></pre> <p>In <code>templates/myapp/upload.html</code>:</p> <pre><code>&lt;form method=\"post\" enctype=\"multipart/form-data\"&gt;\n    {% csrf_token %}\n    {{ form.as_p }}\n    &lt;button type=\"submit\"&gt;Upload&lt;/button&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Django/#serving-files","title":"Serving Files","text":"<p>Configure <code>MEDIA_URL</code> and <code>MEDIA_ROOT</code> in <code>settings.py</code>.</p> <p>In <code>urls.py</code>:</p> <pre><code>from django.conf import settings\nfrom django.conf.urls.static import static\n\nurlpatterns = [\n    # ... your other URL patterns ...\n] + static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)\n</code></pre>"},{"location":"Cheat-Sheets/Django/#logging","title":"Logging","text":""},{"location":"Cheat-Sheets/Django/#configure-logging-settingspy","title":"Configure Logging (settings.py)","text":"<pre><code>LOGGING = {\n    'version': 1,\n    'disable_existing_loggers': False,\n    'handlers': {\n        'console': {\n            'class': 'logging.StreamHandler',\n        },\n        'file': {\n            'level': 'DEBUG',\n            'class': 'logging.FileHandler',\n            'filename': os.path.join(BASE_DIR, 'debug.log'),\n        },\n    },\n    'loggers': {\n        'django': {\n            'handlers': ['console', 'file'],\n            'level': 'INFO',\n        },\n    },\n}\n</code></pre>"},{"location":"Cheat-Sheets/Django/#use-logging","title":"Use Logging","text":"<pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\ndef my_view(request):\n    logger.info(\"My view was accessed\")\n    try:\n        # ... some code that might raise an exception ...\n    except Exception as e:\n        logger.exception(\"An error occurred\")\n</code></pre>"},{"location":"Cheat-Sheets/Django/#django-channels-asynchronous","title":"Django Channels (Asynchronous)","text":""},{"location":"Cheat-Sheets/Django/#installation_2","title":"Installation","text":"<pre><code>pip install channels\n</code></pre>"},{"location":"Cheat-Sheets/Django/#configure-channels-settingspy","title":"Configure Channels (settings.py)","text":"<pre><code>ASGI_APPLICATION = 'myproject.asgi.application'\n\nCHANNEL_LAYERS = {\n    'default': {\n        'BACKEND': 'channels_redis.core.RedisChannelLayer',\n        'CONFIG': {\n            \"hosts\": [('127.0.0.1', 6379)],\n        },\n    },\n}\n</code></pre>"},{"location":"Cheat-Sheets/Django/#create-a-consumer-consumerspy","title":"Create a Consumer (consumers.py)","text":"<pre><code>from channels.generic.websocket import WebsocketConsumer\nimport json\n\nclass MyConsumer(WebsocketConsumer):\n    def connect(self):\n        self.accept()\n\n    def disconnect(self, close_code):\n        pass\n\n    def receive(self, text_data):\n        text_data_json = json.loads(text_data)\n        message = text_data_json['message']\n\n        self.send(text_data=json.dumps({\n            'message': message\n        }))\n</code></pre>"},{"location":"Cheat-Sheets/Django/#configure-routing-routingpy","title":"Configure Routing (routing.py)","text":"<pre><code>from django.urls import re_path\n\nfrom . import consumers\n\nwebsocket_urlpatterns = [\n    re_path(r'ws/myapp/$', consumers.MyConsumer.as_asgi()),\n]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#update-asgi-application-asgipy","title":"Update ASGI Application (asgi.py)","text":"<pre><code>import os\n\nfrom django.core.asgi import get_asgi_application\nfrom channels.routing import ProtocolTypeRouter, URLRouter\nfrom channels.auth import AuthMiddlewareStack\nimport myapp.routing\n\nos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')\n\napplication = ProtocolTypeRouter({\n    \"http\": get_asgi_application(),\n    \"websocket\": AuthMiddlewareStack(\n        URLRouter(\n            myapp.routing.websocket_urlpatterns\n        )\n    ),\n})\n</code></pre>"},{"location":"Cheat-Sheets/Django/#django-allauth-authentication","title":"Django Allauth (Authentication)","text":""},{"location":"Cheat-Sheets/Django/#installation_3","title":"Installation","text":"<pre><code>pip install django-allauth\n</code></pre>"},{"location":"Cheat-Sheets/Django/#configuration-settingspy","title":"Configuration (settings.py)","text":"<pre><code>INSTALLED_APPS = [\n    # ...\n    'django.contrib.sites',\n    'allauth',\n    'allauth.account',\n    'allauth.socialaccount',\n    # ... include providers you want to use ...\n    # 'allauth.socialaccount.providers.google',\n]\n\nAUTHENTICATION_BACKENDS = [\n    'django.contrib.auth.backends.ModelBackend',\n    'allauth.account.auth_backends.AuthenticationBackend',\n]\n\nSITE_ID = 1\n\nLOGIN_REDIRECT_URL = '/'\nACCOUNT_EMAIL_REQUIRED = True\nACCOUNT_USERNAME_REQUIRED = False\nACCOUNT_AUTHENTICATION_METHOD = 'email'\nACCOUNT_EMAIL_VERIFICATION = 'mandatory'\n</code></pre>"},{"location":"Cheat-Sheets/Django/#urls-urlspy_1","title":"URLs (urls.py)","text":"<pre><code>from django.urls import include, path\n\nurlpatterns = [\n    path('accounts/', include('allauth.urls')),\n]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#templates_1","title":"Templates","text":"<p>Use Allauth's template tags and forms for registration, login, etc.</p>"},{"location":"Cheat-Sheets/Django/#django-debug-toolbar","title":"Django Debug Toolbar","text":""},{"location":"Cheat-Sheets/Django/#installation_4","title":"Installation","text":"<pre><code>pip install django-debug-toolbar\n</code></pre>"},{"location":"Cheat-Sheets/Django/#configuration-settingspy_1","title":"Configuration (settings.py)","text":"<pre><code>INSTALLED_APPS = [\n    # ...\n    'debug_toolbar',\n]\n\nMIDDLEWARE = [\n    # ...\n    'debug_toolbar.middleware.DebugToolbarMiddleware',\n]\n\nINTERNAL_IPS = [\n    '127.0.0.1',\n]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#urls-urlspy_2","title":"URLs (urls.py)","text":"<pre><code>from django.urls import include, path\n\nurlpatterns = [\n    # ...\n]\n\nif settings.DEBUG:\n    import debug_toolbar\n    urlpatterns += [\n        path('__debug__/', include(debug_toolbar.urls)),\n    ]\n</code></pre>"},{"location":"Cheat-Sheets/Django/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ul> <li>Use virtual environments to isolate project dependencies.</li> <li>Keep <code>SECRET_KEY</code> secure and out of your codebase. Use environment variables.</li> <li>Use meaningful names for models, views, and URLs.</li> <li>Follow the DRY (Don't Repeat Yourself) principle.</li> <li>Write unit tests to ensure code quality.</li> <li>Use Django's built-in security features (e.g., CSRF protection).</li> <li>Configure static file serving correctly in production.</li> <li>Use a production-ready web server (e.g., Gunicorn, uWSGI) and a process manager (e.g., Supervisor, systemd) for deployment.</li> <li>Use a linter (like <code>flake8</code>) and formatter (like <code>black</code>) to ensure consistent code style.</li> <li>Use a well-defined project structure.</li> <li>Keep your code modular and reusable.</li> <li>Document your code.</li> <li>Use a version control system (e.g., Git).</li> <li>Follow Django's coding style guidelines.</li> <li>Use Django's built-in caching mechanisms to improve performance.</li> <li>Monitor your application for errors and performance issues.</li> <li>Use a CDN (Content Delivery Network) for static files.</li> <li>Optimize database queries.</li> <li>Use asynchronous tasks for long-running operations (e.g., sending emails).</li> <li>Implement proper logging and error handling.</li> <li>Regularly update Django and its dependencies.</li> <li>Use a security scanner to identify potential vulnerabilities.</li> <li>Follow security best practices.</li> </ul>"},{"location":"Cheat-Sheets/Flask/","title":"Flask Cheat Sheet","text":"<ul> <li>Flask Cheat Sheet<ul> <li>Getting Started<ul> <li>Installation</li> <li>Basic App Structure</li> <li>Running the App</li> </ul> </li> <li>Routing<ul> <li>Basic Route</li> <li>Dynamic Routes</li> <li>HTTP Methods</li> <li>URL Building</li> </ul> </li> <li>Templates<ul> <li>Basic Template Rendering</li> <li>Template (templates/hello.html)</li> <li>Template Inheritance</li> <li>Jinja2 Template Engine</li> <li>Common Template Filters</li> </ul> </li> <li>Forms<ul> <li>Basic Form</li> <li>Using Flask-WTF</li> <li>Define a Form (forms.py)</li> <li>Render a Form in a Template</li> <li>Process Form Data in a View</li> </ul> </li> <li>Databases<ul> <li>Using Flask-SQLAlchemy</li> <li>Define a Model</li> <li>Create and Manage Tables</li> <li>Querying the Database</li> </ul> </li> <li>Static Files<ul> <li>Configure Static Files</li> </ul> </li> <li>Blueprints<ul> <li>Create a Blueprint</li> <li>Register a Blueprint</li> </ul> </li> <li>Flask Extensions<ul> <li>Flask-Mail</li> <li>Flask-Migrate</li> <li>Flask-Login</li> </ul> </li> <li>Testing<ul> <li>Using pytest</li> <li>Using unittest</li> </ul> </li> <li>Deployment<ul> <li>Production Settings</li> <li>WSGI Servers</li> <li>Environment Variables</li> <li>Example Deployment with Gunicorn and Nginx</li> </ul> </li> <li>Security</li> <li>Logging<ul> <li>Configure Logging</li> <li>Logging to a File</li> </ul> </li> <li>Flask CLI</li> <li>Context Processors</li> <li>Error Handling<ul> <li>Custom Error Pages</li> <li>Logging Exceptions</li> </ul> </li> <li>Flask-RESTful<ul> <li>Installation</li> <li>Define Resources</li> <li>Request Parsing</li> </ul> </li> <li>Session Management</li> <li>Flask-CORS<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Testing<ul> <li>Using pytest</li> <li>Using unittest</li> </ul> </li> <li>Deployment<ul> <li>Production Settings</li> <li>WSGI Servers</li> <li>Environment Variables</li> <li>Example Deployment with Gunicorn and Nginx</li> </ul> </li> <li>Security</li> <li>Logging<ul> <li>Configure Logging</li> <li>Logging to a File</li> </ul> </li> <li>Flask CLI</li> <li>Context Processors</li> <li>Testing<ul> <li>Using pytest</li> <li>Using unittest</li> </ul> </li> <li>Deployment<ul> <li>Production Settings</li> <li>WSGI Servers</li> <li>Environment Variables</li> <li>Example Deployment with Gunicorn and Nginx</li> </ul> </li> <li>Security</li> <li>Logging<ul> <li>Configure Logging</li> <li>Logging to a File</li> </ul> </li> <li>Flask CLI</li> <li>Context Processors</li> <li>Error Handling<ul> <li>Custom Error Pages</li> <li>Logging Exceptions</li> </ul> </li> <li>Flask-RESTful<ul> <li>Installation</li> <li>Define Resources</li> <li>Request Parsing</li> </ul> </li> <li>Session Management</li> <li>Flask-CORS<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Signals<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-Limiter<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-APScheduler<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-Sitemap<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-WTF CSRF Protection<ul> <li>Configuration</li> <li>Usage in Templates</li> </ul> </li> <li>Flask-FlatPages<ul> <li>Installation</li> <li>Configuration</li> <li>Usage</li> </ul> </li> <li>Flask-Assets<ul> <li>Installation</li> <li>Configuration</li> <li>Usage in Templates</li> </ul> </li> <li>Flask-Babel<ul> <li>Installation</li> <li>Configuration</li> <li>Usage</li> </ul> </li> <li>Flask-SocketIO<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-Principal<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-JWT-Extended<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-Uploads<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-Mail<ul> <li>Installation</li> <li>Configuration</li> <li>Sending Emails</li> </ul> </li> <li>Flask-APScheduler<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-Sitemap<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>Flask-WTF CSRF Protection<ul> <li>Configuration</li> <li>Usage in Templates</li> </ul> </li> <li>Tips and Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of the Flask micro web framework, covering essential commands, concepts, and code snippets for efficient Flask development. It aims to be a one-stop reference for common tasks and best practices.</p>"},{"location":"Cheat-Sheets/Flask/#getting-started","title":"Getting Started","text":""},{"location":"Cheat-Sheets/Flask/#installation","title":"Installation","text":"<pre><code>pip install flask\n</code></pre> <p>Consider using a virtual environment:</p> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Linux/macOS\nvenv\\Scripts\\activate  # On Windows\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#basic-app-structure","title":"Basic App Structure","text":"<pre><code>from flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/')\ndef hello_world():\n    return 'Hello, World!'\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#running-the-app","title":"Running the App","text":"<pre><code>python your_app_name.py\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#routing","title":"Routing","text":""},{"location":"Cheat-Sheets/Flask/#basic-route","title":"Basic Route","text":"<pre><code>from flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n    return 'Index Page'\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#dynamic-routes","title":"Dynamic Routes","text":"<pre><code>from flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/user/&lt;username&gt;')\ndef show_user_profile(username):\n    # show the user profile for that user\n    return f'User {username}'\n\n@app.route('/post/&lt;int:post_id&gt;')\ndef show_post(post_id):\n    # show the post with the given id, the id is an integer\n    return f'Post {post_id}'\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#http-methods","title":"HTTP Methods","text":"<pre><code>from flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        return \"Do the login\"\n    else:\n        return \"Show the login form\"\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#url-building","title":"URL Building","text":"<pre><code>from flask import Flask, url_for\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n    return 'Index'\n\n@app.route('/login')\ndef login():\n    return 'Login'\n\n@app.route('/user/&lt;username&gt;')\ndef profile(username):\n    return f'{username}\\'s profile'\n\nwith app.test_request_context():\n    print(url_for('index'))\n    print(url_for('login'))\n    print(url_for('login', next='/'))\n    print(url_for('profile', username='John Doe'))\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#templates","title":"Templates","text":""},{"location":"Cheat-Sheets/Flask/#basic-template-rendering","title":"Basic Template Rendering","text":"<pre><code>from flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.route('/hello/')\n@app.route('/hello/&lt;name&gt;')\ndef hello(name=None):\n    return render_template('hello.html', name=name)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#template-templateshellohtml","title":"Template (templates/hello.html)","text":"<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Hello&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    {% if name %}\n        &lt;h1&gt;Hello {{ name }}!&lt;/h1&gt;\n    {% else %}\n        &lt;h1&gt;Hello, World!&lt;/h1&gt;\n    {% endif %}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#template-inheritance","title":"Template Inheritance","text":"<p>Base template (<code>templates/base.html</code>):</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{% block title %}My Website{% endblock %}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;header&gt;\n        &lt;h1&gt;{% block header %}My Website{% endblock %}&lt;/h1&gt;\n    &lt;/header&gt;\n\n    &lt;main&gt;\n        {% block content %}{% endblock %}\n    &lt;/main&gt;\n\n    &lt;footer&gt;\n        &lt;p&gt;&amp;copy; 2025 My Website&lt;/p&gt;\n    &lt;/footer&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Child template (<code>templates/hello.html</code>):</p> <pre><code>{% extends \"base.html\" %}\n\n{% block title %}Hello{% endblock %}\n\n{% block content %}\n    {% if name %}\n        &lt;h1&gt;Hello {{ name }}!&lt;/h1&gt;\n    {% else %}\n        &lt;h1&gt;Hello, World!&lt;/h1&gt;\n    {% endif %}\n{% endblock %}\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#jinja2-template-engine","title":"Jinja2 Template Engine","text":"<ul> <li><code>{{ variable }}</code>: Outputs a variable.</li> <li><code>{% tag %}</code>: Template logic tag (e.g., <code>for</code>, <code>if</code>).</li> <li><code>{{ variable|filter }}</code>: Applies a filter to a variable.</li> <li><code>{% extends \"base.html\" %}</code>: Extends a base template.</li> <li><code>{% block block_name %}{% endblock %}</code>: Defines a block for template inheritance.</li> <li><code>{% include \"template_name.html\" %}</code>: Includes another template.</li> <li><code>{% url_for 'view_name' arg1=value1 %}</code>: Generates a URL for a view.</li> </ul>"},{"location":"Cheat-Sheets/Flask/#common-template-filters","title":"Common Template Filters","text":"<ul> <li><code>safe</code>: Marks a string as safe for HTML output.</li> <li><code>capitalize</code>: Capitalizes the first character of a string.</li> <li><code>lower</code>, <code>upper</code>: Converts a string to lowercase or uppercase.</li> <li><code>title</code>: Converts a string to title case.</li> <li><code>trim</code>: Removes leading and trailing whitespace.</li> <li><code>striptags</code>: Strips SGML/XML tags.</li> <li><code>length</code>: Returns the length of a value.</li> <li><code>default(value, default_value='')</code>: Provides a default value if a variable is undefined.</li> <li><code>replace(old, new, count=None)</code>: Replaces occurrences of a substring.</li> <li><code>format(value, *args, **kwargs)</code>: Formats a string using Python's string formatting.</li> </ul>"},{"location":"Cheat-Sheets/Flask/#forms","title":"Forms","text":""},{"location":"Cheat-Sheets/Flask/#basic-form","title":"Basic Form","text":"<pre><code>&lt;form method=\"post\"&gt;\n    &lt;label for=\"name\"&gt;Name:&lt;/label&gt;&lt;br&gt;\n    &lt;input type=\"text\" id=\"name\" name=\"name\"&gt;&lt;br&gt;\n    &lt;label for=\"email\"&gt;Email:&lt;/label&gt;&lt;br&gt;\n    &lt;input type=\"email\" id=\"email\" name=\"email\"&gt;&lt;br&gt;\n    &lt;input type=\"submit\" value=\"Submit\"&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#using-flask-wtf","title":"Using Flask-WTF","text":"<p>Installation:</p> <pre><code>pip install flask-wtf\n</code></pre> <p>Configuration (in your app):</p> <pre><code>import os\nfrom flask import Flask\nfrom flask_wtf import FlaskForm\nfrom wtforms import StringField, SubmitField\nfrom wtforms.validators import DataRequired\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = os.environ.get('SECRET_KEY') or 'your_secret_key'\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#define-a-form-formspy","title":"Define a Form (forms.py)","text":"<pre><code>from flask_wtf import FlaskForm\nfrom wtforms import StringField, SubmitField, TextAreaField, EmailField, BooleanField\nfrom wtforms.validators import DataRequired, Length, Email\n\nclass MyForm(FlaskForm):\n    name = StringField('Name', validators=[DataRequired(), Length(min=2, max=20)])\n    email = EmailField('Email', validators=[DataRequired(), Email()])\n    message = TextAreaField('Message', validators=[DataRequired()])\n    agree = BooleanField('I agree to the terms', validators=[DataRequired()])\n    submit = SubmitField('Submit')\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#render-a-form-in-a-template","title":"Render a Form in a Template","text":"<pre><code>&lt;form method=\"post\"&gt;\n    {{ form.csrf_token }}\n    &lt;div class=\"form-group\"&gt;\n        {{ form.name.label }}&lt;br&gt;\n        {{ form.name(class=\"form-control\") }}\n        {% if form.name.errors %}\n            &lt;ul class=\"errors\"&gt;\n                {% for error in form.name.errors %}\n                    &lt;li&gt;{{ error }}&lt;/li&gt;\n                {% endfor %}\n            &lt;/ul&gt;\n        {% endif %}\n    &lt;/div&gt;\n    &lt;div class=\"form-group\"&gt;\n        {{ form.email.label }}&lt;br&gt;\n        {{ form.email(class=\"form-control\") }}\n        {% if form.email.errors %}\n            &lt;ul class=\"errors\"&gt;\n                {% for error in form.email.errors %}\n                    &lt;li&gt;{{ error }}&lt;/li&gt;\n                {% endfor %}\n            &lt;/ul&gt;\n        {% endif %}\n    &lt;/div&gt;\n    &lt;div class=\"form-group\"&gt;\n        {{ form.message.label }}&lt;br&gt;\n        {{ form.message(class=\"form-control\") }}\n        {% if form.message.errors %}\n            &lt;ul class=\"errors\"&gt;\n                {% for error in form.message.errors %}\n                    &lt;li&gt;{{ error }}&lt;/li&gt;\n                {% endfor %}\n            &lt;/ul&gt;\n        {% endif %}\n    &lt;/div&gt;\n    &lt;div class=\"form-group\"&gt;\n        {{ form.agree.label }}\n        {{ form.agree }}\n        {% if form.agree.errors %}\n            &lt;ul class=\"errors\"&gt;\n                {% for error in form.agree.errors %}\n                    &lt;li&gt;{{ error }}&lt;/li&gt;\n                {% endfor %}\n            &lt;/ul&gt;\n        {% endif %}\n    &lt;/div&gt;\n    {{ form.submit(class=\"btn btn-primary\") }}\n&lt;/form&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#process-form-data-in-a-view","title":"Process Form Data in a View","text":"<pre><code>from flask import Flask, render_template, request, redirect, url_for\nfrom forms import MyForm\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your_secret_key'\n\n@app.route('/form', methods=['GET', 'POST'])\ndef my_form_view():\n    form = MyForm()\n    if form.validate_on_submit():\n        name = form.name.data\n        email = form.email.data\n        message = form.message.data\n        # Process the data (e.g., save to database, send email)\n        return redirect(url_for('success'))\n    return render_template('myform.html', form=form)\n\n@app.route('/success')\ndef success():\n    return \"Form submitted successfully!\"\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#databases","title":"Databases","text":""},{"location":"Cheat-Sheets/Flask/#using-flask-sqlalchemy","title":"Using Flask-SQLAlchemy","text":"<p>Installation:</p> <pre><code>pip install flask-sqlalchemy\n</code></pre> <p>Configuration:</p> <pre><code>from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nimport os\n\napp = Flask(__name__)\napp.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get('DATABASE_URL') or 'sqlite:///site.db'\napp.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\ndb = SQLAlchemy(app)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#define-a-model","title":"Define a Model","text":"<pre><code>from flask_sqlalchemy import SQLAlchemy\nfrom datetime import datetime\n\ndb = SQLAlchemy()\n\nclass User(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(20), unique=True, nullable=False)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n    image_file = db.Column(db.String(20), nullable=False, default='default.jpg')\n    password = db.Column(db.String(60), nullable=False)\n    posts = db.relationship('Post', backref='author', lazy=True)\n\n    def __repr__(self):\n        return f\"User('{self.username}', '{self.email}', '{self.image_file}')\"\n\nclass Post(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    title = db.Column(db.String(100), nullable=False)\n    date_posted = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)\n    content = db.Column(db.Text, nullable=False)\n    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)\n\n    def __repr__(self):\n        return f\"Post('{self.title}', '{self.date_posted}')\"\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#create-and-manage-tables","title":"Create and Manage Tables","text":"<pre><code>from yourapp import app, db\n\nwith app.app_context():\n    db.create_all()  # Create tables\n\n# In the Python shell:\n# from yourapp import db, User, Post\n# user_1 = User(username='Corey', email='corey@example.com')\n# db.session.add(user_1)\n# db.session.commit()\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#querying-the-database","title":"Querying the Database","text":"<pre><code>from yourapp import db, User, Post\n\n# Get all users\nall_users = User.query.all()\n\n# Filter users\nfiltered_users = User.query.filter_by(username='Corey')\n\n# Get a single user by ID\nuser = User.query.get(1)\n\n# Get a single user, handling 404 error\nuser = User.query.get_or_404(1)\n\n# Create a new user\nnew_user = User(username='NewUser', email='new@example.com', password='password')\ndb.session.add(new_user)\ndb.session.commit()\n\n# Update an existing user\nuser = User.query.get(1)\nuser.email = 'updated@example.com'\ndb.session.commit()\n\n# Delete a user\nuser = User.query.get(1)\ndb.session.delete(user)\ndb.session.commit()\n\n# Relationships\nuser = User.query.get(1)\nposts = user.posts  # Access posts related to the user\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#static-files","title":"Static Files","text":""},{"location":"Cheat-Sheets/Flask/#configure-static-files","title":"Configure Static Files","text":"<p>Create a <code>static</code> folder in your app directory.</p> <p>In your template:</p> <pre><code>{% load static %}\n&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"{% static 'css/style.css' %}\"&gt;\n&lt;img src=\"{% static 'images/logo.png' %}\"&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#blueprints","title":"Blueprints","text":""},{"location":"Cheat-Sheets/Flask/#create-a-blueprint","title":"Create a Blueprint","text":"<pre><code>from flask import Blueprint\n\nmain = Blueprint('main', __name__)\n\n@main.route('/')\ndef index():\n    return \"Main Blueprint Index\"\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#register-a-blueprint","title":"Register a Blueprint","text":"<pre><code>from flask import Flask\nfrom yourapp.main import main\n\napp = Flask(__name__)\napp.register_blueprint(main)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-extensions","title":"Flask Extensions","text":""},{"location":"Cheat-Sheets/Flask/#flask-mail","title":"Flask-Mail","text":"<p>Installation:</p> <pre><code>pip install flask-mail\n</code></pre> <p>Configuration:</p> <pre><code>from flask import Flask\nfrom flask_mail import Mail, Message\n\napp = Flask(__name__)\napp.config['MAIL_SERVER'] = 'smtp.gmail.com'\napp.config['MAIL_PORT'] = 587\napp.config['MAIL_USE_TLS'] = True\napp.config['MAIL_USE_SSL'] = False\napp.config['MAIL_USERNAME'] = 'your_email@gmail.com'\napp.config['MAIL_PASSWORD'] = 'your_password'\nmail = Mail(app)\n</code></pre> <p>Sending Emails:</p> <pre><code>from flask import Flask, render_template\nfrom flask_mail import Mail, Message\n\napp = Flask(__name__)\napp.config['MAIL_SERVER'] = 'smtp.gmail.com'\napp.config['MAIL_PORT'] = 587\napp.config['MAIL_USE_TLS'] = True\napp.config['MAIL_USE_SSL'] = False\napp.config['MAIL_USERNAME'] = 'your_email@gmail.com'\napp.config['MAIL_PASSWORD'] = 'your_password'\nmail = Mail(app)\n\n@app.route('/send')\ndef send_email():\n    msg = Message(\"Hello\",\n                  sender=\"your_email@gmail.com\",\n                  recipients=[\"recipient@example.com\"])\n    msg.body = \"Hello Flask message sent from Flask-Mail\"\n    mail.send(msg)\n    return \"Sent\"\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-migrate","title":"Flask-Migrate","text":"<p>Installation:</p> <pre><code>pip install flask-migrate\n</code></pre> <p>Configuration:</p> <pre><code>from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_migrate import Migrate\n\napp = Flask(__name__)\napp.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///site.db'\ndb = SQLAlchemy(app)\nmigrate = Migrate(app, db)\n</code></pre> <p>Migration Commands:</p> <pre><code>flask db init  # Initialize the migration repository\nflask db migrate -m \"Initial migration\"  # Create a new migration\nflask db upgrade  # Apply the latest migration\nflask db downgrade  # Revert to a previous migration\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-login","title":"Flask-Login","text":"<p>Installation:</p> <pre><code>pip install flask-login\n</code></pre> <p>Configuration:</p> <pre><code>from flask import Flask\nfrom flask_login import LoginManager\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your_secret_key'\nlogin_manager = LoginManager(app)\nlogin_manager.login_view = 'login'  # Specify the login view\n</code></pre> <p>User Model:</p> <pre><code>from flask_login import UserMixin\n\nclass User(db.Model, UserMixin):\n    id = db.Column(db.Integer, primary_key=True)\n    # ... other fields ...\n</code></pre> <p>User Loader Callback:</p> <pre><code>from yourapp import login_manager, User\n\n@login_manager.user_loader\ndef load_user(user_id):\n    return User.query.get(int(user_id))\n</code></pre> <p>Protecting Views:</p> <pre><code>from flask_login import login_required\n\n@app.route('/protected')\n@login_required\ndef protected():\n    return \"Protected View\"\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#testing","title":"Testing","text":""},{"location":"Cheat-Sheets/Flask/#using-pytest","title":"Using pytest","text":"<p>Installation:</p> <pre><code>pip install pytest pytest-flask\n</code></pre> <p>Test Example:</p> <pre><code>import pytest\nfrom yourapp import app\n\n@pytest.fixture\ndef client():\n    app.config['TESTING'] = True\n    with app.test_client() as client:\n        yield client\n\ndef test_index_route(client):\n    response = client.get('/')\n    assert response.status_code == 200\n    assert b'Hello, World!' in response.data\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#using-unittest","title":"Using unittest","text":"<pre><code>import unittest\nfrom yourapp import app\n\nclass MyTestCase(unittest.TestCase):\n    def setUp(self):\n        app.config['TESTING'] = True\n        self.app = app.test_client()\n\n    def test_index_route(self):\n        response = self.app.get('/')\n        self.assertEqual(response.status_code, 200)\n        self.assertIn(b'Hello, World!', response.data)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#deployment","title":"Deployment","text":""},{"location":"Cheat-Sheets/Flask/#production-settings","title":"Production Settings","text":"<ul> <li>Set <code>FLASK_ENV=production</code> to disable debug mode.</li> <li>Use a production WSGI server (e.g., Gunicorn, uWSGI).</li> <li>Configure your web server (e.g., Nginx, Apache) to proxy requests to the WSGI server.</li> <li>Use a process manager (e.g., Supervisor, systemd) to manage the WSGI server.</li> <li>Configure logging.</li> <li>Use HTTPS.</li> </ul>"},{"location":"Cheat-Sheets/Flask/#wsgi-servers","title":"WSGI Servers","text":"<p>Gunicorn:</p> <pre><code>pip install gunicorn\ngunicorn yourapp:app --bind 0.0.0.0:8000\n</code></pre> <p>uWSGI:</p> <pre><code>pip install uwsgi\nuwsgi --http 0.0.0.0:8000 --module yourapp\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#environment-variables","title":"Environment Variables","text":"<p>Use environment variables for sensitive settings (e.g., <code>SECRET_KEY</code>, database credentials).</p>"},{"location":"Cheat-Sheets/Flask/#example-deployment-with-gunicorn-and-nginx","title":"Example Deployment with Gunicorn and Nginx","text":"<ol> <li>Install Gunicorn: <code>pip install gunicorn</code></li> <li>Create a WSGI entry point: <code>yourapp.py</code> (already covered)</li> <li>Create a systemd service file: <code>/etc/systemd/system/yourapp.service</code></li> </ol> <pre><code>[Unit]\nDescription=Gunicorn instance to serve yourapp\nAfter=network.target\n\n[Service]\nUser=youruser\nGroup=www-data\nWorkingDirectory=/path/to/your/app\nExecStart=/path/to/your/venv/bin/gunicorn --workers 3 --max-requests 500 --bind unix:/run/yourapp.sock yourapp:app\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <ol> <li>Create an Nginx configuration file: <code>/etc/nginx/sites-available/yourapp</code></li> </ol> <pre><code>server {\n    listen 80;\n    server_name yourdomain.com www.yourdomain.com;\n\n    location / {\n        include proxy_params;\n        proxy_pass http://unix:/run/yourapp.sock;\n    }\n\n    location /static {\n        alias /path/to/your/app/static;\n    }\n}\n</code></pre> <ol> <li>Create a symbolic link:</li> </ol> <pre><code>sudo ln -s /etc/nginx/sites-available/yourapp /etc/nginx/sites-enabled\n</code></pre> <ol> <li>Restart Nginx:</li> </ol> <pre><code>sudo systemctl restart nginx\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#security","title":"Security","text":"<ul> <li>Use a strong <code>SECRET_KEY</code> and keep it secret.</li> <li>Use HTTPS.</li> <li>Sanitize user input to prevent XSS attacks.</li> <li>Use parameterized queries to prevent SQL injection.</li> <li>Use a Content Security Policy (CSP) to prevent various attacks.</li> <li>Protect against CSRF attacks using Flask-WTF.</li> <li>Limit file upload sizes.</li> <li>Validate file uploads.</li> <li>Use a security linter (e.g., Bandit).</li> </ul>"},{"location":"Cheat-Sheets/Flask/#logging","title":"Logging","text":""},{"location":"Cheat-Sheets/Flask/#configure-logging","title":"Configure Logging","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# In your code:\nlogger.info('This is an info message')\nlogger.warning('This is a warning message')\nlogger.error('This is an error message')\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#logging-to-a-file","title":"Logging to a File","text":"<pre><code>import logging\nimport logging.handlers\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n\n# Create a file handler\nlog_handler = logging.handlers.RotatingFileHandler('yourapp.log', maxBytes=10240, backupCount=5)\nlog_handler.setLevel(logging.DEBUG)\n\n# Create a logging format\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(formatter)\n\n# Add the handlers to the logger\nlogger.addHandler(log_handler)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-cli","title":"Flask CLI","text":"<p>Flask provides a command-line interface for managing your application.</p> <ul> <li><code>flask run</code>: Runs the development server.</li> <li><code>flask shell</code>: Opens a Python shell with the Flask application context.</li> <li><code>flask routes</code>: Shows the registered routes.</li> <li><code>flask db</code>: Manages database migrations (requires Flask-Migrate).</li> </ul>"},{"location":"Cheat-Sheets/Flask/#context-processors","title":"Context Processors","text":"<p>Context processors inject variables automatically into all templates.</p> <pre><code>from flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.context_processor\ndef inject_variables():\n    return dict(site_name=\"My Awesome Website\")\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n</code></pre> <p>In <code>templates/index.html</code>:</p> <pre><code>&lt;h1&gt;Welcome to {{ site_name }}!&lt;/h1&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#error-handling","title":"Error Handling","text":""},{"location":"Cheat-Sheets/Flask/#custom-error-pages","title":"Custom Error Pages","text":"<pre><code>from flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.errorhandler(404)\ndef page_not_found(e):\n    return render_template('404.html'), 404\n\n@app.errorhandler(500)\ndef internal_server_error(e):\n    return render_template('500.html'), 500\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#logging-exceptions","title":"Logging Exceptions","text":"<pre><code>import logging\nfrom flask import Flask, render_template\n\napp = Flask(__name__)\nlogger = logging.getLogger(__name__)\n\n@app.route('/')\ndef index():\n    try:\n        # Some code that might raise an exception\n        raise ValueError(\"Something went wrong\")\n    except Exception as e:\n        logger.exception(\"An error occurred\")\n        return render_template('error.html', error=str(e)), 500\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-restful","title":"Flask-RESTful","text":""},{"location":"Cheat-Sheets/Flask/#installation_1","title":"Installation","text":"<pre><code>pip install flask-restful\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#define-resources","title":"Define Resources","text":"<pre><code>from flask import Flask\nfrom flask_restful import Api, Resource\n\napp = Flask(__name__)\napi = Api(app)\n\nclass HelloWorld(Resource):\n    def get(self):\n        return {'hello': 'world'}\n\napi.add_resource(HelloWorld, '/')\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#request-parsing","title":"Request Parsing","text":"<pre><code>from flask_restful import reqparse\n\nparser = reqparse.RequestParser()\nparser.add_argument('name', required=True, help=\"Name is required\")\n\nclass MyResource(Resource):\n    def post(self):\n        args = parser.parse_args()\n        name = args['name']\n        return {'message': f'Hello, {name}!'}\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#session-management","title":"Session Management","text":"<pre><code>from flask import Flask, session, redirect, url_for, escape, request\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your_secret_key'\n\n@app.route('/')\ndef index():\n    if 'username' in session:\n        return f'Logged in as {escape(session[\"username\"])}\nClick here to &lt;a href=\"{url_for(\"logout\")}\"&gt;logout&lt;/a&gt;'\n    return 'You are not logged in\nClick here to &lt;a href=\"{url_for(\"login\")}\"&gt;login&lt;/a&gt;'\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        session['username'] = request.form['username']\n        return redirect(url_for('index'))\n    return '''\n        &lt;form method=\"post\"&gt;\n            &lt;p&gt;&lt;input type=text name=username&gt;\n            &lt;p&gt;&lt;input type=submit value=Login&gt;\n        &lt;/form&gt;\n    '''\n\n@app.route('/logout')\ndef logout():\n    session.pop('username', None)\n    return redirect(url_for('index'))\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-cors","title":"Flask-CORS","text":""},{"location":"Cheat-Sheets/Flask/#installation_2","title":"Installation","text":"<pre><code>pip install flask-cors\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage","title":"Usage","text":"<pre><code>from flask import Flask\nfrom flask_cors import CORS\n\napp = Flask(__name__)\nCORS(app)  # Enable CORS for all routes\n\n@app.route(\"/api/data\")\ndef get_data():\n    return {\"message\": \"This is CORS enabled!\"}\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#testing_1","title":"Testing","text":""},{"location":"Cheat-Sheets/Flask/#using-pytest_1","title":"Using pytest","text":"<p>Installation:</p> <pre><code>pip install pytest pytest-flask\n</code></pre> <p>Test Example:</p> <pre><code>import pytest\nfrom yourapp import app\n\n@pytest.fixture\ndef client():\n    app.config['TESTING'] = True\n    with app.test_client() as client:\n        yield client\n\ndef test_index_route(client):\n    response = client.get('/')\n    assert response.status_code == 200\n    assert b'Hello, World!' in response.data\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#using-unittest_1","title":"Using unittest","text":"<pre><code>import unittest\nfrom yourapp import app\n\nclass MyTestCase(unittest.TestCase):\n    def setUp(self):\n        app.config['TESTING'] = True\n        self.app = app.test_client()\n\n    def test_index_route(self):\n        response = self.app.get('/')\n        self.assertEqual(response.status_code, 200)\n        self.assertIn(b'Hello, World!', response.data)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#deployment_1","title":"Deployment","text":""},{"location":"Cheat-Sheets/Flask/#production-settings_1","title":"Production Settings","text":"<ul> <li>Set <code>FLASK_ENV=production</code> to disable debug mode.</li> <li>Use a production WSGI server (e.g., Gunicorn, uWSGI).</li> <li>Configure your web server (e.g., Nginx, Apache) to proxy requests to the WSGI server.</li> <li>Use a process manager (e.g., Supervisor, systemd) to manage the WSGI server.</li> <li>Configure logging.</li> <li>Use HTTPS.</li> </ul>"},{"location":"Cheat-Sheets/Flask/#wsgi-servers_1","title":"WSGI Servers","text":"<p>Gunicorn:</p> <pre><code>pip install gunicorn\ngunicorn yourapp:app --bind 0.0.0.0:8000\n</code></pre> <p>uWSGI:</p> <pre><code>pip install uwsgi\nuwsgi --http 0.0.0.0:8000 --module yourapp\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#environment-variables_1","title":"Environment Variables","text":"<p>Use environment variables for sensitive settings (e.g., <code>SECRET_KEY</code>, database credentials).</p>"},{"location":"Cheat-Sheets/Flask/#example-deployment-with-gunicorn-and-nginx_1","title":"Example Deployment with Gunicorn and Nginx","text":"<ol> <li>Install Gunicorn: <code>pip install gunicorn</code></li> <li>Create a WSGI entry point: <code>yourapp.py</code> (already covered)</li> <li>Create a systemd service file: <code>/etc/systemd/system/yourapp.service</code></li> </ol> <pre><code>[Unit]\nDescription=Gunicorn instance to serve yourapp\nAfter=network.target\n\n[Service]\nUser=youruser\nGroup=www-data\nWorkingDirectory=/path/to/your/app\nExecStart=/path/to/your/venv/bin/gunicorn --workers 3 --max-requests 500 --bind unix:/run/yourapp.sock yourapp:app\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <ol> <li>Create an Nginx configuration file: <code>/etc/nginx/sites-available/yourapp</code></li> </ol> <pre><code>server {\n    listen 80;\n    server_name yourdomain.com www.yourdomain.com;\n\n    location / {\n        include proxy_params;\n        proxy_pass http://unix:/run/yourapp.sock;\n    }\n\n    location /static {\n        alias /path/to/your/app/static;\n    }\n}\n</code></pre> <ol> <li>Create a symbolic link:</li> </ol> <pre><code>sudo ln -s /etc/nginx/sites-available/yourapp /etc/nginx/sites-enabled\n</code></pre> <ol> <li>Restart Nginx:</li> </ol> <pre><code>sudo systemctl restart nginx\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#security_1","title":"Security","text":"<ul> <li>Use a strong <code>SECRET_KEY</code> and keep it secret.</li> <li>Use HTTPS.</li> <li>Sanitize user input to prevent XSS attacks.</li> <li>Use parameterized queries to prevent SQL injection.</li> <li>Use a Content Security Policy (CSP) to prevent various attacks.</li> <li>Protect against CSRF attacks using Flask-WTF.</li> <li>Limit file upload sizes.</li> <li>Validate file uploads.</li> <li>Use a security linter (e.g., Bandit).</li> </ul>"},{"location":"Cheat-Sheets/Flask/#logging_1","title":"Logging","text":""},{"location":"Cheat-Sheets/Flask/#configure-logging_1","title":"Configure Logging","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# In your code:\nlogger.info('This is an info message')\nlogger.warning('This is a warning message')\nlogger.error('This is an error message')\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#logging-to-a-file_1","title":"Logging to a File","text":"<pre><code>import logging\nimport logging.handlers\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n\n# Create a file handler\nlog_handler = logging.handlers.RotatingFileHandler('yourapp.log', maxBytes=10240, backupCount=5)\nlog_handler.setLevel(logging.DEBUG)\n\n# Create a logging format\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(formatter)\n\n# Add the handlers to the logger\nlogger.addHandler(log_handler)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-cli_1","title":"Flask CLI","text":"<p>Flask provides a command-line interface for managing your application.</p> <ul> <li><code>flask run</code>: Runs the development server.</li> <li><code>flask shell</code>: Opens a Python shell with the Flask application context.</li> <li><code>flask routes</code>: Shows the registered routes.</li> <li><code>flask db</code>: Manages database migrations (requires Flask-Migrate).</li> </ul> <p>To use the Flask CLI, you need to set the <code>FLASK_APP</code> environment variable:</p> <pre><code>export FLASK_APP=yourapp.py\n</code></pre> <p>Then, you can use the <code>flask</code> command:</p> <pre><code>flask run\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#context-processors_1","title":"Context Processors","text":"<p>Context processors inject variables automatically <pre><code>from flask import Flask\nfrom flask_cors import CORS\n\napp = Flask(__name__)\nCORS(app)  # Enable CORS for all routes\n\n@app.route(\"/api/data\")\ndef get_data():\n    return {\"message\": \"This is CORS enabled!\"}\n</code></pre></p>"},{"location":"Cheat-Sheets/Flask/#testing_2","title":"Testing","text":""},{"location":"Cheat-Sheets/Flask/#using-pytest_2","title":"Using pytest","text":"<p>Installation:</p> <pre><code>pip install pytest pytest-flask\n</code></pre> <p>Test Example:</p> <pre><code>import pytest\nfrom yourapp import app\n\n@pytest.fixture\ndef client():\n    app.config['TESTING'] = True\n    with app.test_client() as client:\n        yield client\n\ndef test_index_route(client):\n    response = client.get('/')\n    assert response.status_code == 200\n    assert b'Hello, World!' in response.data\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#using-unittest_2","title":"Using unittest","text":"<pre><code>import unittest\nfrom yourapp import app\n\nclass MyTestCase(unittest.TestCase):\n    def setUp(self):\n        app.config['TESTING'] = True\n        self.app = app.test_client()\n\n    def test_index_route(self):\n        response = self.app.get('/')\n        self.assertEqual(response.status_code, 200)\n        self.assertIn(b'Hello, World!', response.data)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#deployment_2","title":"Deployment","text":""},{"location":"Cheat-Sheets/Flask/#production-settings_2","title":"Production Settings","text":"<ul> <li>Set <code>FLASK_ENV=production</code> to disable debug mode.</li> <li>Use a production WSGI server (e.g., Gunicorn, uWSGI).</li> <li>Configure your web server (e.g., Nginx, Apache) to proxy requests to the WSGI server.</li> <li>Use a process manager (e.g., Supervisor, systemd) to manage the WSGI server.</li> <li>Configure logging.</li> <li>Use HTTPS.</li> </ul>"},{"location":"Cheat-Sheets/Flask/#wsgi-servers_2","title":"WSGI Servers","text":"<p>Gunicorn:</p> <pre><code>pip install gunicorn\ngunicorn yourapp:app --bind 0.0.0.0:8000\n</code></pre> <p>uWSGI:</p> <pre><code>pip install uwsgi\nuwsgi --http 0.0.0.0:8000 --module yourapp\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#environment-variables_2","title":"Environment Variables","text":"<p>Use environment variables for sensitive settings (e.g., <code>SECRET_KEY</code>, database credentials).</p>"},{"location":"Cheat-Sheets/Flask/#example-deployment-with-gunicorn-and-nginx_2","title":"Example Deployment with Gunicorn and Nginx","text":"<ol> <li>Install Gunicorn: <code>pip install gunicorn</code></li> <li>Create a WSGI entry point: <code>yourapp.py</code> (already covered)</li> <li>Create a systemd service file: <code>/etc/systemd/system/yourapp.service</code></li> </ol> <pre><code>[Unit]\nDescription=Gunicorn instance to serve yourapp\nAfter=network.target\n\n[Service]\nUser=youruser\nGroup=www-data\nWorkingDirectory=/path/to/your/app\nExecStart=/path/to/your/venv/bin/gunicorn --workers 3 --max-requests 500 --bind unix:/run/yourapp.sock yourapp:app\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <ol> <li>Create an Nginx configuration file: <code>/etc/nginx/sites-available/yourapp</code></li> </ol> <pre><code>server {\n    listen 80;\n    server_name yourdomain.com www.yourdomain.com;\n\n    location / {\n        include proxy_params;\n        proxy_pass http://unix:/run/yourapp.sock;\n    }\n\n    location /static {\n        alias /path/to/your/app/static;\n    }\n}\n</code></pre> <ol> <li>Create a symbolic link:</li> </ol> <pre><code>sudo ln -s /etc/nginx/sites-available/yourapp /etc/nginx/sites-enabled\n</code></pre> <ol> <li>Restart Nginx:</li> </ol> <pre><code>sudo systemctl restart nginx\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#security_2","title":"Security","text":"<ul> <li>Use a strong <code>SECRET_KEY</code> and keep it secret.</li> <li>Use HTTPS.</li> <li>Sanitize user input to prevent XSS attacks.</li> <li>Use parameterized queries to prevent SQL injection.</li> <li>Use a Content Security Policy (CSP) to prevent various attacks.</li> <li>Protect against CSRF attacks using Flask-WTF.</li> <li>Limit file upload sizes.</li> <li>Validate file uploads.</li> <li>Use a security linter (e.g., Bandit).</li> </ul>"},{"location":"Cheat-Sheets/Flask/#logging_2","title":"Logging","text":""},{"location":"Cheat-Sheets/Flask/#configure-logging_2","title":"Configure Logging","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO,\n                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# In your code:\nlogger.info('This is an info message')\nlogger.warning('This is a warning message')\nlogger.error('This is an error message')\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#logging-to-a-file_2","title":"Logging to a File","text":"<pre><code>import logging\nimport logging.handlers\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n\n# Create a file handler\nlog_handler = logging.handlers.RotatingFileHandler('yourapp.log', maxBytes=10240, backupCount=5)\nlog_handler.setLevel(logging.DEBUG)\n\n# Create a logging format\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlog_handler.setFormatter(formatter)\n\n# Add the handlers to the logger\nlogger.addHandler(log_handler)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-cli_2","title":"Flask CLI","text":"<p>Flask provides a command-line interface for managing your application.</p> <ul> <li><code>flask run</code>: Runs the development server.</li> <li><code>flask shell</code>: Opens a Python shell with the Flask application context.</li> <li><code>flask routes</code>: Shows the registered routes.</li> <li><code>flask db</code>: Manages database migrations (requires Flask-Migrate).</li> </ul> <p>To use the Flask CLI, you need to set the <code>FLASK_APP</code> environment variable:</p> <pre><code>export FLASK_APP=yourapp.py\n</code></pre> <p>Then, you can use the <code>flask</code> command:</p> <pre><code>flask run\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#context-processors_2","title":"Context Processors","text":"<p>Context processors inject variables automatically into all templates.</p> <pre><code>from flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.context_processor\ndef inject_variables():\n    return dict(site_name=\"My Awesome Website\")\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n</code></pre> <p>In <code>templates/index.html</code>:</p> <pre><code>&lt;h1&gt;Welcome to {{ site_name }}!&lt;/h1&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#error-handling_1","title":"Error Handling","text":""},{"location":"Cheat-Sheets/Flask/#custom-error-pages_1","title":"Custom Error Pages","text":"<pre><code>from flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.errorhandler(404)\ndef page_not_found(e):\n    return render_template('404.html'), 404\n\n@app.errorhandler(500)\ndef internal_server_error(e):\n    return render_template('500.html'), 500\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#logging-exceptions_1","title":"Logging Exceptions","text":"<pre><code>import logging\nfrom flask import Flask, render_template\n\napp = Flask(__name__)\nlogger = logging.getLogger(__name__)\n\n@app.route('/')\ndef index():\n    try:\n        # Some code that might raise an exception\n        raise ValueError(\"Something went wrong\")\n    except Exception as e:\n        logger.exception(\"An error occurred\")\n        return render_template('error.html', error=str(e)), 500\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-restful_1","title":"Flask-RESTful","text":""},{"location":"Cheat-Sheets/Flask/#installation_3","title":"Installation","text":"<pre><code>pip install flask-restful\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#define-resources_1","title":"Define Resources","text":"<pre><code>from flask import Flask\nfrom flask_restful import Api, Resource\n\napp = Flask(__name__)\napi = Api(app)\n\nclass HelloWorld(Resource):\n    def get(self):\n        return {'hello': 'world'}\n\napi.add_resource(HelloWorld, '/')\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#request-parsing_1","title":"Request Parsing","text":"<pre><code>from flask_restful import reqparse\n\nparser = reqparse.RequestParser()\nparser.add_argument('name', required=True, help=\"Name is required\")\n\nclass MyResource(Resource):\n    def post(self):\n        args = parser.parse_args()\n        name = args['name']\n        return {'message': f'Hello, {name}!'}\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#session-management_1","title":"Session Management","text":"<pre><code>from flask import Flask, session, redirect, url_for, escape, request\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your_secret_key'\n\n@app.route('/')\ndef index():\n    if 'username' in session:\n        return f'Logged in as {escape(session[\"username\"])}\nClick here to &lt;a href=\"{url_for(\"logout\")}\"&gt;logout&lt;/a&gt;'\n    return 'You are not logged in\nClick here to &lt;a href=\"{url_for(\"login\")}\"&gt;login&lt;/a&gt;'\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        session['username'] = request.form['username']\n        return redirect(url_for('index'))\n    return '''\n        &lt;form method=\"post\"&gt;\n            &lt;p&gt;&lt;input type=text name=username&gt;\n            &lt;p&gt;&lt;input type=submit value=Login&gt;\n        &lt;/form&gt;\n    '''\n\n@app.route('/logout')\ndef logout():\n    session.pop('username', None)\n    return redirect(url_for('index'))\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-cors_1","title":"Flask-CORS","text":""},{"location":"Cheat-Sheets/Flask/#installation_4","title":"Installation","text":"<pre><code>pip install flask-cors\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_1","title":"Usage","text":"<pre><code>from flask import Flask\nfrom flask_cors import CORS\n\napp = Flask(__name__)\nCORS(app)  # Enable CORS for all routes\n\n@app.route(\"/api/data\")\ndef get_data():\n    return {\"message\": \"This is CORS enabled!\"}\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#signals","title":"Signals","text":"<p>Flask doesn't have built-in signals like Django, but you can use a third-party library like <code>blinker</code> to implement signals.</p>"},{"location":"Cheat-Sheets/Flask/#installation_5","title":"Installation","text":"<pre><code>pip install blinker\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_2","title":"Usage","text":"<pre><code>from flask import Flask\nfrom blinker import signal\n\napp = Flask(__name__)\n\nbefore_request = signal('before_request')\n\n@app.before_request\ndef before_request_handler():\n    before_request.send(app)\n\n@before_request.connect\ndef my_listener(sender):\n    print(\"Before request signal received\")\n\n@app.route('/')\ndef index():\n    return \"Hello, World!\"\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-limiter","title":"Flask-Limiter","text":""},{"location":"Cheat-Sheets/Flask/#installation_6","title":"Installation","text":"<pre><code>pip install Flask-Limiter\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_3","title":"Usage","text":"<pre><code>from flask import Flask\nfrom flask_limiter import Limiter\nfrom flask_limiter.util import get_remote_address\n\napp = Flask(__name__)\nlimiter = Limiter(\n    app,\n    key_func=get_remote_address,\n    default_limits=[\"200 per day\", \"50 per hour\"]\n)\n\n@app.route(\"/slow\")\n@limiter.limit(\"10 per minute\")\ndef slow():\n    return \"Slow route\"\n\n@app.route(\"/fast\")\ndef fast():\n    return \"Fast route\"\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-apscheduler","title":"Flask-APScheduler","text":""},{"location":"Cheat-Sheets/Flask/#installation_7","title":"Installation","text":"<pre><code>pip install flask-apscheduler\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_4","title":"Usage","text":"<pre><code>from flask import Flask\nfrom flask_apscheduler import APScheduler\nimport time\n\nclass Config(object):\n    JOBS = [\n        {\n            'id': 'job1',\n            'func': 'yourapp:job1',\n            'trigger': 'interval',\n            'seconds': 10\n        }\n    ]\n    SCHEDULER_API_ENABLED = True\n\napp = Flask(__name__)\napp.config.from_object(Config())\n\nscheduler = APScheduler()\n# it is also possible to enable the API directly\n# scheduler.api_enabled = True\nscheduler.init_app(app)\nscheduler.start()\n\ndef job1():\n    print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-sitemap","title":"Flask-Sitemap","text":""},{"location":"Cheat-Sheets/Flask/#installation_8","title":"Installation","text":"<pre><code>pip install Flask-Sitemap\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_5","title":"Usage","text":"<pre><code>from flask import Flask\nfrom flask_sitemap import Sitemap\n\napp = Flask(__name__)\next = Sitemap(app=app)\n\n@app.route(\"/sitemap.xml\")\ndef sitemap():\n    return ext.generate(base_url='http://example.com')\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-wtf-csrf-protection","title":"Flask-WTF CSRF Protection","text":""},{"location":"Cheat-Sheets/Flask/#configuration","title":"Configuration","text":"<pre><code>from flask import Flask\nfrom flask_wtf.csrf import CSRFProtect\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your_secret_key'\ncsrf = CSRFProtect(app)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage-in-templates","title":"Usage in Templates","text":"<pre><code>&lt;form method=\"post\"&gt;\n    {{ form.csrf_token }}\n    &lt;!-- Your form fields --&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-flatpages","title":"Flask-FlatPages","text":""},{"location":"Cheat-Sheets/Flask/#installation_9","title":"Installation","text":"<pre><code>pip install Flask-FlatPages\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#configuration_1","title":"Configuration","text":"<pre><code>from flask import Flask\nfrom flask_flatpages import FlatPages\n\napp = Flask(__name__)\napp.config['FLATPAGES_EXTENSION'] = '.md'\napp.config['FLATPAGES_ROOT'] = 'pages'\npages = FlatPages(app)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_6","title":"Usage","text":"<p>Create a directory named <code>pages</code> in your project root. Add your flat pages as <code>.md</code> files.</p> <pre><code>from flask import Flask, render_template\nfrom flask_flatpages import FlatPages, pygments_style_defs\n\napp = Flask(__name__)\napp.config['FLATPAGES_EXTENSION'] = '.md'\napp.config['FLATPAGES_ROOT'] = 'pages'\napp.config['FLATPAGES_MARKDOWN_EXTENSIONS'] = ['codehilite', 'fenced_code']\napp.config['PYGMENTS_STYLE'] = 'default'\npages = FlatPages(app)\n\n@app.route('/page/&lt;path:path&gt;')\ndef page(path):\n    page = pages.get_or_404(path)\n    return render_template('page.html', page=page, pygments_style=pygments_style_defs())\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-assets","title":"Flask-Assets","text":""},{"location":"Cheat-Sheets/Flask/#installation_10","title":"Installation","text":"<pre><code>pip install Flask-Assets\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#configuration_2","title":"Configuration","text":"<pre><code>from flask import Flask\nfrom flask_assets import Environment, Bundle\n\napp = Flask(__name__)\nassets = Environment(app)\n\njs = Bundle('js/jquery.js', 'js/base.js', filters='jsmin', output='gen/packed.js')\ncss = Bundle('css/base.css', 'css/common.css', filters='cssmin', output='gen/all.css')\n\nassets.register('all_js', js)\nassets.register('all_css', css)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage-in-templates_1","title":"Usage in Templates","text":"<pre><code>{% assets \"all_js\" %}\n    &lt;script type=\"text/javascript\" src=\"{{ ASSET_URL }}\"&gt;&lt;/script&gt;\n{% endassets %}\n\n{% assets \"all_css\" %}\n    &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"{{ ASSET_URL }}\"&gt;\n{% endassets %}\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-babel","title":"Flask-Babel","text":""},{"location":"Cheat-Sheets/Flask/#installation_11","title":"Installation","text":"<pre><code>pip install Flask-Babel\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#configuration_3","title":"Configuration","text":"<pre><code>from flask import Flask\nfrom flask_babel import Babel\n\napp = Flask(__name__)\napp.config['BABEL_DEFAULT_LOCALE'] = 'en'\nbabel = Babel(app)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_7","title":"Usage","text":"<pre><code>from flask import Flask, render_template\nfrom flask_babel import Babel, gettext\n\napp = Flask(__name__)\napp.config['BABEL_DEFAULT_LOCALE'] = 'en'\nbabel = Babel(app)\n\n@app.route('/')\ndef index():\n    title = gettext('Welcome')\n    return render_template('index.html', title=title)\n</code></pre> <p>In <code>templates/index.html</code>:</p> <pre><code>&lt;h1&gt;{{ title }}&lt;/h1&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-socketio","title":"Flask-SocketIO","text":""},{"location":"Cheat-Sheets/Flask/#installation_12","title":"Installation","text":"<pre><code>pip install flask-socketio\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_8","title":"Usage","text":"<pre><code>from flask import Flask, render_template\nfrom flask_socketio import SocketIO, emit\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'secret!'\nsocketio = SocketIO(app)\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@socketio.on('connect')\ndef test_connect():\n    emit('my response', {'data': 'Connected!'})\n\n@socketio.on('my event')\ndef handle_my_custom_event(json):\n    print('received json: ' + str(json))\n    socketio.emit('my response', json)\n\nif __name__ == '__main__':\n    socketio.run(app, debug=True)\n</code></pre> <p>In <code>templates/index.html</code>:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Flask-SocketIO Test&lt;/title&gt;\n    &lt;script src=\"https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js\" integrity=\"sha512-q/dWj3kcmNeAqFvv3EY9JJ/KEvVcjtgJBmWsGGHa+YwdlOfjoOvozUvCpJlPzl5lwCDsLQIY9Mq1v8XtZiuCQ==\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;\n    &lt;script type=\"text/javascript\" charset=\"utf-8\"&gt;\n        $(document).ready(function() {\n            var socket = io();\n            socket.on('connect', function() {\n                socket.emit('my event', {data: 'I\\'m connected!'});\n            });\n            socket.on('my response', function(msg) {\n                $('#log').append('&lt;p&gt;Received: ' + msg.data + '&lt;/p&gt;');\n            });\n            $('form#emit').submit(function(event) {\n                socket.emit('my event', {data: $('#emit_data').val()});\n                return false;\n            });\n        });\n    &lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Flask-SocketIO Test&lt;/h1&gt;\n    &lt;div id=\"log\"&gt;&lt;/div&gt;\n    &lt;form id=\"emit\" method=\"POST\" action=\"#\"&gt;\n        &lt;input type=\"text\" id=\"emit_data\" name=\"emit_data\" placeholder=\"Message\"&gt;\n        &lt;input type=\"submit\" value=\"Echo\"&gt;\n    &lt;/form&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-principal","title":"Flask-Principal","text":""},{"location":"Cheat-Sheets/Flask/#installation_13","title":"Installation","text":"<pre><code>pip install Flask-Principal\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_9","title":"Usage","text":"<pre><code>from flask import Flask, g\nfrom flask_principal import Principal, Permission, RoleNeed, UserNeed, identity_loaded, UserContext, Identity, AnonymousIdentity\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your_secret_key'\n\nprincipals = Principal(app)\n\n# Define Needs\nadmin_permission = Permission(RoleNeed('admin'))\nposter_permission = Permission(RoleNeed('poster'))\n\n# Define Roles\nadmin_role = RoleNeed('admin')\nposter_role = RoleNeed('poster')\nuser_need = UserNeed(1)\n\n@identity_loaded.connect_via(app)\ndef on_identity_loaded(sender, identity):\n    # Set the identity user object\n    identity.user = get_user()\n\n    # Add the UserNeed to the identity\n    identity.provides.add(UserNeed(identity.user.id))\n\n    # Assuming the user has a method that returns a list of roles\n    for role in identity.user.roles:\n        identity.provides.add(RoleNeed(role.name))\n\ndef get_user():\n    # Replace with your user loading logic (e.g., from database)\n    class User(object):\n        def __init__(self, id, roles):\n            self.id = id\n            self.roles = roles\n\n    class Role(object):\n        def __init__(self, name):\n            self.name = name\n\n    admin_role = Role('admin')\n    poster_role = Role('poster')\n\n    user = User(1, [admin_role, poster_role])\n    return user\n\n@app.route('/')\ndef index():\n    with UserContext(Identity(1)):\n        if admin_permission.can():\n            return \"Admin access granted\"\n        elif poster_permission.can():\n            return \"Poster access granted\"\n        else:\n            return \"Access denied\"\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-jwt-extended","title":"Flask-JWT-Extended","text":""},{"location":"Cheat-Sheets/Flask/#installation_14","title":"Installation","text":"<pre><code>pip install Flask-JWT-Extended\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_10","title":"Usage","text":"<pre><code>from flask import Flask\nfrom flask_jwt_extended import JWTManager, create_access_token, jwt_required, get_jwt_identity\n\napp = Flask(__name__)\napp.config[\"JWT_SECRET_KEY\"] = \"super-secret\"  # Change this!\njwt = JWTManager(app)\n\n@app.route(\"/login\", methods=[\"POST\"])\ndef login():\n    username = request.json.get(\"username\", None)\n    password = request.json.get(\"password\", None)\n    if username != \"test\" or password != \"test\":\n        return jsonify({\"msg\": \"Bad username or password\"}), 401\n\n    access_token = create_access_token(identity=username)\n    return jsonify(access_token=access_token)\n\n@app.route(\"/protected\", methods=[\"GET\"])\n@jwt_required()\ndef protected():\n    current_user = get_jwt_identity()\n    return jsonify(logged_in_as=current_user), 200\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-uploads","title":"Flask-Uploads","text":""},{"location":"Cheat-Sheets/Flask/#installation_15","title":"Installation","text":"<pre><code>pip install Flask-Uploads\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_11","title":"Usage","text":"<pre><code>from flask import Flask, request, render_template\nfrom flask_uploads import UploadSet, configure_uploads, IMAGES, patch_request_class\n\napp = Flask(__name__)\napp.config['UPLOADED_PHOTOS_DEST'] = 'uploads'\napp.config['SECRET_KEY'] = 'super secret key'\nphotos = UploadSet('photos', IMAGES)\n\nconfigure_uploads(app, photos)\npatch_request_class(app)  # set maximum file size, default is 16MB\n\n@app.route('/upload', methods=['GET', 'POST'])\ndef upload():\n    if request.method == 'POST' and 'photo' in request.files:\n        filename = photos.save(request.files['photo'])\n        url = photos.url(filename)\n        return render_template('upload.html', filename=filename, url=url)\n    return render_template('upload.html')\n</code></pre> <p>In <code>templates/upload.html</code>:</p> <pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Upload&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    {% if filename %}\n        &lt;img src=\"{{ url }}\" alt=\"Uploaded Image\"&gt;\n    {% else %}\n        &lt;form method=\"post\" enctype=\"multipart/form-data\"&gt;\n            &lt;input type=\"file\" name=\"photo\"&gt;\n            &lt;button type=\"submit\"&gt;Upload&lt;/button&gt;\n        &lt;/form&gt;\n    {% endif %}\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-mail_1","title":"Flask-Mail","text":""},{"location":"Cheat-Sheets/Flask/#installation_16","title":"Installation","text":"<pre><code>pip install flask-mail\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#configuration_4","title":"Configuration","text":"<pre><code>from flask import Flask\nfrom flask_mail import Mail, Message\n\napp = Flask(__name__)\napp.config['MAIL_SERVER'] = 'smtp.gmail.com'\napp.config['MAIL_PORT'] = 587\napp.config['MAIL_USE_TLS'] = True\napp.config['MAIL_USE_SSL'] = False\napp.config['MAIL_USERNAME'] = 'your_email@gmail.com'\napp.config['MAIL_PASSWORD'] = 'your_password'\nmail = Mail(app)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#sending-emails","title":"Sending Emails","text":"<pre><code>from flask import Flask, render_template\nfrom flask_mail import Mail, Message\n\napp = Flask(__name__)\napp.config['MAIL_SERVER'] = 'smtp.gmail.com'\napp.config['MAIL_PORT'] = 587\napp.config['MAIL_USE_TLS'] = True\napp.config['MAIL_USE_SSL'] = False\napp.config['MAIL_USERNAME'] = 'your_email@gmail.com'\napp.config['MAIL_PASSWORD'] = 'your_password'\nmail = Mail(app)\n\n@app.route('/send')\ndef send_email():\n    msg = Message(\"Hello\",\n                  sender=\"your_email@gmail.com\",\n                  recipients=[\"recipient@example.com\"])\n    msg.body = \"Hello Flask message sent from Flask-Mail\"\n    mail.send(msg)\n    return \"Sent\"\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-apscheduler_1","title":"Flask-APScheduler","text":""},{"location":"Cheat-Sheets/Flask/#installation_17","title":"Installation","text":"<pre><code>pip install flask-apscheduler\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_12","title":"Usage","text":"<pre><code>from flask import Flask\nfrom flask_apscheduler import APScheduler\nimport time\n\nclass Config(object):\n    JOBS = [\n        {\n            'id': 'job1',\n            'func': 'yourapp:job1',\n            'trigger': 'interval',\n            'seconds': 10\n        }\n    ]\n    SCHEDULER_API_ENABLED = True\n\napp = Flask(__name__)\napp.config.from_object(Config())\n\nscheduler = APScheduler()\n# it is also possible to enable the API directly\n# scheduler.api_enabled = True\nscheduler.init_app(app)\nscheduler.start()\n\ndef job1():\n    print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-sitemap_1","title":"Flask-Sitemap","text":""},{"location":"Cheat-Sheets/Flask/#installation_18","title":"Installation","text":"<pre><code>pip install Flask-Sitemap\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage_13","title":"Usage","text":"<pre><code>from flask import Flask\nfrom flask_sitemap import Sitemap\n\napp = Flask(__name__)\next = Sitemap(app=app)\n\n@app.route(\"/sitemap.xml\")\ndef sitemap():\n    return ext.generate(base_url='http://example.com')\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#flask-wtf-csrf-protection_1","title":"Flask-WTF CSRF Protection","text":""},{"location":"Cheat-Sheets/Flask/#configuration_5","title":"Configuration","text":"<pre><code>from flask import Flask\nfrom flask_wtf.csrf import CSRFProtect\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your_secret_key'\ncsrf = CSRFProtect(app)\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#usage-in-templates_2","title":"Usage in Templates","text":"<pre><code>&lt;form method=\"post\"&gt;\n    {{ form.csrf_token }}\n    &lt;!-- Your form fields --&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"Cheat-Sheets/Flask/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ul> <li>Use virtual environments to isolate project dependencies.</li> <li>Keep <code>SECRET_KEY</code> secure and out of your codebase. Use environment variables.</li> <li>Use meaningful names for routes, variables, and functions.</li> <li>Follow the DRY (Don't Repeat Yourself) principle.</li> <li>Write unit tests to ensure code quality.</li> <li>Use a production-ready web server (e.g., Gunicorn, uWSGI) and a process manager (e.g., Supervisor, systemd) for deployment.</li> <li>Use a linter (like <code>flake8</code>) and formatter (like <code>black</code>) to ensure consistent code style.</li> <li>Keep your code modular and reusable.</li> <li>Document your code.</li> <li>Use a version control system (e.g., Git).</li> <li>Follow Flask's coding style guidelines.</li> <li>Use Flask's built-in session management or a more robust solution like Flask-Session.</li> <li>Monitor your application for errors and performance issues.</li> <li>Use a CDN (Content Delivery Network) for static files.</li> <li>Optimize database queries.</li> <li>Use asynchronous tasks for long-running operations (e.g., sending emails) using Celery or similar.</li> <li>Implement proper logging and error handling.</li> <li>Regularly update Flask and its dependencies.</li> <li>Use a security scanner to identify potential vulnerabilities.</li> <li>Follow security best practices.</li> <li>Use a reverse proxy like Nginx or Apache in front of your WSGI server.</li> <li>Use a load balancer for high availability.</li> <li>Automate deployments using tools like Fabric or Ansible.</li> <li>Use a monitoring tool like Sentry or New Relic.</li> <li>Implement health checks for your application.</li> <li>Use a CDN for static assets.</li> <li>Cache frequently accessed data.</li> <li>Use a database connection pool.</li> <li>Optimize your database queries.</li> <li>Use a task queue for long-running tasks.</li> <li>Use a background worker for asynchronous tasks.</li> <li>Use a message queue for inter-process communication.</li> <li>Use a service discovery tool for microservices.</li> <li>Use a containerization tool like Docker.</li> <li>Use an orchestration tool like Kubernetes.</li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/","title":"Hypothesis Tests in Python","text":"<ul> <li>Hypothesis Tests in Python<ul> <li>Normality Tests<ul> <li>Shapiro-Wilk Test</li> <li>D\u2019Agostino\u2019s K^2 Test</li> <li>Anderson-Darling Test</li> </ul> </li> <li>Correlation Tests<ul> <li>Pearson\u2019s Correlation Coefficient</li> <li>Spearman\u2019s Rank Correlation</li> <li>Kendall\u2019s Rank Correlation</li> <li>Chi-Squared Test</li> </ul> </li> <li>Stationary Tests<ul> <li>Augmented Dickey-Fuller Unit Root Test</li> <li>Kwiatkowski-Phillips-Schmidt-Shin</li> </ul> </li> <li>Parametric Statistical Hypothesis Tests<ul> <li>Student\u2019s t-test</li> <li>Paired Student\u2019s t-test</li> <li>Analysis of Variance Test (ANOVA)</li> <li>Repeated Measures ANOVA Test</li> </ul> </li> <li>Nonparametric Statistical Hypothesis Tests<ul> <li>Mann-Whitney U Test</li> <li>Wilcoxon Signed-Rank Test</li> <li>Kruskal-Wallis H Test</li> <li>Friedman Test</li> </ul> </li> <li>Equality of variance test<ul> <li>Levene's test</li> </ul> </li> </ul> </li> </ul> <p>A\u00a0statistical hypothesis test\u00a0is a method of\u00a0statistical inference\u00a0used to decide whether the data at hand sufficiently support a particular hypothesis. Hypothesis testing allows us to make probabilistic statements about population parameters.</p> <p>Few Notes:</p> <ul> <li>When it comes to assumptions such as the expected distribution of data or sample size, the results of a given test are likely to degrade gracefully rather than become immediately unusable if an assumption is violated.</li> <li>Generally, data samples need to be representative of the domain and large enough to expose their distribution to analysis.</li> <li>In some cases, the data can be corrected to meet the assumptions, such as correcting a nearly normal distribution to be normal by removing outliers, or using a correction to the degrees of freedom in a statistical test when samples have differing variance, to name two examples.</li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#normality-tests","title":"Normality Tests","text":"<p>This section lists statistical tests that you can use to check if your data has a Gaussian distribution.</p> <p>Gaussian distribution (also known as normal distribution) is a bell-shaped curve.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#shapiro-wilk-test","title":"Shapiro-Wilk Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Shapiro-Wilk Normality Test\nfrom scipy.stats import shapiro\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nstat, p = shapiro(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.shapiro</li> <li>Shapiro-Wilk test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#dagostinos-k2-test","title":"D\u2019Agostino\u2019s K^2 Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the D'Agostino's K^2 Normality Test\nfrom scipy.stats import normaltest\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nstat, p = normaltest(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.normaltest</li> <li>D'Agostino's K-squared test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#anderson-darling-test","title":"Anderson-Darling Test","text":"<p>Tests whether a data sample has a Gaussian distribution/Normal distribution.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the sample has a Gaussian distribution.</li> <li>H1: the sample does not have a Gaussian distribution.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Anderson-Darling Normality Test\nfrom scipy.stats import anderson\ndata = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\nresult = anderson(data)\nprint('stat=%.3f' % (result.statistic))\nfor i in range(len(result.critical_values)):\n    sl, cv = result.significance_level[i], result.critical_values[i]\n    if result.statistic &lt; cv:\n        print('Probably Gaussian at the %.1f%% level' % (sl))\n    else:\n        print('Probably not Gaussian at the %.1f%% level' % (sl))\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.anderson</li> <li>Anderson-Darling test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#correlation-tests","title":"Correlation Tests","text":"<p>This section lists statistical tests that you can use to check if two samples are related.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#pearsons-correlation-coefficient","title":"Pearson\u2019s Correlation Coefficient","text":"<p>Tests whether two samples have a linear relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Pearson's Correlation test\nfrom scipy.stats import pearsonr\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = pearsonr(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.pearsonr</li> <li>Pearson's correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#spearmans-rank-correlation","title":"Spearman\u2019s Rank Correlation","text":"<p>Tests whether two samples have a monotonic relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Spearman's Rank Correlation Test\nfrom scipy.stats import spearmanr\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = spearmanr(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.spearmanr</li> <li>Spearman's rank correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kendalls-rank-correlation","title":"Kendall\u2019s Rank Correlation","text":"<p>Tests whether two samples have a monotonic relationship.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kendall's Rank Correlation Test\nfrom scipy.stats import kendalltau\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [0.353, 3.517, 0.125, -7.545, -0.555, -1.536, 3.350, -1.578, -3.537, -1.579]\nstat, p = kendalltau(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.kendalltau</li> <li>Kendall rank correlation coefficient on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#chi-squared-test","title":"Chi-Squared Test","text":"<p>Tests whether two categorical variables are related or independent.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations used in the calculation of the contingency table are independent.</li> <li>25 or more examples in each cell of the contingency table.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the two samples are independent.</li> <li>H1: there is a dependency between the samples.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Chi-Squared Test\nfrom scipy.stats import chi2_contingency\ntable = [[10, 20, 30],[6,  9,  17]]\nstat, p, dof, expected = chi2_contingency(table)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably independent')\nelse:\n    print('Probably dependent')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.chi2_contingency</li> <li>Chi-Squared test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#stationary-tests","title":"Stationary Tests","text":"<p>This section lists statistical tests that you can use to check if a time series is stationary or not.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#augmented-dickey-fuller-unit-root-test","title":"Augmented Dickey-Fuller Unit Root Test","text":"<p>Tests whether a time series has a unit root, e.g. has a trend or more generally is autoregressive.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in are temporally ordered.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: a unit root is present (series is non-stationary).</li> <li>H1: a unit root is not present (series is stationary).</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Augmented Dickey-Fuller unit root test\nfrom statsmodels.tsa.stattools import adfuller\ndata = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nstat, p, lags, obs, crit, t = adfuller(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably not Stationary')\nelse:\n    print('Probably Stationary')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>statsmodels.tsa.stattools.adfuller API.</li> <li>Augmented Dickey--Fuller test, Wikipedia.</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kwiatkowski-phillips-schmidt-shin","title":"Kwiatkowski-Phillips-Schmidt-Shin","text":"<p>Tests whether a time series is trend stationary or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in are temporally ordered.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the time series is trend-stationary.</li> <li>H1: the time series is not trend-stationary.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kwiatkowski-Phillips-Schmidt-Shin test\nfrom statsmodels.tsa.stattools import kpss\ndata = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nstat, p, lags, crit = kpss(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably Stationary')\nelse:\n    print('Probably not Stationary')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>statsmodels.tsa.stattools.kpss API.</li> <li>KPSS test, Wikipedia.</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#parametric-statistical-hypothesis-tests","title":"Parametric Statistical Hypothesis Tests","text":"<p>This section lists statistical tests that you can use to compare data samples.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#students-t-test","title":"Student\u2019s t-test","text":"<p>Tests whether the means of two independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Student's t-test\nfrom scipy.stats import ttest_ind\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = ttest_ind(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.ttest_ind</li> <li>Student's t-test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#paired-students-t-test","title":"Paired Student\u2019s t-test","text":"<p>Tests whether the means of two independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Paired Student's t-test\nfrom scipy.stats import ttest_rel\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = ttest_rel(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.ttest_rel</li> <li>Student's t-test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#analysis-of-variance-test-anova","title":"Analysis of Variance Test (ANOVA)","text":"<p>Tests whether the means of two or more independent samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Analysis of Variance Test\nfrom scipy.stats import f_oneway\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\ndata3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\nstat, p = f_oneway(data1, data2, data3)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.f_oneway</li> <li>Analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#repeated-measures-anova-test","title":"Repeated Measures ANOVA Test","text":"<p>Tests whether the means of two or more paired samples are significantly different.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample are normally distributed.</li> <li>Observations in each sample have the same variance.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the means of the samples are equal.</li> <li>H1: one or more of the means of the samples are unequal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Currently not supported in Python. :(\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>Analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#nonparametric-statistical-hypothesis-tests","title":"Nonparametric Statistical Hypothesis Tests","text":"<p>In Non-Parametric tests, we don't make any assumption about the parameters for the given population or the population we are studying. In fact, these tests don't depend on the population. Hence, there is no fixed set of parameters is available, and also there is no distribution (normal distribution, etc.)</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#mann-whitney-u-test","title":"Mann-Whitney U Test","text":"<p>Tests whether the distributions of two independent samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of both samples are equal.</li> <li>H1: the distributions of both samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Mann-Whitney U Test\nfrom scipy.stats import mannwhitneyu\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = mannwhitneyu(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.mannwhitneyu</li> <li>Mann-Whitney U test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#wilcoxon-signed-rank-test","title":"Wilcoxon Signed-Rank Test","text":"<p>Tests whether the distributions of two paired samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of both samples are equal.</li> <li>H1: the distributions of both samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Wilcoxon Signed-Rank Test\nfrom scipy.stats import wilcoxon\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = wilcoxon(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.wilcoxon</li> <li>Wilcoxon signed-rank test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#kruskal-wallis-h-test","title":"Kruskal-Wallis H Test","text":"<p>Tests whether the distributions of two or more independent samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of all samples are equal.</li> <li>H1: the distributions of one or more samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Kruskal-Wallis H Test\nfrom scipy.stats import kruskal\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\nstat, p = kruskal(data1, data2)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.kruskal</li> <li>Kruskal-Wallis one-way analysis of variance on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#friedman-test","title":"Friedman Test","text":"<p>Tests whether the distributions of two or more paired samples are equal or not.</p> <ul> <li> <p>Assumptions</p> <ul> <li>Observations in each sample are independent and identically distributed (iid).</li> <li>Observations in each sample can be ranked.</li> <li>Observations across each sample are paired.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: the distributions of all samples are equal.</li> <li>H1: the distributions of one or more samples are not equal.</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Friedman Test\nfrom scipy.stats import friedmanchisquare\ndata1 = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\ndata2 = [1.142, -0.432, -0.938, -0.729, -0.846, -0.157, 0.500, 1.183, -1.075, -0.169]\ndata3 = [-0.208, 0.696, 0.928, -1.148, -0.213, 0.229, 0.137, 0.269, -0.870, -1.204]\nstat, p = friedmanchisquare(data1, data2, data3)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.friedmanchisquare</li> <li>Friedman test on Wikipedia</li> </ul> </li> </ul>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#equality-of-variance-test","title":"Equality of variance test","text":"<p>Test is used to assess the equality of variance between two different samples.</p>"},{"location":"Cheat-Sheets/Hypothesis-Tests/#levenes-test","title":"Levene's test","text":"<p>Levene\u2019s test is used to assess the equality of variance between two or more different samples.</p> <ul> <li> <p>Assumptions</p> <ul> <li>The samples from the populations under consideration are independent.</li> <li>The populations under consideration are approximately normally distributed.</li> </ul> </li> <li> <p>Interpretation</p> <ul> <li>H0: All the samples variances are equal</li> <li>H1: At least one variance is different from the rest</li> </ul> </li> <li> <p>Python Code</p> <pre><code># Example of the Levene's test\nfrom scipy.stats import levene\na = [8.88, 9.12, 9.04, 8.98, 9.00, 9.08, 9.01, 8.85, 9.06, 8.99]\nb = [8.88, 8.95, 9.29, 9.44, 9.15, 9.58, 8.36, 9.18, 8.67, 9.05]\nc = [8.95, 9.12, 8.95, 8.85, 9.03, 8.84, 9.07, 8.98, 8.86, 8.98]\nstat, p = levene(a, b, c)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p &gt; 0.05:\n    print('Probably the same variances')\nelse:\n    print('Probably at least one variance is different from the rest')\n</code></pre> </li> <li> <p>Sources</p> <ul> <li>scipy.stats.levene</li> <li>Levene's test on Wikipedia</li> </ul> </li> </ul> <p>Source: https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/</p>"},{"location":"Cheat-Sheets/Keras/","title":"Keras Cheat Sheet","text":"<ul> <li>Keras Cheat Sheet<ul> <li>Getting Started<ul> <li>Installation</li> <li>Importing Keras</li> </ul> </li> <li>Model Building<ul> <li>Sequential Model</li> <li>Functional API</li> <li>Model Subclassing</li> </ul> </li> <li>Layers<ul> <li>Core Layers</li> <li>Convolutional Layers</li> <li>Pooling Layers</li> <li>Recurrent Layers</li> <li>Normalization Layers</li> <li>Advanced Activation Layers</li> <li>Embedding Layers</li> <li>Merge Layers</li> <li>Writing Custom Layers</li> </ul> </li> <li>Activation Functions</li> <li>Loss Functions<ul> <li>Regression Losses</li> <li>Classification Losses</li> <li>Custom Loss Functions</li> </ul> </li> <li>Optimizers<ul> <li>Optimizer Configuration</li> </ul> </li> <li>Metrics<ul> <li>Custom Metrics</li> </ul> </li> <li>Model Compilation</li> <li>Training<ul> <li>Training with NumPy Arrays</li> <li>Training with tf.data.Dataset</li> <li>Validation</li> <li>Callbacks</li> </ul> </li> <li>Evaluation</li> <li>Prediction</li> <li>Saving and Loading Models<ul> <li>Save the Entire Model</li> <li>Load the Entire Model</li> <li>Save Model Architecture as JSON</li> <li>Load Model Architecture from JSON</li> <li>Save Model Weights</li> <li>Load Model Weights</li> </ul> </li> <li>Regularization<ul> <li>L1 and L2 Regularization</li> <li>Dropout</li> <li>Batch Normalization</li> </ul> </li> <li>Transfer Learning<ul> <li>Feature Extraction</li> <li>Fine-Tuning</li> </ul> </li> <li>Callbacks<ul> <li>ModelCheckpoint</li> <li>EarlyStopping</li> <li>ReduceLROnPlateau</li> <li>TensorBoard</li> </ul> </li> <li>Custom Training Loops</li> <li>Distributed Training<ul> <li>MirroredStrategy</li> </ul> </li> <li>Hyperparameter Tuning<ul> <li>Using Keras Tuner</li> </ul> </li> <li>TensorFlow Datasets<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>TensorFlow Hub<ul> <li>Installation</li> <li>Usage</li> </ul> </li> <li>TensorFlow Lite<ul> <li>Convert to TensorFlow Lite</li> </ul> </li> <li>Tips and Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of the Keras deep learning library, covering essential concepts, code snippets, and best practices for efficient model building, training, and evaluation. It aims to be a one-stop reference for common tasks.</p>"},{"location":"Cheat-Sheets/Keras/#getting-started","title":"Getting Started","text":""},{"location":"Cheat-Sheets/Keras/#installation","title":"Installation","text":"<pre><code>pip install tensorflow  # Installs TensorFlow with Keras\n# or\npip install keras # Installs Keras with a backend (TensorFlow, Theano, or CNTK)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#importing-keras","title":"Importing Keras","text":"<pre><code>import tensorflow as tf  # If using TensorFlow backend\nfrom tensorflow import keras\n# or\nimport keras  # If using standalone Keras\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#model-building","title":"Model Building","text":""},{"location":"Cheat-Sheets/Keras/#sequential-model","title":"Sequential Model","text":"<pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(784,)),\n    Dense(10, activation='softmax')\n])\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#functional-api","title":"Functional API","text":"<pre><code>from tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.models import Model\n\ninputs = Input(shape=(784,))\nx = Dense(128, activation='relu')(inputs)\noutputs = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#model-subclassing","title":"Model Subclassing","text":"<pre><code>import tensorflow as tf\n\nclass MyModel(tf.keras.Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n\n    def call(self, inputs):\n        x = self.dense1(inputs)\n        return self.dense2(x)\n\nmodel = MyModel()\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#layers","title":"Layers","text":""},{"location":"Cheat-Sheets/Keras/#core-layers","title":"Core Layers","text":"<ul> <li><code>Dense</code>: Fully connected layer.</li> <li><code>Activation</code>: Applies an activation function.</li> <li><code>Dropout</code>: Applies dropout regularization.</li> <li><code>Flatten</code>: Flattens the input.</li> <li><code>Input</code>: Creates an input tensor.</li> <li><code>Reshape</code>: Reshapes the input.</li> <li><code>Embedding</code>: Turns positive integers (indexes) into dense vectors of fixed size.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#convolutional-layers","title":"Convolutional Layers","text":"<ul> <li><code>Conv1D</code>: 1D convolution layer.</li> <li><code>Conv2D</code>: 2D convolution layer.</li> <li><code>Conv3D</code>: 3D convolution layer.</li> <li><code>SeparableConv2D</code>: Depthwise separable 2D convolution layer.</li> <li><code>DepthwiseConv2D</code>: Depthwise 2D convolution layer.</li> <li><code>Conv2DTranspose</code>: Transposed convolution layer (deconvolution).</li> </ul>"},{"location":"Cheat-Sheets/Keras/#pooling-layers","title":"Pooling Layers","text":"<ul> <li><code>MaxPooling1D</code>, <code>MaxPooling2D</code>, <code>MaxPooling3D</code>: Max pooling layers.</li> <li><code>AveragePooling1D</code>, <code>AveragePooling2D</code>, <code>AveragePooling3D</code>: Average pooling layers.</li> <li><code>GlobalMaxPooling1D</code>, <code>GlobalMaxPooling2D</code>, <code>GlobalMaxPooling3D</code>: Global max pooling layers.</li> <li><code>GlobalAveragePooling1D</code>, <code>GlobalAveragePooling2D</code>, <code>GlobalAveragePooling3D</code>: Global average pooling layers.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#recurrent-layers","title":"Recurrent Layers","text":"<ul> <li><code>LSTM</code>: Long Short-Term Memory layer.</li> <li><code>GRU</code>: Gated Recurrent Unit layer.</li> <li><code>SimpleRNN</code>: Fully-connected RNN where the output is to be fed back to input.</li> <li><code>Bidirectional</code>: Wraps another recurrent layer to run it in both directions.</li> <li><code>ConvLSTM2D</code>: ConvLSTM2D layer.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#normalization-layers","title":"Normalization Layers","text":"<ul> <li><code>BatchNormalization</code>: Applies batch normalization.</li> <li><code>LayerNormalization</code>: Applies layer normalization.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#advanced-activation-layers","title":"Advanced Activation Layers","text":"<ul> <li><code>LeakyReLU</code>: Leaky version of a Rectified Linear Unit.</li> <li><code>PReLU</code>: Parametric Rectified Linear Unit.</li> <li><code>ELU</code>: Exponential Linear Unit.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#embedding-layers","title":"Embedding Layers","text":"<ul> <li><code>Embedding</code>: Turns positive integers (indexes) into dense vectors of fixed size.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#merge-layers","title":"Merge Layers","text":"<ul> <li><code>Add</code>: Adds inputs.</li> <li><code>Multiply</code>: Multiplies inputs.</li> <li><code>Average</code>: Averages inputs.</li> <li><code>Maximum</code>: Takes the maximum of inputs.</li> <li><code>Concatenate</code>: Concatenates inputs.</li> <li><code>Dot</code>: Performs a dot product between inputs.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#writing-custom-layers","title":"Writing Custom Layers","text":"<pre><code>import tensorflow as tf\n\nclass MyCustomLayer(tf.keras.layers.Layer):\n    def __init__(self, units=32):\n        super(MyCustomLayer, self).__init__()\n        self.units = units\n\n    def build(self, input_shape):\n        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n                                 initializer='random_normal',\n                                 trainable=True)\n        self.b = self.add_weight(shape=(self.units,),\n                                 initializer='zeros',\n                                 trainable=True)\n\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w) + self.b\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#activation-functions","title":"Activation Functions","text":"<ul> <li><code>relu</code>: Rectified Linear Unit.</li> <li><code>sigmoid</code>: Sigmoid function.</li> <li><code>tanh</code>: Hyperbolic tangent function.</li> <li><code>softmax</code>: Softmax function (for multi-class classification).</li> <li><code>elu</code>: Exponential Linear Unit.</li> <li><code>selu</code>: Scaled Exponential Linear Unit.</li> <li><code>linear</code>: Linear (identity) activation.</li> <li><code>LeakyReLU</code>: Leaky Rectified Linear Unit.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#loss-functions","title":"Loss Functions","text":""},{"location":"Cheat-Sheets/Keras/#regression-losses","title":"Regression Losses","text":"<ul> <li><code>MeanSquaredError</code>: Mean squared error.</li> <li><code>MeanAbsoluteError</code>: Mean absolute error.</li> <li><code>MeanAbsolutePercentageError</code>: Mean absolute percentage error.</li> <li><code>MeanSquaredLogarithmicError</code>: Mean squared logarithmic error.</li> <li><code>Huber</code>: Huber loss.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#classification-losses","title":"Classification Losses","text":"<ul> <li><code>BinaryCrossentropy</code>: Binary cross-entropy (for binary classification).</li> <li><code>CategoricalCrossentropy</code>: Categorical cross-entropy (for multi-class classification with one-hot encoded labels).</li> <li><code>SparseCategoricalCrossentropy</code>: Sparse categorical cross-entropy (for multi-class classification with integer labels).</li> <li><code>Hinge</code>: Hinge loss (for \"maximum-margin\" classification).</li> <li><code>KLDivergence</code>: Kullback-Leibler Divergence loss.</li> <li><code>Poisson</code>: Poisson loss.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#custom-loss-functions","title":"Custom Loss Functions","text":"<pre><code>import tensorflow as tf\n\ndef my_custom_loss(y_true, y_pred):\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#optimizers","title":"Optimizers","text":"<ul> <li><code>SGD</code>: Stochastic Gradient Descent.</li> <li><code>Adam</code>: Adaptive Moment Estimation.</li> <li><code>RMSprop</code>: Root Mean Square Propagation.</li> <li><code>Adagrad</code>: Adaptive Gradient Algorithm.</li> <li><code>Adadelta</code>: Adaptive Delta.</li> <li><code>Adamax</code>: Adamax optimizer from Adam and max operators.</li> <li><code>Nadam</code>: Nesterov Adam optimizer.</li> <li><code>Ftrl</code>: Follow The Regularized Leader optimizer.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#optimizer-configuration","title":"Optimizer Configuration","text":"<pre><code>from tensorflow.keras.optimizers import Adam\n\noptimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#metrics","title":"Metrics","text":"<ul> <li><code>Accuracy</code>: Accuracy.</li> <li><code>BinaryAccuracy</code>: Binary accuracy.</li> <li><code>CategoricalAccuracy</code>: Categorical accuracy.</li> <li><code>SparseCategoricalAccuracy</code>: Sparse categorical accuracy.</li> <li><code>TopKCategoricalAccuracy</code>: Computes how often targets are in the top K predictions.</li> <li><code>MeanAbsoluteError</code>: Mean absolute error.</li> <li><code>MeanSquaredError</code>: Mean squared error.</li> <li><code>Precision</code>: Precision.</li> <li><code>Recall</code>: Recall.</li> <li><code>AUC</code>: Area Under the Curve.</li> <li><code>F1Score</code>: F1 Score.</li> </ul>"},{"location":"Cheat-Sheets/Keras/#custom-metrics","title":"Custom Metrics","text":"<pre><code>import tensorflow as tf\n\nclass MyCustomMetric(tf.keras.metrics.Metric):\n    def __init__(self, name='my_custom_metric', **kwargs):\n        super(MyCustomMetric, self).__init__(name=name, **kwargs)\n        self.sum = self.add_weight(name='sum', initializer='zeros')\n        self.count = self.add_weight(name='count', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        values = tf.abs(y_true - y_pred)\n        if sample_weight is not None:\n            sample_weight = tf.cast(sample_weight, self.dtype)\n            values = tf.multiply(values, sample_weight)\n        self.sum.assign_add(tf.reduce_sum(values))\n        self.count.assign_add(tf.cast(tf.size(y_true), self.dtype))\n\n    def result(self):\n        return self.sum / self.count\n\n    def reset_state(self):\n        self.sum.assign(0.0)\n        self.count.assign(0.0)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#model-compilation","title":"Model Compilation","text":"<pre><code>model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#training","title":"Training","text":""},{"location":"Cheat-Sheets/Keras/#training-with-numpy-arrays","title":"Training with NumPy Arrays","text":"<pre><code>import numpy as np\n\ndata = np.random.random((1000, 784))\nlabels = np.random.randint(10, size=(1000,))\none_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=10)\n\nmodel.fit(data, one_hot_labels, epochs=10, batch_size=32)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#training-with-tfdatadataset","title":"Training with tf.data.Dataset","text":"<pre><code>import tensorflow as tf\n\ndataset = tf.data.Dataset.from_tensor_slices((data, one_hot_labels))\ndataset = dataset.batch(32)\n\nmodel.fit(dataset, epochs=10)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#validation","title":"Validation","text":"<pre><code>val_data = np.random.random((100, 784))\nval_labels = np.random.randint(10, size=(100,))\none_hot_val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=10)\n\nmodel.fit(data, one_hot_labels, epochs=10, batch_size=32,\n          validation_data=(val_data, one_hot_val_labels))\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#callbacks","title":"Callbacks","text":"<ul> <li><code>ModelCheckpoint</code>: Saves the model at certain intervals.</li> <li><code>EarlyStopping</code>: Stops training when a monitored metric has stopped improving.</li> <li><code>TensorBoard</code>: Enables visualization of metrics and more.</li> <li><code>ReduceLROnPlateau</code>: Reduces the learning rate when a metric has stopped improving.</li> <li><code>CSVLogger</code>: Streams epoch results to a CSV file.</li> </ul> <pre><code>from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n\ncheckpoint_callback = ModelCheckpoint(filepath='./checkpoints/model.{epoch:02d}-{val_loss:.2f}.h5',\n                                     save_best_only=True,\n                                     monitor='val_loss',\n                                     verbose=1)\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n\ntensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n\nmodel.fit(data, one_hot_labels, epochs=10, batch_size=32,\n          validation_data=(val_data, one_hot_val_labels),\n          callbacks=[checkpoint_callback, early_stopping_callback, tensorboard_callback])\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#evaluation","title":"Evaluation","text":"<pre><code>loss, accuracy = model.evaluate(val_data, one_hot_val_labels)\nprint('Loss:', loss)\nprint('Accuracy:', accuracy)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#prediction","title":"Prediction","text":"<pre><code>predictions = model.predict(val_data)\npredicted_classes = np.argmax(predictions, axis=1)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#saving-and-loading-models","title":"Saving and Loading Models","text":""},{"location":"Cheat-Sheets/Keras/#save-the-entire-model","title":"Save the Entire Model","text":"<pre><code>model.save('my_model.h5')  # Saves the model architecture, weights, and optimizer state\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#load-the-entire-model","title":"Load the Entire Model","text":"<pre><code>from tensorflow.keras.models import load_model\n\nloaded_model = load_model('my_model.h5')\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#save-model-architecture-as-json","title":"Save Model Architecture as JSON","text":"<pre><code>json_string = model.to_json()\n# Save the JSON string to a file\nwith open('model_architecture.json', 'w') as f:\n    f.write(json_string)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#load-model-architecture-from-json","title":"Load Model Architecture from JSON","text":"<pre><code>from tensorflow.keras.models import model_from_json\n\n# Load the JSON string from a file\nwith open('model_architecture.json', 'r') as f:\n    json_string = f.read()\n\nmodel = model_from_json(json_string)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#save-model-weights","title":"Save Model Weights","text":"<pre><code>model.save_weights('model_weights.h5')\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#load-model-weights","title":"Load Model Weights","text":"<pre><code>model.load_weights('model_weights.h5')\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#regularization","title":"Regularization","text":""},{"location":"Cheat-Sheets/Keras/#l1-and-l2-regularization","title":"L1 and L2 Regularization","text":"<pre><code>from tensorflow.keras import regularizers\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(784,),\n          kernel_regularizer=regularizers.l1(0.01),  # L1 regularization\n          bias_regularizer=regularizers.l2(0.01)),    # L2 regularization\n    Dense(10, activation='softmax')\n])\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#dropout","title":"Dropout","text":"<pre><code>from tensorflow.keras.layers import Dropout\n\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(784,)),\n    Dropout(0.5),  # Dropout layer with 50% dropout rate\n    Dense(10, activation='softmax')\n])\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#batch-normalization","title":"Batch Normalization","text":"<pre><code>from tensorflow.keras.layers import BatchNormalization\n\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(784,)),\n    BatchNormalization(),  # Batch normalization layer\n    Dense(10, activation='softmax')\n])\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#transfer-learning","title":"Transfer Learning","text":""},{"location":"Cheat-Sheets/Keras/#feature-extraction","title":"Feature Extraction","text":"<pre><code>from tensorflow.keras.applications import VGG16\n\n# Load pre-trained VGG16 model without the top (classification) layer\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the weights of the base model\nbase_model.trainable = False\n\n# Add custom classification layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\n\nmodel = Sequential([\n    base_model,\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dense(1, activation='sigmoid')  # Binary classification\n])\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#fine-tuning","title":"Fine-Tuning","text":"<pre><code># Unfreeze some of the layers in the base model\nbase_model.trainable = True\nfor layer in base_model.layers[:-4]:  # Unfreeze the last 4 layers\n    layer.trainable = False\n\n# Recompile the model\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-5),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Continue training\nmodel.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#callbacks_1","title":"Callbacks","text":""},{"location":"Cheat-Sheets/Keras/#modelcheckpoint","title":"ModelCheckpoint","text":"<pre><code>from tensorflow.keras.callbacks import ModelCheckpoint\n\ncheckpoint_callback = ModelCheckpoint(\n    filepath='best_model.h5',\n    monitor='val_loss',\n    save_best_only=True,\n    verbose=1\n)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#earlystopping","title":"EarlyStopping","text":"<pre><code>from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping_callback = EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#reducelronplateau","title":"ReduceLROnPlateau","text":"<pre><code>from tensorflow.keras.callbacks import ReduceLROnPlateau\n\nreduce_lr_callback = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.1,\n    patience=3,\n    verbose=1\n)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#tensorboard","title":"TensorBoard","text":"<pre><code>from tensorflow.keras.callbacks import TensorBoard\n\ntensorboard_callback = TensorBoard(\n    log_dir='./logs',\n    histogram_freq=1,\n    write_graph=True,\n    write_images=True\n)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#custom-training-loops","title":"Custom Training Loops","text":"<pre><code>import tensorflow as tf\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nloss_fn = tf.keras.losses.CategoricalCrossentropy()\nmetric_fn = tf.keras.metrics.CategoricalAccuracy()\n\n@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(images)\n        loss = loss_fn(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    metric_fn.update_state(labels, predictions)\n    return loss\n\nepochs = 10\nfor epoch in range(epochs):\n    for images, labels in dataset:\n        loss = train_step(images, labels)\n    print(f\"Epoch {epoch+1}, Loss: {loss.numpy():.4f}, Accuracy: {metric_fn.result().numpy():.4f}\")\n    metric_fn.reset_state()\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#distributed-training","title":"Distributed Training","text":""},{"location":"Cheat-Sheets/Keras/#mirroredstrategy","title":"MirroredStrategy","text":"<pre><code>import tensorflow as tf\n\nstrategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope():\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(784,)),\n        Dense(10, activation='softmax')\n    ])\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\nmodel.fit(data, one_hot_labels, epochs=10, batch_size=32)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":""},{"location":"Cheat-Sheets/Keras/#using-keras-tuner","title":"Using Keras Tuner","text":"<p>Installation:</p> <pre><code>pip install keras-tuner\n</code></pre> <p>Define a Hypermodel:</p> <pre><code>from tensorflow import keras\nfrom kerastuner.tuners import RandomSearch\n\ndef build_model(hp):\n    model = keras.Sequential()\n    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n    model.add(keras.layers.Dense(\n        hp.Choice('units', [32, 64, 128]),\n        activation='relu'))\n    model.add(keras.layers.Dense(10, activation='softmax'))\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n</code></pre> <p>Run the Tuner:</p> <pre><code>tuner = RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    executions_per_trial=3,\n    directory='my_dir',\n    project_name='my_project')\n\ntuner.search_space_summary()\n\ntuner.search(x_train, y_train,\n             epochs=10,\n             validation_data=(x_val, y_val))\n\nbest_model = tuner.get_best_models(num_models=1)[0]\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#tensorflow-datasets","title":"TensorFlow Datasets","text":""},{"location":"Cheat-Sheets/Keras/#installation_1","title":"Installation","text":"<pre><code>pip install tensorflow-datasets\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#usage","title":"Usage","text":"<pre><code>import tensorflow_datasets as tfds\n\n(ds_train, ds_test), ds_info = tfds.load(\n    'mnist',\n    split=['train', 'test'],\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=True,\n)\n\ndef normalize_img(image, label):\n  \"\"\"Normalizes images: `uint8` -&gt; `float32`.\"\"\"\n  return tf.cast(image, tf.float32) / 255., label\n\nds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\nds_train = ds_train.cache()\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\nds_train = ds_train.batch(128)\nds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n\nds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\nds_test = ds_test.batch(128)\nds_test = ds_test.cache()\nds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n\nmodel.fit(ds_train, epochs=12, validation_data=ds_test)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#tensorflow-hub","title":"TensorFlow Hub","text":""},{"location":"Cheat-Sheets/Keras/#installation_2","title":"Installation","text":"<pre><code>pip install tensorflow-hub\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#usage_1","title":"Usage","text":"<pre><code>import tensorflow_hub as hub\n\nembedding = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\nhub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n\nmodel = tf.keras.Sequential()\nmodel.add(hub_layer)\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#tensorflow-lite","title":"TensorFlow Lite","text":""},{"location":"Cheat-Sheets/Keras/#convert-to-tensorflow-lite","title":"Convert to TensorFlow Lite","text":"<pre><code>converter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)\n</code></pre>"},{"location":"Cheat-Sheets/Keras/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ul> <li>Use virtual environments to isolate project dependencies.</li> <li>Use meaningful names for layers, models, and variables.</li> <li>Follow the DRY (Don't Repeat Yourself) principle.</li> <li>Write unit tests to ensure code quality.</li> <li>Use a consistent coding style.</li> <li>Document your code.</li> <li>Use a version control system (e.g., Git).</li> <li>Use a GPU for training if possible.</li> <li>Monitor your training progress with TensorBoard.</li> <li>Use callbacks to save the best model and stop training early.</li> <li>Use regularization techniques to prevent overfitting.</li> <li>Experiment with different optimizers and learning rates.</li> <li>Use data augmentation to improve model performance.</li> <li>Use transfer learning to leverage pre-trained models.</li> <li>Use a TPU for faster training.</li> <li>Use a distributed training strategy for large datasets.</li> <li>Use a profiler to identify performance bottlenecks.</li> <li>Use a model quantization technique to reduce model size.</li> <li>Use a model pruning technique to reduce model complexity.</li> <li>Use a model distillation technique to create a smaller model.</li> <li>Use a model compression technique to reduce model size.</li> <li>Use a model deployment tool to deploy your model to production.</li> <li>Use a model monitoring tool to monitor your model's performance in production.</li> </ul>"},{"location":"Cheat-Sheets/NumPy/","title":"NumPy","text":"In\u00a0[1]: Copied! <pre>import numpy as np  # Importing NumPy\nnp.__version__  # Check version of NumPy\n</pre> import numpy as np  # Importing NumPy np.__version__  # Check version of NumPy Out[1]: <pre>'1.26.4'</pre> In\u00a0[2]: Copied! <pre>arr1 = np.array([1, 2, 3])\narr1\n</pre> arr1 = np.array([1, 2, 3]) arr1 Out[2]: <pre>array([1, 2, 3])</pre> In\u00a0[3]: Copied! <pre>arr2 = np.array((1, 2, 3))\narr2\n</pre> arr2 = np.array((1, 2, 3)) arr2 Out[3]: <pre>array([1, 2, 3])</pre> In\u00a0[4]: Copied! <pre>arr3 = np.frombuffer(b'Hello World', dtype='S1')\narr3\n</pre> arr3 = np.frombuffer(b'Hello World', dtype='S1') arr3 Out[4]: <pre>array([b'H', b'e', b'l', b'l', b'o', b' ', b'W', b'o', b'r', b'l', b'd'],\n      dtype='|S1')</pre> In\u00a0[5]: Copied! <pre>arr_zeros = np.zeros((2, 3))  # 2x3 array of zeros\narr_zeros\n</pre> arr_zeros = np.zeros((2, 3))  # 2x3 array of zeros arr_zeros Out[5]: <pre>array([[0., 0., 0.],\n       [0., 0., 0.]])</pre> In\u00a0[6]: Copied! <pre>arr_ones = np.ones((2, 3))  # 2x3 array of ones\narr_ones\n</pre> arr_ones = np.ones((2, 3))  # 2x3 array of ones arr_ones Out[6]: <pre>array([[1., 1., 1.],\n       [1., 1., 1.]])</pre> In\u00a0[7]: Copied! <pre>arr_empty = np.empty((2, 3))  # 2x3 empty array\narr_empty\n</pre> arr_empty = np.empty((2, 3))  # 2x3 empty array arr_empty Out[7]: <pre>array([[1., 1., 1.],\n       [1., 1., 1.]])</pre> In\u00a0[8]: Copied! <pre>arr_range = np.arange(0, 10, 2)  # Array from 0 to 9 with step 2\narr_range\n</pre> arr_range = np.arange(0, 10, 2)  # Array from 0 to 9 with step 2 arr_range Out[8]: <pre>array([0, 2, 4, 6, 8])</pre> In\u00a0[9]: Copied! <pre>arr_linspace = np.linspace(0, 1, 5)  # 5 equally spaced numbers from 0 to 1\narr_linspace\n</pre> arr_linspace = np.linspace(0, 1, 5)  # 5 equally spaced numbers from 0 to 1 arr_linspace Out[9]: <pre>array([0.  , 0.25, 0.5 , 0.75, 1.  ])</pre> In\u00a0[10]: Copied! <pre>arr_random = np.random.rand(2, 3)  # 2x3 array with random numbers between 0 and 1\narr_random\n</pre> arr_random = np.random.rand(2, 3)  # 2x3 array with random numbers between 0 and 1 arr_random Out[10]: <pre>array([[0.78160058, 0.52687888, 0.29604995],\n       [0.63947724, 0.99231115, 0.3488577 ]])</pre> In\u00a0[11]: Copied! <pre>arr_identity = np.eye(3)  # 3x3 identity matrix\narr_identity\n</pre> arr_identity = np.eye(3)  # 3x3 identity matrix arr_identity Out[11]: <pre>array([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])</pre> In\u00a0[12]: Copied! <pre>arr_diag = np.diag([1, 2, 3])  # Diagonal matrix from a list\narr_diag\n</pre> arr_diag = np.diag([1, 2, 3])  # Diagonal matrix from a list arr_diag Out[12]: <pre>array([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])</pre> In\u00a0[13]: Copied! <pre>dt = np.dtype([('age', np.int32), ('name', np.str_, 10)])\narr_structured = np.array([(21, 'Alice'), (25, 'Bob')], dtype=dt)\narr_structured\n</pre> dt = np.dtype([('age', np.int32), ('name', np.str_, 10)]) arr_structured = np.array([(21, 'Alice'), (25, 'Bob')], dtype=dt) arr_structured Out[13]: <pre>array([(21, 'Alice'), (25, 'Bob')],\n      dtype=[('age', '&lt;i4'), ('name', '&lt;U10')])</pre> In\u00a0[14]: Copied! <pre>arr_full = np.full((2, 3), 7)  # Create a 2x3 array filled with the value 7\narr_full\n</pre> arr_full = np.full((2, 3), 7)  # Create a 2x3 array filled with the value 7 arr_full Out[14]: <pre>array([[7, 7, 7],\n       [7, 7, 7]])</pre> In\u00a0[15]: Copied! <pre>arr_tile = np.tile([1, 2], (2, 3))  # Repeat [1, 2] in a 2x3 grid\narr_tile\n</pre> arr_tile = np.tile([1, 2], (2, 3))  # Repeat [1, 2] in a 2x3 grid arr_tile Out[15]: <pre>array([[1, 2, 1, 2, 1, 2],\n       [1, 2, 1, 2, 1, 2]])</pre> In\u00a0[16]: Copied! <pre>arr1.shape  # Dimensions of the array\n</pre> arr1.shape  # Dimensions of the array Out[16]: <pre>(3,)</pre> In\u00a0[17]: Copied! <pre>arr1.size  # Total number of elements\n</pre> arr1.size  # Total number of elements Out[17]: <pre>3</pre> In\u00a0[18]: Copied! <pre>arr1.ndim  # Number of dimensions\n</pre> arr1.ndim  # Number of dimensions Out[18]: <pre>1</pre> In\u00a0[19]: Copied! <pre>arr1.dtype  # Data type of elements\n</pre> arr1.dtype  # Data type of elements Out[19]: <pre>dtype('int64')</pre> In\u00a0[20]: Copied! <pre>arr1_float = arr1.astype(float)  # Convert to another type\narr1_float\n</pre> arr1_float = arr1.astype(float)  # Convert to another type arr1_float Out[20]: <pre>array([1., 2., 3.])</pre> In\u00a0[21]: Copied! <pre>arr1.itemsize  # Size of one element in bytes\n</pre> arr1.itemsize  # Size of one element in bytes Out[21]: <pre>8</pre> In\u00a0[22]: Copied! <pre>arr1.nbytes  # Total memory used by array\n</pre> arr1.nbytes  # Total memory used by array Out[22]: <pre>24</pre> In\u00a0[23]: Copied! <pre>arr1.flags  # Memory layout information\n</pre> arr1.flags  # Memory layout information Out[23]: <pre>  C_CONTIGUOUS : True\n  F_CONTIGUOUS : True\n  OWNDATA : True\n  WRITEABLE : True\n  ALIGNED : True\n  WRITEBACKIFCOPY : False</pre> In\u00a0[24]: Copied! <pre>arr_nan_inf = np.array([1, 2, np.nan, np.inf])\nnp.isnan(arr_nan_inf), np.isinf(arr_nan_inf), np.isfinite(arr_nan_inf)\n</pre> arr_nan_inf = np.array([1, 2, np.nan, np.inf]) np.isnan(arr_nan_inf), np.isinf(arr_nan_inf), np.isfinite(arr_nan_inf) Out[24]: <pre>(array([False, False,  True, False]),\n array([False, False, False,  True]),\n array([ True,  True, False, False]))</pre> In\u00a0[25]: Copied! <pre>arr_add = arr1 + 1  # Add 1 to each element\narr_add\n</pre> arr_add = arr1 + 1  # Add 1 to each element arr_add Out[25]: <pre>array([2, 3, 4])</pre> In\u00a0[26]: Copied! <pre>arr_mul = arr1 * 2  # Multiply each element by 2\narr_mul\n</pre> arr_mul = arr1 * 2  # Multiply each element by 2 arr_mul Out[26]: <pre>array([2, 4, 6])</pre> In\u00a0[27]: Copied! <pre>arr_sum = np.add(arr1, arr2)  # Add arrays element-wise\narr_sum\n</pre> arr_sum = np.add(arr1, arr2)  # Add arrays element-wise arr_sum Out[27]: <pre>array([2, 4, 6])</pre> In\u00a0[28]: Copied! <pre>arr_diff = np.subtract(arr1, arr2)  # Subtract arrays element-wise\narr_diff\n</pre> arr_diff = np.subtract(arr1, arr2)  # Subtract arrays element-wise arr_diff Out[28]: <pre>array([0, 0, 0])</pre> In\u00a0[29]: Copied! <pre>arr_sum_total = np.sum(arr1)  # Sum of all elements\narr_sum_total\n</pre> arr_sum_total = np.sum(arr1)  # Sum of all elements arr_sum_total Out[29]: <pre>6</pre> In\u00a0[30]: Copied! <pre>arr_mean = np.mean(arr1)  # Mean of elements\narr_mean\n</pre> arr_mean = np.mean(arr1)  # Mean of elements arr_mean Out[30]: <pre>2.0</pre> In\u00a0[31]: Copied! <pre>arr_max = np.max(arr1)  # Maximum value\narr_max\n</pre> arr_max = np.max(arr1)  # Maximum value arr_max Out[31]: <pre>3</pre> In\u00a0[32]: Copied! <pre>arr_min = np.min(arr1)  # Minimum value\narr_min\n</pre> arr_min = np.min(arr1)  # Minimum value arr_min Out[32]: <pre>1</pre> In\u00a0[33]: Copied! <pre>arr_prod = np.prod(arr1)  # Product of elements\narr_prod\n</pre> arr_prod = np.prod(arr1)  # Product of elements arr_prod Out[33]: <pre>6</pre> In\u00a0[34]: Copied! <pre>arr_cumsum = np.cumsum(arr1)  # Cumulative sum of elements\narr_cumsum\n</pre> arr_cumsum = np.cumsum(arr1)  # Cumulative sum of elements arr_cumsum Out[34]: <pre>array([1, 3, 6])</pre> In\u00a0[35]: Copied! <pre>arr_cumprod = np.cumprod(arr1)  # Cumulative product of elements\narr_cumprod\n</pre> arr_cumprod = np.cumprod(arr1)  # Cumulative product of elements arr_cumprod Out[35]: <pre>array([1, 2, 6])</pre> In\u00a0[36]: Copied! <pre>arr_exp = np.exp(arr1)  # Exponential of each element\narr_exp\n</pre> arr_exp = np.exp(arr1)  # Exponential of each element arr_exp Out[36]: <pre>array([ 2.71828183,  7.3890561 , 20.08553692])</pre> In\u00a0[37]: Copied! <pre>arr_log = np.log(arr1)  # Natural logarithm\narr_log\n</pre> arr_log = np.log(arr1)  # Natural logarithm arr_log Out[37]: <pre>array([0.        , 0.69314718, 1.09861229])</pre> In\u00a0[38]: Copied! <pre>arr_log10 = np.log10(arr1)  # Base-10 logarithm\narr_log10\n</pre> arr_log10 = np.log10(arr1)  # Base-10 logarithm arr_log10 Out[38]: <pre>array([0.        , 0.30103   , 0.47712125])</pre> In\u00a0[39]: Copied! <pre>arr_expm1 = np.expm1(arr1)  # Compute exp(x) - 1\narr_expm1\n</pre> arr_expm1 = np.expm1(arr1)  # Compute exp(x) - 1 arr_expm1 Out[39]: <pre>array([ 1.71828183,  6.3890561 , 19.08553692])</pre> In\u00a0[40]: Copied! <pre>arr_sin = np.sin(arr1)  # Sine of each element\narr_sin\n</pre> arr_sin = np.sin(arr1)  # Sine of each element arr_sin Out[40]: <pre>array([0.84147098, 0.90929743, 0.14112001])</pre> In\u00a0[41]: Copied! <pre>arr_cos = np.cos(arr1)  # Cosine of each element\narr_cos\n</pre> arr_cos = np.cos(arr1)  # Cosine of each element arr_cos Out[41]: <pre>array([ 0.54030231, -0.41614684, -0.9899925 ])</pre> In\u00a0[42]: Copied! <pre>arr_tan = np.tan(arr1)  # Tangent of each element\narr_tan\n</pre> arr_tan = np.tan(arr1)  # Tangent of each element arr_tan Out[42]: <pre>array([ 1.55740772, -2.18503986, -0.14254654])</pre> In\u00a0[43]: Copied! <pre>arr_arcsin = np.arcsin(arr1 / 10)  # Inverse sine\narr_arcsin\n</pre> arr_arcsin = np.arcsin(arr1 / 10)  # Inverse sine arr_arcsin Out[43]: <pre>array([0.10016742, 0.20135792, 0.30469265])</pre> In\u00a0[44]: Copied! <pre>arr_arccos = np.arccos(arr1 / 10)  # Inverse cosine\narr_arccos\n</pre> arr_arccos = np.arccos(arr1 / 10)  # Inverse cosine arr_arccos Out[44]: <pre>array([1.47062891, 1.36943841, 1.26610367])</pre> In\u00a0[45]: Copied! <pre>arr_arctan = np.arctan(arr1 / 10)  # Inverse tangent\narr_arctan\n</pre> arr_arctan = np.arctan(arr1 / 10)  # Inverse tangent arr_arctan Out[45]: <pre>array([0.09966865, 0.19739556, 0.29145679])</pre> In\u00a0[46]: Copied! <pre>arr_round = np.round(arr1_float, decimals=2)  # Round to 2 decimal places\narr_round\n</pre> arr_round = np.round(arr1_float, decimals=2)  # Round to 2 decimal places arr_round Out[46]: <pre>array([1., 2., 3.])</pre> In\u00a0[47]: Copied! <pre>arr_floor = np.floor(arr1_float)  # Floor operation\narr_floor\n</pre> arr_floor = np.floor(arr1_float)  # Floor operation arr_floor Out[47]: <pre>array([1., 2., 3.])</pre> In\u00a0[48]: Copied! <pre>arr_ceil = np.ceil(arr1_float)  # Ceiling operation\narr_ceil\n</pre> arr_ceil = np.ceil(arr1_float)  # Ceiling operation arr_ceil Out[48]: <pre>array([1., 2., 3.])</pre> In\u00a0[49]: Copied! <pre>arr_trunc = np.trunc(arr1_float)  # Truncate elements to integers\narr_trunc\n</pre> arr_trunc = np.trunc(arr1_float)  # Truncate elements to integers arr_trunc Out[49]: <pre>array([1., 2., 3.])</pre> In\u00a0[50]: Copied! <pre>arr_reshaped = arr1.reshape((3, 1))  # Reshape to 3x1 array\narr_reshaped\n</pre> arr_reshaped = arr1.reshape((3, 1))  # Reshape to 3x1 array arr_reshaped Out[50]: <pre>array([[1],\n       [2],\n       [3]])</pre> In\u00a0[51]: Copied! <pre>arr_flattened = arr1.flatten()  # Flatten the array to 1D\narr_flattened\n</pre> arr_flattened = arr1.flatten()  # Flatten the array to 1D arr_flattened Out[51]: <pre>array([1, 2, 3])</pre> In\u00a0[52]: Copied! <pre>arr_raveled = np.ravel(arr1)  # Return a flattened array\narr_raveled\n</pre> arr_raveled = np.ravel(arr1)  # Return a flattened array arr_raveled Out[52]: <pre>array([1, 2, 3])</pre> In\u00a0[53]: Copied! <pre>arr_T = arr1.reshape((1, 3)).T  # Transpose of the array\narr_T\n</pre> arr_T = arr1.reshape((1, 3)).T  # Transpose of the array arr_T Out[53]: <pre>array([[1],\n       [2],\n       [3]])</pre> In\u00a0[54]: Copied! <pre>arr_custom_T = np.transpose(arr1.reshape((3, 1)), (1, 0))  # Custom transpose\narr_custom_T\n</pre> arr_custom_T = np.transpose(arr1.reshape((3, 1)), (1, 0))  # Custom transpose arr_custom_T Out[54]: <pre>array([[1, 2, 3]])</pre> In\u00a0[55]: Copied! <pre>arr_concat = np.concatenate((arr1, arr2))  # Join arrays\narr_concat\n</pre> arr_concat = np.concatenate((arr1, arr2))  # Join arrays arr_concat Out[55]: <pre>array([1, 2, 3, 1, 2, 3])</pre> In\u00a0[56]: Copied! <pre>arr_hstack = np.hstack((arr1.reshape((3, 1)), arr2.reshape((3, 1))))  # Horizontal stack\narr_hstack\n</pre> arr_hstack = np.hstack((arr1.reshape((3, 1)), arr2.reshape((3, 1))))  # Horizontal stack arr_hstack Out[56]: <pre>array([[1, 1],\n       [2, 2],\n       [3, 3]])</pre> In\u00a0[57]: Copied! <pre>arr_vstack = np.vstack((arr1, arr2))  # Vertical stack\narr_vstack\n</pre> arr_vstack = np.vstack((arr1, arr2))  # Vertical stack arr_vstack Out[57]: <pre>array([[1, 2, 3],\n       [1, 2, 3]])</pre> In\u00a0[58]: Copied! <pre>arr_split = np.split(arr_concat, 3)  # Split into 3 equal parts\narr_split\n</pre> arr_split = np.split(arr_concat, 3)  # Split into 3 equal parts arr_split Out[58]: <pre>[array([1, 2]), array([3, 1]), array([2, 3])]</pre> In\u00a0[59]: Copied! <pre>arr_hsplit = np.hsplit(arr_hstack, 2)  # Split horizontally\narr_hsplit\n</pre> arr_hsplit = np.hsplit(arr_hstack, 2)  # Split horizontally arr_hsplit Out[59]: <pre>[array([[1],\n        [2],\n        [3]]),\n array([[1],\n        [2],\n        [3]])]</pre> In\u00a0[60]: Copied! <pre>arr_vsplit = np.vsplit(arr_vstack, 2)  # Split vertically\narr_vsplit\n</pre> arr_vsplit = np.vsplit(arr_vstack, 2)  # Split vertically arr_vsplit Out[60]: <pre>[array([[1, 2, 3]]), array([[1, 2, 3]])]</pre> In\u00a0[61]: Copied! <pre>arr_expanded = np.expand_dims(arr1, axis=0)  # Expand dimensions\narr_expanded\n</pre> arr_expanded = np.expand_dims(arr1, axis=0)  # Expand dimensions arr_expanded Out[61]: <pre>array([[1, 2, 3]])</pre> In\u00a0[62]: Copied! <pre>arr_squeezed = np.squeeze(arr_expanded)  # Remove single-dimensional entries\narr_squeezed\n</pre> arr_squeezed = np.squeeze(arr_expanded)  # Remove single-dimensional entries arr_squeezed Out[62]: <pre>array([1, 2, 3])</pre> In\u00a0[63]: Copied! <pre>arr_tiled = np.tile(arr1, (2, 3))  # Repeat array\narr_tiled\n</pre> arr_tiled = np.tile(arr1, (2, 3))  # Repeat array arr_tiled Out[63]: <pre>array([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n       [1, 2, 3, 1, 2, 3, 1, 2, 3]])</pre> In\u00a0[64]: Copied! <pre>arr_repeated = np.repeat(arr1, 3)  # Repeat elements of an array\narr_repeated\n</pre> arr_repeated = np.repeat(arr1, 3)  # Repeat elements of an array arr_repeated Out[64]: <pre>array([1, 1, 1, 2, 2, 2, 3, 3, 3])</pre> In\u00a0[65]: Copied! <pre>arr_rot90 = np.rot90(arr1.reshape((3, 1)))  # Rotate array by 90 degrees\narr_rot90\n</pre> arr_rot90 = np.rot90(arr1.reshape((3, 1)))  # Rotate array by 90 degrees arr_rot90 Out[65]: <pre>array([[1, 2, 3]])</pre> In\u00a0[66]: Copied! <pre>arr_fliplr = np.fliplr(arr1.reshape((3, 1)))  # Flip array left to right\narr_fliplr\n</pre> arr_fliplr = np.fliplr(arr1.reshape((3, 1)))  # Flip array left to right arr_fliplr Out[66]: <pre>array([[1],\n       [2],\n       [3]])</pre> In\u00a0[67]: Copied! <pre>arr_flipud = np.flipud(arr1.reshape((3, 1)))  # Flip array upside down\narr_flipud\n</pre> arr_flipud = np.flipud(arr1.reshape((3, 1)))  # Flip array upside down arr_flipud Out[67]: <pre>array([[3],\n       [2],\n       [1]])</pre> In\u00a0[68]: Copied! <pre>arr_dot = np.dot(arr1, arr2)  # Dot product\narr_dot\n</pre> arr_dot = np.dot(arr1, arr2)  # Dot product arr_dot Out[68]: <pre>14</pre> In\u00a0[69]: Copied! <pre>arr_matmul = np.matmul(arr1.reshape((3, 1)), arr2.reshape((1, 3)))  # Matrix multiplication\narr_matmul\n</pre> arr_matmul = np.matmul(arr1.reshape((3, 1)), arr2.reshape((1, 3)))  # Matrix multiplication arr_matmul Out[69]: <pre>array([[1, 2, 3],\n       [2, 4, 6],\n       [3, 6, 9]])</pre> In\u00a0[70]: Copied! <pre>arr_matmul_op = arr1.reshape((3, 1)) @ arr2.reshape((1, 3))  # Matrix multiplication using @\narr_matmul_op\n</pre> arr_matmul_op = arr1.reshape((3, 1)) @ arr2.reshape((1, 3))  # Matrix multiplication using @ arr_matmul_op Out[70]: <pre>array([[1, 2, 3],\n       [2, 4, 6],\n       [3, 6, 9]])</pre> In\u00a0[71]: Copied! <pre>A = np.array([[3, 1], [1, 2]])\nb = np.array([9, 8])\nx = np.linalg.solve(A, b)  # Solve linear equations Ax = b\nx\n</pre> A = np.array([[3, 1], [1, 2]]) b = np.array([9, 8]) x = np.linalg.solve(A, b)  # Solve linear equations Ax = b x Out[71]: <pre>array([2., 3.])</pre> In\u00a0[72]: Copied! <pre>arr_eigvals, arr_eigvecs = np.linalg.eig(A)  # Eigenvalues and eigenvectors\narr_eigvals, arr_eigvecs\n</pre> arr_eigvals, arr_eigvecs = np.linalg.eig(A)  # Eigenvalues and eigenvectors arr_eigvals, arr_eigvecs Out[72]: <pre>(array([3.61803399, 1.38196601]),\n array([[ 0.85065081, -0.52573111],\n        [ 0.52573111,  0.85065081]]))</pre> In\u00a0[73]: Copied! <pre>arr_inv = np.linalg.inv(A)  # Inverse of a matrix\narr_inv\n</pre> arr_inv = np.linalg.inv(A)  # Inverse of a matrix arr_inv Out[73]: <pre>array([[ 0.4, -0.2],\n       [-0.2,  0.6]])</pre> In\u00a0[74]: Copied! <pre>arr_det = np.linalg.det(A)  # Determinant of a matrix\narr_det\n</pre> arr_det = np.linalg.det(A)  # Determinant of a matrix arr_det Out[74]: <pre>5.000000000000001</pre> In\u00a0[75]: Copied! <pre>U, S, V = np.linalg.svd(A)  # Singular Value Decomposition\nU, S, V\n</pre> U, S, V = np.linalg.svd(A)  # Singular Value Decomposition U, S, V Out[75]: <pre>(array([[-0.85065081, -0.52573111],\n        [-0.52573111,  0.85065081]]),\n array([3.61803399, 1.38196601]),\n array([[-0.85065081, -0.52573111],\n        [-0.52573111,  0.85065081]]))</pre> In\u00a0[76]: Copied! <pre>arr_norm = np.linalg.norm(arr1)  # Compute matrix or vector norm\narr_norm\n</pre> arr_norm = np.linalg.norm(arr1)  # Compute matrix or vector norm arr_norm Out[76]: <pre>3.7416573867739413</pre> In\u00a0[77]: Copied! <pre>arr_cond = np.linalg.cond(A)  # Compute the condition number of a matrix\narr_cond\n</pre> arr_cond = np.linalg.cond(A)  # Compute the condition number of a matrix arr_cond Out[77]: <pre>2.618033988749896</pre> In\u00a0[78]: Copied! <pre>arr_mean = np.mean(arr1)  # Mean\narr_mean\n</pre> arr_mean = np.mean(arr1)  # Mean arr_mean Out[78]: <pre>2.0</pre> In\u00a0[79]: Copied! <pre>arr_median = np.median(arr1)  # Median\narr_median\n</pre> arr_median = np.median(arr1)  # Median arr_median Out[79]: <pre>2.0</pre> In\u00a0[80]: Copied! <pre>arr_var = np.var(arr1)  # Variance\narr_var\n</pre> arr_var = np.var(arr1)  # Variance arr_var Out[80]: <pre>0.6666666666666666</pre> In\u00a0[81]: Copied! <pre>arr_std = np.std(arr1)  # Standard deviation\narr_std\n</pre> arr_std = np.std(arr1)  # Standard deviation arr_std Out[81]: <pre>0.816496580927726</pre> In\u00a0[82]: Copied! <pre>arr_percentile = np.percentile(arr1, 50)  # 50th percentile (median)\narr_percentile\n</pre> arr_percentile = np.percentile(arr1, 50)  # 50th percentile (median) arr_percentile Out[82]: <pre>2.0</pre> In\u00a0[83]: Copied! <pre>arr_corr = np.corrcoef(arr1, arr2)  # Correlation coefficient\narr_corr\n</pre> arr_corr = np.corrcoef(arr1, arr2)  # Correlation coefficient arr_corr Out[83]: <pre>array([[1., 1.],\n       [1., 1.]])</pre> In\u00a0[84]: Copied! <pre>arr_cov = np.cov(arr1, arr2)  # Covariance\narr_cov\n</pre> arr_cov = np.cov(arr1, arr2)  # Covariance arr_cov Out[84]: <pre>array([[1., 1.],\n       [1., 1.]])</pre> In\u00a0[85]: Copied! <pre>arr_hist, arr_bins = np.histogram(arr1, bins=3)  # Histogram of an array\narr_hist, arr_bins\n</pre> arr_hist, arr_bins = np.histogram(arr1, bins=3)  # Histogram of an array arr_hist, arr_bins Out[85]: <pre>(array([1, 1, 1]), array([1.        , 1.66666667, 2.33333333, 3.        ]))</pre> In\u00a0[86]: Copied! <pre>from scipy import stats\narr_binned_statistic = stats.binned_statistic(arr1, arr1, statistic='mean', bins=3)  # Compute binned statistics\narr_binned_statistic.statistic\n</pre> from scipy import stats arr_binned_statistic = stats.binned_statistic(arr1, arr1, statistic='mean', bins=3)  # Compute binned statistics arr_binned_statistic.statistic Out[86]: <pre>array([1., 2., 3.])</pre> In\u00a0[87]: Copied! <pre>arr_broadcast_add = arr1 + 5  # Add 5 to all elements\narr_broadcast_add\n</pre> arr_broadcast_add = arr1 + 5  # Add 5 to all elements arr_broadcast_add Out[87]: <pre>array([6, 7, 8])</pre> In\u00a0[88]: Copied! <pre>arr_broadcast_array = arr1 + np.array([1, 2, 3])  # Add array [1, 2, 3] to each row\narr_broadcast_array\n</pre> arr_broadcast_array = arr1 + np.array([1, 2, 3])  # Add array [1, 2, 3] to each row arr_broadcast_array Out[88]: <pre>array([2, 4, 6])</pre> In\u00a0[89]: Copied! <pre>arr_broadcast_mult = arr1 * np.array([1, 2, 3])  # Element-wise multiplication with broadcasting\narr_broadcast_mult\n</pre> arr_broadcast_mult = arr1 * np.array([1, 2, 3])  # Element-wise multiplication with broadcasting arr_broadcast_mult Out[89]: <pre>array([1, 4, 9])</pre> In\u00a0[90]: Copied! <pre>arr_broadcast_expand = np.expand_dims(arr1, axis=0) + arr1  # Broadcasting with dimension expansion\narr_broadcast_expand\n</pre> arr_broadcast_expand = np.expand_dims(arr1, axis=0) + arr1  # Broadcasting with dimension expansion arr_broadcast_expand Out[90]: <pre>array([[2, 4, 6]])</pre> In\u00a0[91]: Copied! <pre>first_element = arr1[0]  # First element\nfirst_element\n</pre> first_element = arr1[0]  # First element first_element Out[91]: <pre>1</pre> In\u00a0[92]: Copied! <pre>last_element = arr1[-1]  # Last element\nlast_element\n</pre> last_element = arr1[-1]  # Last element last_element Out[92]: <pre>3</pre> In\u00a0[93]: Copied! <pre>element_0_2 = arr1[0]  # First element\nthird_element = arr1[2]  # Third element\nfirst_element, third_element\n</pre> element_0_2 = arr1[0]  # First element third_element = arr1[2]  # Third element first_element, third_element Out[93]: <pre>(1, 3)</pre> In\u00a0[94]: Copied! <pre>arr_slice_1_3 = arr1[1:3]  # Elements from index 1 to 2\narr_slice_1_3\n</pre> arr_slice_1_3 = arr1[1:3]  # Elements from index 1 to 2 arr_slice_1_3 Out[94]: <pre>array([2, 3])</pre> In\u00a0[95]: Copied! <pre>arr_slice_all = arr1[:]  # All elements\narr_slice_all\n</pre> arr_slice_all = arr1[:]  # All elements arr_slice_all Out[95]: <pre>array([1, 2, 3])</pre> In\u00a0[96]: Copied! <pre>arr_slice_skip = arr1[::2]  # Every other element\narr_slice_skip\n</pre> arr_slice_skip = arr1[::2]  # Every other element arr_slice_skip Out[96]: <pre>array([1, 3])</pre> In\u00a0[97]: Copied! <pre>arr_fancy_index = arr1[[0, 2]]  # Elements 0 and 2\narr_fancy_index\n</pre> arr_fancy_index = arr1[[0, 2]]  # Elements 0 and 2 arr_fancy_index Out[97]: <pre>array([1, 3])</pre> In\u00a0[98]: Copied! <pre>arr_bool_mask = arr1[arr1 &gt; 2]  # Elements greater than 2\narr_bool_mask\n</pre> arr_bool_mask = arr1[arr1 &gt; 2]  # Elements greater than 2 arr_bool_mask Out[98]: <pre>array([3])</pre> In\u00a0[99]: Copied! <pre>arr_where = np.where(arr1 &gt; 2, arr1, -arr1)  # Replace negative values with their absolute value\narr_where\n</pre> arr_where = np.where(arr1 &gt; 2, arr1, -arr1)  # Replace negative values with their absolute value arr_where Out[99]: <pre>array([-1, -2,  3])</pre> In\u00a0[100]: Copied! <pre>arr_set_values = arr1.copy()\narr_set_values[arr_set_values &gt; 2] = 0  # Set all positive elements to 0\narr_set_values\n</pre> arr_set_values = arr1.copy() arr_set_values[arr_set_values &gt; 2] = 0  # Set all positive elements to 0 arr_set_values Out[100]: <pre>array([1, 2, 0])</pre> In\u00a0[101]: Copied! <pre>arr_ix = np.ix_([0, 1], [2, 3])  # Create a mesh grid from indexing arrays\narr_ix\n</pre> arr_ix = np.ix_([0, 1], [2, 3])  # Create a mesh grid from indexing arrays arr_ix Out[101]: <pre>(array([[0],\n        [1]]),\n array([[2, 3]]))</pre> In\u00a0[102]: Copied! <pre>arr_rand = np.random.rand(2, 3)  # Uniform distribution (0, 1)\narr_rand\n</pre> arr_rand = np.random.rand(2, 3)  # Uniform distribution (0, 1) arr_rand Out[102]: <pre>array([[0.67485015, 0.42229856, 0.98348739],\n       [0.01204425, 0.90966669, 0.70587384]])</pre> In\u00a0[103]: Copied! <pre>arr_randn = np.random.randn(2, 3)  # Standard normal distribution\narr_randn\n</pre> arr_randn = np.random.randn(2, 3)  # Standard normal distribution arr_randn Out[103]: <pre>array([[ 0.74664931, -0.14473226,  0.11518257],\n       [-1.03882137,  1.94984805,  1.95339008]])</pre> In\u00a0[104]: Copied! <pre>arr_randint = np.random.randint(0, 10, size=(2, 3))  # Random integers between 0 and 9\narr_randint\n</pre> arr_randint = np.random.randint(0, 10, size=(2, 3))  # Random integers between 0 and 9 arr_randint Out[104]: <pre>array([[4, 7, 8],\n       [9, 8, 8]])</pre> In\u00a0[105]: Copied! <pre>arr_perm = np.random.permutation(arr1)  # Randomly permute an array\narr_perm\n</pre> arr_perm = np.random.permutation(arr1)  # Randomly permute an array arr_perm Out[105]: <pre>array([2, 3, 1])</pre> In\u00a0[106]: Copied! <pre>arr_choice = np.random.choice(arr1, size=3, replace=False)  # Random sample without replacement\narr_choice\n</pre> arr_choice = np.random.choice(arr1, size=3, replace=False)  # Random sample without replacement arr_choice Out[106]: <pre>array([2, 3, 1])</pre> In\u00a0[107]: Copied! <pre>arr_binomial = np.random.binomial(n=10, p=0.5, size=10)  # Binomial distribution\narr_binomial\n</pre> arr_binomial = np.random.binomial(n=10, p=0.5, size=10)  # Binomial distribution arr_binomial Out[107]: <pre>array([4, 4, 1, 5, 6, 7, 3, 7, 6, 7])</pre> In\u00a0[108]: Copied! <pre>arr_poisson = np.random.poisson(lam=3, size=10)  # Poisson distribution\narr_poisson\n</pre> arr_poisson = np.random.poisson(lam=3, size=10)  # Poisson distribution arr_poisson Out[108]: <pre>array([2, 6, 2, 3, 1, 1, 2, 3, 2, 5])</pre> In\u00a0[109]: Copied! <pre>np.random.seed(42)  # Set random seed for reproducibility\narr_rand_seed = np.random.rand(2, 3)\narr_rand_seed\n</pre> np.random.seed(42)  # Set random seed for reproducibility arr_rand_seed = np.random.rand(2, 3) arr_rand_seed Out[109]: <pre>array([[0.37454012, 0.95071431, 0.73199394],\n       [0.59865848, 0.15601864, 0.15599452]])</pre> In\u00a0[110]: Copied! <pre>np.save('array.npy', arr1)  # Save array to binary file\narr_loaded = np.load('array.npy')  # Load array from binary file\narr_loaded\n</pre> np.save('array.npy', arr1)  # Save array to binary file arr_loaded = np.load('array.npy')  # Load array from binary file arr_loaded Out[110]: <pre>array([1, 2, 3])</pre> In\u00a0[111]: Copied! <pre>np.savetxt('array.txt', arr1)  # Save array to text file\narr_loaded_txt = np.loadtxt('array.txt')  # Load array from text file\narr_loaded_txt\n</pre> np.savetxt('array.txt', arr1)  # Save array to text file arr_loaded_txt = np.loadtxt('array.txt')  # Load array from text file arr_loaded_txt Out[111]: <pre>array([1., 2., 3.])</pre> In\u00a0[112]: Copied! <pre>np.savez('arrays.npz', arr1=arr1, arr2=arr2)  # Save multiple arrays to a compressed file\nnpzfile = np.load('arrays.npz')\nnpzfile['arr1'], npzfile['arr2']\n</pre> np.savez('arrays.npz', arr1=arr1, arr2=arr2)  # Save multiple arrays to a compressed file npzfile = np.load('arrays.npz') npzfile['arr1'], npzfile['arr2'] Out[112]: <pre>(array([1, 2, 3]), array([1, 2, 3]))</pre> In\u00a0[113]: Copied! <pre>arr1\n</pre> arr1 Out[113]: <pre>array([1, 2, 3])</pre> In\u00a0[114]: Copied! <pre>np.savetxt('data.csv', arr1, delimiter=',')  # Save data to CSV file\n</pre> np.savetxt('data.csv', arr1, delimiter=',')  # Save data to CSV file In\u00a0[115]: Copied! <pre>arr_csv = np.genfromtxt('data.csv', delimiter=',')  # Load data from CSV file\narr_csv\n</pre> arr_csv = np.genfromtxt('data.csv', delimiter=',')  # Load data from CSV file arr_csv Out[115]: <pre>array([1., 2., 3.])</pre> In\u00a0[116]: Copied! <pre>p = np.poly1d([1, 2, 3])  # Define a polynomial p(x) = 1x^2 + 2x + 3\np(2)  # Evaluate polynomial at x = 2\n</pre> p = np.poly1d([1, 2, 3])  # Define a polynomial p(x) = 1x^2 + 2x + 3 p(2)  # Evaluate polynomial at x = 2 Out[116]: <pre>11</pre> In\u00a0[117]: Copied! <pre>p.roots  # Find roots of the polynomial\n</pre> p.roots  # Find roots of the polynomial Out[117]: <pre>array([-1.+1.41421356j, -1.-1.41421356j])</pre> In\u00a0[118]: Copied! <pre>x = np.array([1, 2, 3, 4])\ny = np.array([1, 4, 9, 16])\np_fit = np.polyfit(x, y, deg=2)  # Fit a polynomial of degree 2 to data points (x, y)\np_fit\n</pre> x = np.array([1, 2, 3, 4]) y = np.array([1, 4, 9, 16]) p_fit = np.polyfit(x, y, deg=2)  # Fit a polynomial of degree 2 to data points (x, y) p_fit Out[118]: <pre>array([ 1.00000000e+00, -6.00566855e-15,  9.41435428e-15])</pre> In\u00a0[119]: Copied! <pre>p_deriv = p.deriv()  # Derivative of the polynomial\np_deriv\n</pre> p_deriv = p.deriv()  # Derivative of the polynomial p_deriv Out[119]: <pre>poly1d([2, 2])</pre> In\u00a0[120]: Copied! <pre>p_integ = p.integ()  # Integral of the polynomial\np_integ\n</pre> p_integ = p.integ()  # Integral of the polynomial p_integ Out[120]: <pre>poly1d([0.33333333, 1.        , 3.        , 0.        ])</pre> In\u00a0[121]: Copied! <pre>def add_five(x):\n    return x + 5\n\nvectorized_func = np.vectorize(add_five)  # Apply a function element-wise to an array\nvectorized_func(arr1)\n</pre> def add_five(x):     return x + 5  vectorized_func = np.vectorize(add_five)  # Apply a function element-wise to an array vectorized_func(arr1) Out[121]: <pre>array([6, 7, 8])</pre> In\u00a0[122]: Copied! <pre>x = np.array([1, 2, 3])\ny = np.array([4, 5, 6])\nX, Y = np.meshgrid(x, y)  # Create a coordinate grid from 1D arrays x and y\nX, Y\n</pre> x = np.array([1, 2, 3]) y = np.array([4, 5, 6]) X, Y = np.meshgrid(x, y)  # Create a coordinate grid from 1D arrays x and y X, Y Out[122]: <pre>(array([[1, 2, 3],\n        [1, 2, 3],\n        [1, 2, 3]]),\n array([[4, 4, 4],\n        [5, 5, 5],\n        [6, 6, 6]]))</pre> In\u00a0[123]: Copied! <pre>arr_add_at = np.array([1, 2, 3])\nnp.add.at(arr_add_at, [0, 1], 5)  # Increment elements at indices `idx` by 5\narr_add_at\n</pre> arr_add_at = np.array([1, 2, 3]) np.add.at(arr_add_at, [0, 1], 5)  # Increment elements at indices `idx` by 5 arr_add_at Out[123]: <pre>array([6, 7, 3])</pre> In\u00a0[124]: Copied! <pre>arr_sorted = np.sort(arr1)  # Sort array\narr_sorted\n</pre> arr_sorted = np.sort(arr1)  # Sort array arr_sorted Out[124]: <pre>array([1, 2, 3])</pre> In\u00a0[125]: Copied! <pre>arr_argsort = np.argsort(arr1)  # Indices of the sorted array\narr_argsort\n</pre> arr_argsort = np.argsort(arr1)  # Indices of the sorted array arr_argsort Out[125]: <pre>array([0, 1, 2])</pre> In\u00a0[126]: Copied! <pre>arr_where_condition = np.where(arr1 &gt; 2)  # Indices where the condition is met\narr_where_condition\n</pre> arr_where_condition = np.where(arr1 &gt; 2)  # Indices where the condition is met arr_where_condition Out[126]: <pre>(array([2]),)</pre> In\u00a0[127]: Copied! <pre>arr_count_nonzero = np.count_nonzero(arr1)  # Count non-zero elements\narr_count_nonzero\n</pre> arr_count_nonzero = np.count_nonzero(arr1)  # Count non-zero elements arr_count_nonzero Out[127]: <pre>3</pre> In\u00a0[128]: Copied! <pre>arr_flags = arr1.flags  # Check memory layout (C_CONTIGUOUS, F_CONTIGUOUS)\narr_flags\n</pre> arr_flags = arr1.flags  # Check memory layout (C_CONTIGUOUS, F_CONTIGUOUS) arr_flags Out[128]: <pre>  C_CONTIGUOUS : True\n  F_CONTIGUOUS : True\n  OWNDATA : True\n  WRITEABLE : True\n  ALIGNED : True\n  WRITEBACKIFCOPY : False</pre> In\u00a0[129]: Copied! <pre>arr_contig = np.ascontiguousarray(arr1)  # Convert to C-contiguous array\narr_contig.flags\n</pre> arr_contig = np.ascontiguousarray(arr1)  # Convert to C-contiguous array arr_contig.flags Out[129]: <pre>  C_CONTIGUOUS : True\n  F_CONTIGUOUS : True\n  OWNDATA : True\n  WRITEABLE : True\n  ALIGNED : True\n  WRITEBACKIFCOPY : False</pre> In\u00a0[130]: Copied! <pre>memmap_arr = np.memmap('data.dat', dtype='float32', mode='w+', shape=(3, 3))  # Memory-mapped file\nmemmap_arr\n</pre> memmap_arr = np.memmap('data.dat', dtype='float32', mode='w+', shape=(3, 3))  # Memory-mapped file memmap_arr Out[130]: <pre>memmap([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]], dtype=float32)</pre> In\u00a0[131]: Copied! <pre>arr_copy = arr1.copy()  # Create a deep copy of the array\narr_copy\n</pre> arr_copy = arr1.copy()  # Create a deep copy of the array arr_copy Out[131]: <pre>array([1, 2, 3])</pre> In\u00a0[132]: Copied! <pre>arr_view = arr1.view()  # Create a view of the array (shallow copy)\narr_view\n</pre> arr_view = arr1.view()  # Create a view of the array (shallow copy) arr_view Out[132]: <pre>array([1, 2, 3])</pre> In\u00a0[133]: Copied! <pre>arr_take = np.take(arr1, [0, 2])  # Take elements at indices 0 and 2\narr_take\n</pre> arr_take = np.take(arr1, [0, 2])  # Take elements at indices 0 and 2 arr_take Out[133]: <pre>array([1, 3])</pre> In\u00a0[134]: Copied! <pre>arr_put = arr1.copy()\nnp.put(arr_put, [0, 2], [-1, -2])  # Set elements at indices 0 and 2\narr_put\n</pre> arr_put = arr1.copy() np.put(arr_put, [0, 2], [-1, -2])  # Set elements at indices 0 and 2 arr_put Out[134]: <pre>array([-1,  2, -2])</pre> In\u00a0[135]: Copied! <pre>arr_choose = np.choose([0, 1], arr1)  # Construct an array from elements chosen from `arr1`\narr_choose\n</pre> arr_choose = np.choose([0, 1], arr1)  # Construct an array from elements chosen from `arr1` arr_choose Out[135]: <pre>array([1, 2])</pre> In\u00a0[136]: Copied! <pre>arr_lexsort = np.lexsort((arr2, arr1))  # Sort by `arr1`, then by `arr2`\narr_lexsort\n</pre> arr_lexsort = np.lexsort((arr2, arr1))  # Sort by `arr1`, then by `arr2` arr_lexsort Out[136]: <pre>array([0, 1, 2])</pre> In\u00a0[137]: Copied! <pre>arr_determinant = np.linalg.det(A)  # Determinant of a matrix\narr_determinant\n</pre> arr_determinant = np.linalg.det(A)  # Determinant of a matrix arr_determinant Out[137]: <pre>5.000000000000001</pre> In\u00a0[138]: Copied! <pre>arr_rank = np.linalg.matrix_rank(A)  # Rank of a matrix\narr_rank\n</pre> arr_rank = np.linalg.matrix_rank(A)  # Rank of a matrix arr_rank Out[138]: <pre>2</pre> In\u00a0[139]: Copied! <pre>arr_trace = np.trace(A)  # Sum of diagonal elements (trace)\narr_trace\n</pre> arr_trace = np.trace(A)  # Sum of diagonal elements (trace) arr_trace Out[139]: <pre>5</pre> In\u00a0[140]: Copied! <pre>arr_kron = np.kron(arr1, arr2)  # Kronecker product of two arrays\narr_kron\n</pre> arr_kron = np.kron(arr1, arr2)  # Kronecker product of two arrays arr_kron Out[140]: <pre>array([1, 2, 3, 2, 4, 6, 3, 6, 9])</pre> In\u00a0[141]: Copied! <pre>arr_outer = np.outer(arr1, arr2)  # Outer product of two arrays\narr_outer\n</pre> arr_outer = np.outer(arr1, arr2)  # Outer product of two arrays arr_outer Out[141]: <pre>array([[1, 2, 3],\n       [2, 4, 6],\n       [3, 6, 9]])</pre> In\u00a0[142]: Copied! <pre>arr_solve = np.linalg.solve(A, b)  # Solve Ax = b for x\narr_solve\n</pre> arr_solve = np.linalg.solve(A, b)  # Solve Ax = b for x arr_solve Out[142]: <pre>array([2., 3.])</pre> In\u00a0[143]: Copied! <pre>arr_lstsq = np.linalg.lstsq(A, b, rcond=None)  # Solve Ax = b using least squares\narr_lstsq[0]\n</pre> arr_lstsq = np.linalg.lstsq(A, b, rcond=None)  # Solve Ax = b using least squares arr_lstsq[0] Out[143]: <pre>array([2., 3.])</pre> In\u00a0[144]: Copied! <pre>arr_dtype = np.array([1, 2, 3], dtype=np.float32)  # Specify data type\narr_dtype\n</pre> arr_dtype = np.array([1, 2, 3], dtype=np.float32)  # Specify data type arr_dtype Out[144]: <pre>array([1., 2., 3.], dtype=float32)</pre> In\u00a0[145]: Copied! <pre>arr_converted_dtype = arr1.astype(np.int32)  # Convert array to specified data type\narr_converted_dtype\n</pre> arr_converted_dtype = arr1.astype(np.int32)  # Convert array to specified data type arr_converted_dtype Out[145]: <pre>array([1, 2, 3], dtype=int32)</pre> In\u00a0[146]: Copied! <pre>arr_complex = np.array([1+2j, 3+4j], dtype=np.complex64)  # Complex data type\narr_complex\n</pre> arr_complex = np.array([1+2j, 3+4j], dtype=np.complex64)  # Complex data type arr_complex Out[146]: <pre>array([1.+2.j, 3.+4.j], dtype=complex64)</pre> In\u00a0[147]: Copied! <pre>arr_dtype_check = arr_complex.dtype  # Check data type\narr_dtype_check\n</pre> arr_dtype_check = arr_complex.dtype  # Check data type arr_dtype_check Out[147]: <pre>dtype('complex64')</pre> In\u00a0[148]: Copied! <pre>np.issubdtype(arr_complex.dtype, np.number)  # Check if the data type is a subtype of `np.number`\n</pre> np.issubdtype(arr_complex.dtype, np.number)  # Check if the data type is a subtype of `np.number` Out[148]: <pre>True</pre>"},{"location":"Cheat-Sheets/NumPy/#numpy","title":"NumPy\u00b6","text":"<p>NumPy, which stands for Numerical Python, is a free, open-source Python library for working with arrays. It's one of the most popular packages for scientific computing in Python, and is used for data manipulation and analysis, including data cleaning, transformation, and aggregation.</p> <ul> <li>Official Website: https://numpy.org/</li> <li>Installation:  (https://numpy.org/install/)<pre>pip install numpy\n</pre> </li> <li>Documentation: https://numpy.org/doc</li> <li>GitHub: https://github.com/numpy/numpy</li> </ul>"},{"location":"Cheat-Sheets/NumPy/#basics","title":"Basics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-creation","title":"Array Creation\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#from-lists-tuples-and-buffers","title":"From Lists, Tuples, and Buffers\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#zeros-ones-and-empty-arrays","title":"Zeros, Ones, and Empty Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#ranges-and-random-numbers","title":"Ranges and Random Numbers\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#identity-and-diagonal-matrices","title":"Identity and Diagonal Matrices\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#structured-arrays","title":"Structured Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#using-npfull-and-nptile","title":"Using <code>np.full</code> and <code>np.tile</code>\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-inspection","title":"Array Inspection\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#shape-and-size","title":"Shape and Size\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#data-type","title":"Data Type\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#memory-layout","title":"Memory Layout\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#checking-for-nan-and-inf-values","title":"Checking for <code>NaN</code> and <code>Inf</code> Values\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-mathematics","title":"Array Mathematics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#basic-operations","title":"Basic Operations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#aggregate-functions","title":"Aggregate Functions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#exponentials-and-logarithms","title":"Exponentials and Logarithms\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#trigonometric-functions","title":"Trigonometric Functions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#rounding-and-precision-control","title":"Rounding and Precision Control\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-manipulation","title":"Array Manipulation\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#reshaping","title":"Reshaping\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#transposing","title":"Transposing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#joining-and-splitting-arrays","title":"Joining and Splitting Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#changing-dimensions","title":"Changing Dimensions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#array-repetition","title":"Array Repetition\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#rotating-and-flipping-arrays","title":"Rotating and Flipping Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#linear-algebra","title":"Linear Algebra\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#dot-product-and-matrix-multiplication","title":"Dot Product and Matrix Multiplication\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#solving-linear-equations","title":"Solving Linear Equations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#eigenvalues-and-eigenvectors","title":"Eigenvalues and Eigenvectors\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#inverse-and-determinant","title":"Inverse and Determinant\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#singular-value-decomposition-svd","title":"Singular Value Decomposition (SVD)\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#norms-and-condition-numbers","title":"Norms and Condition Numbers\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#statistics","title":"Statistics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#descriptive-statistics","title":"Descriptive Statistics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#percentiles","title":"Percentiles\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#correlation-and-covariance","title":"Correlation and Covariance\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#histogram","title":"Histogram\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#binned-statistics","title":"Binned Statistics\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#broadcasting","title":"Broadcasting\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#basic-broadcasting","title":"Basic Broadcasting\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-broadcasting","title":"Advanced Broadcasting\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#indexing-and-slicing","title":"Indexing and Slicing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#basic-indexing","title":"Basic Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#slicing","title":"Slicing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#fancy-indexing","title":"Fancy Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#boolean-masking-and-advanced-indexing","title":"Boolean Masking and Advanced Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#boolean-masking","title":"Boolean Masking\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-indexing-with-conditions","title":"Advanced Indexing with Conditions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#setting-values","title":"Setting Values\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-indexing-with-npix_","title":"Advanced Indexing with np.ix_\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#random","title":"Random\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#random-numbers","title":"Random Numbers\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#random-permutations","title":"Random Permutations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#sampling-and-distributions","title":"Sampling and Distributions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#setting-seed","title":"Setting Seed\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#io-with-numpy","title":"I/O with NumPy\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#reading-and-writing-files","title":"Reading and Writing Files\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#saving-and-loading-multiple-arrays","title":"Saving and Loading Multiple Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#reading-and-writing-csv-files","title":"Reading and Writing CSV Files\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#polynomials","title":"Polynomials\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#polynomial-operations","title":"Polynomial Operations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#polynomial-fitting","title":"Polynomial Fitting\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#polynomial-derivatives-and-integrals","title":"Polynomial Derivatives and Integrals\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-array-operations","title":"Advanced Array Operations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#vectorize-functions","title":"Vectorize Functions\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#meshgrid","title":"Meshgrid\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#broadcasting-with-advanced-indexing","title":"Broadcasting with Advanced Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#sorting-arrays","title":"Sorting Arrays\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#searching-and-counting-elements","title":"Searching and Counting Elements\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#memory-management","title":"Memory Management\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#memory-layout-and-optimization","title":"Memory Layout and Optimization\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#memory-mapping-files","title":"Memory Mapping Files\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#copying-and-views","title":"Copying and Views\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#advanced-indexing","title":"Advanced Indexing\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#using-nptake-and-npput","title":"Using <code>np.take</code> and <code>np.put</code>\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#using-npchoose","title":"Using <code>np.choose</code>\u00b6","text":"<p><code>np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])</code></p>"},{"location":"Cheat-Sheets/NumPy/#using-nplexsort","title":"Using <code>np.lexsort</code>\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#matrix-operations","title":"Matrix Operations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#determinant-rank-and-trace","title":"Determinant, Rank, and Trace\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#kronecker-product-and-outer-product","title":"Kronecker Product and Outer Product\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#solving-systems-of-linear-equations","title":"Solving Systems of Linear Equations\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#data-types","title":"Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#specifying-data-types","title":"Specifying Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#converting-data-types","title":"Converting Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#complex-data-types","title":"Complex Data Types\u00b6","text":""},{"location":"Cheat-Sheets/NumPy/#checking-data-types","title":"Checking Data Types\u00b6","text":""},{"location":"Cheat-Sheets/Pandas/","title":"Pandas","text":"In\u00a0[1]: Copied! <pre># Import Pandas\nimport pandas as pd\npd.__version__ \n\n# only used in this cheat sheet to display the DataFrames\n# from IPython.display import display \n</pre> # Import Pandas import pandas as pd pd.__version__   # only used in this cheat sheet to display the DataFrames # from IPython.display import display  Out[1]: <pre>'2.2.3'</pre> In\u00a0[2]: Copied! <pre># Create a Series from a list\ns = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\nprint(\"Series s:\")\ndisplay(s)\n\n# Create a Series from a dictionary\ndata_dict = {'x': 100, 'y': 200, 'z': 300}\ns_dict = pd.Series(data_dict)\nprint(\"\\nSeries s_dict:\")\ndisplay(s_dict)\n\n# Accessing elements\nprint(\"\\nAccess element by label s['b']:\", s['b'])\nprint(\"Access element by position s.iloc[2]:\", s.iloc[2])\n</pre> # Create a Series from a list s = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd']) print(\"Series s:\") display(s)  # Create a Series from a dictionary data_dict = {'x': 100, 'y': 200, 'z': 300} s_dict = pd.Series(data_dict) print(\"\\nSeries s_dict:\") display(s_dict)  # Accessing elements print(\"\\nAccess element by label s['b']:\", s['b']) print(\"Access element by position s.iloc[2]:\", s.iloc[2]) <pre>Series s:\n</pre> <pre>a    10\nb    20\nc    30\nd    40\ndtype: int64</pre> <pre>\nSeries s_dict:\n</pre> <pre>x    100\ny    200\nz    300\ndtype: int64</pre> <pre>\nAccess element by label s['b']: 20\nAccess element by position s.iloc[2]: 30\n</pre> In\u00a0[3]: Copied! <pre># Create DataFrame from a dictionary of lists\ndf = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'City': ['New York', 'Paris', 'London']\n})\nprint(\"DataFrame df:\")\ndisplay(df)\n\n# Create DataFrame from a list of lists\ndf2 = pd.DataFrame(\n    [[1, 2, 3],\n     [4, 5, 6],\n     [7, 8, 9]],\n    columns=['ColA', 'ColB', 'ColC']\n)\nprint(\"\\nDataFrame df2:\")\ndisplay(df2)\n\n# Check basic attributes\nprint(\"\\nShape of df2:\", df2.shape)\nprint(\"Columns of df2:\", df2.columns)\nprint(\"Index of df2:\", df2.index)\n</pre> # Create DataFrame from a dictionary of lists df = pd.DataFrame({     'Name': ['Alice', 'Bob', 'Charlie'],     'Age': [25, 30, 35],     'City': ['New York', 'Paris', 'London'] }) print(\"DataFrame df:\") display(df)  # Create DataFrame from a list of lists df2 = pd.DataFrame(     [[1, 2, 3],      [4, 5, 6],      [7, 8, 9]],     columns=['ColA', 'ColB', 'ColC'] ) print(\"\\nDataFrame df2:\") display(df2)  # Check basic attributes print(\"\\nShape of df2:\", df2.shape) print(\"Columns of df2:\", df2.columns) print(\"Index of df2:\", df2.index)  <pre>DataFrame df:\n</pre> Name Age City 0 Alice 25 New York 1 Bob 30 Paris 2 Charlie 35 London <pre>\nDataFrame df2:\n</pre> ColA ColB ColC 0 1 2 3 1 4 5 6 2 7 8 9 <pre>\nShape of df2: (3, 3)\nColumns of df2: Index(['ColA', 'ColB', 'ColC'], dtype='object')\nIndex of df2: RangeIndex(start=0, stop=3, step=1)\n</pre> In\u00a0[4]: Copied! <pre>import numpy as np\n\n# Create a MultiIndex from tuples\ntuples = [('Group1', 'Row1'), ('Group1', 'Row2'),\n          ('Group2', 'Row1'), ('Group2', 'Row2')]\nmulti_index = pd.MultiIndex.from_tuples(tuples, names=['Group', 'Row'])\n\n# Create a DataFrame using the MultiIndex\ndf_multi = pd.DataFrame(\n    np.random.randn(4, 2),\n    index=multi_index,\n    columns=['ColX', 'ColY']\n)\nprint(\"MultiIndex DataFrame:\\n\")\ndisplay(df_multi)\nprint(\"\\nIndex levels:\", df_multi.index.levels)\n</pre> import numpy as np  # Create a MultiIndex from tuples tuples = [('Group1', 'Row1'), ('Group1', 'Row2'),           ('Group2', 'Row1'), ('Group2', 'Row2')] multi_index = pd.MultiIndex.from_tuples(tuples, names=['Group', 'Row'])  # Create a DataFrame using the MultiIndex df_multi = pd.DataFrame(     np.random.randn(4, 2),     index=multi_index,     columns=['ColX', 'ColY'] ) print(\"MultiIndex DataFrame:\\n\") display(df_multi) print(\"\\nIndex levels:\", df_multi.index.levels)  <pre>MultiIndex DataFrame:\n\n</pre> ColX ColY Group Row Group1 Row1 -0.587480 -0.817371 Row2 -1.394396 -1.291968 Group2 Row1 1.178137 0.866652 Row2 0.920178 0.593349 <pre>\nIndex levels: [['Group1', 'Group2'], ['Row1', 'Row2']]\n</pre> In\u00a0[5]: Copied! <pre># Using the df we created above\nprint(\"Original df:\")\ndisplay(df)\n\n# Select a single column by label\nprint(\"\\nSingle column df['Name']:\")\ndisplay(df['Name'])\n\n# Using .loc (label-based)\nprint(\"\\nUsing df.loc[0, 'Age']:\")\ndisplay(df.loc[0, 'Age'])\nprint(\"\\nUsing df.loc[0:1, ['Name', 'City']]:\")\ndisplay(df.loc[0:1, ['Name', 'City']])\n\n# Using .iloc (integer position-based)\nprint(\"\\nUsing df.iloc[1, 2]:\")  # second row, third column\ndisplay(df.iloc[1, 2])\nprint(\"\\nUsing df.iloc[0:2, 0:2]:\")\ndisplay(df.iloc[0:2, 0:2])\n\n# Boolean indexing\nprint(\"\\nRows where Age &gt; 25:\")\ndisplay(df[df['Age'] &gt; 25])\n</pre> # Using the df we created above print(\"Original df:\") display(df)  # Select a single column by label print(\"\\nSingle column df['Name']:\") display(df['Name'])  # Using .loc (label-based) print(\"\\nUsing df.loc[0, 'Age']:\") display(df.loc[0, 'Age']) print(\"\\nUsing df.loc[0:1, ['Name', 'City']]:\") display(df.loc[0:1, ['Name', 'City']])  # Using .iloc (integer position-based) print(\"\\nUsing df.iloc[1, 2]:\")  # second row, third column display(df.iloc[1, 2]) print(\"\\nUsing df.iloc[0:2, 0:2]:\") display(df.iloc[0:2, 0:2])  # Boolean indexing print(\"\\nRows where Age &gt; 25:\") display(df[df['Age'] &gt; 25]) <pre>Original df:\n</pre> Name Age City 0 Alice 25 New York 1 Bob 30 Paris 2 Charlie 35 London <pre>\nSingle column df['Name']:\n</pre> <pre>0      Alice\n1        Bob\n2    Charlie\nName: Name, dtype: object</pre> <pre>\nUsing df.loc[0, 'Age']:\n</pre> <pre>np.int64(25)</pre> <pre>\nUsing df.loc[0:1, ['Name', 'City']]:\n</pre> Name City 0 Alice New York 1 Bob Paris <pre>\nUsing df.iloc[1, 2]:\n</pre> <pre>'Paris'</pre> <pre>\nUsing df.iloc[0:2, 0:2]:\n</pre> Name Age 0 Alice 25 1 Bob 30 <pre>\nRows where Age &gt; 25:\n</pre> Name Age City 1 Bob 30 Paris 2 Charlie 35 London In\u00a0[6]: Copied! <pre># Example DataFrame\ndf_wide = pd.DataFrame({\n    'id': [1, 2, 3],\n    'varA': [10, 20, 30],\n    'varB': [40, 50, 60]\n})\nprint(\"Wide DataFrame:\")\ndisplay(df_wide)\n\n# Melt (wide -&gt; long)\ndf_long = pd.melt(df_wide, id_vars='id', var_name='variable', value_name='value')\nprint(\"\\nMelted (long) DataFrame:\")\ndisplay(df_long)\n\n# Pivot (long -&gt; wide)\ndf_pivoted = df_long.pivot(index='id', columns='variable', values='value')\nprint(\"\\nPivoted (wide) DataFrame:\")\ndisplay(df_pivoted)\n\n# Concat examples\ndf_part1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\ndf_part2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\ndf_concat = pd.concat([df_part1, df_part2], ignore_index=True)\nprint(\"\\nConcatenated DataFrame:\")\ndisplay(df_concat)\n</pre> # Example DataFrame df_wide = pd.DataFrame({     'id': [1, 2, 3],     'varA': [10, 20, 30],     'varB': [40, 50, 60] }) print(\"Wide DataFrame:\") display(df_wide)  # Melt (wide -&gt; long) df_long = pd.melt(df_wide, id_vars='id', var_name='variable', value_name='value') print(\"\\nMelted (long) DataFrame:\") display(df_long)  # Pivot (long -&gt; wide) df_pivoted = df_long.pivot(index='id', columns='variable', values='value') print(\"\\nPivoted (wide) DataFrame:\") display(df_pivoted)  # Concat examples df_part1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]}) df_part2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]}) df_concat = pd.concat([df_part1, df_part2], ignore_index=True) print(\"\\nConcatenated DataFrame:\") display(df_concat) <pre>Wide DataFrame:\n</pre> id varA varB 0 1 10 40 1 2 20 50 2 3 30 60 <pre>\nMelted (long) DataFrame:\n</pre> id variable value 0 1 varA 10 1 2 varA 20 2 3 varA 30 3 1 varB 40 4 2 varB 50 5 3 varB 60 <pre>\nPivoted (wide) DataFrame:\n</pre> variable varA varB id 1 10 40 2 20 50 3 30 60 <pre>\nConcatenated DataFrame:\n</pre> A B 0 1 3 1 2 4 2 5 7 3 6 8 In\u00a0[7]: Copied! <pre># Using df_wide again\nprint(\"df_wide:\")\ndisplay(df_wide)\n\n# Subset columns\nsubset_columns = df_wide[['id', 'varA']]\nprint(\"\\nSubset of columns [id, varA]:\")\ndisplay(subset_columns)\n\n# Subset rows by index slicing\nsubset_rows = df_wide.iloc[0:2]  # first two rows\nprint(\"\\nSubset of rows (first two rows):\")\ndisplay(subset_rows)\n\n# Subset using a condition\ncondition_subset = df_wide[df_wide['varA'] &gt; 10]\nprint(\"\\nSubset where varA &gt; 10:\")\ndisplay(condition_subset)\n</pre> # Using df_wide again print(\"df_wide:\") display(df_wide)  # Subset columns subset_columns = df_wide[['id', 'varA']] print(\"\\nSubset of columns [id, varA]:\") display(subset_columns)  # Subset rows by index slicing subset_rows = df_wide.iloc[0:2]  # first two rows print(\"\\nSubset of rows (first two rows):\") display(subset_rows)  # Subset using a condition condition_subset = df_wide[df_wide['varA'] &gt; 10] print(\"\\nSubset where varA &gt; 10:\") display(condition_subset) <pre>df_wide:\n</pre> id varA varB 0 1 10 40 1 2 20 50 2 3 30 60 <pre>\nSubset of columns [id, varA]:\n</pre> id varA 0 1 10 1 2 20 2 3 30 <pre>\nSubset of rows (first two rows):\n</pre> id varA varB 0 1 10 40 1 2 20 50 <pre>\nSubset where varA &gt; 10:\n</pre> id varA varB 1 2 20 50 2 3 30 60 In\u00a0[8]: Copied! <pre>import numpy as np\n\ndf_stats = pd.DataFrame({\n    'Col1': np.random.randint(0, 100, 5),\n    'Col2': np.random.randint(0, 100, 5),\n    'Col3': np.random.randint(0, 100, 5),\n    'Category': ['A', 'B', 'A', 'C', 'B'],\n    'Status': ['Active', 'Inactive', 'Active', 'Active', 'Inactive']\n})\nprint(\"DataFrame with mixed types:\")\ndisplay(df_stats)\n\n# Basic stats (numeric columns only)\nprint(\"\\nNumerical Statistics (describe):\")\ndisplay(df_stats.describe())\n\n# Basic stats for object columns\nprint(\"\\nCategorical Statistics (describe):\")\ndisplay(df_stats.describe(include=['object']))\n\n# Value counts for categorical columns\nprint(\"\\nCategory value counts:\")\ndisplay(df_stats['Category'].value_counts())\nprint(\"\\nStatus value counts:\")\ndisplay(df_stats['Status'].value_counts())\n\n# Mean of numeric columns\nprint(\"\\nMean of numeric columns:\")\ndisplay(df_stats.mean(numeric_only=True))\n\n# Count of all columns (works for both numeric and object types)\nprint(\"\\nCount of all columns:\")\ndisplay(df_stats.count())\n</pre> import numpy as np  df_stats = pd.DataFrame({     'Col1': np.random.randint(0, 100, 5),     'Col2': np.random.randint(0, 100, 5),     'Col3': np.random.randint(0, 100, 5),     'Category': ['A', 'B', 'A', 'C', 'B'],     'Status': ['Active', 'Inactive', 'Active', 'Active', 'Inactive'] }) print(\"DataFrame with mixed types:\") display(df_stats)  # Basic stats (numeric columns only) print(\"\\nNumerical Statistics (describe):\") display(df_stats.describe())  # Basic stats for object columns print(\"\\nCategorical Statistics (describe):\") display(df_stats.describe(include=['object']))  # Value counts for categorical columns print(\"\\nCategory value counts:\") display(df_stats['Category'].value_counts()) print(\"\\nStatus value counts:\") display(df_stats['Status'].value_counts())  # Mean of numeric columns print(\"\\nMean of numeric columns:\") display(df_stats.mean(numeric_only=True))  # Count of all columns (works for both numeric and object types) print(\"\\nCount of all columns:\") display(df_stats.count()) <pre>DataFrame with mixed types:\n</pre> Col1 Col2 Col3 Category Status 0 74 65 92 A Active 1 96 70 76 B Inactive 2 63 68 83 A Active 3 35 85 75 C Active 4 56 11 42 B Inactive <pre>\nNumerical Statistics (describe):\n</pre> Col1 Col2 Col3 count 5.000000 5.000000 5.000000 mean 64.800000 59.800000 73.600000 std 22.509998 28.349603 18.928814 min 35.000000 11.000000 42.000000 25% 56.000000 65.000000 75.000000 50% 63.000000 68.000000 76.000000 75% 74.000000 70.000000 83.000000 max 96.000000 85.000000 92.000000 <pre>\nCategorical Statistics (describe):\n</pre> Category Status count 5 5 unique 3 2 top A Active freq 2 3 <pre>\nCategory value counts:\n</pre> <pre>Category\nA    2\nB    2\nC    1\nName: count, dtype: int64</pre> <pre>\nStatus value counts:\n</pre> <pre>Status\nActive      3\nInactive    2\nName: count, dtype: int64</pre> <pre>\nMean of numeric columns:\n</pre> <pre>Col1    64.8\nCol2    59.8\nCol3    73.6\ndtype: float64</pre> <pre>\nCount of all columns:\n</pre> <pre>Col1        5\nCol2        5\nCol3        5\nCategory    5\nStatus      5\ndtype: int64</pre> In\u00a0[9]: Copied! <pre># Create a DataFrame with NaN values\ndf_missing = pd.DataFrame({\n    'A': [1, np.nan, 3, np.nan],\n    'B': [5, 6, np.nan, 8]\n})\nprint(\"Original df_missing:\")\ndisplay(df_missing)\n\n# Detect missing values\nprint(\"\\nMissing value check:\")\ndisplay(df_missing.isnull())\n\n# Drop rows with any missing values\nprint(\"\\nDrop rows with any NaN:\")\ndisplay(df_missing.dropna())\n\n# Fill missing values with a constant\nfilled_df = df_missing.fillna(0)\nprint(\"\\nFill NaN with 0:\")\ndisplay(filled_df)\n</pre> # Create a DataFrame with NaN values df_missing = pd.DataFrame({     'A': [1, np.nan, 3, np.nan],     'B': [5, 6, np.nan, 8] }) print(\"Original df_missing:\") display(df_missing)  # Detect missing values print(\"\\nMissing value check:\") display(df_missing.isnull())  # Drop rows with any missing values print(\"\\nDrop rows with any NaN:\") display(df_missing.dropna())  # Fill missing values with a constant filled_df = df_missing.fillna(0) print(\"\\nFill NaN with 0:\") display(filled_df) <pre>Original df_missing:\n</pre> A B 0 1.0 5.0 1 NaN 6.0 2 3.0 NaN 3 NaN 8.0 <pre>\nMissing value check:\n</pre> A B 0 False False 1 True False 2 False True 3 True False <pre>\nDrop rows with any NaN:\n</pre> A B 0 1.0 5.0 <pre>\nFill NaN with 0:\n</pre> A B 0 1.0 5.0 1 0.0 6.0 2 3.0 0.0 3 0.0 8.0 In\u00a0[10]: Copied! <pre>df_new_cols = pd.DataFrame({\n    'Length': [2, 3, 4],\n    'Width': [5, 6, 7]\n})\nprint(\"Original df_new_cols:\")\ndisplay(df_new_cols)\n\n# Direct assignment\ndf_new_cols['Area'] = df_new_cols['Length'] * df_new_cols['Width']\nprint(\"\\nAdded 'Area' column:\")\ndisplay(df_new_cols)\n\n# Using assign (returns a copy)\ndf_assigned = df_new_cols.assign(Perimeter=lambda x: 2 * (x['Length'] + x['Width']))\nprint(\"\\nAssigned 'Perimeter' column:\")\ndisplay(df_assigned)\n</pre> df_new_cols = pd.DataFrame({     'Length': [2, 3, 4],     'Width': [5, 6, 7] }) print(\"Original df_new_cols:\") display(df_new_cols)  # Direct assignment df_new_cols['Area'] = df_new_cols['Length'] * df_new_cols['Width'] print(\"\\nAdded 'Area' column:\") display(df_new_cols)  # Using assign (returns a copy) df_assigned = df_new_cols.assign(Perimeter=lambda x: 2 * (x['Length'] + x['Width'])) print(\"\\nAssigned 'Perimeter' column:\") display(df_assigned) <pre>Original df_new_cols:\n</pre> Length Width 0 2 5 1 3 6 2 4 7 <pre>\nAdded 'Area' column:\n</pre> Length Width Area 0 2 5 10 1 3 6 18 2 4 7 28 <pre>\nAssigned 'Perimeter' column:\n</pre> Length Width Area Perimeter 0 2 5 10 14 1 3 6 18 18 2 4 7 28 22 In\u00a0[11]: Copied! <pre>df_group = pd.DataFrame({\n    'Category': ['A', 'A', 'B', 'B', 'C'],\n    'Values': [10, 15, 10, 25, 5]\n})\n\nprint(\"df_group:\")\ndisplay(df_group)\n\n# Group by 'Category'\ngrouped = df_group.groupby('Category')\nprint(\"\\nSum by Category:\")\ndisplay(grouped['Values'].sum())\nprint(\"\\nMean by Category:\")\ndisplay(grouped['Values'].mean())\n\n# Multiple aggregation methods at once\nagg_results = grouped['Values'].agg(['min', 'max', 'mean', 'count'])\nprint(\"\\nMultiple aggregations:\")\ndisplay(agg_results)\n</pre> df_group = pd.DataFrame({     'Category': ['A', 'A', 'B', 'B', 'C'],     'Values': [10, 15, 10, 25, 5] })  print(\"df_group:\") display(df_group)  # Group by 'Category' grouped = df_group.groupby('Category') print(\"\\nSum by Category:\") display(grouped['Values'].sum()) print(\"\\nMean by Category:\") display(grouped['Values'].mean())  # Multiple aggregation methods at once agg_results = grouped['Values'].agg(['min', 'max', 'mean', 'count']) print(\"\\nMultiple aggregations:\") display(agg_results)  <pre>df_group:\n</pre> Category Values 0 A 10 1 A 15 2 B 10 3 B 25 4 C 5 <pre>\nSum by Category:\n</pre> <pre>Category\nA    25\nB    35\nC     5\nName: Values, dtype: int64</pre> <pre>\nMean by Category:\n</pre> <pre>Category\nA    12.5\nB    17.5\nC     5.0\nName: Values, dtype: float64</pre> <pre>\nMultiple aggregations:\n</pre> min max mean count Category A 10 15 12.5 2 B 10 25 17.5 2 C 5 5 5.0 1 In\u00a0[12]: Copied! <pre># Create a Series for rolling example\ns_rolling = pd.Series([1, 2, 3, 4, 5, 6, 7])\nprint(\"Original Series:\")\ndisplay(s_rolling)\n\n# Rolling window of size 3, compute mean\nrolling_mean = s_rolling.rolling(3).mean()\nprint(\"\\nRolling mean with window=3:\")\ndisplay(rolling_mean)\n\n# Expanding: cumulative computations\nexpanding_sum = s_rolling.expanding().sum()\nprint(\"\\nExpanding sum:\")\ndisplay(expanding_sum)\n</pre> # Create a Series for rolling example s_rolling = pd.Series([1, 2, 3, 4, 5, 6, 7]) print(\"Original Series:\") display(s_rolling)  # Rolling window of size 3, compute mean rolling_mean = s_rolling.rolling(3).mean() print(\"\\nRolling mean with window=3:\") display(rolling_mean)  # Expanding: cumulative computations expanding_sum = s_rolling.expanding().sum() print(\"\\nExpanding sum:\") display(expanding_sum) <pre>Original Series:\n</pre> <pre>0    1\n1    2\n2    3\n3    4\n4    5\n5    6\n6    7\ndtype: int64</pre> <pre>\nRolling mean with window=3:\n</pre> <pre>0    NaN\n1    NaN\n2    2.0\n3    3.0\n4    4.0\n5    5.0\n6    6.0\ndtype: float64</pre> <pre>\nExpanding sum:\n</pre> <pre>0     1.0\n1     3.0\n2     6.0\n3    10.0\n4    15.0\n5    21.0\n6    28.0\ndtype: float64</pre> In\u00a0[13]: Copied! <pre>left = pd.DataFrame({'key': ['K0', 'K1', 'K2'], 'A': ['A0', 'A1', 'A2']})\nright = pd.DataFrame({'key': ['K0', 'K2', 'K3'], 'B': ['B0', 'B2', 'B3']})\n\nprint(\"left:\")\ndisplay(left)\nprint(\"\\nright:\")\ndisplay(right)\n\n# Merge using an inner join\nmerged_inner = pd.merge(left, right, on='key', how='inner')\nprint(\"\\nMerged (inner join):\")\ndisplay(merged_inner)\n\n# Merge using an outer join\nmerged_outer = pd.merge(left, right, on='key', how='outer')\nprint(\"\\nMerged (outer join):\")\ndisplay(merged_outer)\n\n# Concat example (stacking rows)\nconcat_example = pd.concat([left, right], axis=0, ignore_index=True)\nprint(\"\\nConcatenated (stack rows):\")\ndisplay(concat_example)\n</pre> left = pd.DataFrame({'key': ['K0', 'K1', 'K2'], 'A': ['A0', 'A1', 'A2']}) right = pd.DataFrame({'key': ['K0', 'K2', 'K3'], 'B': ['B0', 'B2', 'B3']})  print(\"left:\") display(left) print(\"\\nright:\") display(right)  # Merge using an inner join merged_inner = pd.merge(left, right, on='key', how='inner') print(\"\\nMerged (inner join):\") display(merged_inner)  # Merge using an outer join merged_outer = pd.merge(left, right, on='key', how='outer') print(\"\\nMerged (outer join):\") display(merged_outer)  # Concat example (stacking rows) concat_example = pd.concat([left, right], axis=0, ignore_index=True) print(\"\\nConcatenated (stack rows):\") display(concat_example) <pre>left:\n</pre> key A 0 K0 A0 1 K1 A1 2 K2 A2 <pre>\nright:\n</pre> key B 0 K0 B0 1 K2 B2 2 K3 B3 <pre>\nMerged (inner join):\n</pre> key A B 0 K0 A0 B0 1 K2 A2 B2 <pre>\nMerged (outer join):\n</pre> key A B 0 K0 A0 B0 1 K1 A1 NaN 2 K2 A2 B2 3 K3 NaN B3 <pre>\nConcatenated (stack rows):\n</pre> key A B 0 K0 A0 NaN 1 K1 A1 NaN 2 K2 A2 NaN 3 K0 NaN B0 4 K2 NaN B2 5 K3 NaN B3 In\u00a0[29]: Copied! <pre># Create sample DataFrames with multiple columns\nleft = pd.DataFrame({\n    'id_left': ['K0', 'K1', 'K2'],\n    'name': ['A0', 'A1', 'A2'],\n    'score': [10, 20, 30]\n})\nright = pd.DataFrame({\n    'id_right': ['K0', 'K2', 'K3'],\n    'name': ['B0', 'B2', 'B3'],\n    'score': [15, 35, 45]\n})\n\n# Merge with different key columns and suffixes\nmerged = pd.merge(\n    left, right,\n    left_on=['id_left', 'name'],\n    right_on=['id_right', 'name'],\n    how='outer',\n    suffixes=('_L', '_R')\n)\nprint(\"Merged with multiple keys and suffixes:\")\ndisplay(merged)\n</pre> # Create sample DataFrames with multiple columns left = pd.DataFrame({     'id_left': ['K0', 'K1', 'K2'],     'name': ['A0', 'A1', 'A2'],     'score': [10, 20, 30] }) right = pd.DataFrame({     'id_right': ['K0', 'K2', 'K3'],     'name': ['B0', 'B2', 'B3'],     'score': [15, 35, 45] })  # Merge with different key columns and suffixes merged = pd.merge(     left, right,     left_on=['id_left', 'name'],     right_on=['id_right', 'name'],     how='outer',     suffixes=('_L', '_R') ) print(\"Merged with multiple keys and suffixes:\") display(merged) <pre>Merged with multiple keys and suffixes:\n</pre> id_left name score_L id_right score_R 0 K0 A0 10.0 NaN NaN 1 NaN B0 NaN K0 15.0 2 K1 A1 20.0 NaN NaN 3 K2 A2 30.0 NaN NaN 4 NaN B2 NaN K2 35.0 5 NaN B3 NaN K3 45.0 In\u00a0[14]: Copied! <pre>import matplotlib.pyplot as plt\n\ndf_plot = pd.DataFrame({\n    'x': [1, 2, 3, 4, 5],\n    'y': [3, 5, 2, 8, 7]\n})\n\n# Line plot\ndf_plot.plot(x='x', y='y', kind='line', title='Line Plot')\nplt.show()\n\n# Scatter plot\ndf_plot.plot.scatter(x='x', y='y', title='Scatter Plot')\nplt.show()\n</pre> import matplotlib.pyplot as plt  df_plot = pd.DataFrame({     'x': [1, 2, 3, 4, 5],     'y': [3, 5, 2, 8, 7] })  # Line plot df_plot.plot(x='x', y='y', kind='line', title='Line Plot') plt.show()  # Scatter plot df_plot.plot.scatter(x='x', y='y', title='Scatter Plot') plt.show()  In\u00a0[15]: Copied! <pre>print(\"df_plot info:\")\ndisplay(df_plot.info())\n\nprint(\"\\nDataFrame attributes:\")\nprint(\"Shape:\", df_plot.shape)\nprint(\"Columns:\", df_plot.columns)\nprint(\"Index:\", df_plot.index)\nprint(\"\\nDataFrame dtypes:\")\ndisplay(df_plot.dtypes)\n\nprint(\"\\nDescriptive statistics:\")\ndisplay(df_plot.describe())\n</pre> print(\"df_plot info:\") display(df_plot.info())  print(\"\\nDataFrame attributes:\") print(\"Shape:\", df_plot.shape) print(\"Columns:\", df_plot.columns) print(\"Index:\", df_plot.index) print(\"\\nDataFrame dtypes:\") display(df_plot.dtypes)  print(\"\\nDescriptive statistics:\") display(df_plot.describe()) <pre>df_plot info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 5 entries, 0 to 4\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype\n---  ------  --------------  -----\n 0   x       5 non-null      int64\n 1   y       5 non-null      int64\ndtypes: int64(2)\nmemory usage: 212.0 bytes\n</pre> <pre>None</pre> <pre>\nDataFrame attributes:\nShape: (5, 2)\nColumns: Index(['x', 'y'], dtype='object')\nIndex: RangeIndex(start=0, stop=5, step=1)\n\nDataFrame dtypes:\n</pre> <pre>x    int64\ny    int64\ndtype: object</pre> <pre>\nDescriptive statistics:\n</pre> x y count 5.000000 5.00000 mean 3.000000 5.00000 std 1.581139 2.54951 min 1.000000 2.00000 25% 2.000000 3.00000 50% 3.000000 5.00000 75% 4.000000 7.00000 max 5.000000 8.00000 In\u00a0[16]: Copied! <pre>print(\"df_stats\")\ndisplay(df_stats)\n\n# Apply a function to each column\nprint(\"Applying sum to each column:\")\ndisplay(df_stats[['Col1', 'Col2']].apply(sum))\n\n# Apply a function to each element\ndf_applied = df_stats.applymap(lambda x: x * 2)\nprint(\"\\nApplying lambda x: x * 2 to each element:\")\ndisplay(df_applied)\n\n# For a single column (Series)\ndf_stats_col1_applied = df_stats['Col1'].apply(lambda x: x + 10)\nprint(\"\\nAdding 10 to each element in Col1:\")\ndisplay(df_stats_col1_applied)\n\n# Apply function to two columns row-wise\ntemp_df = df_stats.copy() # copyinf DataFrame\ntemp_df['row_sums'] = temp_df.apply(lambda x: x['Col1'] + x['Col2'], axis=1)\nprint(\"\\nSum of Col1 and Col2:\")\ndisplay(temp_df)\n</pre> print(\"df_stats\") display(df_stats)  # Apply a function to each column print(\"Applying sum to each column:\") display(df_stats[['Col1', 'Col2']].apply(sum))  # Apply a function to each element df_applied = df_stats.applymap(lambda x: x * 2) print(\"\\nApplying lambda x: x * 2 to each element:\") display(df_applied)  # For a single column (Series) df_stats_col1_applied = df_stats['Col1'].apply(lambda x: x + 10) print(\"\\nAdding 10 to each element in Col1:\") display(df_stats_col1_applied)  # Apply function to two columns row-wise temp_df = df_stats.copy() # copyinf DataFrame temp_df['row_sums'] = temp_df.apply(lambda x: x['Col1'] + x['Col2'], axis=1) print(\"\\nSum of Col1 and Col2:\") display(temp_df) <pre>df_stats\n</pre> Col1 Col2 Col3 Category Status 0 74 65 92 A Active 1 96 70 76 B Inactive 2 63 68 83 A Active 3 35 85 75 C Active 4 56 11 42 B Inactive <pre>Applying sum to each column:\n</pre> <pre>Col1    324\nCol2    299\ndtype: int64</pre> <pre>\nApplying lambda x: x * 2 to each element:\n</pre> <pre>/var/folders/wj/pbgm2qxx6vbfvq55xm8k42jh0000gn/T/ipykernel_43554/389234560.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  df_applied = df_stats.applymap(lambda x: x * 2)\n</pre> Col1 Col2 Col3 Category Status 0 148 130 184 AA ActiveActive 1 192 140 152 BB InactiveInactive 2 126 136 166 AA ActiveActive 3 70 170 150 CC ActiveActive 4 112 22 84 BB InactiveInactive <pre>\nAdding 10 to each element in Col1:\n</pre> <pre>0     84\n1    106\n2     73\n3     45\n4     66\nName: Col1, dtype: int64</pre> <pre>\nSum of Col1 and Col2:\n</pre> Col1 Col2 Col3 Category Status row_sums 0 74 65 92 A Active 139 1 96 70 76 B Inactive 166 2 63 68 83 A Active 131 3 35 85 75 C Active 120 4 56 11 42 B Inactive 67 In\u00a0[17]: Copied! <pre>s1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\ns2 = pd.Series([4, 5, 6], index=['b', 'c', 'd'])\n\nprint(\"s1:\")\ndisplay(s1)\nprint(\"\\ns2:\")\ndisplay(s2)\n\n# Addition auto-aligns on index\ns_sum = s1 + s2\nprint(\"\\nAuto-aligned sum:\")\ndisplay(s_sum)\n\n# Fill missing with 0 while adding\ns_sum_fill = s1.add(s2, fill_value=0)\nprint(\"\\nSum with fill_value=0:\")\ndisplay(s_sum_fill)\n</pre> s1 = pd.Series([1, 2, 3], index=['a', 'b', 'c']) s2 = pd.Series([4, 5, 6], index=['b', 'c', 'd'])  print(\"s1:\") display(s1) print(\"\\ns2:\") display(s2)  # Addition auto-aligns on index s_sum = s1 + s2 print(\"\\nAuto-aligned sum:\") display(s_sum)  # Fill missing with 0 while adding s_sum_fill = s1.add(s2, fill_value=0) print(\"\\nSum with fill_value=0:\") display(s_sum_fill) <pre>s1:\n</pre> <pre>a    1\nb    2\nc    3\ndtype: int64</pre> <pre>\ns2:\n</pre> <pre>b    4\nc    5\nd    6\ndtype: int64</pre> <pre>\nAuto-aligned sum:\n</pre> <pre>a    NaN\nb    6.0\nc    8.0\nd    NaN\ndtype: float64</pre> <pre>\nSum with fill_value=0:\n</pre> <pre>a    1.0\nb    6.0\nc    8.0\nd    6.0\ndtype: float64</pre> In\u00a0[\u00a0]: Copied! <pre># NOTE: Below lines are examples. They require actual files or database connections to run successfully.\n\n# Reading a CSV\n# df_read_csv = pd.read_csv(\"my_data.csv\")\n\n# Writing to a CSV\n# df_read_csv.to_csv(\"my_output.csv\", index=False)\n\n# Reading an Excel file\n# df_excel = pd.read_excel(\"my_data.xlsx\", sheet_name=\"Sheet1\")\n\n# Writing to Excel\n# df_excel.to_excel(\"my_new_excel.xlsx\", index=False)\n\n# SQL example (requires a real engine and table)\n# from sqlalchemy import create_engine\n# engine = create_engine(\"sqlite:///my_database.db\")\n# df_from_sql = pd.read_sql(\"SELECT * FROM my_table\", engine)\n# df_from_sql.to_sql(\"my_new_table\", engine, if_exists=\"replace\", index=False)\n</pre> # NOTE: Below lines are examples. They require actual files or database connections to run successfully.  # Reading a CSV # df_read_csv = pd.read_csv(\"my_data.csv\")  # Writing to a CSV # df_read_csv.to_csv(\"my_output.csv\", index=False)  # Reading an Excel file # df_excel = pd.read_excel(\"my_data.xlsx\", sheet_name=\"Sheet1\")  # Writing to Excel # df_excel.to_excel(\"my_new_excel.xlsx\", index=False)  # SQL example (requires a real engine and table) # from sqlalchemy import create_engine # engine = create_engine(\"sqlite:///my_database.db\") # df_from_sql = pd.read_sql(\"SELECT * FROM my_table\", engine) # df_from_sql.to_sql(\"my_new_table\", engine, if_exists=\"replace\", index=False)  In\u00a0[18]: Copied! <pre>df_chain = pd.DataFrame({\n    'A': [1, 2, 3, 4],\n    'B': [5, 6, 7, 8]\n})\n\n# Example of method chaining: melt, rename, query\ndf_chain_melted = (\n    df_chain\n    .melt(var_name='Variable', value_name='Value')\n    .rename(columns={'Variable': 'var', 'Value': 'val'})\n    .query('val &gt; 3')\n)\ndisplay(df_chain_melted)\n</pre> df_chain = pd.DataFrame({     'A': [1, 2, 3, 4],     'B': [5, 6, 7, 8] })  # Example of method chaining: melt, rename, query df_chain_melted = (     df_chain     .melt(var_name='Variable', value_name='Value')     .rename(columns={'Variable': 'var', 'Value': 'val'})     .query('val &gt; 3') ) display(df_chain_melted) var val 3 A 4 4 B 5 5 B 6 6 B 7 7 B 8 In\u00a0[19]: Copied! <pre>df_sample = pd.DataFrame({'ColA': [5, 2, 9, 1, 7, 3]})\nprint(\"Original Data:\")\ndisplay(df_sample)\n\n# Random sample of 3 rows\nsampled = df_sample.sample(n=3)\nprint(\"\\nRandom sample of 3 rows:\")\ndisplay(sampled)\n\n# 2 largest values in ColA\nlargest_two = df_sample.nlargest(2, 'ColA')\nprint(\"\\n2 largest in ColA:\")\ndisplay(largest_two)\n\n# 2 smallest values in ColA\nsmallest_two = df_sample.nsmallest(2, 'ColA')\nprint(\"\\n2 smallest in ColA:\")\ndisplay(smallest_two)\n</pre> df_sample = pd.DataFrame({'ColA': [5, 2, 9, 1, 7, 3]}) print(\"Original Data:\") display(df_sample)  # Random sample of 3 rows sampled = df_sample.sample(n=3) print(\"\\nRandom sample of 3 rows:\") display(sampled)  # 2 largest values in ColA largest_two = df_sample.nlargest(2, 'ColA') print(\"\\n2 largest in ColA:\") display(largest_two)  # 2 smallest values in ColA smallest_two = df_sample.nsmallest(2, 'ColA') print(\"\\n2 smallest in ColA:\") display(smallest_two) <pre>Original Data:\n</pre> ColA 0 5 1 2 2 9 3 1 4 7 5 3 <pre>\nRandom sample of 3 rows:\n</pre> ColA 3 1 0 5 5 3 <pre>\n2 largest in ColA:\n</pre> ColA 2 9 4 7 <pre>\n2 smallest in ColA:\n</pre> ColA 3 1 1 2 In\u00a0[20]: Copied! <pre>df_dup = pd.DataFrame({\n    'X': [1, 1, 2, 2, 3],\n    'Y': [10, 10, 20, 30, 30]\n})\nprint(\"Original Data:\")\ndisplay(df_dup)\n\ndf_no_dup = df_dup.drop_duplicates()\nprint(\"\\nAfter drop_duplicates:\")\ndisplay(df_no_dup)\n</pre> df_dup = pd.DataFrame({     'X': [1, 1, 2, 2, 3],     'Y': [10, 10, 20, 30, 30] }) print(\"Original Data:\") display(df_dup)  df_no_dup = df_dup.drop_duplicates() print(\"\\nAfter drop_duplicates:\") display(df_no_dup) <pre>Original Data:\n</pre> X Y 0 1 10 1 1 10 2 2 20 3 2 30 4 3 30 <pre>\nAfter drop_duplicates:\n</pre> X Y 0 1 10 2 2 20 3 2 30 4 3 30 In\u00a0[21]: Copied! <pre>df_counts = pd.Series(['apple', 'banana', 'apple', 'orange', 'banana'])\nprint(\"Original Series:\")\ndisplay(df_counts)\n\nprint(\"\\nValue counts:\")\ndisplay(df_counts.value_counts())\nprint(\"\\nNumber of unique values:\")\ndisplay(df_counts.nunique())\n</pre> df_counts = pd.Series(['apple', 'banana', 'apple', 'orange', 'banana']) print(\"Original Series:\") display(df_counts)  print(\"\\nValue counts:\") display(df_counts.value_counts()) print(\"\\nNumber of unique values:\") display(df_counts.nunique()) <pre>Original Series:\n</pre> <pre>0     apple\n1    banana\n2     apple\n3    orange\n4    banana\ndtype: object</pre> <pre>\nValue counts:\n</pre> <pre>apple     2\nbanana    2\norange    1\nName: count, dtype: int64</pre> <pre>\nNumber of unique values:\n</pre> <pre>3</pre> In\u00a0[22]: Copied! <pre>df_filter = pd.DataFrame({\n    'width_cm': [10, 15, 20],\n    'height_cm': [5, 8, 12],\n    'depth_m': [0.5, 0.8, 1.2]\n})\n\n# Filter columns that contain '_cm'\ncm_cols = df_filter.filter(regex='_cm$')\nprint(\"Original DataFrame:\")\ndisplay(df_filter)\nprint(\"\\nColumns that end with '_cm':\")\ndisplay(cm_cols)\n</pre> df_filter = pd.DataFrame({     'width_cm': [10, 15, 20],     'height_cm': [5, 8, 12],     'depth_m': [0.5, 0.8, 1.2] })  # Filter columns that contain '_cm' cm_cols = df_filter.filter(regex='_cm$') print(\"Original DataFrame:\") display(df_filter) print(\"\\nColumns that end with '_cm':\") display(cm_cols) <pre>Original DataFrame:\n</pre> width_cm height_cm depth_m 0 10 5 0.5 1 15 8 0.8 2 20 12 1.2 <pre>\nColumns that end with '_cm':\n</pre> width_cm height_cm 0 10 5 1 15 8 2 20 12 In\u00a0[23]: Copied! <pre>df_query = pd.DataFrame({\n    'col1': [5, 10, 15],\n    'col2': [2, 4, 6]\n})\nprint(\"Original Data:\")\ndisplay(df_query)\n\n# Filter rows where col1 &gt; 5 AND col2 &lt; 6\nfiltered_query = df_query.query(\"col1 &gt; 5 and col2 &lt; 6\")\nprint(\"\\nFiltered via query:\")\ndisplay(filtered_query)\n</pre> df_query = pd.DataFrame({     'col1': [5, 10, 15],     'col2': [2, 4, 6] }) print(\"Original Data:\") display(df_query)  # Filter rows where col1 &gt; 5 AND col2 &lt; 6 filtered_query = df_query.query(\"col1 &gt; 5 and col2 &lt; 6\") print(\"\\nFiltered via query:\") display(filtered_query) <pre>Original Data:\n</pre> col1 col2 0 5 2 1 10 4 2 15 6 <pre>\nFiltered via query:\n</pre> col1 col2 1 10 4 In\u00a0[24]: Copied! <pre>df_pivot_example = pd.DataFrame({\n    'month': ['Jan', 'Jan', 'Feb', 'Feb'],\n    'category': ['A', 'B', 'A', 'B'],\n    'value': [10, 20, 30, 40]\n})\n\nprint(\"Original DataFrame:\")\ndisplay(df_pivot_example)\n\n# pivot will fail if there are duplicate entries for month &amp; category\n# pivot_table can aggregate duplicates:\ndf_pivoted_tbl = df_pivot_example.pivot_table(\n    index='month',\n    columns='category',\n    values='value',\n    aggfunc='sum'\n)\nprint(\"\\nPivot Table with aggregation:\")\ndisplay(df_pivoted_tbl)\n</pre> df_pivot_example = pd.DataFrame({     'month': ['Jan', 'Jan', 'Feb', 'Feb'],     'category': ['A', 'B', 'A', 'B'],     'value': [10, 20, 30, 40] })  print(\"Original DataFrame:\") display(df_pivot_example)  # pivot will fail if there are duplicate entries for month &amp; category # pivot_table can aggregate duplicates: df_pivoted_tbl = df_pivot_example.pivot_table(     index='month',     columns='category',     values='value',     aggfunc='sum' ) print(\"\\nPivot Table with aggregation:\") display(df_pivoted_tbl) <pre>Original DataFrame:\n</pre> month category value 0 Jan A 10 1 Jan B 20 2 Feb A 30 3 Feb B 40 <pre>\nPivot Table with aggregation:\n</pre> category A B month Feb 30 40 Jan 10 20 In\u00a0[25]: Copied! <pre>df_cum = pd.DataFrame({'vals': [100, 200, 200, 300]})\nprint(\"Original Data:\")\ndisplay(df_cum)\n\n# rank with 'dense' method\ndf_cum['rank'] = df_cum['vals'].rank(method='dense')\nprint(\"\\nRank (dense) on 'vals':\")\ndisplay(df_cum)\n\n# shift by 1\ndf_cum['shifted_vals'] = df_cum['vals'].shift(1)\nprint(\"\\nAfter shifting 'vals' by 1:\")\ndisplay(df_cum)\n\n# cumsum\ndf_cum['cumulative_sum'] = df_cum['vals'].cumsum()\nprint(\"\\nCumulative sum of 'vals':\")\ndisplay(df_cum)\n</pre> df_cum = pd.DataFrame({'vals': [100, 200, 200, 300]}) print(\"Original Data:\") display(df_cum)  # rank with 'dense' method df_cum['rank'] = df_cum['vals'].rank(method='dense') print(\"\\nRank (dense) on 'vals':\") display(df_cum)  # shift by 1 df_cum['shifted_vals'] = df_cum['vals'].shift(1) print(\"\\nAfter shifting 'vals' by 1:\") display(df_cum)  # cumsum df_cum['cumulative_sum'] = df_cum['vals'].cumsum() print(\"\\nCumulative sum of 'vals':\") display(df_cum) <pre>Original Data:\n</pre> vals 0 100 1 200 2 200 3 300 <pre>\nRank (dense) on 'vals':\n</pre> vals rank 0 100 1.0 1 200 2.0 2 200 2.0 3 300 3.0 <pre>\nAfter shifting 'vals' by 1:\n</pre> vals rank shifted_vals 0 100 1.0 NaN 1 200 2.0 100.0 2 200 2.0 200.0 3 300 3.0 200.0 <pre>\nCumulative sum of 'vals':\n</pre> vals rank shifted_vals cumulative_sum 0 100 1.0 NaN 100 1 200 2.0 100.0 300 2 200 2.0 200.0 500 3 300 3.0 200.0 800"},{"location":"Cheat-Sheets/Pandas/#pandas","title":"Pandas\u00b6","text":"<p>Pandas is a fast, flexible, and expressive open-source data analysis/manipulation library built on top of NumPy in Python. It provides data structures like Series (1D) and DataFrame (2D) for handling tabular data, time series, and more. Essential for data cleaning, transformation, and exploration.</p> <ul> <li>Official Website: https://pandas.pydata.org/</li> <li>Installation:  (https://pandas.pydata.org/docs/getting_started/install.html)<pre>pip install pandas\n</pre> </li> <li>Documentation: https://pandas.pydata.org/docs/</li> <li>GitHub: https://pandas.pydata.org/docs/</li> </ul>"},{"location":"Cheat-Sheets/Pandas/#pandas-data-structures","title":"Pandas Data Structures\u00b6","text":""},{"location":"Cheat-Sheets/Pandas/#series","title":"Series\u00b6","text":"<ul> <li>A one-dimensional labeled array capable of holding any data type.</li> <li>Created by passing a list or array of data, optionally with an index.</li> </ul>"},{"location":"Cheat-Sheets/Pandas/#dataframe","title":"DataFrame\u00b6","text":"<ul> <li>A two-dimensional labeled data structure with columns of potentially different types.</li> <li>You can think of it like a table (similar to a spreadsheet or SQL table). You can create a DataFrame from dictionaries, lists, NumPy arrays, and more.</li> </ul>"},{"location":"Cheat-Sheets/Pandas/#multiindex","title":"MultiIndex\u00b6","text":"<p>A MultiIndex (hierarchical index) allows you to store and work with higher-dimensional data in a 2D table by using multiple index levels on rows (and/or columns).</p>"},{"location":"Cheat-Sheets/Pandas/#selection-indexing","title":"Selection &amp; Indexing\u00b6","text":"<p>You can select data in a <code>DataFrame</code> or <code>Series</code> in multiple ways: by label, by position, or by boolean masking.</p>"},{"location":"Cheat-Sheets/Pandas/#reshaping-tidy-data","title":"Reshaping &amp; Tidy Data\u00b6","text":"<p>Common operations to reshape a DataFrame include <code>melt</code> (going from wide to long format), <code>pivot</code> (long to wide), and <code>concat</code>. \"Tidy\" data means each variable has its own column, each observation its own row.</p>"},{"location":"Cheat-Sheets/Pandas/#subsetting-data","title":"Subsetting Data\u00b6","text":"<p>Subsetting data means taking rows or columns that meet certain criteria. You can slice by row/column positions, select columns by name, or filter by conditions.</p>"},{"location":"Cheat-Sheets/Pandas/#summarizing-descriptive-statistics","title":"Summarizing &amp; Descriptive Statistics\u00b6","text":"<p>Pandas provides convenient methods to get summary statistics: <code>mean()</code>, <code>count()</code>, <code>describe()</code>, etc.</p>"},{"location":"Cheat-Sheets/Pandas/#handling-missing-data","title":"Handling Missing Data\u00b6","text":"<p>Pandas provides tools like <code>isnull()</code>, <code>notnull()</code>, <code>dropna()</code>, and <code>fillna()</code> to handle missing values.</p>"},{"location":"Cheat-Sheets/Pandas/#making-new-columns","title":"Making New Columns\u00b6","text":"<p>You can create or modify columns using vectorized operations, <code>assign()</code>, or direct assignment.</p>"},{"location":"Cheat-Sheets/Pandas/#group-data","title":"Group Data\u00b6","text":"<p>Grouping is done with <code>df.groupby()</code>, allowing you to compute aggregates on partitions of the data.</p>"},{"location":"Cheat-Sheets/Pandas/#windows-rolling-expanding","title":"Windows (Rolling, Expanding)\u00b6","text":"<p>Rolling windows let you apply operations over a fixed window size. Expanding windows accumulate all previous values.</p>"},{"location":"Cheat-Sheets/Pandas/#combining-merging-data","title":"Combining &amp; Merging Data\u00b6","text":"<p>You can combine multiple DataFrames using <code>pd.concat()</code>, <code>pd.merge()</code>, and different types of joins (<code>left</code>, <code>right</code>, <code>inner</code>, <code>outer</code>).</p>"},{"location":"Cheat-Sheets/Pandas/#plotting","title":"Plotting\u00b6","text":"<p>Pandas integrates well with <code>matplotlib</code> for quick plotting. You can do <code>df.plot()</code> or create specific plots like <code>df.plot.scatter()</code>, <code>df.plot.hist()</code>, etc.</p>"},{"location":"Cheat-Sheets/Pandas/#dataframe-series-info","title":"DataFrame &amp; Series Info\u00b6","text":"<p>You can retrieve metadata and info about a DataFrame or Series: shape, columns, index, dtypes, and null counts.</p>"},{"location":"Cheat-Sheets/Pandas/#applying-functions","title":"Applying Functions\u00b6","text":"<p>Use <code>df.apply()</code> to apply a function column-wise or row-wise, and <code>df.applymap()</code> for element-wise operations on an entire DataFrame. <code>Series.apply()</code> is element-wise by default.</p>"},{"location":"Cheat-Sheets/Pandas/#data-alignment","title":"Data Alignment\u00b6","text":"<p>When performing operations on two Series or DataFrames with different indexes, pandas aligns the data based on labels by default. Missing labels become <code>NaN</code>. You can use fill parameters to handle this.</p>"},{"location":"Cheat-Sheets/Pandas/#io-reading-writing-data","title":"I/O: Reading &amp; Writing Data\u00b6","text":"<p>You can read data from various formats (CSV, Excel, SQL, etc.) and write DataFrames out similarly.</p>"},{"location":"Cheat-Sheets/Pandas/#method-chaining","title":"Method Chaining\u00b6","text":"<p>Method chaining involves writing multiple pandas operations in a single expression by \"chaining\" them with dots (<code>.</code>). This often improves readability and can reduce the need for intermediate variables.</p>"},{"location":"Cheat-Sheets/Pandas/#sampling-nlargest-and-nsmallest","title":"Sampling, <code>nlargest</code>, and <code>nsmallest</code>\u00b6","text":"<ul> <li>df.sample(n=... or frac=...): Randomly sample a certain number or fraction of rows.</li> <li>df.nlargest(n, 'column'): Select the top n rows based on a column value, sorted descending.</li> <li>df.nsmallest(n, 'column'): Select the bottom n rows based on a column value, sorted ascending.</li> </ul>"},{"location":"Cheat-Sheets/Pandas/#drop-duplicates","title":"Drop Duplicates\u00b6","text":"<ul> <li>df.drop_duplicates(): Removes duplicate rows (or specified subset of columns).</li> <li>By default, it keeps the first occurrence and drops the rest. You can change this behavior with <code>keep='last'</code> or <code>keep=False</code>.</li> </ul>"},{"location":"Cheat-Sheets/Pandas/#value_counts-and-counting-uniques","title":"<code>value_counts</code> and Counting Uniques\u00b6","text":"<ul> <li>Series.value_counts(): Shows unique values in a Series and their frequency counts.</li> <li>Series.nunique(): Counts the number of unique values in the Series.</li> </ul>"},{"location":"Cheat-Sheets/Pandas/#regex-filtering","title":"Regex Filtering\u00b6","text":"<p>df.filter(regex=...): Allows selecting columns that match a certain regular expression pattern. Useful when you have many columns sharing naming patterns.</p>"},{"location":"Cheat-Sheets/Pandas/#using-dfquery","title":"Using <code>df.query(...)</code>\u00b6","text":"<p><code>df.query(expr)</code> uses a string expression to filter rows in a DataFrame. Column names must be valid Python identifiers (letters, numbers, underscores, no spaces) or else be backticked (e.g., `my column`).</p>"},{"location":"Cheat-Sheets/Pandas/#pivot-vs-pivot_table","title":"pivot vs pivot_table\u00b6","text":"<ul> <li>pivot: Reshapes a DataFrame without performing an aggregation. It requires that each index/column pair is unique.</li> <li>pivot_table: Allows grouping and aggregation when you have duplicate indices/columns.</li> </ul>"},{"location":"Cheat-Sheets/Pandas/#shift-rank-and-cumulative-operations","title":"shift, rank, and Cumulative Operations\u00b6","text":"<ul> <li>shift: Moves index by specified periods, introducing NaNs for missing positions.</li> <li>rank: Assigns numeric rank to each entry in a Series (with optional tie-breaking methods).</li> <li>cumsum, cummax, cummin, cumprod: Cumulative sums, maxima, minima, and products over rows or columns.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/","title":"PySpark Cheat Sheet","text":"<ul> <li>PySpark Cheat Sheet<ul> <li>Getting Started<ul> <li>Installation</li> <li>SparkSession</li> <li>SparkContext</li> <li>Stopping SparkSession/SparkContext</li> </ul> </li> <li>Data Loading<ul> <li>Loading from Text Files</li> <li>Loading from CSV Files</li> <li>Loading from Parquet Files</li> <li>Loading from ORC Files</li> <li>Loading from Avro Files</li> <li>Loading from JDBC</li> <li>Loading from Delta Lake</li> </ul> </li> <li>DataFrames<ul> <li>Creating DataFrames</li> <li>DataFrame Operations</li> <li>Applying Python Functions (UDFs)</li> <li>Applying Pandas UDFs (Vectorized UDFs)</li> <li>GroupBy Operations</li> <li>SQL Queries</li> </ul> </li> <li>RDDs (Resilient Distributed Datasets)<ul> <li>Creating RDDs</li> <li>RDD Transformations</li> <li>RDD Actions</li> <li>Pair RDDs</li> </ul> </li> <li>Writing Data<ul> <li>Writing DataFrames</li> <li>Writing RDDs</li> </ul> </li> <li>Spark SQL<ul> <li>Creating Tables</li> <li>Inserting Data</li> <li>Selecting Data</li> <li>Filtering Data</li> <li>Aggregating Data</li> <li>Joining Tables</li> <li>Window Functions in SQL</li> </ul> </li> <li>Spark MLlib<ul> <li>Data Preparation</li> <li>Feature Extraction</li> <li>Feature Scaling</li> <li>Feature Selection</li> <li>Classification</li> <li>Regression</li> <li>Clustering</li> <li>Recommendation</li> <li>Evaluation</li> <li>Cross-Validation</li> <li>Pipelines</li> <li>Model Persistence</li> </ul> </li> <li>Structured Streaming<ul> <li>Reading Data</li> <li>Processing Data</li> <li>Writing Data</li> <li>Available Output Modes</li> <li>Available Sinks</li> </ul> </li> <li>Performance Tuning<ul> <li>Data Partitioning</li> <li>Caching</li> <li>Broadcast Variables</li> <li>Accumulators</li> <li>Memory Management</li> <li>Shuffle Optimization</li> <li>Data Serialization</li> <li>Garbage Collection</li> </ul> </li> <li>Common Issues and Debugging</li> <li>Spark Configuration<ul> <li>SparkConf Options</li> </ul> </li> <li>Tips and Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of the PySpark API, covering essential concepts, code snippets, and best practices for efficient data processing and machine learning with Apache Spark. It aims to be a one-stop reference for common tasks.</p>"},{"location":"Cheat-Sheets/PySpark/#getting-started","title":"Getting Started","text":""},{"location":"Cheat-Sheets/PySpark/#installation","title":"Installation","text":"<pre><code>pip install pyspark\n</code></pre> <p>Consider using a virtual environment:</p> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Linux/macOS\nvenv\\Scripts\\activate  # On Windows\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#sparksession","title":"SparkSession","text":"<pre><code>from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n    .appName(\"MyPySparkApp\") \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()\n\n# To use an existing SparkContext:\n# spark = SparkSession(sparkContext=sc)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#sparkcontext","title":"SparkContext","text":"<pre><code>from pyspark import SparkContext, SparkConf\n\nconf = SparkConf().setAppName(\"MyPySparkApp\").setMaster(\"local[*]\")\nsc = SparkContext(conf=conf)\n\n# To use SparkSession:\n# from pyspark.sql import SparkSession\n# spark = SparkSession(sparkContext=sc)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#stopping-sparksessionsparkcontext","title":"Stopping SparkSession/SparkContext","text":"<pre><code>spark.stop()  # For SparkSession\nsc.stop()     # For SparkContext\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#data-loading","title":"Data Loading","text":""},{"location":"Cheat-Sheets/PySpark/#loading-from-text-files","title":"Loading from Text Files","text":"<pre><code># SparkContext\nlines = sc.textFile(\"path/to/my/textfile.txt\")\n\n# SparkSession\ndf = spark.read.text(\"path/to/my/textfile.txt\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#loading-from-csv-files","title":"Loading from CSV Files","text":"<pre><code># SparkSession\ndf = spark.read.csv(\"path/to/my/csvfile.csv\", header=True, inferSchema=True)```\n\n### Loading from JSON Files\n\n```python\n# SparkSession\ndf = spark.read.json(\"path/to/my/jsonfile.json\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#loading-from-parquet-files","title":"Loading from Parquet Files","text":"<pre><code># SparkSession\ndf = spark.read.parquet(\"path/to/my/parquetfile.parquet\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#loading-from-orc-files","title":"Loading from ORC Files","text":"<pre><code># SparkSession\ndf = spark.read.orc(\"path/to/my/orcfile.orc\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#loading-from-avro-files","title":"Loading from Avro Files","text":"<pre><code># SparkSession\ndf = spark.read.format(\"avro\").load(\"path/to/my/avrofile.avro\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#loading-from-jdbc","title":"Loading from JDBC","text":"<pre><code># SparkSession\ndf = spark.read.format(\"jdbc\") \\\n    .option(\"url\", \"jdbc:postgresql://localhost:5432/mydatabase\") \\\n    .option(\"dbtable\", \"mytable\") \\\n    .option(\"user\", \"myuser\") \\\n    .option(\"password\", \"mypassword\") \\\n    .load()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#loading-from-delta-lake","title":"Loading from Delta Lake","text":"<pre><code>from delta.tables import DeltaTable\n\ndeltaTable = DeltaTable.forPath(spark, \"path/to/my/delta_table\")\ndf = deltaTable.toDF()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#dataframes","title":"DataFrames","text":""},{"location":"Cheat-Sheets/PySpark/#creating-dataframes","title":"Creating DataFrames","text":"<p>From RDD:</p> <pre><code>from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"Example\").getOrCreate()\ndata = [(\"Alice\", 30), (\"Bob\", 25)]\nrdd = spark.sparkContext.parallelize(data)\ndf = spark.createDataFrame(rdd, schema=[\"Name\", \"Age\"])\n</code></pre> <p>From List of Dictionaries:</p> <pre><code>from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"Example\").getOrCreate()\ndata = [{\"Name\": \"Alice\", \"Age\": 30}, {\"Name\": \"Bob\", \"Age\": 25}]\ndf = spark.createDataFrame(data)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#dataframe-operations","title":"DataFrame Operations","text":"<ul> <li><code>df.show()</code>: Displays the DataFrame.</li> <li><code>df.printSchema()</code>: Prints the schema of the DataFrame.</li> <li><code>df.columns</code>: Returns a list of column names.</li> <li><code>df.count()</code>: Returns the number of rows.</li> <li><code>df.describe()</code>: Computes summary statistics.</li> <li><code>df.summary(\"count\", \"mean\", \"stddev\", \"min\", \"max\", \"25%\", \"50%\", \"75%\")</code>: Computes descriptive statistics.</li> <li><code>df.select(\"column1\", \"column2\")</code>: Selects specific columns.</li> <li><code>df.withColumn(\"new_column\", df[\"column1\"] + df[\"column2\"])</code>: Adds a new column.</li> <li><code>df.withColumnRenamed(\"old_name\", \"new_name\")</code>: Renames a column.</li> <li><code>df.drop(\"column1\")</code>: Drops a column.</li> <li><code>df.filter(df[\"age\"] &gt; 25)</code>: Filters rows based on a condition.</li> <li><code>df.where(df[\"age\"] &gt; 25)</code>: Another way to filter rows.</li> <li><code>df.groupBy(\"column1\").count()</code>: Groups data and counts occurrences.</li> <li><code>df.orderBy(\"column1\", ascending=False)</code>: Orders data by a column.</li> <li><code>df.sort(\"column1\", ascending=False)</code>: Another way to order data.</li> <li><code>df.limit(10)</code>: Limits the number of rows.</li> <li><code>df.distinct()</code>: Removes duplicate rows.</li> <li><code>df.union(other_df)</code>: Unions two DataFrames (requires same schema).</li> <li><code>df.unionByName(other_df)</code>: Unions two DataFrames by column name.</li> <li><code>df.intersect(other_df)</code>: Returns the intersection of two DataFrames.</li> <li><code>df.subtract(other_df)</code>: Returns the rows in <code>df</code> but not in <code>other_df</code>.</li> <li><code>df.join(other_df, df[\"key\"] == other_df[\"key\"], how=\"inner\")</code>: Joins two DataFrames.</li> <li><code>df.crossJoin(other_df)</code>: Performs a Cartesian product join.</li> <li><code>df.agg({\"age\": \"avg\"})</code>: Performs aggregation functions (avg, min, max, sum, etc.).</li> <li><code>df.rollup(\"column1\", \"column2\")</code>: Creates rollup aggregates.</li> <li><code>df.cube(\"column1\", \"column2\")</code>: Creates cube aggregates.</li> <li><code>df.pivot(\"column1\", values=[\"value1\", \"value2\"])</code>: Pivots a DataFrame.</li> <li><code>df.sample(withReplacement=False, fraction=0.5, seed=None)</code>: Samples a fraction of rows.</li> <li><code>df.randomSplit([0.8, 0.2], seed=None)</code>: Splits the DataFrame into multiple DataFrames randomly.</li> <li><code>df.cache()</code>: Caches the DataFrame in memory.</li> <li><code>df.persist(StorageLevel.MEMORY_AND_DISK)</code>: Persists the DataFrame with a specific storage level.</li> <li><code>df.unpersist()</code>: Removes the DataFrame from the cache.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#applying-python-functions-udfs","title":"Applying Python Functions (UDFs)","text":"<pre><code>from pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\n\ndef to_upper(s):\n    return s.upper()\n\nto_upper_udf = udf(to_upper, StringType())\n\ndf = df.withColumn(\"upper_name\", to_upper_udf(df[\"Name\"]))\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#applying-pandas-udfs-vectorized-udfs","title":"Applying Pandas UDFs (Vectorized UDFs)","text":"<pre><code>from pyspark.sql.functions import pandas_udf\nfrom pyspark.sql.types import StringType\nimport pandas as pd\n\n@pandas_udf(StringType())\ndef to_upper_pandas(series: pd.Series) -&gt; pd.Series:\n    return series.str.upper()\n\ndf = df.withColumn(\"upper_name\", to_upper_pandas(df[\"Name\"]))\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#groupby-operations","title":"GroupBy Operations","text":"<pre><code>from pyspark.sql.functions import avg, max, min, sum, count\n\n# Group by a single column\ngrouped_df = df.groupBy(\"Department\")\ngrouped_df.count().show()\n\n# Group by multiple columns\ngrouped_df = df.groupBy(\"Department\", \"City\")\ngrouped_df.agg(avg(\"Salary\"), sum(\"Bonus\")).show()\n\n# Applying aggregation functions\nfrom pyspark.sql.functions import col\ndf.groupBy(\"Department\") \\\n  .agg(avg(col(\"Salary\")).alias(\"Average Salary\"),\n       sum(col(\"Bonus\")).alias(\"Total Bonus\")) \\\n  .show()\n\n# Window functions\nfrom pyspark.sql import Window\nfrom pyspark.sql.functions import rank, dense_rank, row_number\n\nwindowSpec  = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\ndf.withColumn(\"rank\",rank().over(windowSpec)).show()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#sql-queries","title":"SQL Queries","text":"<p>Register DataFrame as a temporary view:</p> <pre><code>df.createOrReplaceTempView(\"my_table\")\n</code></pre> <p>Run SQL queries:</p> <pre><code>result_df = spark.sql(\"SELECT Name, Age FROM my_table WHERE Age &gt; 25\")\nresult_df.show()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#rdds-resilient-distributed-datasets","title":"RDDs (Resilient Distributed Datasets)","text":""},{"location":"Cheat-Sheets/PySpark/#creating-rdds","title":"Creating RDDs","text":"<p>From a List:</p> <pre><code>data = [1, 2, 3, 4, 5]\nrdd = sc.parallelize(data)\n</code></pre> <p>From a Text File:</p> <pre><code>rdd = sc.textFile(\"path/to/my/textfile.txt\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#rdd-transformations","title":"RDD Transformations","text":"<ul> <li><code>rdd.map(lambda x: x * 2)</code>: Applies a function to each element.</li> <li><code>rdd.filter(lambda x: x &gt; 2)</code>: Filters elements based on a condition.</li> <li><code>rdd.flatMap(lambda x: x.split())</code>: Flattens and maps elements.</li> <li><code>rdd.distinct()</code>: Removes duplicate elements.</li> <li><code>rdd.sample(withReplacement=False, fraction=0.5)</code>: Samples elements.</li> <li><code>rdd.union(other_rdd)</code>: Unions two RDDs.</li> <li><code>rdd.intersection(other_rdd)</code>: Intersects two RDDs.</li> <li><code>rdd.subtract(other_rdd)</code>: Subtracts one RDD from another.</li> <li><code>rdd.cartesian(other_rdd)</code>: Computes the Cartesian product of two RDDs.</li> <li><code>rdd.sortBy(lambda x: x, ascending=False)</code>: Sorts elements.</li> <li><code>rdd.repartition(numPartitions=4)</code>: Changes the number of partitions.</li> <li><code>rdd.coalesce(numPartitions=1)</code>: Decreases the number of partitions.</li> <li><code>rdd.pipe(command)</code>: Pipes each element to a shell command.</li> <li><code>rdd.zip(other_rdd)</code>: Zips two RDDs together.</li> <li><code>rdd.zipWithIndex()</code>: Zips the RDD with its element indices.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#rdd-actions","title":"RDD Actions","text":"<ul> <li><code>rdd.collect()</code>: Returns all elements as a list.</li> <li><code>rdd.count()</code>: Returns the number of elements.</li> <li><code>rdd.first()</code>: Returns the first element.</li> <li><code>rdd.take(3)</code>: Returns the first N elements.</li> <li><code>rdd.top(3)</code>: Returns the top N elements.</li> <li><code>rdd.reduce(lambda x, y: x + y)</code>: Reduces elements using a function.</li> <li><code>rdd.fold(zeroValue, op)</code>: Folds elements using a function and a zero value.</li> <li><code>rdd.aggregate(zeroValue, seqOp, combOp)</code>: Aggregates elements using sequence and combination functions.</li> <li><code>rdd.foreach(lambda x: print(x))</code>: Applies a function to each element.</li> <li><code>rdd.saveAsTextFile(\"path/to/output\")</code>: Saves the RDD as a text file.</li> <li><code>rdd.saveAsPickleFile(\"path/to/output\")</code>: Saves the RDD as a serialized Python object file.</li> <li><code>rdd.countByKey()</code>: Returns the count of each key (for pair RDDs).</li> <li><code>rdd.collectAsMap()</code>: Returns the elements as a dictionary (for pair RDDs).</li> <li><code>rdd.lookup(key)</code>: Returns the values for a given key (for pair RDDs).</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#pair-rdds","title":"Pair RDDs","text":"<ul> <li><code>rdd.map(lambda x: (x, 1))</code>: Creates a pair RDD.</li> <li><code>rdd.reduceByKey(lambda x, y: x + y)</code>: Reduces values for each key.</li> <li><code>rdd.groupByKey()</code>: Groups values for each key.</li> <li><code>rdd.aggregateByKey(zeroValue, seqFunc, combFunc)</code>: Aggregates values for each key.</li> <li><code>rdd.foldByKey(zeroValue, func)</code>: Folds values for each key.</li> <li><code>rdd.combineByKey(createCombiner, mergeValue, mergeCombiners)</code>: Generic combine function for each key.</li> <li><code>rdd.sortByKey()</code>: Sorts by key.</li> <li><code>rdd.join(other_rdd)</code>: Joins two pair RDDs.</li> <li><code>rdd.leftOuterJoin(other_rdd)</code>: Performs a left outer join.</li> <li><code>rdd.rightOuterJoin(other_rdd)</code>: Performs a right outer join.</li> <li><code>rdd.fullOuterJoin(other_rdd)</code>: Performs a full outer join.</li> <li><code>rdd.cogroup(other_rdd)</code>: Groups values for each key in multiple RDDs.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#writing-data","title":"Writing Data","text":""},{"location":"Cheat-Sheets/PySpark/#writing-dataframes","title":"Writing DataFrames","text":"<p>To CSV:</p> <pre><code>df.write.csv(\"path/to/output/csv\", header=True, mode=\"overwrite\")\n</code></pre> <p>To JSON:</p> <pre><code>df.write.json(\"path/to/output/json\", mode=\"overwrite\")\n</code></pre> <p>To Parquet:</p> <pre><code>df.write.parquet(\"path/to/output/parquet\", mode=\"overwrite\")\n</code></pre> <p>To ORC:</p> <pre><code>df.write.orc(\"path/to/output/orc\", mode=\"overwrite\")\n</code></pre> <p>To Avro:</p> <pre><code>df.write.format(\"avro\").save(\"path/to/output/avro\", mode=\"overwrite\")\n</code></pre> <p>To JDBC:</p> <pre><code>df.write.format(\"jdbc\") \\\n    .option(\"url\", \"jdbc:postgresql://localhost:5432/mydatabase\") \\\n    .option(\"dbtable\", \"mytable\") \\\n    .option(\"user\", \"myuser\") \\\n    .option(\"password\", \"mypassword\") \\\n    .mode(\"overwrite\") \\\n    .save()\n</code></pre> <p>To Delta Lake:</p> <pre><code>df.write.format(\"delta\").mode(\"overwrite\").save(\"path/to/delta_table\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#writing-rdds","title":"Writing RDDs","text":"<pre><code>rdd.saveAsTextFile(\"path/to/output\")\nrdd.saveAsPickleFile(\"path/to/output\")\nrdd.saveAsSequenceFile(\"path/to/output\") # For Hadoop SequenceFile format\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#spark-sql","title":"Spark SQL","text":""},{"location":"Cheat-Sheets/PySpark/#creating-tables","title":"Creating Tables","text":"<p>From DataFrame:</p> <pre><code>df.write.saveAsTable(\"my_table\")\n</code></pre> <p>Using SQL:</p> <pre><code>spark.sql(\"CREATE TABLE my_table (name STRING, age INT) USING parquet\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#inserting-data","title":"Inserting Data","text":"<p>From DataFrame:</p> <pre><code>df.write.insertInto(\"my_table\")\n</code></pre> <p>Using SQL:</p> <pre><code>spark.sql(\"INSERT INTO my_table VALUES ('Alice', 30)\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#selecting-data","title":"Selecting Data","text":"<pre><code>spark.sql(\"SELECT * FROM my_table\").show()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#filtering-data","title":"Filtering Data","text":"<pre><code>spark.sql(\"SELECT * FROM my_table WHERE age &gt; 25\").show()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#aggregating-data","title":"Aggregating Data","text":"<pre><code>spark.sql(\"SELECT name, AVG(age) FROM my_table GROUP BY name\").show()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#joining-tables","title":"Joining Tables","text":"<pre><code>spark.sql(\"SELECT * FROM table1 JOIN table2 ON table1.key = table2.key\").show()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#window-functions-in-sql","title":"Window Functions in SQL","text":"<pre><code>spark.sql(\"\"\"\nSELECT\n    name,\n    age,\n    RANK() OVER (ORDER BY age DESC) as age_rank\nFROM\n    my_table\n\"\"\").show()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#spark-mllib","title":"Spark MLlib","text":""},{"location":"Cheat-Sheets/PySpark/#data-preparation","title":"Data Preparation","text":"<pre><code>from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n\n# StringIndexer\nindexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\nindexed_df = indexer.fit(df).transform(df)\n\n# VectorAssembler\nassembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\"], outputCol=\"features\")\noutput_df = assembler.transform(indexed_df)\n\n# StandardScaler\nscaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n                        withStd=True, withMean=True)\nscalerModel = scaler.fit(output_df)\nscaled_df = scalerModel.transform(output_df)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#feature-extraction","title":"Feature Extraction","text":"<ul> <li><code>Tokenizer</code>: Splits strings into words.</li> <li><code>StopWordsRemover</code>: Removes stop words.</li> <li><code>CountVectorizer</code>: Converts text documents to vectors of term counts.</li> <li><code>IDF</code>: Computes Inverse Document Frequency.</li> <li><code>Word2Vec</code>: Learns vector representations of words.</li> <li><code>NGram</code>: Generates n-grams from input sequences.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#feature-scaling","title":"Feature Scaling","text":"<ul> <li><code>StandardScaler</code>: Standardizes features by removing the mean and scaling to unit variance.</li> <li><code>MinMaxScaler</code>: Transforms features by scaling each feature to a given range.</li> <li><code>MaxAbsScaler</code>: Scales each feature to the [-1, 1] range by dividing through the largest maximum absolute value in each feature.</li> <li><code>Normalizer</code>: Normalizes each sample to unit norm.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#feature-selection","title":"Feature Selection","text":"<ul> <li><code>VectorSlicer</code>: Creates a new feature vector by selecting a subset of features from an existing vector.</li> <li><code>RFormula</code>: Implements the R formula string syntax for selecting features.</li> <li><code>PCA</code>: Reduces the dimensionality of feature vectors using Principal Component Analysis.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#classification","title":"Classification","text":"<p>Logistic Regression:</p> <pre><code>from pyspark.ml.classification import LogisticRegression\n\nlr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\nmodel = lr.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre> <p>Decision Tree:</p> <pre><code>from pyspark.ml.classification import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\nmodel = dt.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre> <p>Random Forest:</p> <pre><code>from pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\nmodel = rf.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre> <p>Gradient-Boosted Trees (GBT):</p> <pre><code>from pyspark.ml.classification import GBTClassifier\n\ngbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\")\nmodel = gbt.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre> <p>Multilayer Perceptron Classifier (MLPC):</p> <pre><code>from pyspark.ml.classification import MultilayerPerceptronClassifier\n\nlayers = [4, 5, 4, 3] # Input size, hidden layers, output size\nmlp = MultilayerPerceptronClassifier(layers=layers, featuresCol='features', labelCol='label')\nmodel = mlp.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#regression","title":"Regression","text":"<p>Linear Regression:</p> <pre><code>from pyspark.ml.regression import LinearRegression\n\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\nmodel = lr.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre> <p>Decision Tree Regression:</p> <pre><code>from pyspark.ml.regression import DecisionTreeRegressor\n\ndt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\")\nmodel = dt.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre> <p>Random Forest Regression:</p> <pre><code>from pyspark.ml.regression import RandomForestRegressor\n\nrf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")\nmodel = rf.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre> <p>Gradient-Boosted Trees (GBT) Regression:</p> <pre><code>from pyspark.ml.regression import GBTRegressor\n\ngbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\")\nmodel = gbt.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#clustering","title":"Clustering","text":"<p>K-Means:</p> <pre><code>from pyspark.ml.clustering import KMeans\n\nkmeans = KMeans(k=3, featuresCol=\"features\")\nmodel = kmeans.fit(data)\npredictions = model.transform(data)\n</code></pre> <p>Gaussian Mixture Model (GMM):</p> <pre><code>from pyspark.ml.clustering import GaussianMixture\n\ngmm = GaussianMixture().setK(2).setSeed(538009335)\nmodel = gmm.fit(data)\npredictions = model.transform(data)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#recommendation","title":"Recommendation","text":"<p>Alternating Least Squares (ALS):</p> <pre><code>from pyspark.ml.recommendation import ALS\n\nals = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\nmodel = als.fit(training_data)\npredictions = model.transform(test_data)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#evaluation","title":"Evaluation","text":"<p>Classification Metrics:</p> <pre><code>from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Accuracy = %s\" % (accuracy))\n</code></pre> <p>Regression Metrics:</p> <pre><code>from pyspark.ml.evaluation import RegressionEvaluator\n\nevaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions)\nprint(\"RMSE = %s\" % (rmse))\n</code></pre> <p>Clustering Metrics:</p> <pre><code>from pyspark.ml.evaluation import ClusteringEvaluator\n\nevaluator = ClusteringEvaluator(featuresCol=\"features\")\nsilhouette = evaluator.evaluate(predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#cross-validation","title":"Cross-Validation","text":"<pre><code>from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(lr.regParam, [0.1, 0.01]) \\\n    .addGrid(lr.fitIntercept, [False, True]) \\\n    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n    .build()\n\ncrossval = CrossValidator(estimator=lr,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=3)\n\ncvModel = crossval.fit(training_data)\npredictions = cvModel.transform(test_data)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#pipelines","title":"Pipelines","text":"<pre><code>from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\n\n# Define stages\nindexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\nassembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\"], outputCol=\"features\")\nlr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n\n# Create pipeline\npipeline = Pipeline(stages=[indexer, assembler, lr])\n\n# Fit the pipeline\nmodel = pipeline.fit(training_data)\n\n# Transform the data\npredictions = model.transform(test_data)\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#model-persistence","title":"Model Persistence","text":"<pre><code>model.save(\"path/to/my/model\")\nloaded_model = PipelineModel.load(\"path/to/my/model\")\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#structured-streaming","title":"Structured Streaming","text":""},{"location":"Cheat-Sheets/PySpark/#reading-data","title":"Reading Data","text":"<pre><code>df = spark.readStream.format(\"socket\") \\\n    .option(\"host\", \"localhost\") \\\n    .option(\"port\", 9999) \\\n    .load()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#processing-data","title":"Processing Data","text":"<pre><code>from pyspark.sql.functions import explode, split\n\nwords = df.select(explode(split(df.value, \" \")).alias(\"word\"))\nwordCounts = words.groupBy(\"word\").count()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#writing-data_1","title":"Writing Data","text":"<pre><code>query = wordCounts.writeStream \\\n    .outputMode(\"complete\") \\\n    .format(\"console\") \\\n    .start()\n\nquery.awaitTermination()\n</code></pre>"},{"location":"Cheat-Sheets/PySpark/#available-output-modes","title":"Available Output Modes","text":"<ul> <li><code>\"append\"</code>: Only new rows are written to the sink.</li> <li><code>\"complete\"</code>: All rows are written to the sink every time there are updates.</li> <li><code>\"update\"</code>: Only updated rows are written to the sink.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#available-sinks","title":"Available Sinks","text":"<ul> <li><code>\"console\"</code>: Prints to the console.</li> <li><code>\"memory\"</code>: Stores the output in memory.</li> <li><code>\"parquet\"</code>, <code>\"csv\"</code>, <code>\"json\"</code>, <code>\"jdbc\"</code>: Writes to files or databases.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#performance-tuning","title":"Performance Tuning","text":""},{"location":"Cheat-Sheets/PySpark/#data-partitioning","title":"Data Partitioning","text":"<ul> <li>Use <code>repartition()</code> or <code>coalesce()</code> to control the number of partitions.</li> <li>Partition data based on frequently used keys.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#caching","title":"Caching","text":"<ul> <li>Use <code>cache()</code> or <code>persist()</code> to store intermediate results in memory or on disk.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#broadcast-variables","title":"Broadcast Variables","text":"<ul> <li>Use <code>sc.broadcast()</code> to broadcast small datasets to all executors.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#accumulators","title":"Accumulators","text":"<ul> <li>Use <code>sc.accumulator()</code> to create global counters.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#memory-management","title":"Memory Management","text":"<ul> <li>Tune <code>spark.executor.memory</code> and <code>spark.driver.memory</code> to allocate sufficient memory.</li> <li>Avoid creating large objects in the driver.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#shuffle-optimization","title":"Shuffle Optimization","text":"<ul> <li>Tune <code>spark.sql.shuffle.partitions</code> to control the number of shuffle partitions.</li> <li>Use <code>mapPartitions</code> to perform operations on each partition.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#data-serialization","title":"Data Serialization","text":"<ul> <li>Use Kryo serialization for better performance.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#garbage-collection","title":"Garbage Collection","text":"<ul> <li>Tune garbage collection settings to reduce GC overhead.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#common-issues-and-debugging","title":"Common Issues and Debugging","text":"<ul> <li>Out of Memory Errors: Increase executor memory or reduce the amount of data being processed.</li> <li>Slow Performance: Analyze the Spark UI to identify bottlenecks.</li> <li>Serialization Errors: Ensure that all objects being serialized are serializable.</li> <li>Data Skew: Partition data to distribute it evenly across executors.</li> <li>Driver OOM: Increase driver memory or reduce the amount of data being collected to the driver.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#spark-configuration","title":"Spark Configuration","text":""},{"location":"Cheat-Sheets/PySpark/#sparkconf-options","title":"SparkConf Options","text":"<ul> <li><code>spark.app.name</code>: Application name.</li> <li><code>spark.master</code>: Spark master URL.</li> <li><code>spark.executor.memory</code>: Memory per executor.</li> <li><code>spark.driver.memory</code>: Memory for the driver process.</li> <li><code>spark.executor.cores</code>: Number of cores per executor.</li> <li><code>spark.default.parallelism</code>: Default number of partitions.</li> <li><code>spark.sql.shuffle.partitions</code>: Number of partitions to use when shuffling data for joins or aggregations.</li> <li><code>spark.serializer</code>: Serializer class name (e.g., <code>org.apache.spark.serializer.KryoSerializer</code>).</li> <li><code>spark.driver.maxResultSize</code>: Maximum size of the result that the driver can collect.</li> <li><code>spark.kryoserializer.buffer.max</code>: Maximum buffer size for Kryo serialization.</li> <li><code>spark.sql.adaptive.enabled</code>: Enables adaptive query execution.</li> <li><code>spark.sql.adaptive.coalescePartitions.enabled</code>: Enables adaptive partition coalescing.</li> </ul>"},{"location":"Cheat-Sheets/PySpark/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ul> <li>Use virtual environments to isolate project dependencies.</li> <li>Use meaningful names for variables and functions.</li> <li>Follow the DRY (Don't Repeat Yourself) principle.</li> <li>Write unit tests to ensure code quality.</li> <li>Use a consistent coding style.</li> <li>Document your code.</li> <li>Use a version control system (e.g., Git).</li> <li>Use appropriate data types for your data.</li> <li>Optimize your Spark configuration for your workload.</li> <li>Use caching to improve performance.</li> <li>Use partitioning to distribute data evenly.</li> <li>Avoid shuffling data unnecessarily.</li> <li>Use broadcast variables for small datasets.</li> <li>Use accumulators for global counters.</li> <li>Use the Spark UI to monitor your application.</li> <li>Use a logging framework to log events and errors.</li> <li>Use a security framework to protect your data.</li> <li>Use a resource manager (e.g., YARN, Mesos, Kubernetes) to manage your cluster.</li> <li>Use a deployment tool to deploy your application to production.</li> <li>Monitor your application for performance issues.</li> <li>Use a CDN (Content Delivery Network) for static files.</li> <li>Optimize database queries.</li> <li>Use asynchronous tasks for long-running operations.</li> <li>Implement proper logging and error handling.</li> <li>Regularly update PySpark and its dependencies.</li> <li>Use a security scanner to identify potential vulnerabilities.</li> <li>Follow security best practices.</li> <li>Use a reverse proxy like Nginx or Apache in front of your Spark application.</li> <li>Use a load balancer for high availability.</li> <li>Automate deployments using tools like Fabric or Ansible.</li> <li>Use a monitoring tool like Prometheus or Grafana.</li> <li>Implement health checks for your application.</li> <li>Use a CDN for static assets.</li> <li>Cache frequently accessed data.</li> <li>Use a database connection pool.</li> <li>Optimize your database queries.</li> <li>Use a task queue for long-running tasks.</li> <li>Use a background worker for asynchronous tasks.</li> <li>Use a message queue for inter-process communication.</li> <li>Use a service discovery tool for microservices.</li> <li>Use a containerization tool like Docker.</li> <li>Use an orchestration tool like Kubernetes.</li> <li>Use Delta Lake for reliable data lakes.</li> <li>Use Apache Arrow for faster data transfer between Python and Spark.</li> <li>Use vectorized UDFs for better performance.</li> <li>Use adaptive query execution (AQE) to optimize queries at runtime.</li> <li>Use cost-based optimization (CBO) to choose the best query plan.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/","title":"PyTorch Cheat Sheet","text":"<ul> <li>PyTorch Cheat Sheet<ul> <li>Getting Started<ul> <li>Installation</li> <li>Importing PyTorch</li> </ul> </li> <li>Tensors<ul> <li>Creating Tensors</li> <li>Tensor Attributes</li> <li>Tensor Operations</li> <li>Data Types</li> <li>Device Management</li> <li>Moving Data Between CPU and GPU</li> </ul> </li> <li>Neural Networks<ul> <li>Defining a Model</li> <li>Layers</li> <li>Activation Functions</li> <li>Loss Functions</li> <li>Optimizers</li> <li>Optimizer Configuration</li> <li>Learning Rate Schedulers</li> <li>Metrics</li> </ul> </li> <li>Training<ul> <li>Training Loop</li> <li>DataLoaders</li> <li>Transforms</li> <li>Mixed Precision Training</li> </ul> </li> <li>Evaluation</li> <li>Prediction</li> <li>Saving and Loading Models<ul> <li>Save the Entire Model</li> <li>Load the Entire Model</li> <li>Save Model State Dictionary</li> <li>Load Model State Dictionary</li> </ul> </li> <li>CUDA (GPU Support)<ul> <li>Check CUDA Availability</li> <li>Set Device</li> <li>Move Tensors to GPU</li> <li>CUDA Best Practices</li> </ul> </li> <li>Distributed Training<ul> <li>DataParallel</li> <li>DistributedDataParallel (DDP)</li> <li>Distributed Data Loading</li> </ul> </li> <li>Autograd<ul> <li>Tracking Gradients</li> <li>Disabling Gradient Tracking</li> <li>Detaching Tensors</li> <li>Custom Autograd Functions</li> </ul> </li> <li>Data Augmentation</li> <li>Learning Rate Schedulers</li> <li>TensorBoard Integration</li> <li>ONNX Export</li> <li>TorchScript<ul> <li>Tracing</li> <li>Scripting</li> </ul> </li> <li>Deployment<ul> <li>Serving with Flask</li> <li>Serving with TorchServe</li> </ul> </li> <li>Distributed Training<ul> <li>DataParallel</li> <li>DistributedDataParallel (DDP)</li> <li>Gradient Clipping</li> <li>Weight Decay</li> <li>Early Stopping</li> <li>Learning Rate Finders</li> <li>Gradient Accumulation</li> </ul> </li> <li>Common Issues and Debugging</li> <li>Tips and Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of the PyTorch deep learning library, covering essential concepts, code snippets, and best practices for efficient model building, training, and deployment. It aims to be a one-stop reference for common tasks.</p>"},{"location":"Cheat-Sheets/PyTorch/#getting-started","title":"Getting Started","text":""},{"location":"Cheat-Sheets/PyTorch/#installation","title":"Installation","text":"<pre><code>pip install torch torchvision torchaudio\n</code></pre> <p>For CUDA support:</p> <pre><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n</code></pre> <p>Replace <code>cu121</code> with your CUDA version. Check the PyTorch website for the most up-to-date installation instructions.</p>"},{"location":"Cheat-Sheets/PyTorch/#importing-pytorch","title":"Importing PyTorch","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#tensors","title":"Tensors","text":""},{"location":"Cheat-Sheets/PyTorch/#creating-tensors","title":"Creating Tensors","text":"<p>From a List:</p> <pre><code>data = [1, 2, 3, 4, 5]\ntensor = torch.tensor(data)\n</code></pre> <p>From a NumPy Array:</p> <pre><code>import numpy as np\n\ndata = np.array([1, 2, 3, 4, 5])\ntensor = torch.from_numpy(data)\n</code></pre> <p>Zeros and Ones:</p> <pre><code>zeros = torch.zeros(size=(3, 4))\nones = torch.ones(size=(3, 4))\n</code></pre> <p>Full (fill with a specific value):</p> <pre><code>full = torch.full(size=(3, 4), fill_value=7)\n</code></pre> <p>Ranges:</p> <pre><code>arange = torch.arange(start=0, end=10, step=2) # 0, 2, 4, 6, 8\nlinspace = torch.linspace(start=0, end=1, steps=5) # 0.0, 0.25, 0.5, 0.75, 1.0\n</code></pre> <p>Random Numbers:</p> <pre><code>rand = torch.rand(size=(3, 4))  # Uniform distribution [0, 1)\nrandn = torch.randn(size=(3, 4)) # Standard normal distribution\nrandint = torch.randint(low=0, high=10, size=(3, 4)) # Integer values\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#tensor-attributes","title":"Tensor Attributes","text":"<pre><code>tensor.shape       # Shape of the tensor\ntensor.size()      # Same as shape\ntensor.ndim        # Number of dimensions\ntensor.dtype       # Data type of the tensor\ntensor.device      # Device where the tensor is stored (CPU or GPU)\ntensor.requires_grad # Whether gradients are tracked\ntensor.layout      # Memory layout (torch.strided, torch.sparse_coo)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#tensor-operations","title":"Tensor Operations","text":"<p>Arithmetic:</p> <pre><code>a = torch.tensor([1, 2, 3])\nb = torch.tensor([4, 5, 6])\n\nc = a + b       # Element-wise addition\nd = a * b       # Element-wise multiplication\ne = a.add(b)    # In-place addition\nf = a.mul(b)    # In-place multiplication\ng = torch.add(a, b) # Functional form\nh = torch.mul(a, b) # Functional form\n</code></pre> <p>Slicing and Indexing:</p> <pre><code>tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\ntensor[0]       # First row\ntensor[:, 1]     # Second column\ntensor[0, 1]    # Element at row 0, column 1\ntensor[0:2, 1:3] # Slicing\n</code></pre> <p>Reshaping:</p> <pre><code>tensor = torch.arange(12)\nreshaped_tensor = tensor.reshape(3, 4)\ntransposed_tensor = tensor.T # For 2D tensors\nflattened_tensor = tensor.flatten() # Flatten to 1D\nviewed_tensor = tensor.view(3, 4) # Similar to reshape, but shares memory\n</code></pre> <p>Concatenation:</p> <pre><code>tensor1 = torch.tensor([[1, 2], [3, 4]])\ntensor2 = torch.tensor([[5, 6], [7, 8]])\n\nconcatenated_tensor = torch.cat((tensor1, tensor2), dim=0) # Concatenate along rows\nstacked_tensor = torch.stack((tensor1, tensor2), dim=0) # Stack along a new dimension\n</code></pre> <p>Matrix Multiplication:</p> <pre><code>a = torch.randn(3, 4)\nb = torch.randn(4, 5)\nc = torch.matmul(a, b) # Matrix multiplication\nd = a @ b # Matrix multiplication (shorthand)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#data-types","title":"Data Types","text":"<ul> <li><code>torch.float32</code> or <code>torch.float</code>: 32-bit floating point</li> <li><code>torch.float64</code> or <code>torch.double</code>: 64-bit floating point</li> <li><code>torch.float16</code> or <code>torch.half</code>: 16-bit floating point</li> <li><code>torch.bfloat16</code>: BFloat16 floating point (useful for mixed precision)</li> <li><code>torch.int8</code>: 8-bit integer (signed)</li> <li><code>torch.int16</code> or <code>torch.short</code>: 16-bit integer (signed)</li> <li><code>torch.int32</code> or <code>torch.int</code>: 32-bit integer (signed)</li> <li><code>torch.int64</code> or <code>torch.long</code>: 64-bit integer (signed)</li> <li><code>torch.uint8</code>: 8-bit integer (unsigned)</li> <li><code>torch.bool</code>: Boolean</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#device-management","title":"Device Management","text":"<pre><code>device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntensor = tensor.to(device)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#moving-data-between-cpu-and-gpu","title":"Moving Data Between CPU and GPU","text":"<pre><code>cpu_tensor = tensor.cpu()\ngpu_tensor = tensor.cuda() # or tensor.to('cuda')\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#neural-networks","title":"Neural Networks","text":""},{"location":"Cheat-Sheets/PyTorch/#defining-a-model","title":"Defining a Model","text":"<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(784, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nmodel = Net()\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#layers","title":"Layers","text":"<ul> <li><code>nn.Linear</code>: Fully connected layer.</li> <li><code>nn.Conv1d</code>: 1D convolution layer.</li> <li><code>nn.Conv2d</code>: 2D convolution layer.</li> <li><code>nn.Conv3d</code>: 3D convolution layer.</li> <li><code>nn.ConvTranspose2d</code>: Transposed convolution layer (deconvolution).</li> <li><code>nn.MaxPool1d</code>, <code>nn.MaxPool2d</code>, <code>nn.MaxPool3d</code>: Max pooling layers.</li> <li><code>nn.AvgPool1d</code>, <code>nn.AvgPool2d</code>, <code>nn.AvgPool3d</code>: Average pooling layers.</li> <li><code>nn.AdaptiveAvgPool2d</code>: Adaptive average pooling layer.</li> <li><code>nn.ReLU</code>: ReLU activation function.</li> <li><code>nn.Sigmoid</code>: Sigmoid activation function.</li> <li><code>nn.Tanh</code>: Tanh activation function.</li> <li><code>nn.BatchNorm1d</code>, <code>nn.BatchNorm2d</code>, <code>nn.BatchNorm3d</code>: Batch normalization layers.</li> <li><code>nn.LayerNorm</code>: Layer normalization layer.</li> <li><code>nn.Dropout</code>: Dropout layer.</li> <li><code>nn.Embedding</code>: Embedding layer.</li> <li><code>nn.LSTM</code>: LSTM layer.</li> <li><code>nn.GRU</code>: GRU layer.</li> <li><code>nn.Transformer</code>: Transformer layer.</li> <li><code>nn.TransformerEncoder</code>, <code>nn.TransformerDecoder</code>: Transformer encoder and decoder layers.</li> <li><code>nn.MultiheadAttention</code>: Multi-head attention layer.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#activation-functions","title":"Activation Functions","text":"<ul> <li><code>torch.relu</code>: Rectified Linear Unit.</li> <li><code>torch.sigmoid</code>: Sigmoid function.</li> <li><code>torch.tanh</code>: Hyperbolic tangent function.</li> <li><code>torch.softmax</code>: Softmax function (for multi-class classification).</li> <li><code>torch.elu</code>: Exponential Linear Unit.</li> <li><code>torch.selu</code>: Scaled Exponential Linear Unit.</li> <li><code>torch.leaky_relu</code>: Leaky Rectified Linear Unit.</li> <li><code>torch.gelu</code>: Gaussian Error Linear Unit (GELU).</li> <li><code>torch.silu</code>: SiLU (Sigmoid Linear Unit) or Swish.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#loss-functions","title":"Loss Functions","text":"<ul> <li><code>nn.CrossEntropyLoss</code>: Cross-entropy loss (for multi-class classification).</li> <li><code>nn.BCELoss</code>: Binary cross-entropy loss (for binary classification).</li> <li><code>nn.BCEWithLogitsLoss</code>: Binary cross-entropy with logits (more stable).</li> <li><code>nn.MSELoss</code>: Mean squared error loss (for regression).</li> <li><code>nn.L1Loss</code>: Mean absolute error loss (for regression).</li> <li><code>nn.SmoothL1Loss</code>: Huber loss (for robust regression).</li> <li><code>nn.CTCLoss</code>: Connectionist Temporal Classification loss (for sequence labeling).</li> <li><code>nn.TripletMarginLoss</code>: Triplet margin loss (for learning embeddings).</li> <li><code>nn.CosineEmbeddingLoss</code>: Cosine embedding loss.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#optimizers","title":"Optimizers","text":"<ul> <li><code>optim.SGD</code>: Stochastic Gradient Descent.</li> <li><code>optim.Adam</code>: Adaptive Moment Estimation.</li> <li><code>optim.RMSprop</code>: Root Mean Square Propagation.</li> <li><code>optim.Adagrad</code>: Adaptive Gradient Algorithm.</li> <li><code>optim.Adadelta</code>: Adaptive Delta.</li> <li><code>optim.AdamW</code>: Adam with weight decay regularization.</li> <li><code>optim.SparseAdam</code>: Adam optimizer for sparse tensors.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#optimizer-configuration","title":"Optimizer Configuration","text":"<pre><code>optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#learning-rate-schedulers","title":"Learning Rate Schedulers","text":"<pre><code>from torch.optim.lr_scheduler import StepLR\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n\nfor epoch in range(100):\n    # Training loop\n    scheduler.step()\n</code></pre> <p>Common Schedulers:</p> <ul> <li><code>StepLR</code>: Decays the learning rate by a factor every few steps.</li> <li><code>MultiStepLR</code>: Decays the learning rate at specified milestones.</li> <li><code>ExponentialLR</code>: Decays the learning rate exponentially.</li> <li><code>CosineAnnealingLR</code>: Uses a cosine annealing schedule.</li> <li><code>ReduceLROnPlateau</code>: Reduces the learning rate when a metric has stopped improving.</li> <li><code>CyclicLR</code>: Sets the learning rate cyclically.</li> <li><code>OneCycleLR</code>: Sets the learning rate according to the 1cycle policy.</li> <li><code>CosineAnnealingWarmRestarts</code>: Cosine annealing with warm restarts.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#metrics","title":"Metrics","text":"<ul> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>F1-Score</li> <li>AUC (Area Under the Curve)</li> <li>IoU (Intersection over Union)</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#training","title":"Training","text":""},{"location":"Cheat-Sheets/PyTorch/#training-loop","title":"Training Loop","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Sample data\nX = torch.randn(100, 784)\ny = torch.randint(0, 10, (100,))\n\n# Create dataset and dataloader\ndataset = TensorDataset(X, y)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# Model, loss, optimizer\nmodel = nn.Linear(784, 10)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nepochs = 10\nfor epoch in range(epochs):\n    for inputs, labels in dataloader:\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#dataloaders","title":"DataLoaders","text":"<pre><code>from torch.utils.data import Dataset, DataLoader\n\nclass MyDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]\n\ndataset = MyDataset(data, labels)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#transforms","title":"Transforms","text":"<pre><code>import torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n\ntrainset = torchvision.datasets.ImageFolder(root='./data/train', transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n                                          shuffle=True, num_workers=4, pin_memory=True)\n</code></pre> <p>Common Augmentations:</p> <ul> <li><code>transforms.RandomHorizontalFlip</code>: Horizontally flips the image.</li> <li><code>transforms.RandomVerticalFlip</code>: Vertically flips the image.</li> <li><code>transforms.RandomRotation</code>: Rotates the image by a random angle.</li> <li><code>transforms.RandomAffine</code>: Applies random affine transformations.</li> <li><code>transforms.RandomPerspective</code>: Performs perspective transformation of the given image randomly with a given magnitude.</li> <li><code>transforms.RandomCrop</code>: Crops a random portion of the image.</li> <li><code>transforms.CenterCrop</code>: Crops the image from the center.</li> <li><code>transforms.ColorJitter</code>: Randomly changes the brightness, contrast, saturation, and hue of an image.</li> <li><code>transforms.RandomGrayscale</code>: Converts the image to grayscale with a certain probability.</li> <li><code>transforms.RandomErasing</code>: Randomly erases a rectangular region in the image.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#mixed-precision-training","title":"Mixed Precision Training","text":"<pre><code>scaler = torch.cuda.amp.GradScaler()\n\nfor epoch in range(epochs):\n    for inputs, labels in dataloader:\n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast():\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#evaluation","title":"Evaluation","text":"<pre><code>model.eval()  # Set the model to evaluation mode\nwith torch.no_grad():  # Disable gradient calculation\n    correct = 0\n    total = 0\n    for images, labels in testloader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print(f'Accuracy: {100 * correct / total:.2f}%')\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#prediction","title":"Prediction","text":"<pre><code>model.eval()\nwith torch.no_grad():\n    input_tensor = torch.randn(1, 3, 224, 224).to(device)  # Example input\n    output = model(input_tensor)\n    predicted_class = torch.argmax(output).item()\n    print(f'Predicted class: {predicted_class}')\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#saving-and-loading-models","title":"Saving and Loading Models","text":""},{"location":"Cheat-Sheets/PyTorch/#save-the-entire-model","title":"Save the Entire Model","text":"<pre><code>torch.save(model, 'my_model.pth') # Saves the entire model object\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#load-the-entire-model","title":"Load the Entire Model","text":"<pre><code>model = torch.load('my_model.pth')\nmodel.eval()\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#save-model-state-dictionary","title":"Save Model State Dictionary","text":"<pre><code>torch.save(model.state_dict(), 'model_state_dict.pth') # Saves only the model's learned parameters\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#load-model-state-dictionary","title":"Load Model State Dictionary","text":"<pre><code>model = Net()  # Instantiate the model\nmodel.load_state_dict(torch.load('model_state_dict.pth'))\nmodel.eval()\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#cuda-gpu-support","title":"CUDA (GPU Support)","text":""},{"location":"Cheat-Sheets/PyTorch/#check-cuda-availability","title":"Check CUDA Availability","text":"<pre><code>torch.cuda.is_available()\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#set-device","title":"Set Device","text":"<pre><code>device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#move-tensors-to-gpu","title":"Move Tensors to GPU","text":"<pre><code>tensor = tensor.to(device)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#cuda-best-practices","title":"CUDA Best Practices","text":"<ul> <li>Use pinned memory for data transfer: <code>torch.utils.data.DataLoader(..., pin_memory=True)</code></li> <li>Use asynchronous data transfer: <code>torch.cuda.Stream()</code></li> <li>Use mixed precision training: <code>torch.cuda.amp.autocast()</code> and <code>torch.cuda.amp.GradScaler()</code></li> <li>Use <code>torch.backends.cudnn.benchmark = True</code> for faster convolutions when input sizes are fixed.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#distributed-training","title":"Distributed Training","text":""},{"location":"Cheat-Sheets/PyTorch/#dataparallel","title":"DataParallel","text":"<pre><code>model = nn.DataParallel(model)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#distributeddataparallel-ddp","title":"DistributedDataParallel (DDP)","text":"<pre><code>import torch.distributed as dist\nimport torch.multiprocessing as mp\nimport os\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef train(rank, world_size):\n    setup(rank, world_size)\n\n    model = Net().to(rank)\n    ddp_model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n\n    # Training loop\n    cleanup()\n\nif __name__ == \"__main__\":\n    world_size = torch.cuda.device_count()\n    mp.spawn(train,\n             args=(world_size,),\n             nprocs=world_size,\n             join=True)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#distributed-data-loading","title":"Distributed Data Loading","text":"<p>When using DDP, you'll want to use a <code>DistributedSampler</code> to ensure each process gets a unique subset of the data:</p> <pre><code>from torch.utils.data.distributed import DistributedSampler\n\ntrain_sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\ntrainloader = DataLoader(dataset, batch_size=32, shuffle=False, sampler=train_sampler) # shuffle=False is important here\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#autograd","title":"Autograd","text":""},{"location":"Cheat-Sheets/PyTorch/#tracking-gradients","title":"Tracking Gradients","text":"<pre><code>x = torch.randn(3, requires_grad=True)\ny = x + 2\nz = y * y * 3\nout = z.mean()\nout.backward()\nprint(x.grad)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#disabling-gradient-tracking","title":"Disabling Gradient Tracking","text":"<pre><code>with torch.no_grad():\n    y = x + 2\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#detaching-tensors","title":"Detaching Tensors","text":"<pre><code>y = x.detach()  # Creates a new tensor with the same content but no gradient history\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#custom-autograd-functions","title":"Custom Autograd Functions","text":"<pre><code>class MyReLU(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, input):\n        ctx.save_for_backward(input)\n        return input.clamp(min=0)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        input, = ctx.saved_tensors\n        grad_input = grad_output.clone()\n        grad_input[input &lt; 0] = 0\n        return grad_input\n\nmy_relu = MyReLU.apply\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#data-augmentation","title":"Data Augmentation","text":"<pre><code>import torchvision.transforms as transforms\n\ntransform = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(degrees=15),\n    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n</code></pre> <p>Common Augmentations:</p> <ul> <li><code>transforms.RandomHorizontalFlip</code>: Horizontally flips the image.</li> <li><code>transforms.RandomVerticalFlip</code>: Vertically flips the image.</li> <li><code>transforms.RandomRotation</code>: Rotates the image by a random angle.</li> <li><code>transforms.RandomAffine</code>: Applies random affine transformations.</li> <li><code>transforms.RandomPerspective</code>: Performs perspective transformation of the given image randomly with a given magnitude.</li> <li><code>transforms.RandomCrop</code>: Crops a random portion of the image.</li> <li><code>transforms.CenterCrop</code>: Crops the image from the center.</li> <li><code>transforms.ColorJitter</code>: Randomly changes the brightness, contrast, saturation, and hue of an image.</li> <li><code>transforms.RandomGrayscale</code>: Converts the image to grayscale with a certain probability.</li> <li><code>transforms.RandomErasing</code>: Randomly erases a rectangular region in the image.</li> <li><code>transforms.RandomResizedCrop</code>: Crops a random portion of the image and resizes it.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#learning-rate-schedulers_1","title":"Learning Rate Schedulers","text":"<pre><code>from torch.optim.lr_scheduler import StepLR\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n\nfor epoch in range(100):\n    # Training loop\n    scheduler.step()\n</code></pre> <p>Common Schedulers:</p> <ul> <li><code>StepLR</code>: Decays the learning rate by a factor every few steps.</li> <li><code>MultiStepLR</code>: Decays the learning rate at specified milestones.</li> <li><code>ExponentialLR</code>: Decays the learning rate exponentially.</li> <li><code>CosineAnnealingLR</code>: Uses a cosine annealing schedule.</li> <li><code>ReduceLROnPlateau</code>: Reduces the learning rate when a metric has stopped improving.</li> <li><code>CyclicLR</code>: Sets the learning rate cyclically.</li> <li><code>OneCycleLR</code>: Sets the learning rate according to the 1cycle policy.</li> <li><code>CosineAnnealingWarmRestarts</code>: Cosine annealing with warm restarts.</li> <li><code>LambdaLR</code>: Allows defining a custom learning rate schedule using a lambda function.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#tensorboard-integration","title":"TensorBoard Integration","text":"<pre><code>from torch.utils.tensorboard import SummaryWriter\n\nwriter = SummaryWriter(\"runs/experiment_1\")\n\n# Log scalar values\nwriter.add_scalar('Loss/train', loss.item(), epoch)\nwriter.add_scalar('Accuracy/train', accuracy, epoch)\n\n# Log model graph\nwriter.add_graph(model, images)\n\n# Log images\nwriter.add_image('Image', img_grid, epoch)\n\n# Log histograms\nwriter.add_histogram('fc1.weight', model.fc1.weight, epoch)\n\n# Log embeddings\nwriter.add_embedding(features, metadata=labels, tag='my_embedding')\n\nwriter.close()\n</code></pre> <p>Run TensorBoard:</p> <pre><code>tensorboard --logdir=runs\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#onnx-export","title":"ONNX Export","text":"<pre><code>dummy_input = torch.randn(1, 3, 224, 224).to(device) # Example input\ntorch.onnx.export(model, dummy_input, \"model.onnx\", verbose=True, input_names=['input'], output_names=['output'], dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n                                                                                                                             'output' : {0 : 'batch_size'}})\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#torchscript","title":"TorchScript","text":""},{"location":"Cheat-Sheets/PyTorch/#tracing","title":"Tracing","text":"<pre><code>model.eval()\nexample = torch.rand(1, 3, 224, 224).to(device)\ntraced_script_module = torch.jit.trace(model, example)\ntraced_script_module.save(\"model_traced.pt\")\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#scripting","title":"Scripting","text":"<pre><code>@torch.jit.script\ndef scripted_function(x, y):\n    return x + y\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#deployment","title":"Deployment","text":""},{"location":"Cheat-Sheets/PyTorch/#serving-with-flask","title":"Serving with Flask","text":"<pre><code>from flask import Flask, request, jsonify\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\n\napp = Flask(__name__)\nmodel = torch.load('my_model.pth')\nmodel.eval()\n\ndef transform_image(image):\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    image = Image.open(image).convert('RGB')\n    return transform(image).unsqueeze(0)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    if request.method == 'POST':\n        if request.files.get('image'):\n            try:\n                img_tensor = transform_image(request.files['image'])\n                with torch.no_grad():\n                    prediction = model(img_tensor)\n                predicted_class = torch.argmax(prediction).item()\n                return jsonify({'prediction': str(predicted_class)})\n            except Exception as e:\n                return jsonify({'error': str(e)})\n        return jsonify({'error': 'No image found'})\n    return jsonify({'message': 'Use POST method'})\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#serving-with-torchserve","title":"Serving with TorchServe","text":"<ol> <li>Install TorchServe:</li> </ol> <pre><code>pip install torchserve torch-model-archiver\n</code></pre> <ol> <li>Create a model archive:</li> </ol> <pre><code>torch-model-archiver --model-name my_model --version 1.0 --model-file model.py --serialized-file model.pth --handler handler.py --extra-files index_to_name.json\n</code></pre> <ol> <li>Start TorchServe:</li> </ol> <pre><code>torchserve --start --model-store model_store --models my_model=my_model.mar\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#distributed-training_1","title":"Distributed Training","text":""},{"location":"Cheat-Sheets/PyTorch/#dataparallel_1","title":"DataParallel","text":"<pre><code>model = nn.DataParallel(model)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#distributeddataparallel-ddp_1","title":"DistributedDataParallel (DDP)","text":"<pre><code>import torch.distributed as dist\nimport torch.multiprocessing as mp\nimport os\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef train(rank, world_size):\n    setup(rank, world_size)\n\n    model = Net().to(rank)\n    ddp_model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n\n    # Training loop\n    cleanup()\n\nif __name__ == \"__main__\":\n    world_size = torch.cuda.device_count()\n    mp.spawn(train,\n             args=(world_size,),\n             nprocs=world_size,\n             join=True)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#gradient-clipping","title":"Gradient Clipping","text":"<pre><code>torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type=2.0)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#weight-decay","title":"Weight Decay","text":"<p>Weight decay (L2 regularization) is often included directly in the optimizer:</p> <pre><code>optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#early-stopping","title":"Early Stopping","text":"<pre><code>patience = 10\nbest_val_loss = float('inf')\ncounter = 0\n\nfor epoch in range(num_epochs):\n    # Training and validation steps\n    val_loss = validate(model, validation_loader, criterion)\n\n    if val_loss &lt; best_val_loss:\n        best_val_loss = val_loss\n        counter = 0\n        torch.save(model.state_dict(), 'best_model.pth')\n    else:\n        counter += 1\n\n    if counter &gt;= patience:\n        print(\"Early stopping triggered\")\n        break\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#learning-rate-finders","title":"Learning Rate Finders","text":"<pre><code># Requires a separate library like `torch_lr_finder`\nfrom torch_lr_finder import LRFinder\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-7, weight_decay=0.01)\nlr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\nlr_finder.range_test(trainloader, end_lr=1, num_iter=100)\nlr_finder.plot()\nlr_finder.reset()\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#gradient-accumulation","title":"Gradient Accumulation","text":"<p>Gradient accumulation allows you to simulate larger batch sizes when you are limited by GPU memory. It works by accumulating gradients over multiple smaller batches before performing the optimization step.</p> <pre><code>accumulation_steps = 4 # Accumulate gradients over 4 batches\n\noptimizer.zero_grad() # Reset gradients before starting\n\nfor i, (inputs, labels) in enumerate(trainloader):\n    outputs = model(inputs)\n    loss = criterion(outputs, labels)\n    loss = loss / accumulation_steps # Normalize the loss\n    loss.backward()\n\n    if (i + 1) % accumulation_steps == 0: # Every accumulation_steps batches\n        optimizer.step()        # Perform optimization step\n        optimizer.zero_grad()   # Reset gradients\n</code></pre>"},{"location":"Cheat-Sheets/PyTorch/#common-issues-and-debugging","title":"Common Issues and Debugging","text":"<ul> <li>CUDA Out of Memory Errors: Reduce batch size, use mixed precision training, use gradient checkpointing, use a smaller model, or use multiple GPUs.</li> <li>Slow Training: Profile your code to identify bottlenecks, use a GPU, use data parallelism or distributed training, optimize data loading, or use faster operations.</li> <li>NaN Losses: Reduce learning rate, use gradient clipping, use a different optimizer, check for numerical instability, or normalize your data.</li> <li>Overfitting: Use regularization techniques, data augmentation, early stopping, or reduce model complexity.</li> <li>Underfitting: Increase model capacity, train for longer, use a more complex optimizer, or add more features.</li> <li>Incorrect Tensor Shapes: Carefully check the shapes of your tensors and ensure they are compatible with the operations you are performing. Use <code>tensor.shape</code> to inspect tensor shapes.</li> <li>Incorrect Data Types: Ensure that your tensors have the correct data types (e.g., <code>torch.float32</code> for floating-point operations, <code>torch.long</code> for indices). Use <code>tensor.dtype</code> to inspect tensor data types.</li> <li>Device Mismatch: Ensure that all tensors and models are on the same device (CPU or GPU). Use <code>tensor.to(device)</code> and <code>model.to(device)</code> to move tensors and models to the correct device.</li> <li>Gradients Not Flowing: Check that <code>requires_grad=True</code> is set for the tensors you want to compute gradients for. Check that you are not detaching tensors from the computation graph unintentionally.</li> <li>Dead Neurons (ReLU): Use Leaky ReLU or other activation functions that allow a small gradient to flow even when the input is negative.</li> <li>Exploding Gradients: Use gradient clipping to limit the magnitude of gradients.</li> <li>Vanishing Gradients: Use skip connections (e.g., ResNet), batch normalization, or different activation functions.</li> <li>Data Loading Bottlenecks: Increase the number of worker processes in your <code>DataLoader</code> and use pinned memory.</li> <li>Incorrect Loss Function: Ensure that you are using the appropriate loss function for your task (e.g., <code>CrossEntropyLoss</code> for multi-class classification, <code>MSELoss</code> for regression).</li> <li>Incorrect Optimizer: Experiment with different optimizers and learning rates to find the best configuration for your task.</li> <li>Unstable Training: Use a smaller learning rate, increase the batch size, or use a more stable optimizer.</li> <li>Model Not Learning: Check your data for errors, ensure that your model is complex enough to learn the task, and try different hyperparameters.</li> </ul>"},{"location":"Cheat-Sheets/PyTorch/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ul> <li>Use virtual environments to isolate project dependencies.</li> <li>Use meaningful names for variables and functions.</li> <li>Follow the DRY (Don't Repeat Yourself) principle.</li> <li>Write unit tests to ensure code quality.</li> <li>Use a consistent coding style (e.g., PEP 8).</li> <li>Document your code.</li> <li>Use a version control system (e.g., Git).</li> <li>Use appropriate data types for your data.</li> <li>Optimize your PyTorch configuration for your workload.</li> <li>Use caching to improve performance.</li> <li>Use a logging framework to log events and errors.</li> <li>Use a security framework to protect your data.</li> <li>Use a resource manager (e.g., YARN, Mesos, Kubernetes) to manage your cluster.</li> <li>Use a deployment tool to deploy your application to production.</li> <li>Monitor your application for performance issues.</li> <li>Use a CDN (Content Delivery Network) for static files.</li> <li>Optimize database queries.</li> <li>Use asynchronous tasks for long-running operations.</li> <li>Implement proper logging and error handling.</li> <li>Regularly update PyTorch and its dependencies.</li> <li>Use a security scanner to identify potential vulnerabilities.</li> <li>Follow security best practices.</li> <li>Use a reverse proxy like Nginx or Apache in front of your PyTorch application.</li> <li>Use a load balancer for high availability.</li> <li>Automate deployments using tools like Fabric or Ansible.</li> <li>Use a monitoring tool like Prometheus or Grafana.</li> <li>Implement health checks for your application.</li> <li>Use a CDN for static assets.</li> <li>Cache frequently accessed data.</li> <li>Use a database connection pool.</li> <li>Optimize your database queries.</li> <li>Use a task queue for long-running tasks.</li> <li>Use a background worker for asynchronous tasks.</li> <li>Use a message queue for inter-process communication.</li> <li>Use a service discovery tool for microservices.</li> <li>Use a containerization tool like Docker.</li> <li>Use an orchestration tool like Kubernetes.</li> <li>Use a model compression technique to reduce model size.</li> <li>Use quantization to reduce model size and improve inference speed.</li> <li>Use pruning to remove unnecessary connections from the model.</li> <li>Use knowledge distillation to transfer knowledge from a large model to a smaller model.</li> <li>Use a model deployment framework like TorchServe, TensorFlow Serving, or ONNX Runtime.</li> <li>Use a model monitoring tool to track model performance in production.</li> <li>Implement A/B testing to compare different model versions.</li> <li>Use a CI/CD pipeline to automate the model deployment process.</li> <li>Use a feature store to manage your features.</li> <li>Use a data catalog to manage your data.</li> <li>Use a data lineage tool to track the flow of data through your system.</li> <li>Use a data governance tool to ensure data quality and compliance.</li> <li>Use a model registry to manage your models.</li> <li>Use a model versioning tool to track changes to your models.</li> <li>Use a model explainability tool to understand why your model is making certain predictions.</li> <li>Use a model fairness tool to ensure that your model is not biased against certain groups of people.</li> <li>Use a model security tool to protect your model from adversarial attacks.</li> <li>Use a model privacy tool to protect the privacy of your data.</li> </ul>"},{"location":"Cheat-Sheets/Python/","title":"Python Cheat Sheet","text":"<ul> <li>Python Cheat Sheet<ul> <li>Getting Started<ul> <li>Installation</li> <li>Running Python Code</li> </ul> </li> <li>Basic Syntax<ul> <li>Comments</li> <li>Variables</li> <li>Data Types</li> <li>Operators</li> <li>Control Flow</li> <li>Functions</li> <li>Data Structures</li> <li>List Comprehensions</li> <li>Dictionary Comprehensions</li> <li>Set Comprehensions</li> <li>Generators</li> </ul> </li> <li>Modules and Packages<ul> <li>Importing Modules</li> <li>Creating Modules</li> <li>Packages</li> </ul> </li> <li>File I/O<ul> <li>Reading from a File</li> <li>Writing to a File</li> <li>Appending to a File</li> <li>Reading Lines from a File</li> </ul> </li> <li>String Formatting<ul> <li>f-strings (Python 3.6+)</li> <li>str.format()</li> <li>% Formatting</li> </ul> </li> <li>Regular Expressions<ul> <li>Importing the re Module</li> <li>Common Functions</li> <li>Example</li> </ul> </li> <li>Date and Time<ul> <li>Importing the datetime Module</li> <li>Common Functions</li> <li>Example</li> </ul> </li> <li>JSON Processing<ul> <li>Importing the json Module</li> <li>Common Functions</li> <li>Example</li> </ul> </li> <li>Working with CSV Files<ul> <li>Importing the csv Module</li> <li>Reading CSV Files</li> <li>Writing CSV Files</li> <li>Reading CSV Files as Dictionaries</li> <li>Writing CSV Files from Dictionaries</li> </ul> </li> <li>Working with OS<ul> <li>Importing the os Module</li> <li>Common Functions</li> <li>Example</li> </ul> </li> <li>Working with Collections<ul> <li>Importing the collections Module</li> <li>Common Data Structures</li> <li>Example</li> </ul> </li> <li>Working with Itertools<ul> <li>Importing the itertools Module</li> <li>Common Functions</li> <li>Example</li> </ul> </li> <li>Working with functools<ul> <li>Importing the functools Module</li> <li>Common Functions</li> <li>Example</li> </ul> </li> <li>Concurrency and Parallelism<ul> <li>Threads</li> <li>Processes</li> <li>Asyncio</li> </ul> </li> <li>Type Hints</li> <li>Virtual Environments<ul> <li>Creating a Virtual Environment</li> <li>Activating a Virtual Environment</li> <li>Deactivating a Virtual Environment</li> </ul> </li> <li>Testing<ul> <li>Using unittest</li> <li>Using pytest</li> </ul> </li> <li>Decorators</li> <li>Context Managers</li> <li>Object-Oriented Programming (OOP)<ul> <li>Classes and Objects</li> <li>Inheritance</li> <li>Encapsulation</li> <li>Polymorphism</li> <li>Class Methods and Static Methods</li> </ul> </li> <li>Metaclasses</li> <li>Abstract Base Classes (ABCs)</li> <li>Exception Handling<ul> <li>Raising Exceptions</li> <li>Custom Exceptions</li> </ul> </li> <li>Iterators and Generators<ul> <li>Iterators</li> <li>Generators</li> </ul> </li> <li>Decorators<ul> <li>Decorators with Arguments</li> </ul> </li> <li>Context Managers</li> <li>Descriptors</li> <li>Metaclasses</li> <li>Abstract Base Classes (ABCs)</li> <li>Working with Dates and Times</li> <li>Working with CSV Files</li> <li>Working with JSON</li> <li>Working with Regular Expressions</li> <li>Working with OS</li> <li>Working with Collections</li> <li>Working with Itertools</li> <li>Working with Functools</li> <li>Concurrency and Parallelism<ul> <li>Threads</li> <li>Processes</li> <li>Asyncio</li> <li>ThreadPoolExecutor</li> <li>ProcessPoolExecutor</li> </ul> </li> <li>Type Hints</li> <li>Virtual Environments<ul> <li>Creating a Virtual Environment</li> <li>Activating a Virtual Environment</li> <li>Deactivating a Virtual Environment</li> </ul> </li> <li>Testing<ul> <li>Using unittest</li> <li>Using pytest</li> </ul> </li> <li>Logging</li> <li>Debugging<ul> <li>Using pdb (Python Debugger)</li> <li>Using print() Statements</li> </ul> </li> <li>Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of the Python programming language, covering essential syntax, data structures, functions, modules, and best practices for efficient development. It aims to be a one-stop reference for common tasks.</p>"},{"location":"Cheat-Sheets/Python/#getting-started","title":"Getting Started","text":""},{"location":"Cheat-Sheets/Python/#installation","title":"Installation","text":"<p>Check if Python is already installed:</p> <pre><code>python --version\npython3 --version\n</code></pre> <p>Install Python using a package manager (e.g., <code>apt</code>, <code>brew</code>, <code>choco</code>) or from the official website:</p> <ul> <li>Python Downloads</li> </ul>"},{"location":"Cheat-Sheets/Python/#running-python-code","title":"Running Python Code","text":"<p>Interactive Mode:</p> <pre><code>python\npython3\n</code></pre> <p>Run a Python Script:</p> <pre><code>python my_script.py\npython3 my_script.py\n</code></pre>"},{"location":"Cheat-Sheets/Python/#basic-syntax","title":"Basic Syntax","text":""},{"location":"Cheat-Sheets/Python/#comments","title":"Comments","text":"<pre><code># This is a single-line comment\n\n\"\"\"\nThis is a multi-line comment\n\"\"\"\n</code></pre>"},{"location":"Cheat-Sheets/Python/#variables","title":"Variables","text":"<pre><code>x = 10\nname = \"Alice\"\nis_active = True\n</code></pre>"},{"location":"Cheat-Sheets/Python/#data-types","title":"Data Types","text":"<ul> <li><code>int</code>: Integer</li> <li><code>float</code>: Floating-point number</li> <li><code>str</code>: String</li> <li><code>bool</code>: Boolean (True/False)</li> <li><code>list</code>: List</li> <li><code>tuple</code>: Tuple</li> <li><code>dict</code>: Dictionary</li> <li><code>set</code>: Set</li> <li><code>NoneType</code>: None</li> </ul>"},{"location":"Cheat-Sheets/Python/#operators","title":"Operators","text":"<p>Arithmetic:</p> <ul> <li><code>+</code>: Addition</li> <li><code>-</code>: Subtraction</li> <li><code>*</code>: Multiplication</li> <li><code>/</code>: Division</li> <li><code>//</code>: Floor division</li> <li><code>%</code>: Modulus</li> <li><code>**</code>: Exponentiation</li> </ul> <p>Comparison:</p> <ul> <li><code>==</code>: Equal to</li> <li><code>!=</code>: Not equal to</li> <li><code>&gt;</code>: Greater than</li> <li><code>&lt;</code>: Less than</li> <li><code>&gt;=</code>: Greater than or equal to</li> <li><code>&lt;=</code>: Less than or equal to</li> </ul> <p>Logical:</p> <ul> <li><code>and</code>: Logical AND</li> <li><code>or</code>: Logical OR</li> <li><code>not</code>: Logical NOT</li> </ul> <p>Assignment:</p> <ul> <li><code>=</code>: Assignment</li> <li><code>+=</code>, <code>-=</code>, <code>*=</code>, <code>/=</code>, <code>//=</code>, <code>%=</code>, <code>**=</code>: Compound assignment</li> </ul> <p>Identity:</p> <ul> <li><code>is</code>: Tests if two variables refer to the same object</li> <li><code>is not</code>: Tests if two variables do not refer to the same object</li> </ul> <p>Membership:</p> <ul> <li><code>in</code>: Tests if a value is a member of a sequence</li> <li><code>not in</code>: Tests if a value is not a member of a sequence</li> </ul> <p>Bitwise:</p> <ul> <li><code>&amp;</code>: Bitwise AND</li> <li><code>|</code>: Bitwise OR</li> <li><code>^</code>: Bitwise XOR</li> <li><code>~</code>: Bitwise NOT</li> <li><code>&lt;&lt;</code>: Left shift</li> <li><code>&gt;&gt;</code>: Right shift</li> </ul>"},{"location":"Cheat-Sheets/Python/#control-flow","title":"Control Flow","text":"<p>If Statement:</p> <pre><code>x = 10\nif x &gt; 0:\n    print(\"Positive\")\nelif x == 0:\n    print(\"Zero\")\nelse:\n    print(\"Negative\")\n</code></pre> <p>For Loop:</p> <pre><code>for i in range(5):\n    print(i)\n</code></pre> <p>While Loop:</p> <pre><code>i = 0\nwhile i &lt; 5:\n    print(i)\n    i += 1\n</code></pre> <p>Break and Continue:</p> <pre><code>for i in range(10):\n    if i == 3:\n        break  # Exit the loop\n    if i == 1:\n        continue  # Skip to the next iteration\n    print(i)\n</code></pre> <p>Try-Except Block:</p> <pre><code>try:\n    result = 10 / 0\nexcept ZeroDivisionError:\n    print(\"Cannot divide by zero\")\nfinally:\n    print(\"This will always execute\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#functions","title":"Functions","text":"<p>Defining a Function:</p> <pre><code>def greet(name=\"World\"):\n    \"\"\"This function greets the person passed in as a parameter.\n    If no parameter is passed, it greets the world.\"\"\"\n    print(f\"Hello, {name}!\")\n\ngreet(\"Alice\")\ngreet()\n</code></pre> <p>Function Arguments:</p> <ul> <li>Positional arguments</li> <li>Keyword arguments</li> <li>Default arguments</li> <li><code>*args</code>: Variable-length positional arguments (as a tuple)</li> <li><code>**kwargs</code>: Variable-length keyword arguments (as a dictionary)</li> </ul> <pre><code>def my_function(a, b=2, *args, **kwargs):\n    print(f\"a: {a}, b: {b}, args: {args}, kwargs: {kwargs}\")\n\nmy_function(1, 2, 3, 4, name=\"Alice\", age=30)\n</code></pre> <p>Lambda Functions:</p> <pre><code>square = lambda x: x ** 2\nprint(square(5))\n</code></pre>"},{"location":"Cheat-Sheets/Python/#data-structures","title":"Data Structures","text":"<p>Lists:</p> <pre><code>my_list = [1, 2, \"hello\", True]\nmy_list.append(5)\nmy_list.insert(2, \"new\")\nmy_list.remove(2)\nmy_list.pop(1)\nprint(my_list[0])\nprint(my_list[-1])\nprint(my_list[1:3])\n</code></pre> <p>Tuples:</p> <pre><code>my_tuple = (1, 2, \"hello\")\nprint(my_tuple[0])\n</code></pre> <p>Dictionaries:</p> <pre><code>my_dict = {\"name\": \"Alice\", \"age\": 30}\nmy_dict[\"city\"] = \"New York\"\nprint(my_dict[\"name\"])\nprint(my_dict.get(\"age\"))\nprint(my_dict.keys())\nprint(my_dict.values())\nprint(my_dict.items())\n</code></pre> <p>Sets:</p> <pre><code>my_set = {1, 2, 3, 4}\nmy_set.add(5)\nmy_set.remove(2)\nprint(my_set)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#list-comprehensions","title":"List Comprehensions","text":"<pre><code>numbers = [1, 2, 3, 4, 5]\nsquares = [x ** 2 for x in numbers]\neven_squares = [x ** 2 for x in numbers if x % 2 == 0]\n</code></pre>"},{"location":"Cheat-Sheets/Python/#dictionary-comprehensions","title":"Dictionary Comprehensions","text":"<pre><code>numbers = [1, 2, 3, 4, 5]\nsquare_dict = {x: x ** 2 for x in numbers}\n</code></pre>"},{"location":"Cheat-Sheets/Python/#set-comprehensions","title":"Set Comprehensions","text":"<pre><code>numbers = [1, 2, 2, 3, 4, 4, 5]\nunique_squares = {x ** 2 for x in numbers}\n</code></pre>"},{"location":"Cheat-Sheets/Python/#generators","title":"Generators","text":"<pre><code>def my_generator(n):\n    for i in range(n):\n        yield i ** 2\n\nfor value in my_generator(5):\n    print(value)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#modules-and-packages","title":"Modules and Packages","text":""},{"location":"Cheat-Sheets/Python/#importing-modules","title":"Importing Modules","text":"<pre><code>import math\nprint(math.sqrt(16))\n\nimport datetime\nnow = datetime.datetime.now()\nprint(now)\n\nfrom collections import Counter\n</code></pre>"},{"location":"Cheat-Sheets/Python/#creating-modules","title":"Creating Modules","text":"<p>Create a file named <code>my_module.py</code>:</p> <pre><code>def my_function():\n    print(\"Hello from my_module!\")\n\nmy_variable = 10\n</code></pre> <p>Import and use the module:</p> <pre><code>import my_module\n\nmy_module.my_function()\nprint(my_module.my_variable)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#packages","title":"Packages","text":"<p>Create a directory named <code>my_package</code> with an <code>__init__.py</code> file inside.</p> <p>Create modules inside the package (e.g., <code>my_package/module1.py</code>, <code>my_package/module2.py</code>).</p> <p>Import and use the package:</p> <pre><code>import my_package.module1\nfrom my_package import module2\n\nmy_package.module1.my_function()\nmodule2.another_function()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#file-io","title":"File I/O","text":""},{"location":"Cheat-Sheets/Python/#reading-from-a-file","title":"Reading from a File","text":"<pre><code>with open(\"my_file.txt\", \"r\") as f:\n    content = f.read()\n    print(content)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#writing-to-a-file","title":"Writing to a File","text":"<pre><code>with open(\"my_file.txt\", \"w\") as f:\n    f.write(\"Hello, file!\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#appending-to-a-file","title":"Appending to a File","text":"<pre><code>with open(\"my_file.txt\", \"a\") as f:\n    f.write(\"\\nAppending to the file.\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#reading-lines-from-a-file","title":"Reading Lines from a File","text":"<pre><code>with open(\"my_file.txt\", \"r\") as f:\n    for line in f:\n        print(line.strip())\n</code></pre>"},{"location":"Cheat-Sheets/Python/#string-formatting","title":"String Formatting","text":""},{"location":"Cheat-Sheets/Python/#f-strings-python-36","title":"f-strings (Python 3.6+)","text":"<pre><code>name = \"Alice\"\nage = 30\nprint(f\"My name is {name} and I am {age} years old.\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#strformat","title":"str.format()","text":"<pre><code>name = \"Alice\"\nage = 30\nprint(\"My name is {} and I am {} years old.\".format(name, age))\n</code></pre>"},{"location":"Cheat-Sheets/Python/#formatting","title":"% Formatting","text":"<pre><code>name = \"Alice\"\nage = 30\nprint(\"My name is %s and I am %d years old.\" % (name, age))\n</code></pre>"},{"location":"Cheat-Sheets/Python/#regular-expressions","title":"Regular Expressions","text":""},{"location":"Cheat-Sheets/Python/#importing-the-re-module","title":"Importing the <code>re</code> Module","text":"<pre><code>import re\n</code></pre>"},{"location":"Cheat-Sheets/Python/#common-functions","title":"Common Functions","text":"<ul> <li><code>re.search(pattern, string)</code>: Searches for a pattern in a string.</li> <li><code>re.match(pattern, string)</code>: Matches a pattern at the beginning of a string.</li> <li><code>re.findall(pattern, string)</code>: Finds all occurrences of a pattern.</li> <li><code>re.sub(pattern, replacement, string)</code>: Replaces occurrences of a pattern.</li> <li><code>re.split(pattern, string)</code>: Splits a string by a pattern.</li> </ul>"},{"location":"Cheat-Sheets/Python/#example","title":"Example","text":"<pre><code>import re\n\ntext = \"The quick brown fox jumps over the lazy dog.\"\npattern = r\"\\b\\w{5}\\b\"  # Matches 5-letter words\n\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['quick', 'brown', 'jumps']\n</code></pre>"},{"location":"Cheat-Sheets/Python/#date-and-time","title":"Date and Time","text":""},{"location":"Cheat-Sheets/Python/#importing-the-datetime-module","title":"Importing the <code>datetime</code> Module","text":"<pre><code>import datetime\n</code></pre>"},{"location":"Cheat-Sheets/Python/#common-functions_1","title":"Common Functions","text":"<ul> <li><code>datetime.datetime.now()</code>: Returns the current date and time.</li> <li><code>datetime.date.today()</code>: Returns the current date.</li> <li><code>datetime.datetime(year, month, day, hour, minute, second)</code>: Creates a datetime object.</li> <li><code>datetime.timedelta(days, seconds, microseconds)</code>: Represents a duration.</li> <li><code>datetime.strftime(format)</code>: Formats a datetime object as a string.</li> <li><code>datetime.strptime(date_string, format)</code>: Parses a string into a datetime object.</li> </ul>"},{"location":"Cheat-Sheets/Python/#example_1","title":"Example","text":"<pre><code>import datetime\n\nnow = datetime.datetime.now()\nprint(now)\n\nformatted_date = now.strftime(\"%Y-%m-%d %H:%M:%S\")\nprint(formatted_date)\n\nparsed_date = datetime.datetime.strptime(\"2025-02-08 10:30:00\", \"%Y-%m-%d %H:%M:%S\")\nprint(parsed_date)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#json-processing","title":"JSON Processing","text":""},{"location":"Cheat-Sheets/Python/#importing-the-json-module","title":"Importing the <code>json</code> Module","text":"<pre><code>import json\n</code></pre>"},{"location":"Cheat-Sheets/Python/#common-functions_2","title":"Common Functions","text":"<ul> <li><code>json.dumps(object)</code>: Serializes a Python object to a JSON string.</li> <li><code>json.loads(json_string)</code>: Deserializes a JSON string to a Python object.</li> <li><code>json.dump(object, file)</code>: Serializes a Python object to a JSON file.</li> <li><code>json.load(file)</code>: Deserializes a JSON file to a Python object.</li> </ul>"},{"location":"Cheat-Sheets/Python/#example_2","title":"Example","text":"<pre><code>import json\n\ndata = {\"name\": \"Alice\", \"age\": 30}\njson_string = json.dumps(data)\nprint(json_string)\n\nparsed_data = json.loads(json_string)\nprint(parsed_data[\"name\"])\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-csv-files","title":"Working with CSV Files","text":""},{"location":"Cheat-Sheets/Python/#importing-the-csv-module","title":"Importing the <code>csv</code> Module","text":"<pre><code>import csv\n</code></pre>"},{"location":"Cheat-Sheets/Python/#reading-csv-files","title":"Reading CSV Files","text":"<pre><code>with open('my_data.csv', 'r') as file:\n    reader = csv.reader(file)\n    for row in reader:\n        print(row)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#writing-csv-files","title":"Writing CSV Files","text":"<pre><code>data = [['Name', 'Age', 'City'],\n        ['Alice', 30, 'New York'],\n        ['Bob', 25, 'Paris']]\n\nwith open('output.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerows(data)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#reading-csv-files-as-dictionaries","title":"Reading CSV Files as Dictionaries","text":"<pre><code>import csv\n\nwith open('my_data.csv', mode='r') as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n    for row in csv_reader:\n        print(row['Name'], row['Age'], row['City'])\n</code></pre>"},{"location":"Cheat-Sheets/Python/#writing-csv-files-from-dictionaries","title":"Writing CSV Files from Dictionaries","text":"<pre><code>import csv\n\nfieldnames = ['Name', 'Age', 'City']\ndata = [\n    {'Name': 'Alice', 'Age': 30, 'City': 'New York'},\n    {'Name': 'Bob', 'Age': 25, 'City': 'Paris'}\n]\n\nwith open('output.csv', mode='w', newline='') as csv_file:\n    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n\n    writer.writeheader()\n    writer.writerows(data)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-os","title":"Working with OS","text":""},{"location":"Cheat-Sheets/Python/#importing-the-os-module","title":"Importing the <code>os</code> Module","text":"<pre><code>import os\n</code></pre>"},{"location":"Cheat-Sheets/Python/#common-functions_3","title":"Common Functions","text":"<ul> <li><code>os.getcwd()</code>: Returns the current working directory.</li> <li><code>os.chdir(path)</code>: Changes the current working directory.</li> <li><code>os.listdir(path)</code>: Returns a list of files and directories in a directory.</li> <li><code>os.mkdir(path)</code>: Creates a directory.</li> <li><code>os.makedirs(path)</code>: Creates a directory and any necessary parent directories.</li> <li><code>os.remove(path)</code>: Removes a file.</li> <li><code>os.rmdir(path)</code>: Removes a directory.</li> <li><code>os.path.join(path1, path2, ...)</code>: Joins path components.</li> <li><code>os.path.exists(path)</code>: Checks if a path exists.</li> <li><code>os.path.isfile(path)</code>: Checks if a path is a file.</li> <li><code>os.path.isdir(path)</code>: Checks if a path is a directory.</li> <li><code>os.path.splitext(path)</code>: Splits a path into filename and extension.</li> </ul>"},{"location":"Cheat-Sheets/Python/#example_3","title":"Example","text":"<pre><code>import os\n\ncurrent_directory = os.getcwd()\nprint(current_directory)\n\nnew_path = os.path.join(current_directory, \"my_folder\")\nif not os.path.exists(new_path):\n    os.makedirs(new_path)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-collections","title":"Working with Collections","text":""},{"location":"Cheat-Sheets/Python/#importing-the-collections-module","title":"Importing the <code>collections</code> Module","text":"<pre><code>import collections\n</code></pre>"},{"location":"Cheat-Sheets/Python/#common-data-structures","title":"Common Data Structures","text":"<ul> <li><code>Counter</code>: Counts the frequency of items in a sequence.</li> <li><code>defaultdict</code>: A dictionary that provides a default value for missing keys.</li> <li><code>namedtuple</code>: Creates named tuples.</li> <li><code>deque</code>: A double-ended queue.</li> </ul>"},{"location":"Cheat-Sheets/Python/#example_4","title":"Example","text":"<pre><code>from collections import Counter, defaultdict, namedtuple\n\n# Counter\nmy_list = [1, 2, 2, 3, 3, 3]\ncount = Counter(my_list)\nprint(count)\n\n# defaultdict\nmy_dict = defaultdict(int)\nmy_dict[\"a\"] += 1\nprint(my_dict[\"a\"])\nprint(my_dict[\"b\"])\n\n# namedtuple\nPoint = namedtuple(\"Point\", [\"x\", \"y\"])\np = Point(10, 20)\nprint(p.x, p.y)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-itertools","title":"Working with Itertools","text":""},{"location":"Cheat-Sheets/Python/#importing-the-itertools-module","title":"Importing the <code>itertools</code> Module","text":"<pre><code>import itertools\n</code></pre>"},{"location":"Cheat-Sheets/Python/#common-functions_4","title":"Common Functions","text":"<ul> <li><code>itertools.count(start, step)</code>: Returns an infinite iterator that produces consecutive integers.</li> <li><code>itertools.cycle(iterable)</code>: Returns an infinite iterator that cycles through the elements of an iterable.</li> <li><code>itertools.repeat(object, times)</code>: Returns an iterator that produces the same object a specified number of times.</li> <li><code>itertools.chain(*iterables)</code>: Chains multiple iterables together into a single iterator.</li> <li><code>itertools.combinations(iterable, r)</code>: Returns all possible combinations of length <code>r</code> from the elements of an iterable.</li> <li><code>itertools.permutations(iterable, r)</code>: Returns all possible permutations of length <code>r</code> from the elements of an iterable.</li> <li><code>itertools.product(*iterables)</code>: Returns the Cartesian product of multiple iterables.</li> <li><code>itertools.groupby(iterable, key)</code>: Groups consecutive elements of an iterable based on a key function.</li> </ul>"},{"location":"Cheat-Sheets/Python/#example_5","title":"Example","text":"<pre><code>import itertools\n\n# Count\nfor i in itertools.count(start=10, step=2):\n    if i &gt; 20:\n        break\n    print(i)\n\n# Cycle\ncount = 0\nfor item in itertools.cycle(['A', 'B', 'C']):\n    if count &gt; 5:\n        break\n    print(item)\n    count += 1\n\n# Combinations\nfor combo in itertools.combinations([1, 2, 3, 4], 2):\n    print(combo)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-functools","title":"Working with functools","text":""},{"location":"Cheat-Sheets/Python/#importing-the-functools-module","title":"Importing the <code>functools</code> Module","text":"<pre><code>import functools\n</code></pre>"},{"location":"Cheat-Sheets/Python/#common-functions_5","title":"Common Functions","text":"<ul> <li><code>functools.partial(func, *args, **kwargs)</code>: Creates a new function with some of the arguments of the original function pre-filled.</li> <li><code>functools.lru_cache(maxsize=128)</code>: Decorator that caches the results of a function call.</li> <li><code>functools.reduce(function, iterable[, initializer])</code>: Apply function of two arguments cumulatively to the items of iterable, from left to right, so as to reduce the iterable to a single value.</li> </ul>"},{"location":"Cheat-Sheets/Python/#example_6","title":"Example","text":"<pre><code>import functools\n\ndef power(base, exponent):\n    return base ** exponent\n\nsquare = functools.partial(power, exponent=2)\ncube = functools.partial(power, exponent=3)\n\nprint(square(5))  # Output: 25\nprint(cube(2))    # Output: 8\n\n@functools.lru_cache(maxsize=None)\ndef fibonacci(n):\n    if n &lt; 2:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\nprint(fibonacci(10))\n</code></pre>"},{"location":"Cheat-Sheets/Python/#concurrency-and-parallelism","title":"Concurrency and Parallelism","text":""},{"location":"Cheat-Sheets/Python/#threads","title":"Threads","text":"<pre><code>import threading\n\ndef my_task(name):\n    print(f\"Thread {name}: starting\")\n    # Perform some work\n    print(f\"Thread {name}: finishing\")\n\nthreads = []\nfor i in range(3):\n    t = threading.Thread(target=my_task, args=(i,))\n    threads.append(t)\n    t.start()\n\nfor t in threads:\n    t.join()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#processes","title":"Processes","text":"<pre><code>import multiprocessing\n\ndef my_task(name):\n    print(f\"Process {name}: starting\")\n    # Perform some work\n    print(f\"Process {name}: finishing\")\n\nprocesses = []\nfor i in range(3):\n    p = multiprocessing.Process(target=my_task, args=(i,))\n    processes.append(p)\n    p.start()\n\nfor p in processes:\n    p.join()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#asyncio","title":"Asyncio","text":"<pre><code>import asyncio\n\nasync def my_coroutine(name):\n    print(f\"Coroutine {name}: starting\")\n    await asyncio.sleep(1)\n    print(f\"Coroutine {name}: finishing\")\n\nasync def main():\n    tasks = [my_coroutine(i) for i in range(3)]\n    await asyncio.gather(*tasks)\n\nasyncio.run(main())\n</code></pre>"},{"location":"Cheat-Sheets/Python/#type-hints","title":"Type Hints","text":"<pre><code>def add(x: int, y: int) -&gt; int:\n    return x + y\n\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\nfrom typing import List, Tuple, Dict\n\nmy_list: List[int] = [1, 2, 3]\nmy_tuple: Tuple[str, int] = (\"Alice\", 30)\nmy_dict: Dict[str, int] = {\"a\": 1, \"b\": 2}\n</code></pre>"},{"location":"Cheat-Sheets/Python/#virtual-environments","title":"Virtual Environments","text":""},{"location":"Cheat-Sheets/Python/#creating-a-virtual-environment","title":"Creating a Virtual Environment","text":"<pre><code>python -m venv myenv\n</code></pre>"},{"location":"Cheat-Sheets/Python/#activating-a-virtual-environment","title":"Activating a Virtual Environment","text":"<p>On Linux/macOS:</p> <pre><code>source myenv/bin/activate\n</code></pre> <p>On Windows:</p> <pre><code>myenv\\Scripts\\activate\n</code></pre>"},{"location":"Cheat-Sheets/Python/#deactivating-a-virtual-environment","title":"Deactivating a Virtual Environment","text":"<pre><code>deactivate\n</code></pre>"},{"location":"Cheat-Sheets/Python/#testing","title":"Testing","text":""},{"location":"Cheat-Sheets/Python/#using-unittest","title":"Using <code>unittest</code>","text":"<pre><code>import unittest\n\nclass MyTestCase(unittest.TestCase):\n    def test_addition(self):\n        self.assertEqual(1 + 1, 2)\n\n    def test_subtraction(self):\n        self.assertNotEqual(5 - 2, 4)\n\nif __name__ == '__main__':\n    unittest.main()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#using-pytest","title":"Using <code>pytest</code>","text":"<p>Installation:</p> <pre><code>pip install pytest\n</code></pre> <p>Test Example:</p> <pre><code># test_my_module.py\ndef add(x, y):\n    return x + y\n\ndef test_add():\n    assert add(1, 2) == 3\n    assert add(-1, 1) == 0\n</code></pre> <p>Run tests:</p> <pre><code>pytest\n</code></pre>"},{"location":"Cheat-Sheets/Python/#decorators","title":"Decorators","text":"<pre><code>def my_decorator(func):\n    def wrapper(*args, **kwargs):\n        print(\"Before function execution\")\n        result = func(*args, **kwargs)\n        print(\"After function execution\")\n        return result\n    return wrapper\n\n@my_decorator\ndef say_hello(name):\n    print(f\"Hello, {name}!\")\n\nsay_hello(\"Alice\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#context-managers","title":"Context Managers","text":"<pre><code>with open(\"my_file.txt\", \"r\") as f:\n    content = f.read()\n    print(content)\n\n# Custom context manager\nclass MyContextManager:\n    def __enter__(self):\n        print(\"Entering the context\")\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\"Exiting the context\")\n        if exc_type:\n            print(f\"An exception occurred: {exc_type}\")\n\n    def do_something(self):\n        print(\"Doing something in the context\")\n\nwith MyContextManager() as cm:\n    cm.do_something()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#object-oriented-programming-oop","title":"Object-Oriented Programming (OOP)","text":""},{"location":"Cheat-Sheets/Python/#classes-and-objects","title":"Classes and Objects","text":"<pre><code>class Dog:\n    def __init__(self, name, breed):\n        self.name = name\n        self.breed = breed\n\n    def bark(self):\n        print(\"Woof!\")\n\nmy_dog = Dog(\"Buddy\", \"Golden Retriever\")\nprint(my_dog.name)\nmy_dog.bark()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#inheritance","title":"Inheritance","text":"<pre><code>class Animal:\n    def __init__(self, name):\n        self.name = name\n\n    def speak(self):\n        raise NotImplementedError(\"Subclass must implement abstract method\")\n\nclass Dog(Animal):\n    def speak(self):\n        return \"Woof!\"\n\nclass Cat(Animal):\n    def speak(self):\n        return \"Meow!\"\n\ndog = Dog(\"Buddy\")\ncat = Cat(\"Whiskers\")\nprint(dog.speak())\nprint(cat.speak())\n</code></pre>"},{"location":"Cheat-Sheets/Python/#encapsulation","title":"Encapsulation","text":"<pre><code>class MyClass:\n    def __init__(self):\n        self._protected_variable = 10  # Protected variable (convention)\n        self.__private_variable = 20  # Private variable (name mangling)\n\n    def get_private(self): #getter\n        return self.__private_variable\n\n    def set_private(self, value): #setter\n        if value &gt; 0:\n            self.__private_variable = value\n\nobj = MyClass()\nprint(obj._protected_variable)\n# print(obj.__private_variable)  # AttributeError: 'MyClass' object has no attribute '__private_variable'\nprint(obj.get_private()) # Accessing private variable through a getter method.\nobj.set_private(30)\nprint(obj.get_private())\n</code></pre>"},{"location":"Cheat-Sheets/Python/#polymorphism","title":"Polymorphism","text":"<pre><code>class Animal:\n    def speak(self):\n        raise NotImplementedError(\"Subclass must implement abstract method\")\n\nclass Dog(Animal):\n    def speak(self):\n        return \"Woof!\"\n\nclass Cat(Animal):\n    def speak(self):\n        return \"Meow!\"\n\ndef animal_sound(animal):\n    print(animal.speak())\n\ndog = Dog(\"Buddy\")\ncat = Cat(\"Whiskers\")\nanimal_sound(dog)\nanimal_sound(cat)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#class-methods-and-static-methods","title":"Class Methods and Static Methods","text":"<pre><code>class MyClass:\n    class_variable = 0\n\n    def __init__(self, instance_variable):\n        self.instance_variable = instance_variable\n\n    @classmethod\n    def increment_class_variable(cls):\n        cls.class_variable += 1\n\n    @staticmethod\n    def static_method():\n        print(\"This is a static method\")\n\nMyClass.increment_class_variable()\nprint(MyClass.class_variable)\nMyClass.static_method()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#metaclasses","title":"Metaclasses","text":"<pre><code>class MyMetaclass(type):\n    def __new__(cls, name, bases, attrs):\n        attrs['attribute'] = 100\n        return super().__new__(cls, name, bases, attrs)\n\nclass MyClass(metaclass=MyMetaclass):\n    pass\n\nobj = MyClass()\nprint(obj.attribute)  # Output: 100\n</code></pre>"},{"location":"Cheat-Sheets/Python/#abstract-base-classes-abcs","title":"Abstract Base Classes (ABCs)","text":"<pre><code>from abc import ABC, abstractmethod\n\nclass MyAbstractClass(ABC):\n    @abstractmethod\n    def my_method(self):\n        pass\n\nclass MyConcreteClass(MyAbstractClass):\n    def my_method(self):\n        print(\"Implementation of my_method\")\n\n# obj = MyAbstractClass()  # TypeError: Can't instantiate abstract class MyAbstractClass with abstract methods my_method\nobj = MyConcreteClass()\nobj.my_method()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#exception-handling","title":"Exception Handling","text":"<pre><code>try:\n    result = 10 / 0\nexcept ZeroDivisionError:\n    print(\"Cannot divide by zero\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\nelse:\n    print(\"No errors occurred\")\nfinally:\n    print(\"This will always execute\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#raising-exceptions","title":"Raising Exceptions","text":"<pre><code>def divide(x, y):\n    if y == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return x / y\n</code></pre>"},{"location":"Cheat-Sheets/Python/#custom-exceptions","title":"Custom Exceptions","text":"<pre><code>class MyCustomError(Exception):\n    pass\n\ndef my_function():\n    raise MyCustomError(\"Something went wrong\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#iterators-and-generators","title":"Iterators and Generators","text":""},{"location":"Cheat-Sheets/Python/#iterators","title":"Iterators","text":"<pre><code>my_list = [1, 2, 3]\nmy_iterator = iter(my_list)\nprint(next(my_iterator))\nprint(next(my_iterator))\nprint(next(my_iterator))\n</code></pre>"},{"location":"Cheat-Sheets/Python/#generators_1","title":"Generators","text":"<pre><code>def my_generator(n):\n    for i in range(n):\n        yield i ** 2\n\nfor value in my_generator(5):\n    print(value)\n\n# Generator expression\nsquares = (x**2 for x in range(5))\nfor square in squares:\n    print(square)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#decorators_1","title":"Decorators","text":"<pre><code>def my_decorator(func):\n    def wrapper(*args, **kwargs):\n        print(\"Before function execution\")\n        result = func(*args, **kwargs)\n        print(\"After function execution\")\n        return result\n    return wrapper\n\n@my_decorator\ndef say_hello(name):\n    print(f\"Hello, {name}!\")\n\nsay_hello(\"Alice\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#decorators-with-arguments","title":"Decorators with Arguments","text":"<pre><code>def repeat(num_times):\n    def decorator_repeat(func):\n        def wrapper(*args, **kwargs):\n            for _ in range(num_times):\n                result = func(*args, **kwargs)\n            return result\n        return wrapper\n    return decorator_repeat\n\n@repeat(num_times=3)\ndef greet(name):\n    print(f\"Hello {name}\")\n\ngreet(\"Alice\")\n</code></pre>"},{"location":"Cheat-Sheets/Python/#context-managers_1","title":"Context Managers","text":"<pre><code>with open(\"my_file.txt\", \"r\") as f:\n    content = f.read()\n    print(content)\n\n# Custom context manager\nclass MyContextManager:\n    def __enter__(self):\n        print(\"Entering the context\")\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\"Exiting the context\")\n        if exc_type:\n            print(f\"An exception occurred: {exc_type}\")\n\n    def do_something(self):\n        print(\"Doing something in the context\")\n\nwith MyContextManager() as cm:\n    cm.do_something()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#descriptors","title":"Descriptors","text":"<pre><code>class MyDescriptor:\n    def __get__(self, instance, owner):\n        print(f\"Getting: instance={instance}, owner={owner}\")\n        return instance._value\n\n    def __set__(self, instance, value):\n        print(f\"Setting: instance={instance}, value={value}\")\n        instance._value = value\n\n    def __delete__(self, instance):\n        print(f\"Deleting: instance={instance}\")\n        del instance._value\n\nclass MyClass:\n    my_attribute = MyDescriptor()\n\nobj = MyClass()\nobj.my_attribute = 10\nprint(obj.my_attribute)\ndel obj.my_attribute\n</code></pre>"},{"location":"Cheat-Sheets/Python/#metaclasses_1","title":"Metaclasses","text":"<pre><code>class MyMetaclass(type):\n    def __new__(cls, name, bases, attrs):\n        attrs['attribute'] = 100\n        return super().__new__(cls, name, bases, attrs)\n\nclass MyClass(metaclass=MyMetaclass):\n    pass\n\nobj = MyClass()\nprint(obj.attribute)  # Output: 100\n</code></pre>"},{"location":"Cheat-Sheets/Python/#abstract-base-classes-abcs_1","title":"Abstract Base Classes (ABCs)","text":"<pre><code>from abc import ABC, abstractmethod\n\nclass MyAbstractClass(ABC):\n    @abstractmethod\n    def my_method(self):\n        pass\n\nclass MyConcreteClass(MyAbstractClass):\n    def my_method(self):\n        print(\"Implementation of my_method\")\n\n# obj = MyAbstractClass()  # TypeError: Can't instantiate abstract class MyAbstractClass with abstract methods my_method\nobj = MyConcreteClass()\nobj.my_method()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-dates-and-times","title":"Working with Dates and Times","text":"<pre><code>import datetime\n\nnow = datetime.datetime.now()\nprint(now)\n\ntoday = datetime.date.today()\nprint(today)\n\n# Creating datetime objects\ndt = datetime.datetime(2024, 1, 1, 12, 30, 0)\n\n# Formatting datetime objects\nformatted_date = now.strftime(\"%Y-%m-%d %H:%M:%S\")\nprint(formatted_date)\n\n# Parsing strings into datetime objects\nparsed_date = datetime.datetime.strptime(\"2024-01-01 12:30:00\", \"%Y-%m-%d %H:%M:%S\")\nprint(parsed_date)\n\n# Time deltas\ndelta = datetime.timedelta(days=5, hours=3)\nnew_date = now + delta\nprint(new_date)\n\n# Working with timezones\nimport pytz\ntimezone = pytz.timezone(\"America/Los_Angeles\")\nlocalized_time = timezone.localize(datetime.datetime(2024, 1, 1, 12, 0, 0))\nprint(localized_time)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-csv-files_1","title":"Working with CSV Files","text":"<pre><code>import csv\n\n# Reading CSV files\nwith open('my_data.csv', 'r') as file:\n    reader = csv.reader(file)\n    for row in reader:\n        print(row)\n\n# Writing CSV files\ndata = [['Name', 'Age', 'City'],\n        ['Alice', 30, 'New York'],\n        ['Bob', 25, 'Paris']]\n\nwith open('output.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerows(data)\n\n# Reading CSV files as dictionaries\nwith open('my_data.csv', mode='r') as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n    for row in csv_reader:\n        print(row['Name'], row['Age'], row['City'])\n\n# Writing CSV files from dictionaries\nfieldnames = ['Name', 'Age', 'City']\ndata = [\n    {'Name': 'Alice', 'Age': 30, 'City': 'New York'},\n    {'Name': 'Bob', 'Age': 25, 'City': 'Paris'}\n]\n\nwith open('output.csv', mode='w', newline='') as csv_file:\n    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n\n    writer.writeheader()\n    writer.writerows(data)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-json","title":"Working with JSON","text":"<pre><code>import json\n\n# Serializing Python objects to JSON\ndata = {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\njson_string = json.dumps(data, indent=4) # indent for pretty printing\nprint(json_string)\n\n# Deserializing JSON to Python objects\nparsed_data = json.loads(json_string)\nprint(parsed_data[\"name\"])\n\n# Reading JSON from a file\nwith open(\"data.json\", \"r\") as f:\n    data = json.load(f)\n\n# Writing JSON to a file\nwith open(\"data.json\", \"w\") as f:\n    json.dump(data, f, indent=4)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-regular-expressions","title":"Working with Regular Expressions","text":"<pre><code>import re\n\ntext = \"The quick brown fox jumps over the lazy dog.\"\npattern = r\"\\b\\w{5}\\b\"  # Matches 5-letter words\n\n# Search for a pattern\nmatch = re.search(pattern, text)\nif match:\n    print(match.group(0))\n\n# Find all occurrences of a pattern\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['quick', 'brown', 'jumps']\n\n# Replace occurrences of a pattern\nnew_text = re.sub(pattern, \"five\", text)\nprint(new_text)\n\n# Split a string by a pattern\nparts = re.split(r\"\\s+\", text) # Split by whitespace\nprint(parts)\n\n# Compile a pattern for reuse\ncompiled_pattern = re.compile(pattern)\nmatches = compiled_pattern.findall(text)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-os_1","title":"Working with OS","text":"<pre><code>import os\n\n# Get the current working directory\ncurrent_directory = os.getcwd()\nprint(current_directory)\n\n# Change the current working directory\nos.chdir(\"/path/to/new/directory\")\n\n# List files and directories\nfiles_and_dirs = os.listdir(\".\")\nprint(files_and_dirs)\n\n# Create a directory\nos.mkdir(\"my_new_directory\")\nos.makedirs(\"path/to/new/directory\") # Creates intermediate directories as needed\n\n# Remove a file\nos.remove(\"my_file.txt\")\n\n# Remove a directory\nos.rmdir(\"my_empty_directory\")\nimport shutil\nshutil.rmtree(\"my_directory\") # Removes a directory and its contents\n\n# Join path components\nnew_path = os.path.join(current_directory, \"my_folder\")\nprint(new_path)\n\n# Check if a path exists\nif os.path.exists(new_path):\n    print(\"Path exists\")\n\n# Check if a path is a file\nif os.path.isfile(\"my_file.txt\"):\n    print(\"It's a file\")\n\n# Check if a path is a directory\nif os.path.isdir(\"my_folder\"):\n    print(\"It's a directory\")\n\n# Get the file extension\nfilename, extension = os.path.splitext(\"my_file.txt\")\nprint(extension)\n\n# Get environment variables\nprint(os.environ.get(\"HOME\"))\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-collections_1","title":"Working with Collections","text":"<pre><code>import collections\n\n# Counter\nmy_list = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]\ncount = collections.Counter(my_list)\nprint(count)\nprint(count.most_common(2))\n\n# defaultdict\nmy_dict = collections.defaultdict(int)\nmy_dict[\"a\"] += 1\nprint(my_dict[\"a\"])\nprint(my_dict[\"b\"])  # Accessing a missing key returns the default value\n\n# namedtuple\nPoint = collections.namedtuple(\"Point\", [\"x\", \"y\"])\np = Point(10, 20)\nprint(p.x, p.y)\n\n# deque\nmy_deque = collections.deque([1, 2, 3])\nmy_deque.append(4)\nmy_deque.appendleft(0)\nmy_deque.pop()\nmy_deque.popleft()\nprint(my_deque)\n\n# OrderedDict (less relevant in Python 3.7+ where dicts maintain insertion order)\nmy_ordered_dict = collections.OrderedDict()\nmy_ordered_dict['a'] = 1\nmy_ordered_dict['b'] = 2\nmy_ordered_dict['c'] = 3\nprint(my_ordered_dict)\n\n# ChainMap\ndict1 = {'a': 1, 'b': 2}\ndict2 = {'c': 3, 'd': 4}\nchain = collections.ChainMap(dict1, dict2)\nprint(chain['a'])\nprint(chain['c'])\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-itertools_1","title":"Working with Itertools","text":"<pre><code>import itertools\n\n# Count\nfor i in itertools.count(start=10, step=2):\n    if i &gt; 20:\n        break\n    print(i)\n\n# Cycle\ncount = 0\nfor item in itertools.cycle(['A', 'B', 'C']):\n    if count &gt; 5:\n        break\n    print(item)\n    count += 1\n\n# Repeat\nfor item in itertools.repeat(\"Hello\", 3):\n    print(item)\n\n# Chain\nlist1 = [1, 2, 3]\nlist2 = [4, 5, 6]\nfor item in itertools.chain(list1, list2):\n    print(item)\n\n# Combinations\nfor combo in itertools.combinations([1, 2, 3, 4], 2):\n    print(combo)\n\n# Permutations\nfor perm in itertools.permutations([1, 2, 3], 2):\n    print(perm)\n\n# Product\nfor prod in itertools.product([1, 2], ['a', 'b']):\n    print(prod)\n\n# Groupby\ndata = [('A', 1), ('A', 2), ('B', 3), ('B', 4), ('C', 5)]\nfor key, group in itertools.groupby(data, key=lambda x: x[0]):\n    print(key, list(group))\n\n# islice\ndata = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nfor item in itertools.islice(data, 2, 7, 2):  # start, stop, step\n    print(item)\n\n# starmap\ndata = [(1, 2), (3, 4), (5, 6)]\nfor result in itertools.starmap(lambda x, y: x * y, data):\n    print(result)\n\n# takewhile\ndata = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nfor item in itertools.takewhile(lambda x: x &lt; 5, data):\n    print(item)\n\n# dropwhile\nfor item in itertools.dropwhile(lambda x: x &lt; 5, data):\n    print(item)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#working-with-functools_1","title":"Working with Functools","text":"<pre><code>import functools\n\n# partial\ndef power(base, exponent):\n    return base ** exponent\n\nsquare = functools.partial(power, exponent=2)\ncube = functools.partial(power, exponent=3)\n\nprint(square(5))  # Output: 25\nprint(cube(2))    # Output: 8\n\n# lru_cache\n@functools.lru_cache(maxsize=None)\ndef fibonacci(n):\n    if n &lt; 2:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)\n\nprint(fibonacci(10))\n\n# reduce\nnumbers = [1, 2, 3, 4, 5]\nproduct = functools.reduce(lambda x, y: x * y, numbers)\nprint(product)\n\n# wraps\ndef my_decorator(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        \"\"\"Wrapper function docstring\"\"\"\n        print(\"Before function execution\")\n        result = func(*args, **kwargs)\n        print(\"After function execution\")\n        return result\n    return wrapper\n\n@my_decorator\ndef say_hello(name):\n    \"\"\"This function greets the person passed in as a parameter.\"\"\"\n    print(f\"Hello, {name}!\")\n\nprint(say_hello.__name__) # Output: say_hello\nprint(say_hello.__doc__) # Output: This function greets the person passed in as a parameter.\n</code></pre>"},{"location":"Cheat-Sheets/Python/#concurrency-and-parallelism_1","title":"Concurrency and Parallelism","text":""},{"location":"Cheat-Sheets/Python/#threads_1","title":"Threads","text":"<pre><code>import threading\n\ndef my_task(name):\n    print(f\"Thread {name}: starting\")\n    # Perform some work\n    print(f\"Thread {name}: finishing\")\n\nthreads = []\nfor i in range(3):\n    t = threading.Thread(target=my_task, args=(i,))\n    threads.append(t)\n    t.start()\n\nfor t in threads:\n    t.join()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#processes_1","title":"Processes","text":"<pre><code>import multiprocessing\n\ndef my_task(name):\n    print(f\"Process {name}: starting\")\n    # Perform some work\n    print(f\"Process {name}: finishing\")\n\nprocesses = []\nfor i in range(3):\n    p = multiprocessing.Process(target=my_task, args=(i,))\n    processes.append(p)\n    p.start()\n\nfor p in processes:\n    p.join()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#asyncio_1","title":"Asyncio","text":"<pre><code>import asyncio\n\nasync def my_coroutine(name):\n    print(f\"Coroutine {name}: starting\")\n    await asyncio.sleep(1)\n    print(f\"Coroutine {name}: finishing\")\n\nasync def main():\n    tasks = [my_coroutine(i) for i in range(3)]\n    await asyncio.gather(*tasks)\n\nasyncio.run(main())\n</code></pre>"},{"location":"Cheat-Sheets/Python/#threadpoolexecutor","title":"ThreadPoolExecutor","text":"<pre><code>from concurrent.futures import ThreadPoolExecutor\n\ndef task(n):\n    print(f\"Processing {n}\")\n    return n * 2\n\nwith ThreadPoolExecutor(max_workers=3) as executor:\n    results = executor.map(task, range(5))\n    for result in results:\n        print(result)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#processpoolexecutor","title":"ProcessPoolExecutor","text":"<pre><code>from concurrent.futures import ProcessPoolExecutor\n\ndef task(n):\n    print(f\"Processing {n}\")\n    return n * 2\n\nwith ProcessPoolExecutor(max_workers=3) as executor:\n    results = executor.map(task, range(5))\n    for result in results:\n        print(result)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#type-hints_1","title":"Type Hints","text":"<pre><code>def add(x: int, y: int) -&gt; int:\n    return x + y\n\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\nfrom typing import List, Tuple, Dict, Optional, Union, Any\n\nmy_list: List[int] = [1, 2, 3]\nmy_tuple: Tuple[str, int] = (\"Alice\", 30)\nmy_dict: Dict[str, int] = {\"a\": 1, \"b\": 2}\n\ndef process_item(item: Union[str, int]) -&gt; Optional[str]:\n    if isinstance(item, str):\n        return item.upper()\n    elif isinstance(item, int):\n        return str(item * 2)\n    else:\n        return None\n\ndef my_function(x: Any) -&gt; None:\n    pass\n</code></pre>"},{"location":"Cheat-Sheets/Python/#virtual-environments_1","title":"Virtual Environments","text":""},{"location":"Cheat-Sheets/Python/#creating-a-virtual-environment_1","title":"Creating a Virtual Environment","text":"<pre><code>python -m venv myenv\n</code></pre>"},{"location":"Cheat-Sheets/Python/#activating-a-virtual-environment_1","title":"Activating a Virtual Environment","text":"<p>On Linux/macOS:</p> <pre><code>source myenv/bin/activate\n</code></pre> <p>On Windows:</p> <pre><code>myenv\\Scripts\\activate\n</code></pre>"},{"location":"Cheat-Sheets/Python/#deactivating-a-virtual-environment_1","title":"Deactivating a Virtual Environment","text":"<pre><code>deactivate\n</code></pre>"},{"location":"Cheat-Sheets/Python/#testing_1","title":"Testing","text":""},{"location":"Cheat-Sheets/Python/#using-unittest_1","title":"Using <code>unittest</code>","text":"<pre><code>import unittest\n\nclass MyTestCase(unittest.TestCase):\n    def test_addition(self):\n        self.assertEqual(1 + 1, 2)\n\n    def test_subtraction(self):\n        self.assertNotEqual(5 - 2, 4)\n\n    def test_raises_exception(self):\n        with self.assertRaises(ValueError):\n            raise ValueError\n\nif __name__ == '__main__':\n    unittest.main()\n</code></pre>"},{"location":"Cheat-Sheets/Python/#using-pytest_1","title":"Using <code>pytest</code>","text":"<p>Installation:</p> <pre><code>pip install pytest\n</code></pre> <p>Test Example:</p> <pre><code># test_my_module.py\ndef add(x, y):\n    return x + y\n\ndef test_add():\n    assert add(1, 2) == 3\n    assert add(-1, 1) == 0\n</code></pre> <p>Run tests:</p> <pre><code>pytest\n</code></pre>"},{"location":"Cheat-Sheets/Python/#logging","title":"Logging","text":"<pre><code>import logging\n\n# Basic configuration\nlogging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n# Create a logger\nlogger = logging.getLogger(__name__)\n\n# Log messages\nlogger.debug(\"This is a debug message\")\nlogger.info(\"This is an info message\")\nlogger.warning(\"This is a warning message\")\nlogger.error(\"This is an error message\")\nlogger.critical(\"This is a critical message\")\n\n# Logging to a file\nfile_handler = logging.FileHandler('my_log.log')\nfile_handler.setLevel(logging.WARNING)\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#debugging","title":"Debugging","text":""},{"location":"Cheat-Sheets/Python/#using-pdb-python-debugger","title":"Using <code>pdb</code> (Python Debugger)","text":"<pre><code>import pdb\n\ndef my_function(x, y):\n    z = x + y\n    pdb.set_trace()  # Set a breakpoint\n    return z\n\nmy_function(1, 2)\n</code></pre>"},{"location":"Cheat-Sheets/Python/#using-print-statements","title":"Using <code>print()</code> Statements","text":"<pre><code>def my_function(x, y):\n    print(f\"x: {x}, y: {y}\")\n    z = x + y\n    print(f\"z: {z}\")\n    return z\n</code></pre>"},{"location":"Cheat-Sheets/Python/#best-practices","title":"Best Practices","text":"<ul> <li>Use virtual environments to isolate project dependencies.</li> <li>Use meaningful names for variables and functions.</li> <li>Follow the DRY (Don't Repeat Yourself) principle.</li> <li>Write unit tests to ensure code quality.</li> <li>Use a consistent coding style (PEP 8).</li> <li>Document your code.</li> <li>Use a version control system (e.g., Git).</li> <li>Use appropriate data types for your data.</li> <li>Handle exceptions gracefully.</li> <li>Use logging to track events and errors.</li> <li>Use a security linter (e.g., Bandit) to identify potential vulnerabilities.</li> <li>Follow security best practices.</li> <li>Use a linter (like <code>flake8</code>) and formatter (like <code>black</code>) to ensure consistent code style.</li> <li>Use a code coverage tool (like <code>coverage.py</code>) to measure test coverage.</li> <li>Use a static analysis tool (like <code>mypy</code>) to check for type errors.</li> <li>Use a profiler to identify performance bottlenecks.</li> <li>Use a debugger to step through your code and inspect variables.</li> <li>Use a build tool (like <code>setuptools</code>) to package and distribute your code.</li> <li>Use a continuous integration (CI) system to automatically run tests and build your code.</li> <li>Use a continuous deployment (CD) system to automatically deploy your code to production.</li> <li>Use a monitoring tool to track the performance of your application in production.</li> <li>Use a configuration management tool (like Ansible, Chef, or Puppet) to manage your infrastructure.</li> <li>Use a containerization tool like Docker.</li> <li>Use an orchestration tool like Kubernetes.</li> </ul>"},{"location":"Cheat-Sheets/RegEx/","title":"Regular Expressions (RegEx) Cheat Sheet","text":"<ul> <li>Regular Expressions (RegEx) Cheat Sheet<ul> <li>Basic Syntax<ul> <li>Literals</li> <li>Special Characters</li> <li>Character Classes</li> <li>Predefined Character Classes</li> <li>Quantifiers</li> <li>Anchors</li> <li>Alternation</li> <li>Grouping and Capturing</li> <li>Lookarounds</li> <li>Flags (Modifiers)</li> <li>Character Properties (Unicode)</li> <li>Examples</li> </ul> </li> <li>Advanced Techniques<ul> <li>Atomic Groups</li> <li>Recursive Patterns</li> <li>Conditional Expressions</li> <li>Named Capture Groups</li> <li>Comments</li> <li>Free-Spacing Mode (x flag)</li> <li>Branch Reset Groups</li> <li>Subroutine Calls</li> </ul> </li> <li>Common RegEx Engines and Differences</li> <li>Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of regular expressions (RegEx), covering syntax, character classes, quantifiers, anchors, groups, flags, and advanced techniques. It aims to be a complete reference for using regular expressions, with a focus on Python examples.</p>"},{"location":"Cheat-Sheets/RegEx/#basic-syntax","title":"Basic Syntax","text":""},{"location":"Cheat-Sheets/RegEx/#literals","title":"Literals","text":"<p>Characters match themselves literally, except for special characters.</p> <ul> <li><code>abc</code>: Matches the literal string \"abc\".</li> </ul> <pre><code>import re\ntext = \"abc def ghi\"\npattern = r\"abc\"\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: abc\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#special-characters","title":"Special Characters","text":"<p>These characters have special meanings in RegEx:</p> <ul> <li><code>. ^ $ * + ? { } [ ] \\ | ( )</code></li> </ul> <p>To match these characters literally, escape them with a backslash (<code>\\</code>):</p> <ul> <li><code>\\.</code>: Matches a literal dot (<code>.</code>).</li> <li><code>\\\\</code>: Matches a literal backslash (<code>\\</code>).</li> </ul> <pre><code>import re\ntext = \"123.456\"\npattern = r\"\\.\"  # Matches a literal dot\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: .\n\ntext = \"path\\\\to\\\\file\"\npattern = r\"\\\\\" # Matches a literal backslash\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\") # Output: \\\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#character-classes","title":"Character Classes","text":"<ul> <li><code>.</code>: Matches any character except a newline (unless the <code>s</code> flag is used).</li> <li><code>[abc]</code>: Matches any character inside the brackets (a, b, or c).</li> <li><code>[^abc]</code>: Matches any character not inside the brackets.</li> <li><code>[a-z]</code>: Matches any character in the range a to z (lowercase).</li> <li><code>[A-Z]</code>: Matches any character in the range A to Z (uppercase).</li> <li><code>[0-9]</code>: Matches any digit.</li> <li><code>[a-zA-Z0-9]</code>: Matches any alphanumeric character.</li> </ul> <pre><code>import re\n\ntext = \"apple banana cherry\"\npattern = r\"[abc]\"  # Matches 'a', 'b', or 'c'\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['a', 'a', 'b', 'a', 'a', 'a', 'a', 'c']\n\ntext = \"apple banana cherry\"\npattern = r\"[^abc]\"  # Matches any character except 'a', 'b', or 'c'\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['p', 'p', 'l', 'e', ' ', 'n', 'n', ' ', 'h', 'e', 'r', 'r', 'y']\n\ntext = \"apple1 banana2 cherry3\"\npattern = r\"[0-9]\"  # Matches any digit\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['1', '2', '3']\n\ntext = \"Hello. World!\"\npattern = r\".\" # Matches any character except newline\nmatches = re.findall(pattern, text)\nprint(matches) # Output: ['H', 'e', 'l', 'l', 'o', '.', ' ', 'W', 'o', 'r', 'l', 'd', '!']\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#predefined-character-classes","title":"Predefined Character Classes","text":"<ul> <li><code>\\d</code>: Matches any digit (equivalent to <code>[0-9]</code>).</li> <li><code>\\D</code>: Matches any non-digit (equivalent to <code>[^0-9]</code>).</li> <li><code>\\w</code>: Matches any word character (alphanumeric + underscore, equivalent to <code>[a-zA-Z0-9_]</code>).</li> <li><code>\\W</code>: Matches any non-word character (equivalent to <code>[^a-zA-Z0-9_]</code>).</li> <li><code>\\s</code>: Matches any whitespace character (space, tab, newline, etc.).</li> <li><code>\\S</code>: Matches any non-whitespace character.</li> <li><code>\\b</code>: Matches a word boundary.</li> <li><code>\\B</code>: Matches a non-word boundary.</li> <li><code>\\t</code>: Matches a tab character.</li> <li><code>\\n</code>: Matches a newline character.</li> <li><code>\\r</code>: Matches a carriage return character.</li> <li><code>\\f</code>: Matches a form feed character.</li> <li><code>\\v</code>: Matches a vertical tab character.</li> <li><code>\\0</code>: Matches a null character.</li> <li><code>[\\b]</code>: Matches a backspace character (inside a character class).</li> </ul> <pre><code>import re\n\ntext = \"123 abc 456\"\npattern = r\"\\d+\"  # Matches one or more digits\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['123', '456']\n\ntext = \"Hello World\"\npattern = r\"\\bWorld\\b\"  # Matches \"World\" at a word boundary\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: World\n\ntext = \"Hello\\tWorld\\n\"\npattern = r\"\\s+\"  # Matches one or more whitespace characters\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['\\t', '\\n']\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#quantifiers","title":"Quantifiers","text":"<ul> <li><code>*</code>: Matches 0 or more occurrences.</li> <li><code>+</code>: Matches 1 or more occurrences.</li> <li><code>?</code>: Matches 0 or 1 occurrence.</li> <li><code>{n}</code>: Matches exactly <code>n</code> occurrences.</li> <li><code>{n,}</code>: Matches <code>n</code> or more occurrences.</li> <li><code>{n,m}</code>: Matches between <code>n</code> and <code>m</code> occurrences (inclusive).</li> <li><code>*?</code>, <code>+?</code>, <code>??</code>, <code>{n,}?</code>, <code>{n,m}?</code>: Non-greedy (lazy) versions.</li> </ul> <pre><code>import re\n\ntext = \"aaabbbccc\"\npattern = r\"a+\"  # Matches one or more 'a's\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['aaa']\n\ntext = \"ab abb abbb\"\npattern = r\"ab{2,4}\"  # Matches 'ab' with 2 to 4 'b's\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['abb', 'abbb']\n\ntext = \"color colour\"\npattern = r\"colou?r\"  # Matches 'color' or 'colour'\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['color', 'colour']\n\ntext = \"aaaa\"\npattern = r\"a*?\" # Matches 0 or more 'a', non-greedy\nmatches = re.findall(pattern, text)\nprint(matches) # Output: ['', 'a', '', 'a', '', 'a', '', 'a', '']\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#anchors","title":"Anchors","text":"<ul> <li><code>^</code>: Matches the beginning of the string (or line).</li> <li><code>$</code>: Matches the end of the string (or line).</li> <li><code>\\A</code>: Matches the beginning of the string.</li> <li><code>\\Z</code>: Matches the end of the string, or before a newline at the end.</li> <li><code>\\z</code>: Matches the end of the string.</li> </ul> <pre><code>import re\n\ntext = \"hello world\"\npattern = r\"^hello\"  # Matches 'hello' at the beginning\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: hello\n\ntext = \"world\\nhello\"\npattern = r\"hello$\"  # Matches 'hello' at the end\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\") # Output: hello\n\ntext = \"hello world\\n\"\npattern = r\"\\Ahello\"\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\") # Output: hello\n\ntext = \"hello world\\n\"\npattern = r\"world\\Z\"\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\") # Output: world\n\ntext = \"hello world\"\npattern = r\"world\\z\"\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\") # Output: world\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#alternation","title":"Alternation","text":"<ul> <li><code>|</code>: Matches either the expression before or the expression after the <code>|</code>.</li> </ul> <pre><code>import re\n\ntext = \"cat and dog\"\npattern = r\"cat|dog\"  # Matches 'cat' or 'dog'\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['cat', 'dog']\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#grouping-and-capturing","title":"Grouping and Capturing","text":"<ul> <li><code>( )</code>: Groups expressions and creates a capturing group.</li> <li><code>(?: )</code>: Groups expressions without creating a capturing group.</li> <li><code>\\1</code>, <code>\\2</code>, etc.: Backreferences to captured groups.</li> </ul> <pre><code>import re\n\ntext = \"apple apple\"\npattern = r\"(\\w+) \\1\"  # Matches repeated words\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: apple apple\nprint(match.group(1)) if match else print(\"No match\")  # Output: apple\n\ntext = \"12-34-56\"\npattern = r\"(\\d{2})-(?:(\\d{2})-(\\d{2}))\"  # Non-capturing group for the middle part\nmatch = re.search(pattern, text)\nif match:\n    print(match.groups())  # Output: ('12', '34', '56')\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#lookarounds","title":"Lookarounds","text":"<ul> <li><code>(?= )</code>: Positive lookahead.</li> <li><code>(?! )</code>: Negative lookahead.</li> <li><code>(?&lt;= )</code>: Positive lookbehind.</li> <li><code>(?&lt;! )</code>: Negative lookbehind.</li> </ul> <pre><code>import re\n\ntext = \"apple123 banana456\"\npattern = r\"\\w+(?=\\d+)\"  # Matches words followed by digits (positive lookahead)\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['apple', 'banana']\n\ntext = \"apple banana cherry\"\npattern = r\"\\w+(?!e)\"  # Matches words NOT followed by 'e' (negative lookahead)\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['appl', 'banan', 'banan', 'cherr', 'cherr']\n\ntext = \"123apple 456banana\"\npattern = r\"(?&lt;=\\d+)\\w+\"  # Matches words preceded by digits (positive lookbehind)\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['apple', 'banana']\n\ntext = \"apple banana cherry\"\npattern = r\"(?&lt;!a)\\w+\"  # Matches words NOT preceded by 'a' (negative lookbehind)\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['pple', 'banana', 'cherry']\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#flags-modifiers","title":"Flags (Modifiers)","text":"<ul> <li><code>i</code>: Case-insensitive.</li> <li><code>m</code>: Multiline.</li> <li><code>s</code>: Dotall (single-line).</li> <li><code>g</code>: Global (find all matches).</li> <li><code>x</code>: Extended (allow whitespace and comments).</li> <li><code>u</code>: Unicode.</li> </ul> <pre><code>import re\n\ntext = \"Hello World\"\npattern = r\"world\"\nmatch = re.search(pattern, text, re.IGNORECASE)  # Case-insensitive\nprint(match.group(0)) if match else print(\"No match\")  # Output: World\n\ntext = \"Line 1\\nLine 2\\nLine 3\"\npattern = r\"^Line\"\nmatches = re.findall(pattern, text, re.MULTILINE)  # Multiline\nprint(matches)  # Output: ['Line', 'Line', 'Line']\n\ntext = \"Hello\\nWorld\"\npattern = r\"Hello.World\"\nmatch = re.search(pattern, text, re.DOTALL)  # Dotall\nprint(match.group(0)) if match else print(\"No match\")  # Output: Hello\\nWorld\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#character-properties-unicode","title":"Character Properties (Unicode)","text":"<ul> <li><code>\\p{Property}</code>: Matches a character with the specified Unicode property.</li> <li><code>\\P{Property}</code>: Matches a character without the specified Unicode property.</li> </ul> <pre><code>import re\n\ntext = \"Hello 123 \u3053\u3093\u306b\u3061\u306f\"\npattern = r\"\\p{L}+\"  # Matches one or more letters\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['Hello', '\u3053\u3093\u306b\u3061\u306f']\n\ntext = \"Hello 123 \u3053\u3093\u306b\u3061\u306f\"\npattern = r\"\\p{N}+\"  # Matches one or more numbers\nmatches = re.findall(pattern, text)\nprint(matches)  # Output: ['123']\n\ntext = \"Hello 123 \u3053\u3093\u306b\u3061\u306f\"\npattern = r\"\\P{L}+\"  # Matches one or more characters that are NOT letters\nmatches = re.findall(pattern, text)\nprint(matches) # Output: [' ', '123 ', ' ']\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#examples","title":"Examples","text":"<ul> <li>Email: <code>^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$</code></li> </ul> <pre><code>import re\nemail = \"test@example.com\"\npattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\nmatch = re.match(pattern, email)\nprint(bool(match))  # Output: True\n</code></pre> <ul> <li>URL: <code>^(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)*\\/?$</code></li> </ul> <pre><code>import re\nurl = \"https://www.example.com/path/to/page.html\"\npattern = r\"^(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)*\\/?$\"\nmatch = re.match(pattern, url)\nprint(bool(match))  # Output: True\n</code></pre> <ul> <li>IP Address: <code>^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$</code></li> </ul> <pre><code>import re\nip = \"192.168.1.1\"\npattern = r\"^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$\"\nmatch = re.match(pattern, ip)\nprint(bool(match))  # Output: True\n</code></pre> <ul> <li>Hex Color Code: <code>^#?([a-fA-F0-9]{6}|[a-fA-F0-9]{3})$</code></li> </ul> <pre><code>import re\nhex_code = \"#FF0000\"\npattern = r\"^#?([a-fA-F0-9]{6}|[a-fA-F0-9]{3})$\"\nmatch = re.match(pattern, hex_code)\nprint(bool(match))  # Output: True\n</code></pre> <ul> <li>Date (YYYY-MM-DD): <code>^\\d{4}-\\d{2}-\\d{2}$</code></li> </ul> <pre><code>import re\ndate = \"2024-01-08\"\npattern = r\"^\\d{4}-\\d{2}-\\d{2}$\"\nmatch = re.match(pattern, date)\nprint(bool(match))  # Output: True\n</code></pre> <ul> <li>HTML Tag: <code>&lt;([a-z]+)([^&lt;]+)*(?:&gt;(.*)&lt;\\/\\1&gt;|\\s+\\/&gt;)</code></li> </ul> <pre><code>import re\nhtml = \"&lt;p&gt;This is a paragraph.&lt;/p&gt;\"\npattern = r\"&lt;([a-z]+)([^&lt;]+)*(?:&gt;(.*)&lt;\\/\\1&gt;|\\s+\\/&gt;)\"\nmatch = re.search(pattern, html)\nprint(match.group(1)) if match else print(\"No match\")  # Output: p\n</code></pre> <ul> <li>Phone Number (US): <code>\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}</code></li> </ul> <pre><code>import re\nphone = \"(555) 123-4567\"\npattern = r\"\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\"\nmatch = re.search(pattern, phone)\nprint(bool(match))  # Output: True\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"Cheat-Sheets/RegEx/#atomic-groups","title":"Atomic Groups","text":"<ul> <li><code>(?&gt; )</code>: Atomic group.</li> </ul> <pre><code>import re\n\ntext = \"aaaaaaaaab\"\npattern = r\"a+b\"  # Regular +\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: ab\n\ntext = \"aaaaaaaaab\"\npattern = r\"a+?b\"  # Non-greedy +?\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: ab\n\ntext = \"aaaaaaaaab\"\npattern = r\"(?&gt;a+)b\"  # Atomic group\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: No match (because a+ consumed all 'a's)\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#recursive-patterns","title":"Recursive Patterns","text":"<ul> <li><code>(?R)</code> or <code>(?0)</code>: Recursively matches the entire pattern.</li> <li><code>(?1)</code>, <code>(?2)</code>, etc.: Recursively matches a specific capturing group.</li> </ul> <pre><code>import re\n\ntext = \"((abc)def(ghi))\"\npattern = r\"\\(([^()]|(?R))*\\)\"  # Matches balanced parentheses\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: ((abc)def(ghi))\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#conditional-expressions","title":"Conditional Expressions","text":"<ul> <li><code>(?(condition)yes-pattern|no-pattern)</code></li> </ul> <pre><code>import re\n\ntext = \"ab\"\npattern = r\"(?(?&lt;=a)b|c)\"  # If preceded by 'a', match 'b'; otherwise, match 'c'.\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: b\n\ntext = \"cb\"\npattern = r\"(?(?&lt;=a)b|c)\"  # If preceded by 'a', match 'b'; otherwise, match 'c'.\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: c\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#named-capture-groups","title":"Named Capture Groups","text":"<ul> <li><code>(?P&lt;name&gt; )</code>: Creates a named capturing group.</li> <li><code>(?P=name)</code>: Backreference to a named capturing group.</li> </ul> <pre><code>import re\n\ntext = \"apple apple\"\npattern = r\"(?P&lt;word&gt;\\w+) (?P=word)\"  # Matches repeated words\nmatch = re.search(pattern, text)\nprint(match.group('word')) if match else print(\"No match\")  # Output: apple\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#comments","title":"Comments","text":"<ul> <li><code>(?#comment)</code>: Inline comment.</li> </ul> <pre><code>import re\n\ntext = \"123-4567\"\npattern = r\"\\d{3}(?#This is a comment)-?\\d{4}\"\nmatch = re.search(pattern, text)\nprint(match.group(0)) if match else print(\"No match\")  # Output: 123-4567\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#free-spacing-mode-x-flag","title":"Free-Spacing Mode (<code>x</code> flag)","text":"<pre><code>import re\n\ntext = \"123-4567\"\npattern = r\"\"\"\n    \\d{3}  # Area code\n    -?     # Optional separator\n    \\d{4}  # Phone number\n\"\"\"\nmatch = re.search(pattern, text, re.VERBOSE)  # Use re.VERBOSE or re.X\nprint(match.group(0)) if match else print(\"No match\")  # Output: 123-4567\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#branch-reset-groups","title":"Branch Reset Groups","text":"<ul> <li><code>(?| )</code>: Resets the capture group numbering within each alternative.</li> </ul> <pre><code>import re\n\ntext = \"abc\"\npattern = r\"(?|(a)|(b)|(c))\"  # All alternatives capture to group 1\nmatch = re.search(pattern, text)\nprint(match.group(1)) if match else print(\"No match\")  # Output: a\n\ntext = \"def\"\npattern = r\"(?|(a)|(b)|(c))\"  # All alternatives capture to group 1\nmatch = re.search(pattern, text)\nprint(match.group(1)) if match else print(\"No match\")  # Output: None\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#subroutine-calls","title":"Subroutine Calls","text":"<ul> <li><code>(?&amp;name)</code>: Calls a named subroutine.</li> </ul> <pre><code>import re\ntext = \"((abc)def(ghi))\"\npattern = r\"\"\"\n(?(DEFINE)\n  (?P&lt;paren&gt;\\(([^()]|(?&amp;paren))*\\))  # Define a named subroutine 'paren'\n)\n^(?&amp;paren)$  # Call the subroutine\n\"\"\"\nmatch = re.search(pattern, text, re.VERBOSE)\nprint(match.group(0)) if match else print(\"No match\")  # Output: ((abc)def(ghi))\n</code></pre>"},{"location":"Cheat-Sheets/RegEx/#common-regex-engines-and-differences","title":"Common RegEx Engines and Differences","text":"<ul> <li>PCRE (Perl Compatible Regular Expressions): Widely used, feature-rich.</li> <li>JavaScript: Good support, but lookbehind assertions were limited (now widely supported).</li> <li>Python (<code>re</code> module): Excellent support, including Unicode properties.</li> <li>.NET: Powerful and feature-rich.</li> <li>Java: Good support, some syntax differences.</li> <li>POSIX: Basic and Extended Regular Expressions (BRE and ERE). Limited features.</li> </ul>"},{"location":"Cheat-Sheets/RegEx/#best-practices","title":"Best Practices","text":"<ul> <li>Be specific: Avoid overly broad patterns.</li> <li>Use character classes: <code>\\d</code> is more efficient than <code>[0-9]</code>.</li> <li>Use non-capturing groups <code>(?:...)</code> when you don't need the captured text.</li> <li>Be aware of greediness: Use non-greedy quantifiers (<code>*?</code>, <code>+?</code>, etc.).</li> <li>Test your regex: Use online tools (regex101.com, regexr.com) or Python's <code>re</code> module interactively.</li> <li>Comment complex regexes: Use the <code>x</code> flag (extended mode) for readability.</li> <li>Avoid catastrophic backtracking: Be careful with nested quantifiers.</li> <li>Escape special characters: Always escape special characters.</li> <li>Use raw strings in Python: Use <code>r\"\\d+\"</code> to avoid escaping backslashes.</li> <li>Consider alternatives: Sometimes, regular expressions are not the best tool.</li> <li>Know your engine: Be aware of the features and limitations of your RegEx engine.</li> </ul>"},{"location":"Cheat-Sheets/SQL/","title":"SQL Cheat Sheet","text":"<ul> <li>SQL Cheat Sheet<ul> <li>Data Types<ul> <li>Numeric</li> <li>String</li> <li>Date and Time</li> <li>Boolean</li> <li>Other</li> </ul> </li> <li>Data Definition Language (DDL)<ul> <li>CREATE TABLE</li> <li>ALTER TABLE</li> <li>DROP TABLE</li> <li>TRUNCATE TABLE</li> <li>CREATE INDEX</li> <li>DROP INDEX</li> <li>CREATE VIEW</li> <li>DROP VIEW</li> </ul> </li> <li>Data Manipulation Language (DML)<ul> <li>INSERT</li> <li>UPDATE</li> <li>DELETE</li> </ul> </li> <li>Data Query Language (DQL)<ul> <li>SELECT</li> <li>WHERE Clause</li> <li>ORDER BY Clause</li> <li>LIMIT and OFFSET Clauses</li> <li>GROUP BY Clause</li> <li>HAVING Clause</li> </ul> </li> <li>Joins<ul> <li>INNER JOIN</li> <li>LEFT JOIN (LEFT OUTER JOIN)</li> <li>RIGHT JOIN (RIGHT OUTER JOIN)</li> <li>FULL JOIN (FULL OUTER JOIN)</li> <li>Self Join</li> <li>Cross Join</li> </ul> </li> <li>Subqueries</li> <li>Common Table Expressions (CTEs)</li> <li>Window Functions</li> <li>Transaction Control Language (TCL)<ul> <li>START TRANSACTION (or BEGIN)</li> <li>COMMIT</li> <li>ROLLBACK</li> <li>SAVEPOINT</li> <li>ROLLBACK TO SAVEPOINT</li> <li>SET TRANSACTION</li> </ul> </li> <li>String Functions</li> <li>Date and Time Functions</li> <li>Conditional Expressions<ul> <li>CASE</li> <li>IF (MySQL, SQL Server)</li> <li>COALESCE</li> <li>NULLIF</li> </ul> </li> <li>User-Defined Functions (UDFs)</li> <li>Stored Procedures</li> <li>Triggers</li> <li>Indexes<ul> <li>Creating Indexes</li> <li>Dropping Indexes</li> </ul> </li> <li>Views<ul> <li>Creating Views</li> <li>Dropping Views</li> </ul> </li> <li>Transactions</li> <li>Security</li> <li>Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of SQL (Structured Query Language), covering data types, Data Definition Language (DDL), Data Manipulation Language (DML), Data Query Language (DQL), Transaction Control Language (TCL), joins, subqueries, window functions, common table expressions (CTEs), and best practices. It aims to be a complete reference for writing and understanding SQL queries.  This cheat sheet is designed to be generally applicable across different SQL database systems (e.g., MySQL, PostgreSQL, SQL Server, Oracle, SQLite), but notes specific differences where significant.</p>"},{"location":"Cheat-Sheets/SQL/#data-types","title":"Data Types","text":""},{"location":"Cheat-Sheets/SQL/#numeric","title":"Numeric","text":"<ul> <li><code>INT</code>, <code>INTEGER</code>: Integer values.</li> <li><code>SMALLINT</code>: Smaller integer values.</li> <li><code>BIGINT</code>: Larger integer values.</li> <li><code>TINYINT</code>: Very small integer values (MySQL, SQL Server).</li> <li><code>REAL</code>: Single-precision floating-point numbers.</li> <li><code>FLOAT(p)</code>: Floating-point number with precision <code>p</code>.</li> <li><code>DOUBLE PRECISION</code>: Double-precision floating-point numbers.</li> <li><code>DECIMAL(p, s)</code>, <code>NUMERIC(p, s)</code>: Fixed-point numbers with precision <code>p</code> and scale <code>s</code>.</li> </ul>"},{"location":"Cheat-Sheets/SQL/#string","title":"String","text":"<ul> <li><code>CHAR(n)</code>: Fixed-length character string of length <code>n</code>.</li> <li><code>VARCHAR(n)</code>: Variable-length character string with a maximum length of <code>n</code>.</li> <li><code>TEXT</code>: Variable-length character string with no specified maximum length (or a very large maximum).</li> <li><code>NCHAR(n)</code>, <code>NVARCHAR(n)</code>: Unicode character strings (for storing characters from different languages).</li> </ul>"},{"location":"Cheat-Sheets/SQL/#date-and-time","title":"Date and Time","text":"<ul> <li><code>DATE</code>: Date (YYYY-MM-DD).</li> <li><code>TIME</code>: Time (HH:MI:SS).</li> <li><code>DATETIME</code>, <code>TIMESTAMP</code>: Date and time.</li> <li><code>INTERVAL</code>: A period of time.</li> </ul>"},{"location":"Cheat-Sheets/SQL/#boolean","title":"Boolean","text":"<ul> <li><code>BOOLEAN</code>: True or False.  (Some databases, like MySQL, use <code>TINYINT(1)</code> to represent booleans).</li> </ul>"},{"location":"Cheat-Sheets/SQL/#other","title":"Other","text":"<ul> <li><code>BLOB</code>: Binary large object (for storing binary data).</li> <li><code>CLOB</code>: Character large object (for storing large text data).</li> <li><code>JSON</code>, <code>JSONB</code>: JSON data (supported by some databases like PostgreSQL).</li> <li><code>UUID</code>: Universally Unique Identifier (supported by some databases like PostgreSQL).</li> <li><code>ENUM</code>: Enumerated type (MySQL, PostgreSQL).</li> <li><code>ARRAY</code>: Array type (PostgreSQL).</li> </ul>"},{"location":"Cheat-Sheets/SQL/#data-definition-language-ddl","title":"Data Definition Language (DDL)","text":""},{"location":"Cheat-Sheets/SQL/#create-table","title":"CREATE TABLE","text":"<pre><code>CREATE TABLE table_name (\n    column1 datatype constraints,\n    column2 datatype constraints,\n    ...\n    PRIMARY KEY (column1),\n    FOREIGN KEY (column_fk) REFERENCES other_table(other_column)\n);\n\n-- Example\nCREATE TABLE employees (\n    id INT PRIMARY KEY,\n    first_name VARCHAR(50),\n    last_name VARCHAR(50),\n    email VARCHAR(100) UNIQUE,\n    hire_date DATE,\n    salary DECIMAL(10, 2),\n    department_id INT,\n    FOREIGN KEY (department_id) REFERENCES departments(id)\n);\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#alter-table","title":"ALTER TABLE","text":"<pre><code>-- Add a column\nALTER TABLE table_name ADD COLUMN column_name datatype;\n\n-- Drop a column\nALTER TABLE table_name DROP COLUMN column_name;\n\n-- Modify a column\nALTER TABLE table_name MODIFY COLUMN column_name new_datatype;  -- MySQL, SQL Server\nALTER TABLE table_name ALTER COLUMN column_name TYPE new_datatype; -- PostgreSQL\n\n-- Add a constraint\nALTER TABLE table_name ADD CONSTRAINT constraint_name constraint_definition;\n\n-- Drop a constraint\nALTER TABLE table_name DROP CONSTRAINT constraint_name; -- Most databases\nALTER TABLE table_name DROP INDEX constraint_name; -- MySQL (for UNIQUE constraints)\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#drop-table","title":"DROP TABLE","text":"<pre><code>DROP TABLE table_name;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#truncate-table","title":"TRUNCATE TABLE","text":"<pre><code>TRUNCATE TABLE table_name;  -- Removes all rows, faster than DELETE\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#create-index","title":"CREATE INDEX","text":"<pre><code>CREATE INDEX index_name ON table_name (column1, column2, ...);\n\n-- Unique index\nCREATE UNIQUE INDEX index_name ON table_name (column1);\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#drop-index","title":"DROP INDEX","text":"<pre><code>DROP INDEX index_name ON table_name; -- Most databases\nALTER TABLE table_name DROP INDEX index_name; -- MySQL\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#create-view","title":"CREATE VIEW","text":"<pre><code>CREATE VIEW view_name AS\nSELECT column1, column2, ...\nFROM table_name\nWHERE condition;\n\n-- Example\nCREATE VIEW employee_names AS\nSELECT first_name, last_name\nFROM employees;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#drop-view","title":"DROP VIEW","text":"<pre><code>DROP VIEW view_name;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#data-manipulation-language-dml","title":"Data Manipulation Language (DML)","text":""},{"location":"Cheat-Sheets/SQL/#insert","title":"INSERT","text":"<pre><code>INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...);\n\n-- Insert multiple rows\nINSERT INTO table_name (column1, column2) VALUES\n(value1a, value2a),\n(value1b, value2b),\n(value1c, value2c);\n\n-- Insert from another table\nINSERT INTO table_name (column1, column2)\nSELECT column1, column2\nFROM other_table\nWHERE condition;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#update","title":"UPDATE","text":"<pre><code>UPDATE table_name\nSET column1 = value1, column2 = value2, ...\nWHERE condition;\n\n-- Example\nUPDATE employees\nSET salary = salary * 1.10\nWHERE department_id = 1;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#delete","title":"DELETE","text":"<pre><code>DELETE FROM table_name WHERE condition;\n\n-- Example\nDELETE FROM employees WHERE id = 123;\n\n-- Delete all rows (slower than TRUNCATE TABLE)\nDELETE FROM table_name;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#data-query-language-dql","title":"Data Query Language (DQL)","text":""},{"location":"Cheat-Sheets/SQL/#select","title":"SELECT","text":"<pre><code>SELECT column1, column2, ...\nFROM table_name\nWHERE condition\nORDER BY column1 ASC, column2 DESC\nLIMIT n OFFSET m;\n\n-- Select all columns\nSELECT * FROM table_name;\n\n-- Select with aliases\nSELECT column1 AS alias1, column2 AS alias2 FROM table_name;\n\n-- Select distinct values\nSELECT DISTINCT column1 FROM table_name;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#where-clause","title":"WHERE Clause","text":"<pre><code>SELECT * FROM table_name WHERE column1 = value1 AND column2 &gt; value2;\nSELECT * FROM table_name WHERE column1 IN (value1, value2, value3);\nSELECT * FROM table_name WHERE column1 BETWEEN value1 AND value2;\nSELECT * FROM table_name WHERE column1 LIKE 'pattern%'; -- % is a wildcard\nSELECT * FROM table_name WHERE column1 IS NULL;\nSELECT * FROM table_name WHERE column1 IS NOT NULL;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#order-by-clause","title":"ORDER BY Clause","text":"<pre><code>SELECT * FROM table_name ORDER BY column1 ASC, column2 DESC;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#limit-and-offset-clauses","title":"LIMIT and OFFSET Clauses","text":"<pre><code>SELECT * FROM table_name LIMIT 10;  -- Get the first 10 rows\nSELECT * FROM table_name LIMIT 10 OFFSET 5;  -- Get 10 rows starting from row 6```\n\n### Aggregate Functions\n\n*   `COUNT()`: Counts rows.\n*   `SUM()`: Sums values.\n*   `AVG()`: Calculates the average.\n*   `MIN()`: Finds the minimum value.\n*   `MAX()`: Finds the maximum value.\n\n```sql\nSELECT COUNT(*) FROM table_name;\nSELECT SUM(salary) FROM employees;\nSELECT AVG(age) FROM employees;\nSELECT MIN(hire_date) FROM employees;\nSELECT MAX(salary) FROM employees;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#group-by-clause","title":"GROUP BY Clause","text":"<pre><code>SELECT department_id, AVG(salary) AS average_salary\nFROM employees\nGROUP BY department_id;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#having-clause","title":"HAVING Clause","text":"<pre><code>SELECT department_id, AVG(salary) AS average_salary\nFROM employees\nGROUP BY department_id\nHAVING AVG(salary) &gt; 50000;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#joins","title":"Joins","text":""},{"location":"Cheat-Sheets/SQL/#inner-join","title":"INNER JOIN","text":"<pre><code>SELECT e.first_name, e.last_name, d.department_name\nFROM employees e\nINNER JOIN departments d ON e.department_id = d.id;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#left-join-left-outer-join","title":"LEFT JOIN (LEFT OUTER JOIN)","text":"<pre><code>SELECT e.first_name, e.last_name, d.department_name\nFROM employees e\nLEFT JOIN departments d ON e.department_id = d.id;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#right-join-right-outer-join","title":"RIGHT JOIN (RIGHT OUTER JOIN)","text":"<pre><code>SELECT e.first_name, e.last_name, d.department_name\nFROM employees e\nRIGHT JOIN departments d ON e.department_id = d.id;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#full-join-full-outer-join","title":"FULL JOIN (FULL OUTER JOIN)","text":"<pre><code>-- Full outer join is not supported by all databases (e.g., MySQL).\n-- Use a combination of LEFT JOIN and RIGHT JOIN with UNION for equivalent functionality.\nSELECT e.first_name, e.last_name, d.department_name\nFROM employees e\nFULL OUTER JOIN departments d ON e.department_id = d.id;\n\n-- Equivalent in MySQL:\nSELECT e.first_name, e.last_name, d.department_name\nFROM employees e\nLEFT JOIN departments d ON e.department_id = d.id\nUNION\nSELECT e.first_name, e.last_name, d.department_name\nFROM employees e\nRIGHT JOIN departments d ON e.department_id = d.id;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#self-join","title":"Self Join","text":"<pre><code>SELECT e1.first_name, e2.first_name AS manager_name\nFROM employees e1\nJOIN employees e2 ON e1.manager_id = e2.id;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#cross-join","title":"Cross Join","text":"<pre><code>SELECT *\nFROM table1\nCROSS JOIN table2;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#subqueries","title":"Subqueries","text":"<pre><code>-- Subquery in WHERE clause\nSELECT *\nFROM employees\nWHERE salary &gt; (SELECT AVG(salary) FROM employees);\n\n-- Subquery in SELECT clause\nSELECT first_name, last_name,\n       (SELECT COUNT(*) FROM orders WHERE orders.employee_id = employees.id) AS order_count\nFROM employees;\n\n-- Subquery in FROM clause\nSELECT *\nFROM (SELECT first_name, last_name, salary FROM employees) AS employee_salaries\nWHERE salary &gt; 60000;\n\n-- Correlated subquery\nSELECT e.first_name, e.last_name\nFROM employees e\nWHERE e.salary &gt; (SELECT AVG(salary) FROM employees WHERE department_id = e.department_id);\n\n-- EXISTS and NOT EXISTS\nSELECT *\nFROM employees e\nWHERE EXISTS (SELECT 1 FROM orders o WHERE o.employee_id = e.id);\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#common-table-expressions-ctes","title":"Common Table Expressions (CTEs)","text":"<pre><code>WITH employee_summary AS (\n    SELECT department_id, AVG(salary) AS avg_salary\n    FROM employees\n    GROUP BY department_id\n)\nSELECT d.department_name, es.avg_salary\nFROM departments d\nJOIN employee_summary es ON d.id = es.department_id;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#window-functions","title":"Window Functions","text":"<pre><code>SELECT\n    first_name,\n    last_name,\n    salary,\n    AVG(salary) OVER (PARTITION BY department_id) AS avg_salary_by_department,\n    RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) AS salary_rank\nFROM employees;\n</code></pre> <p>Common Window Functions:</p> <ul> <li><code>ROW_NUMBER()</code>: Assigns a unique sequential integer to each row within its partition.</li> <li><code>RANK()</code>: Assigns a rank to each row within its partition, with gaps in rank values.</li> <li><code>DENSE_RANK()</code>: Assigns a rank to each row within its partition, without gaps.</li> <li><code>NTILE(n)</code>: Divides the rows within a partition into <code>n</code> groups.</li> <li><code>LAG(column, offset, default)</code>: Accesses data from a previous row.</li> <li><code>LEAD(column, offset, default)</code>: Accesses data from a subsequent row.</li> <li><code>FIRST_VALUE(column)</code>: Returns the first value in a window frame.</li> <li><code>LAST_VALUE(column)</code>: Returns the last value in a window frame.</li> <li><code>NTH_VALUE(column, n)</code>: Returns the nth value in a window frame.</li> </ul>"},{"location":"Cheat-Sheets/SQL/#transaction-control-language-tcl","title":"Transaction Control Language (TCL)","text":""},{"location":"Cheat-Sheets/SQL/#start-transaction-or-begin","title":"START TRANSACTION (or BEGIN)","text":"<pre><code>START TRANSACTION;\n-- or\nBEGIN;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#commit","title":"COMMIT","text":"<pre><code>COMMIT;  -- Save changes\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#rollback","title":"ROLLBACK","text":"<pre><code>ROLLBACK;  -- Discard changes\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#savepoint","title":"SAVEPOINT","text":"<pre><code>SAVEPOINT savepoint_name;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#rollback-to-savepoint","title":"ROLLBACK TO SAVEPOINT","text":"<pre><code>ROLLBACK TO SAVEPOINT savepoint_name;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#set-transaction","title":"SET TRANSACTION","text":"<pre><code>SET TRANSACTION ISOLATION LEVEL READ COMMITTED; -- Example\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#string-functions","title":"String Functions","text":"<ul> <li><code>CONCAT(str1, str2, ...)</code>: Concatenates strings.</li> <li><code>LENGTH(str)</code> or <code>LEN(str)</code>: Returns the length of a string.</li> <li><code>SUBSTRING(str, start, length)</code> or <code>SUBSTR(str, start, length)</code>: Extracts a substring.</li> <li><code>UPPER(str)</code> or <code>UCASE(str)</code>: Converts a string to uppercase.</li> <li><code>LOWER(str)</code> or <code>LCASE(str)</code>: Converts a string to lowercase.</li> <li><code>TRIM(str)</code>: Removes leading and trailing whitespace.</li> <li><code>LTRIM(str)</code>: Removes leading whitespace.</li> <li><code>RTRIM(str)</code>: Removes trailing whitespace.</li> <li><code>REPLACE(str, old, new)</code>: Replaces occurrences of a substring.</li> <li><code>INSTR(str, substr)</code> or <code>POSITION(substr IN str)</code>: Returns the position of a substring.</li> <li><code>LEFT(str, length)</code>: Returns the leftmost characters of a string.</li> <li><code>RIGHT(str, length)</code>: Returns the rightmost characters of a string.</li> <li><code>LPAD(str, length, padstr)</code>: Left-pads a string.</li> <li><code>RPAD(str, length, padstr)</code>: Right-pads a string.</li> </ul>"},{"location":"Cheat-Sheets/SQL/#date-and-time-functions","title":"Date and Time Functions","text":"<ul> <li><code>NOW()</code>, <code>CURRENT_TIMESTAMP</code>: Returns the current date and time.</li> <li><code>CURDATE()</code>, <code>CURRENT_DATE</code>: Returns the current date.</li> <li><code>CURTIME()</code>, <code>CURRENT_TIME</code>: Returns the current time.</li> <li><code>DATE(expression)</code>: Extracts the date part of a date or datetime expression.</li> <li><code>TIME(expression)</code>: Extracts the time part of a time or datetime expression.</li> <li><code>YEAR(date)</code>, <code>MONTH(date)</code>, <code>DAY(date)</code>: Extracts the year, month, or day.</li> <li><code>HOUR(time)</code>, <code>MINUTE(time)</code>, <code>SECOND(time)</code>: Extracts the hour, minute, or second.</li> <li><code>DATE_ADD(date, INTERVAL expr unit)</code>, <code>DATE_SUB(date, INTERVAL expr unit)</code>: Adds or subtracts a time interval.</li> <li><code>DATEDIFF(date1, date2)</code>: Returns the difference between two dates (in days).</li> <li><code>TIMESTAMPDIFF(unit, datetime1, datetime2)</code>: Returns the difference between two datetimes in a specified unit.</li> <li><code>DATE_FORMAT(date, format)</code>: Formats a date.</li> </ul>"},{"location":"Cheat-Sheets/SQL/#conditional-expressions","title":"Conditional Expressions","text":""},{"location":"Cheat-Sheets/SQL/#case","title":"CASE","text":"<pre><code>SELECT\n    first_name,\n    last_name,\n    CASE\n        WHEN salary &gt; 80000 THEN 'High'\n        WHEN salary &gt; 50000 THEN 'Medium'\n        ELSE 'Low'\n    END AS salary_level\nFROM employees;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#if-mysql-sql-server","title":"IF (MySQL, SQL Server)","text":"<pre><code>SELECT first_name, last_name, IF(salary &gt; 50000, 'High', 'Low') AS salary_level\nFROM employees;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#coalesce","title":"COALESCE","text":"<pre><code>SELECT COALESCE(column1, column2, 'Default Value') AS result FROM table_name;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#nullif","title":"NULLIF","text":"<pre><code>SELECT NULLIF(column1, value) AS result FROM table_name;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#user-defined-functions-udfs","title":"User-Defined Functions (UDFs)","text":"<p>(Syntax varies significantly between database systems)</p> <p>Example (MySQL):</p> <pre><code>DELIMITER //\nCREATE FUNCTION my_function(param1 INT, param2 VARCHAR(255))\nRETURNS INT\nDETERMINISTIC\nBEGIN\n    -- Function logic\n    RETURN result;\nEND //\nDELIMITER ;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#stored-procedures","title":"Stored Procedures","text":"<p>(Syntax varies significantly between database systems)</p> <p>Example (MySQL):</p> <pre><code>DELIMITER //\nCREATE PROCEDURE my_procedure(IN param1 INT, OUT param2 VARCHAR(255))\nBEGIN\n    -- Procedure logic\n    SELECT column1 INTO param2 FROM table_name WHERE column2 = param1;\nEND //\nDELIMITER ;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#triggers","title":"Triggers","text":"<p>(Syntax varies significantly between database systems)</p> <p>Example (MySQL):</p> <pre><code>DELIMITER //\nCREATE TRIGGER my_trigger\nBEFORE INSERT ON employees\nFOR EACH ROW\nBEGIN\n    -- Trigger logic\n    SET NEW.created_at = NOW();\nEND //\nDELIMITER ;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#indexes","title":"Indexes","text":""},{"location":"Cheat-Sheets/SQL/#creating-indexes","title":"Creating Indexes","text":"<pre><code>CREATE INDEX idx_lastname ON employees (last_name);\nCREATE UNIQUE INDEX idx_email ON employees (email);\nCREATE INDEX idx_lastname_firstname ON employees (last_name, first_name);\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#dropping-indexes","title":"Dropping Indexes","text":"<pre><code>DROP INDEX idx_lastname ON employees; -- Standard SQL\nALTER TABLE employees DROP INDEX idx_lastname; -- MySQL\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#views","title":"Views","text":""},{"location":"Cheat-Sheets/SQL/#creating-views","title":"Creating Views","text":"<pre><code>CREATE VIEW high_salary_employees AS\nSELECT employee_id, first_name, last_name, salary\nFROM employees\nWHERE salary &gt; 80000;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#dropping-views","title":"Dropping Views","text":"<pre><code>DROP VIEW high_salary_employees;\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#transactions","title":"Transactions","text":"<pre><code>START TRANSACTION; -- or BEGIN;\n\n-- SQL statements\n\nCOMMIT; -- Save changes\n-- or\nROLLBACK; -- Discard changes\n</code></pre>"},{"location":"Cheat-Sheets/SQL/#security","title":"Security","text":"<ul> <li>User Management: <code>CREATE USER</code>, <code>ALTER USER</code>, <code>DROP USER</code>, <code>GRANT</code>, <code>REVOKE</code>.</li> <li>Permissions: Grant specific privileges (e.g., <code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>) to users or roles on database objects.</li> <li>Roles: Create roles to group privileges and assign them to users.</li> <li>Views: Use views to restrict access to sensitive data.</li> <li>Stored Procedures: Use stored procedures to encapsulate logic and control access.</li> <li>Encryption: Encrypt sensitive data at rest and in transit.</li> <li>Auditing: Enable auditing to track database activity.</li> <li>SQL Injection Prevention: Use parameterized queries or prepared statements to prevent SQL injection attacks.</li> </ul>"},{"location":"Cheat-Sheets/SQL/#best-practices","title":"Best Practices","text":"<ul> <li>Use meaningful names: Choose descriptive names for tables, columns, and other database objects.</li> <li>Normalize your database: Design your database schema to reduce data redundancy and improve data integrity.</li> <li>Use appropriate data types: Select data types that are appropriate for the data you are storing.</li> <li>Use indexes: Create indexes on columns that are frequently used in <code>WHERE</code> clauses and <code>JOIN</code> conditions.</li> <li>Optimize your queries: Write efficient queries that minimize the amount of data that needs to be processed.</li> <li>Use transactions: Use transactions to ensure data consistency and integrity.</li> <li>Back up your database: Regularly back up your database to prevent data loss.</li> <li>Secure your database: Implement appropriate security measures to protect your data.</li> <li>Use comments: Add comments to your SQL code to explain what it does.</li> <li>Use a consistent coding style: Follow a consistent coding style to make your code easier to read and maintain.</li> <li>Test your queries: Thoroughly test your queries to ensure they are working as expected.</li> <li>Use a database management tool: Use a tool like MySQL Workbench, pgAdmin, SQL Server Management Studio, or Dbeaver to manage your database.</li> <li>Use version control: Use a version control system (e.g., Git) to track changes to your database schema and code.</li> <li>Use an ORM (Object-Relational Mapper): Consider using an ORM (e.g., SQLAlchemy, Django ORM) to simplify database interactions.</li> <li>Avoid <code>SELECT *</code>: Explicitly list the columns you need to retrieve.</li> <li>Use <code>EXISTS</code> instead of <code>COUNT(*)</code> when checking for existence: <code>EXISTS</code> is often more efficient.</li> <li>Use <code>JOIN</code> instead of subqueries when possible: Joins are generally faster.</li> <li>Use <code>UNION ALL</code> instead of <code>UNION</code> when you don't need to remove duplicates: <code>UNION ALL</code> is faster.</li> <li>Use <code>CASE</code> expressions for conditional logic: <code>CASE</code> expressions are more flexible than <code>IF</code>.</li> <li>Use CTEs to improve readability: CTEs can make complex queries easier to understand.</li> <li>Use window functions for advanced analytics: Window functions allow you to perform calculations across rows.</li> <li>Use stored procedures and functions to encapsulate logic: This can improve code reusability and maintainability.</li> <li>Use triggers to automate tasks: Triggers can be used to automatically perform actions when certain events occur.</li> <li>Use views to simplify complex queries: Views can make it easier to access data from multiple tables.</li> <li>Use indexes to improve query performance: Indexes can significantly speed up queries that filter or sort data.</li> <li>Use explain plans to analyze query performance: Explain plans show you how the database is executing your queries.</li> <li>Use a database profiler to identify performance bottlenecks: Profilers can help you find slow queries and other performance issues.</li> <li>Use a database monitoring tool to track database performance: Monitoring tools can help you identify and resolve performance problems.</li> <li>Regularly update your database software: Updates often include performance improvements and security fixes.</li> <li>Follow database best practices: Each database system has its own set of best practices.</li> </ul>"},{"location":"Cheat-Sheets/Sk-learn/","title":"Scikit-learn Cheat Sheet","text":"<ul> <li>Scikit-learn Cheat Sheet<ul> <li>Getting Started<ul> <li>Installation</li> <li>Importing Scikit-learn</li> </ul> </li> <li>Data Preprocessing<ul> <li>Loading Data<ul> <li>Built-in Datasets</li> <li>From Pandas DataFrame</li> </ul> </li> <li>Splitting Data</li> <li>Feature Scaling<ul> <li>Standardization</li> <li>Min-Max Scaling</li> <li>Robust Scaling</li> <li>Normalization</li> </ul> </li> <li>Handling Missing Values<ul> <li>Imputation (SimpleImputer)</li> <li>Dropping Missing Values</li> </ul> </li> <li>Encoding Categorical Features<ul> <li>One-Hot Encoding</li> <li>Ordinal Encoding</li> <li>Label Encoding (for target variable)</li> </ul> </li> <li>Feature Engineering<ul> <li>Polynomial Features</li> <li>Custom Transformers</li> </ul> </li> <li>Feature Selection<ul> <li>VarianceThreshold</li> <li>SelectKBest</li> <li>SelectFromModel</li> <li>RFE (Recursive Feature Elimination)</li> </ul> </li> </ul> </li> <li>Model Selection and Training<ul> <li>Linear Regression</li> <li>Logistic Regression</li> <li>Support Vector Machines (SVM)</li> <li>Decision Trees</li> <li>Random Forest</li> <li>Gradient Boosting</li> <li>K-Nearest Neighbors (KNN)</li> <li>Naive Bayes</li> <li>Clustering (K-Means)</li> <li>Principal Component Analysis (PCA)</li> <li>Model Persistence</li> </ul> </li> <li>Model Evaluation<ul> <li>Regression Metrics</li> <li>Classification Metrics</li> <li>ROC Curve and AUC</li> <li>Cross-Validation</li> <li>Learning Curves</li> <li>Validation Curves</li> </ul> </li> <li>Hyperparameter Tuning<ul> <li>GridSearchCV</li> <li>RandomizedSearchCV</li> </ul> </li> <li>Pipelines</li> <li>Ensemble Methods<ul> <li>Bagging</li> <li>Boosting (AdaBoost)</li> <li>Stacking</li> <li>Voting Classifier</li> </ul> </li> <li>Dimensionality Reduction<ul> <li>PCA</li> <li>Linear Discriminant Analysis (LDA)</li> <li>t-distributed Stochastic Neighbor Embedding (t-SNE)</li> <li>Non-negative Matrix Factorization (NMF)</li> </ul> </li> <li>Model Inspection<ul> <li>Feature Importances</li> <li>Partial Dependence Plots</li> <li>Permutation Importance</li> </ul> </li> <li>Calibration</li> <li>Dummy Estimators</li> <li>Multi-label Classification</li> <li>Multi-class and Multi-label Classification</li> <li>Outlier Detection</li> <li>Semi-Supervised Learning</li> <li>Tips and Best Practices</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of the Scikit-learn (sklearn) machine learning library, covering essential concepts, code snippets, and best practices for efficient model building, training, evaluation, and deployment. It aims to be a one-stop reference for common tasks.</p>"},{"location":"Cheat-Sheets/Sk-learn/#getting-started","title":"Getting Started","text":""},{"location":"Cheat-Sheets/Sk-learn/#installation","title":"Installation","text":"<pre><code>pip install scikit-learn\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#importing-scikit-learn","title":"Importing Scikit-learn","text":"<pre><code>import sklearn\nfrom sklearn import datasets  # For built-in datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#data-preprocessing","title":"Data Preprocessing","text":""},{"location":"Cheat-Sheets/Sk-learn/#loading-data","title":"Loading Data","text":""},{"location":"Cheat-Sheets/Sk-learn/#built-in-datasets","title":"Built-in Datasets","text":"<pre><code>from sklearn import datasets\n\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\n\nboston = datasets.load_boston() # Now deprecated, use fetch_california_housing\ncalifornia_housing = datasets.fetch_california_housing()\nX = california_housing.data\ny = california_housing.target\n\ndigits = datasets.load_digits()\nX = digits.data\ny = digits.target\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#from-pandas-dataframe","title":"From Pandas DataFrame","text":"<pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"your_data.csv\")\nX = df.drop(\"target_column\", axis=1)\ny = df[\"target_column\"]\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#splitting-data","title":"Splitting Data","text":"<pre><code>from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training, 20% testing\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#feature-scaling","title":"Feature Scaling","text":""},{"location":"Cheat-Sheets/Sk-learn/#standardization","title":"Standardization","text":"<pre><code>from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#min-max-scaling","title":"Min-Max Scaling","text":"<pre><code>from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#robust-scaling","title":"Robust Scaling","text":"<pre><code>from sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#normalization","title":"Normalization","text":"<pre><code>from sklearn.preprocessing import Normalizer\n\nnormalizer = Normalizer()\nX_train_normalized = normalizer.fit_transform(X_train)\nX_test_normalized = normalizer.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#handling-missing-values","title":"Handling Missing Values","text":""},{"location":"Cheat-Sheets/Sk-learn/#imputation-simpleimputer","title":"Imputation (SimpleImputer)","text":"<pre><code>from sklearn.impute import SimpleImputer\nimport numpy as np\n\nimputer = SimpleImputer(strategy=\"mean\")  # Replace missing values with the mean\n# Other strategies: \"median\", \"most_frequent\", \"constant\"\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)```\n\n#### Imputation (KNNImputer)\n\n```python\nfrom sklearn.impute import KNNImputer\n\nimputer = KNNImputer(n_neighbors=5)\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#dropping-missing-values","title":"Dropping Missing Values","text":"<pre><code>import pandas as pd\n# Assuming X_train and X_test are pandas DataFrames\nX_train_dropped = X_train.dropna()\nX_test_dropped = X_test.dropna()\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#encoding-categorical-features","title":"Encoding Categorical Features","text":""},{"location":"Cheat-Sheets/Sk-learn/#one-hot-encoding","title":"One-Hot Encoding","text":"<pre><code>from sklearn.preprocessing import OneHotEncoder\nimport pandas as pd\n\n# Assuming X_train and X_test are pandas DataFrames\nencoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False) # sparse=False for older versions\nX_train_encoded = encoder.fit_transform(X_train[['categorical_feature']])\nX_test_encoded = encoder.transform(X_test[['categorical_feature']])\n\n# Or, using pandas:\nX_train_encoded = pd.get_dummies(X_train, columns=['categorical_feature'])\nX_test_encoded = pd.get_dummies(X_test, columns=['categorical_feature'])\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#ordinal-encoding","title":"Ordinal Encoding","text":"<pre><code>from sklearn.preprocessing import OrdinalEncoder\n\nencoder = OrdinalEncoder()\nX_train_encoded = encoder.fit_transform(X_train[['ordinal_feature']])\nX_test_encoded = encoder.transform(X_test[['ordinal_feature']])\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#label-encoding-for-target-variable","title":"Label Encoding (for target variable)","text":"<pre><code>from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ny_train_encoded = encoder.fit_transform(y_train)\ny_test_encoded = encoder.transform(y_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#feature-engineering","title":"Feature Engineering","text":""},{"location":"Cheat-Sheets/Sk-learn/#polynomial-features","title":"Polynomial Features","text":"<pre><code>from sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2)\nX_train_poly = poly.fit_transform(X_train)\nX_test_poly = poly.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#custom-transformers","title":"Custom Transformers","text":"<pre><code>from sklearn.preprocessing import FunctionTransformer\nimport numpy as np\n\ndef log_transform(x):\n    return np.log1p(x)\n\nlog_transformer = FunctionTransformer(log_transform)\nX_train_log = log_transformer.transform(X_train)\nX_test_log = log_transformer.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#feature-selection","title":"Feature Selection","text":""},{"location":"Cheat-Sheets/Sk-learn/#variancethreshold","title":"VarianceThreshold","text":"<pre><code>from sklearn.feature_selection import VarianceThreshold\n\nselector = VarianceThreshold(threshold=0.1)  # Remove features with variance below 0.1\nX_train_selected = selector.fit_transform(X_train)\nX_test_selected = selector.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#selectkbest","title":"SelectKBest","text":"<pre><code>from sklearn.feature_selection import SelectKBest, f_classif\n\nselector = SelectKBest(score_func=f_classif, k=5)  # Select top 5 features\nX_train_selected = selector.fit_transform(X_train, y_train)\nX_test_selected = selector.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#selectfrommodel","title":"SelectFromModel","text":"<pre><code>from sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\n\nestimator = LogisticRegression(penalty=\"l1\", solver='liblinear')\nselector = SelectFromModel(estimator)\nX_train_selected = selector.fit_transform(X_train, y_train)\nX_test_selected = selector.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#rfe-recursive-feature-elimination","title":"RFE (Recursive Feature Elimination)","text":"<pre><code>from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\nestimator = LogisticRegression()\nselector = RFE(estimator, n_features_to_select=5)\nX_train_selected = selector.fit_transform(X_train, y_train)\nX_test_selected = selector.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#model-selection-and-training","title":"Model Selection and Training","text":""},{"location":"Cheat-Sheets/Sk-learn/#linear-regression","title":"Linear Regression","text":"<pre><code>from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#logistic-regression","title":"Logistic Regression","text":"<pre><code>from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver='liblinear') # Add solver for smaller datasets\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#support-vector-machines-svm","title":"Support Vector Machines (SVM)","text":"<pre><code>from sklearn.svm import SVC, SVR\n\n# For classification\nmodel = SVC(kernel='linear', C=1.0)\nmodel.fit(X_train, y_train)\n\n# For regression\nmodel = SVR(kernel='linear', C=1.0)\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#decision-trees","title":"Decision Trees","text":"<pre><code>from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n\n# For classification\nmodel = DecisionTreeClassifier(max_depth=5)\nmodel.fit(X_train, y_train)\n\n# For regression\nmodel = DecisionTreeRegressor(max_depth=5)\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#random-forest","title":"Random Forest","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n\n# For classification\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5)\nmodel.fit(X_train, y_train)\n\n# For regression\nmodel = RandomForestRegressor(n_estimators=100, max_depth=5)\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#gradient-boosting","title":"Gradient Boosting","text":"<pre><code>from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n\n# For classification\nmodel = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\nmodel.fit(X_train, y_train)\n\n# For regression\nmodel = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#k-nearest-neighbors-knn","title":"K-Nearest Neighbors (KNN)","text":"<pre><code>from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n\n# For classification\nmodel = KNeighborsClassifier(n_neighbors=5)\nmodel.fit(X_train, y_train)\n\n# For regression\nmodel = KNeighborsRegressor(n_neighbors=5)\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#naive-bayes","title":"Naive Bayes","text":"<pre><code>from sklearn.naive_bayes import GaussianNB\n\nmodel = GaussianNB()\nmodel.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#clustering-k-means","title":"Clustering (K-Means)","text":"<pre><code>from sklearn.cluster import KMeans\n\nmodel = KMeans(n_clusters=3, random_state=42, n_init = 'auto') # Added n_init\nmodel.fit(X_train)\nlabels = model.predict(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#principal-component-analysis-pca","title":"Principal Component Analysis (PCA)","text":"<pre><code>from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#model-persistence","title":"Model Persistence","text":"<pre><code>import joblib\n\n# Save the model\njoblib.dump(model, 'my_model.pkl')\n\n# Load the model\nloaded_model = joblib.load('my_model.pkl')\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#model-evaluation","title":"Model Evaluation","text":""},{"location":"Cheat-Sheets/Sk-learn/#regression-metrics","title":"Regression Metrics","text":"<pre><code>from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#classification-metrics","title":"Classification Metrics","text":"<pre><code>from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#roc-curve-and-auc","title":"ROC Curve and AUC","text":"<pre><code>from sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib.pyplot as plt\n\n# For binary classification\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nauc = roc_auc_score(y_test, y_pred_proba)\n\nplt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#cross-validation","title":"Cross-Validation","text":"<pre><code>from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n\n# K-Fold Cross-Validation\ncv_scores = cross_val_score(model, X, y, cv=5)  # 5-fold cross-validation\n\n# Stratified K-Fold (for classification)\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = cross_val_score(model, X, y, cv=cv)\n\nprint(f\"Cross-validation scores: {cv_scores}\")\nprint(f\"Mean cross-validation score: {cv_scores.mean():.2f}\")\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#learning-curves","title":"Learning Curves","text":"<pre><code>from sklearn.model_selection import learning_curve\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntrain_sizes, train_scores, test_scores = learning_curve(\n    model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10))\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(train_sizes, train_mean, label='Training score')\nplt.plot(train_sizes, test_mean, label='Cross-validation score')\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1)\nplt.xlabel('Training examples')\nplt.ylabel('Score')\nplt.legend()\nplt.title('Learning Curve')\nplt.show()\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#validation-curves","title":"Validation Curves","text":"<pre><code>from sklearn.model_selection import validation_curve\nimport numpy as np\n\nparam_range = np.logspace(-6, -1, 5)\ntrain_scores, test_scores = validation_curve(\n    model, X, y, param_name=\"gamma\", param_range=param_range,\n    cv=5, scoring=\"accuracy\")\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(param_range, train_mean, label='Training score')\nplt.plot(param_range, test_mean, label='Cross-validation score')\nplt.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.1)\nplt.fill_between(param_range, test_mean - test_std, test_mean + test_std, alpha=0.1)\nplt.xscale('log')\nplt.xlabel('Parameter Value')\nplt.ylabel('Score')\nplt.legend()\nplt.title('Validation Curve')\nplt.show()\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":""},{"location":"Cheat-Sheets/Sk-learn/#gridsearchcv","title":"GridSearchCV","text":"<pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'kernel': ['linear', 'rbf'],\n    'gamma': [0.1, 1, 'scale', 'auto']\n}\n\ngrid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=2)\ngrid_search.fit(X_train, y_train)\n\nprint(f\"Best parameters: {grid_search.best_params_}\")\nprint(f\"Best cross-validation score: {grid_search.best_score_:.2f}\")\nbest_model = grid_search.best_estimator_\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#randomizedsearchcv","title":"RandomizedSearchCV","text":"<pre><code>from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy.stats import randint\n\nparam_dist = {\n    'n_estimators': randint(10, 200),\n    'max_depth': [3, 5, 10, None],\n    'min_samples_split': randint(2, 11),\n    'min_samples_leaf': randint(1, 11),\n    'bootstrap': [True, False]\n}\n\nrandom_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist,\n                                   n_iter=20, cv=5, scoring='accuracy', random_state=42, verbose=2)\nrandom_search.fit(X_train, y_train)\n\nprint(f\"Best parameters: {random_search.best_params_}\")\nprint(f\"Best cross-validation score: {random_search.best_score_:.2f}\")\nbest_model = random_search.best_estimator_\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#pipelines","title":"Pipelines","text":"<pre><code>from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('svm', SVC())\n])\n\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#ensemble-methods","title":"Ensemble Methods","text":""},{"location":"Cheat-Sheets/Sk-learn/#bagging","title":"Bagging","text":"<pre><code>from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nbase_estimator = DecisionTreeClassifier(max_depth=5)\nbagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=10, random_state=42)\nbagging.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#boosting-adaboost","title":"Boosting (AdaBoost)","text":"<pre><code>from sklearn.ensemble import AdaBoostClassifier\n\nadaboost = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\nadaboost.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#stacking","title":"Stacking","text":"<pre><code>from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nestimators = [\n    ('svm', SVC(kernel='linear', C=1.0)),\n    ('dt', DecisionTreeClassifier(max_depth=5))\n]\nfinal_estimator = LogisticRegression()\n\nstacking = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\nstacking.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#voting-classifier","title":"Voting Classifier","text":"<pre><code>from sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nestimator1 = LogisticRegression(solver='liblinear')\nestimator2 = SVC(kernel='linear', C=1.0, probability=True) # probability=True for soft voting\n\nvoting = VotingClassifier(estimators=[('lr', estimator1), ('svc', estimator2)], voting='soft') # 'hard' for majority voting\nvoting.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#dimensionality-reduction","title":"Dimensionality Reduction","text":""},{"location":"Cheat-Sheets/Sk-learn/#pca","title":"PCA","text":"<pre><code>from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#linear-discriminant-analysis-lda","title":"Linear Discriminant Analysis (LDA)","text":"<pre><code>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nlda = LinearDiscriminantAnalysis(n_components=2)\nX_train_lda = lda.fit_transform(X_train, y_train)  # Supervised, needs y_train\nX_test_lda = lda.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#t-distributed-stochastic-neighbor-embedding-t-sne","title":"t-distributed Stochastic Neighbor Embedding (t-SNE)","text":"<pre><code>from sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=2, random_state=42)\nX_train_tsne = tsne.fit_transform(X_train)  # Usually only fit_transform\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#non-negative-matrix-factorization-nmf","title":"Non-negative Matrix Factorization (NMF)","text":"<pre><code>from sklearn.decomposition import NMF\n\nnmf = NMF(n_components=2, random_state=42)\nX_train_nmf = nmf.fit_transform(X_train)\nX_test_nmf = nmf.transform(X_test)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#model-inspection","title":"Model Inspection","text":""},{"location":"Cheat-Sheets/Sk-learn/#feature-importances","title":"Feature Importances","text":"<pre><code># For tree-based models (RandomForest, GradientBoosting)\nimportances = model.feature_importances_\nprint(importances)\n\n# For linear models (LogisticRegression, LinearRegression)\ncoefficients = model.coef_\nprint(coefficients)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#partial-dependence-plots","title":"Partial Dependence Plots","text":"<pre><code>from sklearn.inspection import plot_partial_dependence\n\nplot_partial_dependence(model, X_train, features=[0, 1])  # Plot for features 0 and 1\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#permutation-importance","title":"Permutation Importance","text":"<pre><code>from sklearn.inspection import permutation_importance\n\nresult = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\nprint(result.importances_mean)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#calibration","title":"Calibration","text":"<pre><code>from sklearn.calibration import CalibratedClassifierCV\n\ncalibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=5) # 'sigmoid' is another method\ncalibrated_model.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#dummy-estimators","title":"Dummy Estimators","text":"<pre><code>from sklearn.dummy import DummyClassifier, DummyRegressor\n\n# For classification\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\ndummy_clf.fit(X_train, y_train)\n\n# For regression\ndummy_reg = DummyRegressor(strategy=\"mean\")\ndummy_reg.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#multi-label-classification","title":"Multi-label Classification","text":"<pre><code>from sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nmultilabel_model = MultiOutputClassifier(RandomForestClassifier())\nmultilabel_model.fit(X_train, y_train) # y_train is a 2D array of shape (n_samples, n_labels)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#multi-class-and-multi-label-classification","title":"Multi-class and Multi-label Classification","text":"<pre><code>from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\n\novr_model = OneVsRestClassifier(SVC(kernel='linear'))\novr_model.fit(X_train, y_train)\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#outlier-detection","title":"Outlier Detection","text":"<pre><code>from sklearn.ensemble import IsolationForest\n\noutlier_detector = IsolationForest(random_state=42)\noutlier_detector.fit(X_train)\noutliers = outlier_detector.predict(X_test) # 1 for inliers, -1 for outliers\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#semi-supervised-learning","title":"Semi-Supervised Learning","text":"<pre><code>from sklearn.semi_supervised import LabelPropagation\n\nlabel_prop_model = LabelPropagation()\nlabel_prop_model.fit(X_train, y_train) # y_train can contain -1 for unlabeled samples\n</code></pre>"},{"location":"Cheat-Sheets/Sk-learn/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ul> <li>Data Preprocessing: Always preprocess your data (scaling, encoding, handling missing values) before training a model.</li> <li>Cross-Validation: Use cross-validation to get a reliable estimate of your model's performance.</li> <li>Hyperparameter Tuning: Use <code>GridSearchCV</code> or <code>RandomizedSearchCV</code> to find the best hyperparameters for your model.</li> <li>Pipelines: Use pipelines to streamline your workflow and prevent data leakage.</li> <li>Model Persistence: Save your trained models using <code>joblib</code> or <code>pickle</code>.</li> <li>Feature Importance: Use feature importance techniques to understand which features are most important for your model.</li> <li>Regularization: Use regularization techniques (L1, L2, Dropout) to prevent overfitting.</li> <li>Ensemble Methods: Combine multiple models to improve performance.</li> <li>Choose the Right Model: Select a model that is appropriate for your data and task.</li> <li>Evaluate Your Model: Use appropriate evaluation metrics for your task.</li> <li>Understand Your Data: Spend time exploring and understanding your data before building a model.</li> <li>Start Simple: Begin with a simple model and gradually increase complexity.</li> <li>Iterate: Machine learning is an iterative process. Experiment with different models, features, and hyperparameters.</li> <li>Document Your Work: Keep track of your experiments and results.</li> <li>Use Version Control: Use Git to track changes to your code.</li> <li>Use Virtual Environments: Isolate project dependencies.</li> <li>Read the Documentation: The Scikit-learn documentation is excellent.</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/","title":"TensorFlow Cheat Sheet","text":"<ul> <li>TensorFlow Cheat Sheet<ul> <li>Getting Started<ul> <li>Installation</li> <li>Importing TensorFlow</li> <li>Checking Version</li> <li>Checking GPU Availability</li> </ul> </li> <li>Tensors<ul> <li>Creating Tensors</li> <li>Tensor Attributes</li> <li>Tensor Operations</li> <li>Indexing and Slicing</li> <li>Data Types</li> </ul> </li> <li>Variables</li> <li>Automatic Differentiation (Autograd)<ul> <li>Persistent Gradient Tape</li> <li>Watching Non-Variable Tensors</li> </ul> </li> <li>Keras API<ul> <li>Model Building<ul> <li>Sequential Model</li> <li>Functional API</li> <li>Model Subclassing</li> </ul> </li> <li>Layers</li> <li>Activation Functions</li> <li>Loss Functions</li> <li>Optimizers</li> <li>Metrics</li> <li>Model Compilation</li> <li>Training</li> <li>Evaluation</li> <li>Prediction</li> <li>Saving and Loading Models</li> <li>Callbacks</li> <li>Regularization</li> <li>Custom Layers</li> <li>Custom Loss Functions</li> <li>Custom Metrics</li> <li>Custom Training Loops</li> </ul> </li> <li>Data Input Pipelines (tf.data)<ul> <li>Creating Datasets</li> <li>Dataset Transformations</li> <li>Reading TFRecord Files</li> </ul> </li> <li>Distributed Training<ul> <li>MirroredStrategy</li> <li>MultiWorkerMirroredStrategy</li> <li>ParameterServerStrategy</li> <li>TPUStrategy</li> </ul> </li> <li>TensorFlow Hub<ul> <li>Using Pre-trained Models</li> </ul> </li> <li>TensorFlow Lite<ul> <li>Converting to TensorFlow Lite</li> <li>Quantization</li> <li>Inference with TensorFlow Lite</li> </ul> </li> <li>TensorFlow Serving<ul> <li>Exporting a SavedModel</li> <li>Serving with TensorFlow Serving</li> </ul> </li> <li>TensorFlow Extended (TFX)</li> <li>TensorFlow Probability<ul> <li>Installation</li> <li>Distributions</li> <li>Bijectors</li> <li>Markov Chain Monte Carlo (MCMC)</li> </ul> </li> <li>TensorFlow Datasets (TFDS)<ul> <li>Installation</li> <li>Loading Datasets</li> <li>Processing Datasets</li> </ul> </li> <li>TensorFlow Addons<ul> <li>Installation</li> <li>Usage (Example: WeightNormalization)</li> </ul> </li> <li>Eager Execution</li> <li>tf.function</li> <li>Custom Training with GradientTape</li> <li>Custom Callbacks</li> <li>Mixed Precision Training</li> <li>Profiling</li> <li>Best Practices</li> <li>Common Issues and Debugging</li> </ul> </li> </ul> <p>This cheat sheet provides an exhaustive overview of TensorFlow 2.x, covering essential concepts, code snippets, and best practices for efficient deep learning model building, training, evaluation, and deployment. It aims to be a one-stop reference for common tasks.</p>"},{"location":"Cheat-Sheets/tensorflow/#getting-started","title":"Getting Started","text":""},{"location":"Cheat-Sheets/tensorflow/#installation","title":"Installation","text":"<pre><code>pip install tensorflow\n</code></pre> <p>For GPU support:</p> <pre><code>pip install tensorflow-gpu  # (Deprecated in TF 2.10)\n# For newer versions, TensorFlow automatically uses GPU if available\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#importing-tensorflow","title":"Importing TensorFlow","text":"<pre><code>import tensorflow as tf\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#checking-version","title":"Checking Version","text":"<pre><code>print(tf.__version__)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#checking-gpu-availability","title":"Checking GPU Availability","text":"<pre><code>print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensors","title":"Tensors","text":""},{"location":"Cheat-Sheets/tensorflow/#creating-tensors","title":"Creating Tensors","text":"<pre><code># Constant tensors\na = tf.constant([[1, 2], [3, 4]])\nb = tf.zeros((2, 3))\nc = tf.ones((3, 2))\nd = tf.eye(3)  # Identity matrix\ne = tf.random.normal((2, 2))  # Normal distribution\nf = tf.random.uniform((2, 2))  # Uniform distribution\n\n# From NumPy arrays\nimport numpy as np\narr = np.array([1, 2, 3])\ntensor_from_np = tf.convert_to_tensor(arr)\n\n# Sequences\nrange_tensor = tf.range(start=0, limit=10, delta=2) # 0, 2, 4, 6, 8\nlinspace_tensor = tf.linspace(start=0.0, stop=1.0, num=5) # 0.0, 0.25, 0.5, 0.75, 1.0\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensor-attributes","title":"Tensor Attributes","text":"<pre><code>tensor = tf.constant([[1, 2], [3, 4]])\nprint(tensor.shape)       # Shape of the tensor\nprint(tensor.dtype)       # Data type of the tensor\nprint(tensor.device)      # Device where the tensor is stored (CPU or GPU)\nprint(tensor.numpy())     # Convert to a NumPy array\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensor-operations","title":"Tensor Operations","text":"<pre><code>a = tf.constant([[1, 2], [3, 4]])\nb = tf.constant([[5, 6], [7, 8]])\n\n# Element-wise operations\nc = a + b       # Addition\nd = a - b       # Subtraction\ne = a * b       # Multiplication\nf = a / b       # Division\ng = tf.add(a, b) # Functional form\nh = tf.multiply(a, b) # Functional form\n\n# Matrix multiplication\ni = tf.matmul(a, b)\n\n# Transpose\nj = tf.transpose(a)\n\n# Reshape\nk = tf.reshape(a, (1, 4))\n\n# Squeeze and Expand\nl = tf.squeeze(tf.constant([[[1], [2], [3]]])) # Removes dimensions of size 1\nm = tf.expand_dims(tf.constant([1, 2, 3]), axis=0) # Adds a dimension of size 1\n\n# Concatenation\nn = tf.concat([a, b], axis=0)  # Concatenate along rows\no = tf.stack([a, b], axis=0)   # Stack along a new dimension\n\n# Reduce operations\np = tf.reduce_sum(a)        # Sum of all elements\nq = tf.reduce_mean(a)       # Mean of all elements\nr = tf.reduce_max(a)        # Maximum element\ns = tf.reduce_min(a)        # Minimum element\nt = tf.reduce_prod(a)       # Product of all elements\n\n# Argmax and Argmin\nu = tf.argmax(a, axis=1)    # Index of the maximum element along axis 1\nv = tf.argmin(a, axis=0)    # Index of the minimum element along axis 0\n\n# Casting\nw = tf.cast(a, tf.float32)  # Cast to float32\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#indexing-and-slicing","title":"Indexing and Slicing","text":"<pre><code>tensor = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(tensor[0])       # First row\nprint(tensor[:, 1])     # Second column\nprint(tensor[0:2, 1:3]) # Slicing\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#data-types","title":"Data Types","text":"<ul> <li><code>tf.float16</code>, <code>tf.float32</code>, <code>tf.float64</code>: Floating-point numbers.</li> <li><code>tf.int8</code>, <code>tf.int16</code>, <code>tf.int32</code>, <code>tf.int64</code>: Signed integers.</li> <li><code>tf.uint8</code>, <code>tf.uint16</code>, <code>tf.uint32</code>, <code>tf.uint64</code>: Unsigned integers.</li> <li><code>tf.bool</code>: Boolean.</li> <li><code>tf.string</code>: String.</li> <li><code>tf.complex64</code>, <code>tf.complex128</code>: Complex numbers.</li> <li><code>tf.qint8</code>, <code>tf.qint32</code>, <code>tf.quint8</code>: Quantized integers.</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/#variables","title":"Variables","text":"<pre><code>var = tf.Variable([1.0, 2.0])\nvar.assign([3.0, 4.0])\nvar.assign_add([1.0, 1.0])\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#automatic-differentiation-autograd","title":"Automatic Differentiation (Autograd)","text":"<pre><code>x = tf.Variable(3.0)\n\nwith tf.GradientTape() as tape:\n    y = x**2\n\ndy_dx = tape.gradient(y, x)\nprint(dy_dx.numpy())  # Output: 6.0\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#persistent-gradient-tape","title":"Persistent Gradient Tape","text":"<pre><code>x = tf.Variable(3.0)\n\nwith tf.GradientTape(persistent=True) as tape:\n    y = x**2\n    z = y * 2\n\ndy_dx = tape.gradient(y, x)  # 6.0\ndz_dx = tape.gradient(z, x)  # 12.0\nprint(dy_dx.numpy())\nprint(dz_dx.numpy())\n\ndel tape  # Drop the reference to the tape\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#watching-non-variable-tensors","title":"Watching Non-Variable Tensors","text":"<pre><code>x = tf.constant(3.0)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = x * x\ndy_dx = tape.gradient(y, x)\nprint(dy_dx.numpy())\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#keras-api","title":"Keras API","text":""},{"location":"Cheat-Sheets/tensorflow/#model-building","title":"Model Building","text":""},{"location":"Cheat-Sheets/tensorflow/#sequential-model","title":"Sequential Model","text":"<pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(784,)),\n    Dense(10, activation='softmax')\n])\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#functional-api","title":"Functional API","text":"<pre><code>from tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.models import Model\n\ninputs = Input(shape=(784,))\nx = Dense(128, activation='relu')(inputs)\noutputs = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#model-subclassing","title":"Model Subclassing","text":"<pre><code>import tensorflow as tf\n\nclass MyModel(tf.keras.Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n\n    def call(self, inputs, training=None): # Add training argument\n        x = self.dense1(inputs)\n        return self.dense2(x)\n\nmodel = MyModel()\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#layers","title":"Layers","text":"<ul> <li><code>tf.keras.layers.Dense</code>: Fully connected layer.</li> <li><code>tf.keras.layers.Conv2D</code>: 2D convolution layer.</li> <li><code>tf.keras.layers.MaxPooling2D</code>: Max pooling layer.</li> <li><code>tf.keras.layers.ReLU</code>: ReLU activation function.</li> <li><code>tf.keras.layers.Activation</code>: Applies an activation function.</li> <li><code>tf.keras.layers.Softmax</code>: Softmax activation function.</li> <li><code>tf.keras.layers.BatchNormalization</code>: Batch normalization layer.</li> <li><code>tf.keras.layers.Dropout</code>: Dropout layer.</li> <li><code>tf.keras.layers.Flatten</code>: Flattens the input.</li> <li><code>tf.keras.layers.Reshape</code>: Reshapes the input.</li> <li><code>tf.keras.layers.Embedding</code>: Embedding layer.</li> <li><code>tf.keras.layers.LSTM</code>: LSTM layer.</li> <li><code>tf.keras.layers.GRU</code>: GRU layer.</li> <li><code>tf.keras.layers.Bidirectional</code>: Bidirectional wrapper for RNNs.</li> <li><code>tf.keras.layers.Input</code>: Creates an input tensor.</li> <li><code>tf.keras.layers.Add</code>, <code>tf.keras.layers.Multiply</code>, <code>tf.keras.layers.Concatenate</code>: Merge layers.</li> <li><code>tf.keras.layers.GlobalAveragePooling2D</code>, <code>tf.keras.layers.GlobalMaxPooling2D</code>: Global pooling layers.</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/#activation-functions","title":"Activation Functions","text":"<ul> <li><code>'relu'</code>: Rectified Linear Unit.</li> <li><code>'sigmoid'</code>: Sigmoid function.</li> <li><code>'tanh'</code>: Hyperbolic tangent function.</li> <li><code>'softmax'</code>: Softmax function.</li> <li><code>'elu'</code>: Exponential Linear Unit.</li> <li><code>'selu'</code>: Scaled Exponential Linear Unit.</li> <li><code>'linear'</code>: Linear (identity) activation.</li> <li><code>'LeakyReLU'</code>: Leaky Rectified Linear Unit.</li> <li><code>'PReLU'</code>: Parametric Rectified Linear Unit.</li> <li><code>'gelu'</code>: Gaussian Error Linear Unit.</li> <li><code>'swish'</code>: Swish activation function.</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/#loss-functions","title":"Loss Functions","text":"<ul> <li><code>tf.keras.losses.CategoricalCrossentropy</code>: Categorical cross-entropy.</li> <li><code>tf.keras.losses.SparseCategoricalCrossentropy</code>: Sparse categorical cross-entropy.</li> <li><code>tf.keras.losses.BinaryCrossentropy</code>: Binary cross-entropy.</li> <li><code>tf.keras.losses.MeanSquaredError</code>: Mean squared error.</li> <li><code>tf.keras.losses.MeanAbsoluteError</code>: Mean absolute error.</li> <li><code>tf.keras.losses.Hinge</code>: Hinge loss.</li> <li><code>tf.keras.losses.KLDivergence</code>: Kullback-Leibler Divergence loss.</li> <li><code>tf.keras.losses.Huber</code>: Huber loss.</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/#optimizers","title":"Optimizers","text":"<ul> <li><code>tf.keras.optimizers.SGD</code>: Stochastic Gradient Descent.</li> <li><code>tf.keras.optimizers.Adam</code>: Adaptive Moment Estimation.</li> <li><code>tf.keras.optimizers.RMSprop</code>: Root Mean Square Propagation.</li> <li><code>tf.keras.optimizers.Adagrad</code>: Adaptive Gradient Algorithm.</li> <li><code>tf.keras.optimizers.Adadelta</code>: Adaptive Delta.</li> <li><code>tf.keras.optimizers.Adamax</code>: Adamax optimizer.</li> <li><code>tf.keras.optimizers.Nadam</code>: Nesterov Adam optimizer.</li> <li><code>tf.keras.optimizers.Ftrl</code>: Follow The Regularized Leader optimizer.</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/#metrics","title":"Metrics","text":"<ul> <li><code>tf.keras.metrics.Accuracy</code>: Accuracy.</li> <li><code>tf.keras.metrics.BinaryAccuracy</code>: Binary accuracy.</li> <li><code>tf.keras.metrics.CategoricalAccuracy</code>: Categorical accuracy.</li> <li><code>tf.keras.metrics.SparseCategoricalAccuracy</code>: Sparse categorical accuracy.</li> <li><code>tf.keras.metrics.TopKCategoricalAccuracy</code>: Top-K categorical accuracy.</li> <li><code>tf.keras.metrics.MeanSquaredError</code>: Mean squared error.</li> <li><code>tf.keras.metrics.MeanAbsoluteError</code>: Mean absolute error.</li> <li><code>tf.keras.metrics.Precision</code>: Precision.</li> <li><code>tf.keras.metrics.Recall</code>: Recall.</li> <li><code>tf.keras.metrics.AUC</code>: Area Under the Curve.</li> <li><code>tf.keras.metrics.F1Score</code>: F1 score.</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/#model-compilation","title":"Model Compilation","text":"<pre><code>model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#training","title":"Training","text":"<pre><code>import numpy as np\n\ndata = np.random.random((1000, 784))\nlabels = np.random.randint(10, size=(1000,))\none_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=10)\n\nmodel.fit(data, one_hot_labels, epochs=10, batch_size=32, validation_split=0.2)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#evaluation","title":"Evaluation","text":"<pre><code>loss, accuracy = model.evaluate(data, one_hot_labels)\nprint('Loss:', loss)\nprint('Accuracy:', accuracy)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#prediction","title":"Prediction","text":"<pre><code>predictions = model.predict(data)\npredicted_classes = np.argmax(predictions, axis=1)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#saving-and-loading-models","title":"Saving and Loading Models","text":"<pre><code># Save the entire model\nmodel.save('my_model.h5')\n\n# Load the entire model\nloaded_model = tf.keras.models.load_model('my_model.h5')\n\n# Save model weights\nmodel.save_weights('my_model_weights.h5')\n\n# Load model weights\nmodel.load_weights('my_model_weights.h5')\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#callbacks","title":"Callbacks","text":"<ul> <li><code>tf.keras.callbacks.ModelCheckpoint</code>: Saves the model at certain intervals.</li> <li><code>tf.keras.callbacks.EarlyStopping</code>: Stops training when a monitored metric has stopped improving.</li> <li><code>tf.keras.callbacks.TensorBoard</code>: Enables visualization of metrics and more.</li> <li><code>tf.keras.callbacks.ReduceLROnPlateau</code>: Reduces the learning rate when a metric has stopped improving.</li> <li><code>tf.keras.callbacks.CSVLogger</code>: Streams epoch results to a CSV file.</li> <li><code>tf.keras.callbacks.LearningRateScheduler</code>: Schedules the learning rate.</li> <li><code>tf.keras.callbacks.TerminateOnNaN</code>: Terminates training when a NaN loss is encountered.</li> </ul> <pre><code>from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n\ncheckpoint_callback = ModelCheckpoint(filepath='./checkpoints/model.{epoch:02d}-{val_loss:.2f}.h5',\n                                     save_best_only=True,\n                                     monitor='val_loss',\n                                     verbose=1)\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n\ntensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n\nmodel.fit(data, one_hot_labels, epochs=10, batch_size=32,\n          validation_data=(val_data, one_hot_val_labels),\n          callbacks=[checkpoint_callback, early_stopping_callback, tensorboard_callback])\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#regularization","title":"Regularization","text":"<ul> <li><code>tf.keras.regularizers.l1(0.01)</code>: L1 regularization.</li> <li><code>tf.keras.regularizers.l2(0.01)</code>: L2 regularization.</li> <li><code>tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01)</code>: L1 and L2 regularization.</li> </ul> <pre><code>from tensorflow.keras import regularizers\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(784,),\n          kernel_regularizer=regularizers.l1(0.01),  # L1 regularization\n          bias_regularizer=regularizers.l2(0.01)),    # L2 regularization\n    Dense(10, activation='softmax')\n])\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#custom-layers","title":"Custom Layers","text":"<pre><code>import tensorflow as tf\n\nclass MyCustomLayer(tf.keras.layers.Layer):\n    def __init__(self, units=32):\n        super(MyCustomLayer, self).__init__()\n        self.units = units\n\n    def build(self, input_shape):\n        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n                                 initializer='random_normal',\n                                 trainable=True)\n        self.b = self.add_weight(shape=(self.units,),\n                                 initializer='zeros',\n                                 trainable=True)\n\n    def call(self, inputs):\n        return tf.matmul(inputs, self.w) + self.b\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#custom-loss-functions","title":"Custom Loss Functions","text":"<pre><code>import tensorflow as tf\n\ndef my_custom_loss(y_true, y_pred):\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.reduce_mean(squared_difference, axis=-1)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#custom-metrics","title":"Custom Metrics","text":"<pre><code>import tensorflow as tf\n\nclass MyCustomMetric(tf.keras.metrics.Metric):\n    def __init__(self, name='my_custom_metric', **kwargs):\n        super(MyCustomMetric, self).__init__(name=name, **kwargs)\n        self.sum = self.add_weight(name='sum', initializer='zeros')\n        self.count = self.add_weight(name='count', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        values = tf.abs(y_true - y_pred)\n        if sample_weight is not None:\n            sample_weight = tf.cast(sample_weight, self.dtype)\n            values = tf.multiply(values, sample_weight)\n        self.sum.assign_add(tf.reduce_sum(values))\n        self.count.assign_add(tf.cast(tf.size(y_true), self.dtype))\n\n    def result(self):\n        return self.sum / self.count\n\n    def reset_state(self):\n        self.sum.assign(0.0)\n        self.count.assign(0.0)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#custom-training-loops","title":"Custom Training Loops","text":"<pre><code>import tensorflow as tf\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nloss_fn = tf.keras.losses.CategoricalCrossentropy()\nmetric_fn = tf.keras.metrics.CategoricalAccuracy()\n\n@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(images)\n        loss = loss_fn(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    metric_fn.update_state(labels, predictions)\n    return loss\n\nepochs = 10\nfor epoch in range(epochs):\n    for images, labels in dataset:\n        loss = train_step(images, labels)\n    print(f\"Epoch {epoch+1}, Loss: {loss.numpy():.4f}, Accuracy: {metric_fn.result().numpy():.4f}\")\n    metric_fn.reset_state()\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#data-input-pipelines-tfdata","title":"Data Input Pipelines (tf.data)","text":""},{"location":"Cheat-Sheets/tensorflow/#creating-datasets","title":"Creating Datasets","text":"<pre><code>import tensorflow as tf\n\n# From NumPy arrays\ndataset = tf.data.Dataset.from_tensor_slices((data, one_hot_labels))\n\n# From a list of files\ndataset = tf.data.Dataset.list_files(\"path/to/data/*.tfrecord\")\n\n# From a generator\ndef my_generator():\n    for i in range(1000):\n        yield i, i**2\n\ndataset = tf.data.Dataset.from_generator(my_generator, output_types=(tf.int32, tf.int32))\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#dataset-transformations","title":"Dataset Transformations","text":"<ul> <li><code>dataset.batch(batch_size)</code>: Combines consecutive elements into batches.</li> <li><code>dataset.shuffle(buffer_size)</code>: Randomly shuffles the elements of the dataset.</li> <li><code>dataset.repeat(count=None)</code>: Repeats the dataset (indefinitely if <code>count</code> is None).</li> <li><code>dataset.map(map_func)</code>: Applies a function to each element.</li> <li><code>dataset.prefetch(buffer_size)</code>: Prefetches elements for performance.</li> <li><code>dataset.cache()</code>: Caches the elements of the dataset.</li> <li><code>dataset.filter(predicate)</code>: Filters elements based on a predicate.</li> <li><code>dataset.interleave(map_func, cycle_length=None, block_length=None)</code>: Maps <code>map_func</code> across the dataset and interleaves the results.</li> <li><code>dataset.flat_map(map_func)</code>: Maps <code>map_func</code> across the dataset and flattens the result.</li> <li><code>dataset.take(count)</code>: Creates a dataset with at most <code>count</code> elements.</li> <li><code>dataset.skip(count)</code>: Skips the first <code>count</code> elements.</li> <li><code>dataset.zip(datasets)</code>: Zips together multiple datasets.</li> </ul> <pre><code>dataset = tf.data.Dataset.from_tensor_slices((data, one_hot_labels))\ndataset = dataset.shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#reading-tfrecord-files","title":"Reading TFRecord Files","text":"<pre><code>raw_dataset = tf.data.TFRecordDataset(\"my_data.tfrecord\")\n\n# Define a feature description\nfeature_description = {\n    'feature0': tf.io.FixedLenFeature([], tf.int64),\n    'feature1': tf.io.FixedLenFeature([], tf.string),\n    'feature2': tf.io.FixedLenFeature([10], tf.float32),\n}\n\ndef _parse_function(example_proto):\n  # Parse the input tf.train.Example proto using the feature description.\n  return tf.io.parse_single_example(example_proto, feature_description)\n\nparsed_dataset = raw_dataset.map(_parse_function)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#distributed-training","title":"Distributed Training","text":""},{"location":"Cheat-Sheets/tensorflow/#mirroredstrategy","title":"MirroredStrategy","text":"<pre><code>import tensorflow as tf\n\nstrategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n        tf.keras.layers.Dense(10, activation='softmax')\n    ])\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\nmodel.fit(data, one_hot_labels, epochs=10, batch_size=32)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#multiworkermirroredstrategy","title":"MultiWorkerMirroredStrategy","text":"<pre><code>import os, json\n\nos.environ['TF_CONFIG'] = json.dumps({\n    'cluster': {\n        'worker': [\"localhost:12345\", \"localhost:23456\"]\n    },\n    'task': {'type': 'worker', 'index': 0}\n})\n\nstrategy = tf.distribute.MultiWorkerMirroredStrategy()\n\nwith strategy.scope():\n    # ... build and compile model ...\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#parameterserverstrategy","title":"ParameterServerStrategy","text":"<pre><code>import os, json\nos.environ['TF_CONFIG'] = json.dumps({\n    'cluster': {\n        'worker': [\"localhost:12345\", \"localhost:23456\"],\n        'ps': [\"localhost:34567\"]\n    },\n    'task': {'type': 'worker', 'index': 0}\n})\n\nstrategy = tf.distribute.experimental.ParameterServerStrategy()\n\nwith strategy.scope():\n    # ... build and compile model ...\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tpustrategy","title":"TPUStrategy","text":"<pre><code>resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.TPUStrategy(resolver)\n\nwith strategy.scope():\n    # ... build and compile model ...\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensorflow-hub","title":"TensorFlow Hub","text":""},{"location":"Cheat-Sheets/tensorflow/#using-pre-trained-models","title":"Using Pre-trained Models","text":"<pre><code>import tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n                   trainable=False),  # Feature extraction\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.build([None, 224, 224, 3])  # Build the model\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensorflow-lite","title":"TensorFlow Lite","text":""},{"location":"Cheat-Sheets/tensorflow/#converting-to-tensorflow-lite","title":"Converting to TensorFlow Lite","text":"<pre><code>converter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\nwith open('model.tflite', 'wb') as f:\n    f.write(tflite_model)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#quantization","title":"Quantization","text":"<pre><code>converter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\ntflite_quant_model = converter.convert()\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#inference-with-tensorflow-lite","title":"Inference with TensorFlow Lite","text":"<pre><code>interpreter = tf.lite.Interpreter(model_content=tflite_model)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\n# Set input tensor\ninput_data = np.array(np.random.random_sample(input_details[0]['shape']), dtype=np.float32)\ninterpreter.set_tensor(input_details[0]['index'], input_data)\n\ninterpreter.invoke()\n\noutput_data = interpreter.get_tensor(output_details[0]['index'])\nprint(output_data)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensorflow-serving","title":"TensorFlow Serving","text":""},{"location":"Cheat-Sheets/tensorflow/#exporting-a-savedmodel","title":"Exporting a SavedModel","text":"<pre><code>tf.saved_model.save(model, \"path/to/saved_model\")\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#serving-with-tensorflow-serving","title":"Serving with TensorFlow Serving","text":"<ol> <li> <p>Install TensorFlow Serving:</p> <pre><code># See TensorFlow Serving installation guide for details\n</code></pre> </li> <li> <p>Start the server:</p> <pre><code>tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=my_model --model_base_path=/path/to/saved_model\n</code></pre> </li> <li> <p>Send requests (using <code>requests</code> library in Python):</p> </li> </ol> <pre><code>import requests\nimport json\n\ndata = json.dumps({\"instances\": [[1.0, 2.0, ...]]}) # Example input data\nheaders = {\"content-type\": \"application/json\"}\njson_response = requests.post('http://localhost:8501/v1/models/my_model:predict', data=data, headers=headers)\npredictions = json.loads(json_response.text)['predictions']\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensorflow-extended-tfx","title":"TensorFlow Extended (TFX)","text":"<p>TFX is a platform for building and deploying production ML pipelines.  It includes components for:</p> <ul> <li>Data validation (<code>tensorflow_data_validation</code>)</li> <li>Data transformation (<code>tensorflow_transform</code>)</li> <li>Model training (<code>tensorflow</code>)</li> <li>Model analysis (<code>tensorflow_model_analysis</code>)</li> <li>Model serving (<code>tensorflow_serving</code>)</li> <li>Pipeline orchestration (Apache Beam, Apache Airflow, Kubeflow Pipelines)</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/#tensorflow-probability","title":"TensorFlow Probability","text":""},{"location":"Cheat-Sheets/tensorflow/#installation_1","title":"Installation","text":"<pre><code>pip install tensorflow-probability\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#distributions","title":"Distributions","text":"<pre><code>import tensorflow_probability as tfp\n\ntfd = tfp.distributions\n\n# Normal distribution\nnormal_dist = tfd.Normal(loc=0., scale=1.)\nsamples = normal_dist.sample(10)\nlog_prob = normal_dist.log_prob(0.)\n\n# Bernoulli distribution\nbernoulli_dist = tfd.Bernoulli(probs=0.7)\nsamples = bernoulli_dist.sample(10)\n\n# Categorical distribution\ncategorical_dist = tfd.Categorical(probs=[0.2, 0.3, 0.5])\nsamples = categorical_dist.sample(10)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#bijectors","title":"Bijectors","text":"<pre><code>import tensorflow_probability as tfp\n\ntfb = tfp.bijectors\n\n# Affine bijector\naffine_bijector = tfb.Affine(shift=2., scale_diag=[3., 4.])\ntransformed_tensor = affine_bijector.forward(tf.constant([[1., 2.]]))\n\n# Exp bijector\nexp_bijector = tfb.Exp()\ntransformed_tensor = exp_bijector.forward(tf.constant([0., 1., 2.]))\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#markov-chain-monte-carlo-mcmc","title":"Markov Chain Monte Carlo (MCMC)","text":"<pre><code>import tensorflow_probability as tfp\n\ntfd = tfp.distributions\ntfm = tfp.mcmc\n\n# Define a target distribution (e.g., a normal distribution)\ntarget_log_prob_fn = tfd.Normal(loc=0., scale=1.).log_prob\n\n# Define a kernel (e.g., Hamiltonian Monte Carlo)\nkernel = tfm.HamiltonianMonteCarlo(\n    target_log_prob_fn=target_log_prob_fn,\n    step_size=0.1,\n    num_leapfrog_steps=3)\n\n# Run the MCMC sampler\nsamples, _ = tfm.sample_chain(\n    num_results=1000,\n    current_state=0.,\n    kernel=kernel)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensorflow-datasets-tfds","title":"TensorFlow Datasets (TFDS)","text":""},{"location":"Cheat-Sheets/tensorflow/#installation_2","title":"Installation","text":"<pre><code>pip install tensorflow-datasets\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#loading-datasets","title":"Loading Datasets","text":"<pre><code>import tensorflow_datasets as tfds\n\n# Load a dataset\n(ds_train, ds_test), ds_info = tfds.load(\n    'mnist',\n    split=['train', 'test'],\n    shuffle_files=True,\n    as_supervised=True,\n    with_info=True,\n)\n\n# Print dataset information\nprint(ds_info)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#processing-datasets","title":"Processing Datasets","text":"<pre><code>def normalize_img(image, label):\n  \"\"\"Normalizes images: `uint8` -&gt; `float32`.\"\"\"\n  return tf.cast(image, tf.float32) / 255., label\n\nds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\nds_train = ds_train.cache()\nds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\nds_train = ds_train.batch(128)\nds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n\nds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\nds_test = ds_test.batch(128)\nds_test = ds_test.cache()\nds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tensorflow-addons","title":"TensorFlow Addons","text":""},{"location":"Cheat-Sheets/tensorflow/#installation_3","title":"Installation","text":"<pre><code>pip install tensorflow-addons\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#usage-example-weightnormalization","title":"Usage (Example: WeightNormalization)","text":"<pre><code>import tensorflow_addons as tfa\n\nmodel = tf.keras.Sequential([\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(64, activation=\"relu\"), data_init=False),\n    tf.keras.layers.Dense(10, activation=\"softmax\"),\n])\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#eager-execution","title":"Eager Execution","text":"<p>Eager execution is enabled by default in TensorFlow 2.x.  You can check if it's enabled:</p> <pre><code>tf.executing_eagerly()  # Returns True\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#tffunction","title":"tf.function","text":"<pre><code>@tf.function\ndef my_function(x, y):\n    return x + y\n\n# Call the function\nresult = my_function(tf.constant(1), tf.constant(2))\nprint(result)\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#custom-training-with-gradienttape","title":"Custom Training with GradientTape","text":"<pre><code>import tensorflow as tf\n\n# Define the model, optimizer, and loss function\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(10, input_shape=(784,), activation='softmax')])\noptimizer = tf.keras.optimizers.Adam()\nloss_fn = tf.keras.losses.CategoricalCrossentropy()\n\n# Define a training step\n@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(images)\n        loss = loss_fn(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss\n\n# Training loop\nepochs = 10\nfor epoch in range(epochs):\n    for images, labels in dataset:\n        loss = train_step(images, labels)\n    print(f\"Epoch {epoch+1}, Loss: {loss.numpy():.4f}\")\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#custom-callbacks","title":"Custom Callbacks","text":"<pre><code>class MyCustomCallback(tf.keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs=None):\n        print(f\"Starting epoch {epoch}\")\n\n    def on_epoch_end(self, epoch, logs=None):\n        print(f\"Finished epoch {epoch}, loss: {logs['loss']:.4f}\")\n\n    def on_train_batch_begin(self, batch, logs=None):\n        print(f\"Training: Starting batch {batch}\")\n\n    def on_train_batch_end(self, batch, logs=None):\n        print(f\"Training: Finished batch {batch}, loss: {logs['loss']:.4f}\")\n\nmodel.fit(data, one_hot_labels, epochs=10, callbacks=[MyCustomCallback()])\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#mixed-precision-training","title":"Mixed Precision Training","text":"<pre><code>from tensorflow.keras.mixed_precision import experimental as mixed_precision\n\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy)\n\n# Build model with mixed precision\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n    tf.keras.layers.Dense(10, activation='softmax', dtype='float32') # Output layer should be float32\n])\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\noptimizer = mixed_precision.LossScaleOptimizer(optimizer)\n\n@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(images)\n        loss = tf.keras.losses.categorical_crossentropy(labels, predictions)\n        scaled_loss = optimizer.get_scaled_loss(loss)\n    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#profiling","title":"Profiling","text":"<pre><code>import tensorflow as tf\n\n# Profile the training steps 2 to 5\ntf.profiler.experimental.start('logdir')\n\nfor step in range(10):\n    # Your training step here\n    with tf.profiler.experimental.Trace('train', step_num=step):\n        # ... your training code ...\n        pass\ntf.profiler.experimental.stop()\n</code></pre> <p>Then, use TensorBoard to visualize the profiling results:</p> <pre><code>tensorboard --logdir logdir\n</code></pre>"},{"location":"Cheat-Sheets/tensorflow/#best-practices","title":"Best Practices","text":"<ul> <li>Use <code>tf.data</code> for efficient input pipelines: <code>tf.data</code> provides optimized data loading and preprocessing.</li> <li>Use <code>tf.function</code> to compile your functions into graphs: This can significantly improve performance.</li> <li>Use mixed precision training on compatible GPUs: This can speed up training and reduce memory usage.</li> <li>Use distributed training strategies for large models and datasets: Distribute the workload across multiple GPUs or machines.</li> <li>Use TensorBoard to monitor training progress: Visualize metrics, graphs, and more.</li> <li>Save and restore your models regularly: Use checkpoints to save your model's progress.</li> <li>Use Keras whenever possible: The Keras API is generally easier to use and more intuitive than the lower-level TensorFlow APIs.</li> <li>Use pre-trained models and transfer learning: Leverage existing models to speed up development and improve performance.</li> <li>Regularize your models to prevent overfitting: Use techniques like dropout, L1/L2 regularization, and batch normalization.</li> <li>Tune your hyperparameters: Use techniques like grid search, random search, or Bayesian optimization to find the best hyperparameters for your model.</li> <li>Validate your models carefully: Use a separate validation set to evaluate your model's performance and prevent overfitting.</li> <li>Use appropriate data types: Use <code>tf.float32</code> for most computations, but consider <code>tf.float16</code> for mixed precision training.</li> <li>Vectorize your operations: Avoid using Python loops when possible; use TensorFlow's vectorized operations instead.</li> <li>Use XLA (Accelerated Linear Algebra) for further performance improvements: Add <code>@tf.function(experimental_compile=True)</code> to your functions.</li> <li>Profile your code: Use the TensorFlow Profiler to identify performance bottlenecks.</li> <li>Keep your TensorFlow version up-to-date: Newer versions often include performance improvements and bug fixes.</li> <li>Read the TensorFlow documentation: The TensorFlow documentation is comprehensive and well-written.</li> </ul>"},{"location":"Cheat-Sheets/tensorflow/#common-issues-and-debugging","title":"Common Issues and Debugging","text":"<ul> <li> <p>Out of Memory (OOM) Errors:</p> <ul> <li>Reduce batch size.</li> <li>Use mixed precision training (<code>tf.float16</code>).</li> <li>Use gradient accumulation.</li> <li>Use a smaller model.</li> <li>Use gradient checkpointing.</li> <li>Free up memory by deleting unused tensors and variables.</li> <li>Use <code>tf.config.experimental.set_memory_growth(gpu, True)</code> to allow GPU memory to grow as needed (instead of allocating all at once).</li> </ul> </li> <li> <p>NaN (Not a Number) Losses:</p> <ul> <li>Reduce the learning rate.</li> <li>Use gradient clipping.</li> <li>Check for numerical instability (e.g., division by zero, taking the logarithm of a non-positive number).</li> <li>Use a different optimizer.</li> <li>Initialize weights appropriately.</li> <li>Use batch normalization.</li> <li>Check your data for errors (e.g., NaN values).</li> </ul> </li> <li> <p>Slow Training:</p> <ul> <li>Use a GPU.</li> <li>Use <code>tf.data</code> for efficient input pipelines.</li> <li>Use mixed precision training.</li> <li>Use distributed training.</li> <li>Use XLA compilation.</li> <li>Profile your code to identify bottlenecks.</li> <li>Increase batch size (if memory allows).</li> <li>Use asynchronous data loading.</li> <li>Use prefetching.</li> </ul> </li> <li> <p>Shape Mismatches:</p> <ul> <li>Carefully check the shapes of your tensors and ensure they are compatible with the operations you are performing.</li> <li>Use <code>tf.shape</code> and <code>tf.reshape</code> to inspect and modify tensor shapes.</li> </ul> </li> <li> <p>Data Type Errors:</p> <ul> <li>Ensure that your tensors have the correct data types (e.g., <code>tf.float32</code> for floating-point operations, <code>tf.int64</code> for indices).</li> <li>Use <code>tf.cast</code> to convert between data types.</li> </ul> </li> <li> <p>Device Placement Errors:</p> <ul> <li>Ensure that all tensors and operations are placed on the same device (CPU or GPU).</li> <li>Use <code>tf.device</code> to explicitly specify the device.</li> <li>Use <code>tf.distribute.Strategy</code> for distributed training.</li> </ul> </li> <li> <p>Gradient Issues (Vanishing/Exploding Gradients):</p> <ul> <li>Use gradient clipping.</li> <li>Use batch normalization.</li> <li>Use skip connections (e.g., ResNet).</li> <li>Use a different activation function (e.g., ReLU, LeakyReLU).</li> <li>Use a smaller learning rate.</li> <li>Use a different optimizer.</li> </ul> </li> <li> <p>Overfitting:</p> <ul> <li>Use regularization techniques (L1/L2 regularization, dropout).</li> <li>Use data augmentation.</li> <li>Use early stopping.</li> <li>Reduce model complexity.</li> <li>Increase the amount of training data.</li> </ul> </li> <li> <p>Underfitting:</p> <ul> <li>Increase model capacity.</li> <li>Train for longer.</li> <li>Use a more complex optimizer.</li> <li>Add more features.</li> <li>Reduce regularization.</li> </ul> </li> <li> <p>Debugging with <code>tf.print</code>:</p> <pre><code>@tf.function\ndef my_function(x):\n    tf.print(\"x:\", x)  # Print the value of x\n    return x * 2\n</code></pre> </li> <li> <p>Debugging with <code>tf.debugging.assert_*</code>:</p> <pre><code>@tf.function\ndef my_function(x):\n    tf.debugging.assert_positive(x, message=\"x must be positive\")\n    return x * 2\n</code></pre> </li> <li> <p>Using the TensorFlow Debugger (tfdbg): (Less common with TF 2.x eager execution, but still useful for graph mode)</p> </li> <li> <p>Using Python's <code>pdb</code> debugger:  You can use <code>pdb.set_trace()</code> inside your <code>@tf.function</code> decorated functions, but you'll need to run your code with eager execution disabled (<code>tf.config.run_functions_eagerly(False)</code>) or use <code>tf.py_function</code>.</p> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/","title":"Home","text":""},{"location":"Deploying-ML-models/deploying-ml-models/#introduction","title":"Introduction","text":"<p>This is a completely open-source platform for maintaining curated list of interview questions and answers for people looking and preparing for data science opportunities.</p> <p>Not only this, the platform will also serve as one point destination for all your needs like tutorials, online materials, etc.</p> <p>This platform is maintained by you! \ud83e\udd17 You can help us by answering/ improving existing questions as well as by sharing any new questions that you faced during your interviews.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#contribute-to-the-platform","title":"Contribute to the platform","text":"<p>Contribution in any form will be deeply appreciated. \ud83d\ude4f</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#add-questions","title":"Add questions","text":"<p>\u2753 Add your questions here. Please ensure to provide a detailed description to allow your fellow contributors to understand your questions and answer them to your satisfaction.</p> <p></p> <p>\ud83e\udd1d Please note that as of now, you cannot directly add a question via a pull request. This will help us to maintain the quality of the content for you.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#add-answerstopics","title":"Add answers/topics","text":"<p>\ud83d\udcdd These are the answers/topics that need your help at the moment</p> <ul> <li> Add documentation for the project</li> <li> Online Material for Learning</li> <li> Suggested Learning Paths</li> <li> Cheat Sheets<ul> <li> Django</li> <li> Flask</li> <li> Numpy</li> <li> Pandas</li> <li> PySpark</li> <li> Python</li> <li> RegEx</li> <li> SQL</li> </ul> </li> <li> NLP Interview Questions</li> <li> Add python common DSA interview questions</li> <li> Add Major ML topics<ul> <li> Linear Regression </li> <li> Logistic Regression </li> <li> SVM </li> <li> Random Forest </li> <li> Gradient boosting </li> <li> PCA </li> <li> Collaborative Filtering </li> <li> K-means clustering </li> <li> kNN </li> <li> ARIMA </li> <li> Neural Networks </li> <li> Decision Trees </li> <li> Overfitting, Underfitting</li> <li> Unbalanced, Skewed data</li> <li> Activation functions relu/ leaky relu</li> <li> Normalization</li> <li> DBSCAN </li> <li> Normal Distribution </li> <li> Precision, Recall </li> <li> Loss Function MAE, RMSE </li> </ul> </li> <li> Add Pandas questions</li> <li> Add NumPy questions</li> <li> Add TensorFlow questions</li> <li> Add PyTorch questions</li> <li> Add list of learning resources</li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#reportsolve-issues","title":"Report/Solve Issues","text":"<p>\ud83d\udd27 To report any issues find me on LinkedIn or raise an issue on GitHub.</p> <p>\ud83d\udee0 You can also solve existing issues on GitHub and create a pull request.</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#say-thanks","title":"Say Thanks","text":"<p>\ud83d\ude0a If this platform helped you in any way, it would be great if you could share it with others.</p> <p> </p> <pre><code>Check out this \ud83d\udc47 platform \ud83d\udc47 for data science content:\n\ud83d\udc49 https://singhsidhukuldeep.github.io/data-science-interview-prep/ \ud83d\udc48\n\n#data-science #machine-learning #interview-preparation \n</code></pre> <p>You can also star the repository on GitHub    and watch-out for any updates </p>"},{"location":"Deploying-ML-models/deploying-ml-models/#features","title":"Features","text":"<ul> <li> <p>\ud83c\udfa8 Beautiful: The design is built on top of most popular libraries like MkDocs and material which allows the platform to be responsive and to work on all sorts of devices \u2013 from mobile phones to wide-screens. The underlying fluid layout will always adapt perfectly to the available screen space.</p> </li> <li> <p>\ud83e\uddd0 Searchable: almost magically, all the content on the website is searchable without any further ado. The built-in search \u2013 server-less \u2013 is fast and accurate in responses to any of the queries.</p> </li> <li> <p>\ud83d\ude4c Accessible:</p> <ul> <li>Easy to use: \ud83d\udc4c The website is hosted on github-pages and is free and open to use to over 40 million users of GitHub in 100+ countries.</li> <li>Easy to contribute: \ud83e\udd1d The website embodies the concept of collaboration to the latter. Allowing anyone to add/improve the content. To make contributing easy, everything is written in MarkDown and then compiled to beautiful html.</li> </ul> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#setup","title":"Setup","text":"<p>No setup is required for usage of the platform</p> <p>Important: It is strongly advised to use virtual environment and not change anything in <code>gh-pages</code></p>"},{"location":"Deploying-ML-models/deploying-ml-models/#linux-systems","title":"<code>Linux</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nsource venv/bin/activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>deactivate\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#windows-systems","title":"<code>Windows</code> Systems","text":"<pre><code>python3 -m venv ./venv\n\nvenv\\Scripts\\activate\n\npip3 install -r requirements.txt\n</code></pre> <pre><code>venv\\Scripts\\deactivate\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#to-install-the-latest","title":"To install the latest","text":"<pre><code>pip3 install mkdocs\npip3 install mkdocs-material\n</code></pre>"},{"location":"Deploying-ML-models/deploying-ml-models/#useful-commands","title":"Useful Commands","text":"<ul> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Use\u00a0<code>mkdocs gh-deploy --help</code>\u00a0to get a full list of options available for the\u00a0<code>gh-deploy</code>\u00a0command.     Be aware that you will not be able to review the built site before it is pushed to GitHub. Therefore, you may want to verify any changes you make to the docs beforehand by using the\u00a0<code>build</code>\u00a0or\u00a0<code>serve</code>\u00a0commands and reviewing the built files locally.</li> <li><code>mkdocs new [dir-name]</code> - Create a new project. No need to create a new project</li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#useful-documents","title":"Useful Documents","text":"<ul> <li> <p>\ud83d\udcd1 MkDocs: https://github.com/mkdocs/mkdocs</p> </li> <li> <p>\ud83c\udfa8 Theme: https://github.com/squidfunk/mkdocs-material</p> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#faq","title":"FAQ","text":"<ul> <li> <p>Can I filter questions based on companies? \ud83e\udd2a</p> <p>As much as this platform aims to help you with your interview preparation, it is not a short-cut to crack one. Think of this platform as a practicing field to help you sharpen your skills for your interview processes. However, for your convenience we have sorted all the questions by topics for you. \ud83e\udd13</p> <p>This doesn't mean that such feature won't be added in the future.  \"Never say Never\"</p> <p>But as of now there is neither plan nor data to do so. \ud83d\ude22</p> </li> <li> <p>Why is this platform free? \ud83e\udd17</p> <p>Currently there is no major cost involved in maintaining this platform other than time and effort that is put in by every contributor.  If you want to help you can contribute here. </p> <p>If you still want to pay for something that is free, we would request you to donate it to a charity of your choice instead. \ud83d\ude07</p> </li> </ul>"},{"location":"Deploying-ML-models/deploying-ml-models/#credits","title":"Credits","text":""},{"location":"Deploying-ML-models/deploying-ml-models/#maintained-by","title":"Maintained by","text":"<p>\ud83d\udc68\u200d\ud83c\udf93 Kuldeep Singh Sidhu </p> <p>Github: github/singhsidhukuldeep <code>https://github.com/singhsidhukuldeep</code></p> <p>Website: Kuldeep Singh Sidhu (Website) <code>http://kuldeepsinghsidhu.com</code></p> <p>LinkedIn: Kuldeep Singh Sidhu (LinkedIn) <code>https://www.linkedin.com/in/singhsidhukuldeep/</code></p>"},{"location":"Deploying-ML-models/deploying-ml-models/#contributors","title":"Contributors","text":"<p>\ud83d\ude0e The full list of all the contributors is available here</p>"},{"location":"Deploying-ML-models/deploying-ml-models/#current-status","title":"Current Status","text":""},{"location":"Interview-Questions/Interview-Questions/","title":"Interview Questions (Intro)","text":"<p>These are currently most commonly asked questions. Questions can be removed if they are no longer popular in interview circles and added as new question banks are released.</p>"},{"location":"Interview-Questions/Machine-Learning/","title":"Machine Learning Interview Questions","text":"<p>This document provides a curated list of 100 Machine Learning interview questions commonly asked in technical interviews. It covers topics ranging from basic ML concepts and data preprocessing to deep learning, reinforcement learning, and advanced optimization techniques. The list is updated frequently to serve as a comprehensive reference for interview preparation.</p> Sno Question Title Practice Links Companies Asking Difficulty Topics 1 Bias-Variance Tradeoff Machine Learning Mastery Google, Facebook, Amazon Medium Model Evaluation, Generalization 2 Regularization Techniques (L1, L2) Machine Learning Mastery Google, Amazon, Microsoft Medium Overfitting, Generalization 3 Cross-Validation Scikit-Learn Cross Validation Google, Facebook, Amazon Easy Model Evaluation 4 Overfitting and Underfitting Analytics Vidhya Google, Amazon, Facebook Easy Model Evaluation 5 Gradient Descent Towards Data Science Google, Amazon, Microsoft Medium Optimization 6 Supervised vs Unsupervised Learning IBM Cloud Learn Google, Facebook, Amazon Easy ML Basics 7 Classification vs Regression Towards Data Science Google, Amazon, Facebook Easy ML Basics 8 Evaluation Metrics: Precision, Recall, F1-score Towards Data Science Google, Amazon, Microsoft Medium Model Evaluation 9 Decision Trees Machine Learning Mastery Google, Amazon, Facebook Medium Tree-based Models 10 Ensemble Learning: Bagging and Boosting Towards Data Science Google, Amazon, Microsoft Medium Ensemble Methods 11 Random Forest Towards Data Science Google, Amazon, Facebook Medium Ensemble, Decision Trees 12 Support Vector Machines (SVM) Machine Learning Mastery Google, Facebook, Amazon Hard Classification, Kernel Methods 13 k-Nearest Neighbors (k-NN) Towards Data Science Google, Amazon, Facebook Easy Instance-based Learning 14 Dimensionality Reduction: PCA Towards Data Science Google, Amazon, Microsoft Medium Dimensionality Reduction 15 Handling Missing Data Machine Learning Mastery Google, Amazon, Facebook Easy Data Preprocessing 16 Parametric vs Non-Parametric Models Towards Data Science Google, Amazon Medium Model Types 17 Neural Networks: Basics Towards Data Science Google, Facebook, Amazon Medium Deep Learning 18 Convolutional Neural Networks (CNNs) Towards Data Science Google, Facebook, Amazon Hard Deep Learning, Computer Vision 19 Recurrent Neural Networks (RNNs) and LSTMs Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Sequence Models 20 Reinforcement Learning Basics Towards Data Science Google, Amazon, Facebook Hard Reinforcement Learning 21 Hyperparameter Tuning Machine Learning Mastery Google, Amazon, Microsoft Medium Model Optimization 22 Feature Engineering Towards Data Science Google, Amazon, Facebook Medium Data Preprocessing 23 ROC Curve and AUC Towards Data Science Google, Amazon, Microsoft Medium Model Evaluation 24 Regression Evaluation Metrics Scikit-Learn Google, Amazon, Facebook Medium Model Evaluation, Regression 25 Curse of Dimensionality Machine Learning Mastery Google, Amazon, Facebook Hard Data Preprocessing 26 Logistic Regression Towards Data Science Google, Amazon, Facebook Easy Classification, Regression 27 Linear Regression Analytics Vidhya Google, Amazon, Facebook Easy Regression 28 Loss Functions in ML Towards Data Science Google, Amazon, Microsoft Medium Optimization, Model Evaluation 29 Gradient Descent Variants Machine Learning Mastery Google, Amazon, Facebook Medium Optimization 30 Data Normalization and Standardization Machine Learning Mastery Google, Amazon, Facebook Easy Data Preprocessing 31 k-Means Clustering Towards Data Science Google, Amazon, Facebook Medium Clustering 32 Other Clustering Techniques Analytics Vidhya Google, Amazon, Facebook Medium Clustering 33 Anomaly Detection Towards Data Science Google, Amazon, Facebook Hard Outlier Detection 34 Learning Rate in Optimization Machine Learning Mastery Google, Amazon, Microsoft Medium Optimization 35 Deep Learning vs. Traditional ML IBM Cloud Learn Google, Amazon, Facebook Medium Deep Learning, ML Basics 36 Dropout in Neural Networks Towards Data Science Google, Amazon, Facebook Medium Deep Learning, Regularization 37 Backpropagation Analytics Vidhya Google, Amazon, Facebook Hard Deep Learning, Neural Networks 38 Role of Activation Functions Machine Learning Mastery Google, Amazon, Facebook Medium Neural Networks 39 Word Embeddings and Their Use Towards Data Science Google, Amazon, Facebook Medium NLP, Deep Learning 40 Transfer Learning Machine Learning Mastery Google, Amazon, Facebook Medium Deep Learning, Model Reuse 41 Bayesian Optimization for Hyperparameters Towards Data Science Google, Amazon, Microsoft Hard Hyperparameter Tuning, Optimization 42 Model Interpretability: SHAP and LIME Towards Data Science Google, Amazon, Facebook Hard Model Interpretability, Explainability 43 Ensemble Methods: Stacking and Blending Machine Learning Mastery Google, Amazon, Microsoft Hard Ensemble Methods 44 Gradient Boosting Machines (GBM) Basics Towards Data Science Google, Amazon, Facebook Medium Ensemble, Boosting 45 Extreme Gradient Boosting (XGBoost) Overview Towards Data Science Google, Amazon, Facebook Medium Ensemble, Boosting 46 LightGBM vs XGBoost Comparison Analytics Vidhya Google, Amazon Medium Ensemble, Boosting 47 CatBoost: Handling Categorical Features Towards Data Science Google, Amazon, Facebook Medium Ensemble, Categorical Data 48 Time Series Forecasting with ARIMA Analytics Vidhya Google, Amazon, Facebook Hard Time Series, Forecasting 49 Time Series Forecasting with LSTM Towards Data Science Google, Amazon, Facebook Hard Time Series, Deep Learning 50 Robust Scaling Techniques Towards Data Science Google, Amazon, Facebook Medium Data Preprocessing 51 Data Imputation Techniques in ML Machine Learning Mastery Google, Amazon, Facebook Medium Data Preprocessing 52 Handling Imbalanced Datasets: SMOTE and Others Towards Data Science Google, Amazon, Facebook Hard Data Preprocessing, Classification 53 Bias in Machine Learning: Fairness and Ethics Towards Data Science Google, Amazon, Facebook Hard Ethics, Fairness 54 Model Deployment: From Prototype to Production Towards Data Science Google, Amazon, Facebook Medium Deployment 55 Online Learning Algorithms Towards Data Science Google, Amazon, Microsoft Hard Online Learning 56 Concept Drift in Machine Learning Towards Data Science Google, Amazon, Facebook Hard Model Maintenance 57 Transfer Learning in NLP: BERT, GPT Towards Data Science Google, Amazon, Facebook Hard NLP, Deep Learning 58 Natural Language Processing: Text Preprocessing Analytics Vidhya Google, Amazon, Facebook Easy NLP, Data Preprocessing 59 Text Vectorization: TF-IDF vs Word2Vec Towards Data Science Google, Amazon, Facebook Medium NLP, Feature Extraction 60 Transformer Architecture and Self-Attention Towards Data Science Google, Amazon, Facebook Hard NLP, Deep Learning 61 Understanding BERT for NLP Tasks Towards Data Science Google, Amazon, Facebook Hard NLP, Deep Learning 62 Understanding GPT Models Towards Data Science Google, Amazon, Facebook Hard NLP, Deep Learning 63 Data Augmentation Techniques in ML Towards Data Science Google, Amazon, Facebook Medium Data Preprocessing 64 Adversarial Machine Learning: Attack and Defense Towards Data Science Google, Amazon, Facebook Hard Security, ML 65 Explainable AI (XAI) in Practice Towards Data Science Google, Amazon, Facebook Hard Model Interpretability 66 Federated Learning: Concepts and Challenges Towards Data Science Google, Amazon, Facebook Hard Distributed Learning 67 Multi-Task Learning in Neural Networks Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Multi-Task 68 Metric Learning and Siamese Networks Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Metric Learning 69 Deep Reinforcement Learning: DQN Overview Towards Data Science Google, Amazon, Facebook Hard Reinforcement Learning, Deep Learning 70 Policy Gradient Methods in Reinforcement Learning Towards Data Science Google, Amazon, Facebook Hard Reinforcement Learning 71 Actor-Critic Methods in RL Towards Data Science Google, Amazon, Facebook Hard Reinforcement Learning 72 Monte Carlo Methods in Machine Learning Towards Data Science Google, Amazon, Facebook Medium Optimization, Probabilistic Methods 73 Expectation-Maximization Algorithm Towards Data Science Google, Amazon, Facebook Hard Clustering, Probabilistic Models 74 Gaussian Mixture Models (GMM) Towards Data Science Google, Amazon, Facebook Medium Clustering, Probabilistic Models 75 Bayesian Inference in ML Towards Data Science Google, Amazon, Facebook Hard Bayesian Methods 76 Markov Chain Monte Carlo (MCMC) Methods Towards Data Science Google, Amazon, Facebook Hard Bayesian Methods, Probabilistic Models 77 Variational Autoencoders (VAEs) Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Generative Models 78 Generative Adversarial Networks (GANs) Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Generative Models 79 Conditional GANs for Data Generation Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Generative Models 80 Sequence-to-Sequence Models in NLP Towards Data Science Google, Amazon, Facebook Hard NLP, Deep Learning 81 Attention Mechanisms in Seq2Seq Models Towards Data Science Google, Amazon, Facebook Hard NLP, Deep Learning 82 Capsule Networks: An Introduction Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Neural Networks 83 Self-Supervised Learning in Deep Learning Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Unsupervised Learning 84 Zero-Shot and Few-Shot Learning Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Transfer Learning 85 Meta-Learning: Learning to Learn Towards Data Science Google, Amazon, Facebook Hard Deep Learning, Optimization 86 Hyperparameter Sensitivity Analysis Towards Data Science Google, Amazon, Facebook Medium Hyperparameter Tuning 87 High-Dimensional Feature Selection Techniques Towards Data Science Google, Amazon, Facebook Hard Feature Engineering, Dimensionality Reduction 88 Multi-Label Classification Techniques Towards Data Science Google, Amazon, Facebook Hard Classification, Multi-Output 89 Ordinal Regression in Machine Learning Towards Data Science Google, Amazon, Facebook Medium Regression, Classification 90 Survival Analysis in ML Towards Data Science Google, Amazon, Facebook Hard Statistics, ML 91 Semi-Supervised Learning Methods Towards Data Science Google, Amazon, Facebook Hard Unsupervised Learning, ML Basics 92 Unsupervised Feature Learning Towards Data Science Google, Amazon, Facebook Medium Unsupervised Learning, Feature Extraction 93 Clustering Evaluation Metrics: Silhouette, Davies-Bouldin Towards Data Science Google, Amazon, Facebook Medium Clustering, Evaluation 94 Dimensionality Reduction: t-SNE and UMAP Towards Data Science Google, Amazon, Facebook Medium Dimensionality Reduction 95 Probabilistic Graphical Models: Bayesian Networks Towards Data Science Google, Amazon, Facebook Hard Probabilistic Models, Graphical Models 96 Hidden Markov Models (HMMs) in ML Towards Data Science Google, Amazon, Facebook Hard Probabilistic Models, Sequence Modeling 97 Recommender Systems: Collaborative Filtering Towards Data Science Google, Amazon, Facebook Medium Recommender Systems 98 Recommender Systems: Content-Based Filtering Towards Data Science Google, Amazon, Facebook Medium Recommender Systems 99 Anomaly Detection in Time Series Data Towards Data Science Google, Amazon, Facebook Hard Time Series, Anomaly Detection 100 Optimization Algorithms Beyond Gradient Descent (Adam, RMSProp, etc.) Towards Data Science Google, Amazon, Facebook Medium Optimization, Deep Learning"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-google-interview","title":"Questions asked in Google interview","text":"<ul> <li>Bias-Variance Tradeoff  </li> <li>Cross-Validation  </li> <li>Overfitting and Underfitting  </li> <li>Gradient Descent  </li> <li>Neural Networks: Basics  </li> <li>Convolutional Neural Networks (CNNs)  </li> <li>Recurrent Neural Networks (RNNs) and LSTMs  </li> <li>Reinforcement Learning Basics  </li> <li>Hyperparameter Tuning  </li> <li>Transfer Learning  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-facebook-interview","title":"Questions asked in Facebook interview","text":"<ul> <li>Bias-Variance Tradeoff  </li> <li>Cross-Validation  </li> <li>Overfitting and Underfitting  </li> <li>Neural Networks: Basics  </li> <li>Convolutional Neural Networks (CNNs)  </li> <li>Recurrent Neural Networks (RNNs) and LSTMs  </li> <li>Support Vector Machines (SVM)  </li> <li>k-Nearest Neighbors (k-NN)  </li> <li>Feature Engineering  </li> <li>Dropout in Neural Networks  </li> <li>Backpropagation  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-amazon-interview","title":"Questions asked in Amazon interview","text":"<ul> <li>Bias-Variance Tradeoff  </li> <li>Regularization Techniques (L1, L2)  </li> <li>Cross-Validation  </li> <li>Overfitting and Underfitting  </li> <li>Decision Trees  </li> <li>Ensemble Learning: Bagging and Boosting  </li> <li>Random Forest  </li> <li>Support Vector Machines (SVM)  </li> <li>Neural Networks: Basics  </li> <li>Hyperparameter Tuning  </li> <li>ROC Curve and AUC  </li> <li>Logistic Regression  </li> <li>Data Normalization and Standardization  </li> <li>k-Means Clustering  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-microsoft-interview","title":"Questions asked in Microsoft interview","text":"<ul> <li>Regularization Techniques (L1, L2)  </li> <li>Gradient Descent  </li> <li>Convolutional Neural Networks (CNNs)  </li> <li>Recurrent Neural Networks (RNNs) and LSTMs  </li> <li>Support Vector Machines (SVM)  </li> <li>Hyperparameter Tuning  </li> <li>ROC Curve and AUC  </li> <li>Loss Functions in ML  </li> <li>Learning Rate in Optimization  </li> <li>Bayesian Optimization for Hyperparameters  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-uber-interview","title":"Questions asked in Uber interview","text":"<ul> <li>Reinforcement Learning Basics  </li> <li>Anomaly Detection  </li> <li>Gradient Descent Variants  </li> <li>Model Deployment: From Prototype to Production  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-swiggy-interview","title":"Questions asked in Swiggy interview","text":"<ul> <li>Handling Missing Data  </li> <li>Data Imputation Techniques in ML  </li> <li>Feature Engineering  </li> <li>Model Interpretability: SHAP and LIME  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-flipkart-interview","title":"Questions asked in Flipkart interview","text":"<ul> <li>Ensemble Methods: Stacking and Blending  </li> <li>Time Series Forecasting with ARIMA  </li> <li>Time Series Forecasting with LSTM  </li> <li>Model Deployment: From Prototype to Production  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-ola-interview","title":"Questions asked in Ola interview","text":"<ul> <li>Time Series Forecasting with LSTM  </li> <li>Data Normalization and Standardization  </li> <li>Recurrent Neural Networks (RNNs) and LSTMs  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-paytm-interview","title":"Questions asked in Paytm interview","text":"<ul> <li>Model Deployment: From Prototype to Production  </li> <li>Online Learning Algorithms  </li> <li>Handling Imbalanced Datasets: SMOTE and Others  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-oyo-interview","title":"Questions asked in OYO interview","text":"<ul> <li>Data Preprocessing Techniques  </li> <li>Ensemble Learning: Bagging and Boosting  </li> <li>Regularization Techniques (L1, L2)  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-whatsapp-interview","title":"Questions asked in WhatsApp interview","text":"<ul> <li>Neural Networks: Basics  </li> <li>Convolutional Neural Networks (CNNs)  </li> <li>Recurrent Neural Networks (RNNs) and LSTMs  </li> <li>Dropout in Neural Networks  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-slack-interview","title":"Questions asked in Slack interview","text":"<ul> <li>Bias-Variance Tradeoff  </li> <li>Cross-Validation  </li> <li>Feature Engineering  </li> <li>Transfer Learning  </li> </ul>"},{"location":"Interview-Questions/Machine-Learning/#questions-asked-in-airbnb-interview","title":"Questions asked in Airbnb interview","text":"<ul> <li>Bias-Variance Tradeoff  </li> <li>Hyperparameter Tuning  </li> <li>Transfer Learning  </li> <li>Model Interpretability: SHAP and LIME  </li> </ul> <p>Note: The practice links are curated from reputable sources such as Machine Learning Mastery, Towards Data Science, Analytics Vidhya, and Scikit-learn. You can update/contribute to these lists or add new ones as more resources become available.</p>"},{"location":"Interview-Questions/Natural-Language-Processing/","title":"Natural Language Processing (NLP) Interview Questions","text":"<p>This document provides a curated list of 100 NLP interview questions commonly asked in technical interviews. Covering topics from the fundamentals of text processing to deep learning\u2013based language models, this list is updated frequently and is intended to serve as a comprehensive reference for interview preparation.</p> Sno Question Title Practice Links Companies Asking Difficulty Topics 1 What is Natural Language Processing? Analytics Vidhya NLP Basics Google, Facebook, Amazon Easy NLP Basics 2 Explain Tokenization. Towards Data Science \u2013 Tokenization Google, Amazon, Facebook Easy Preprocessing 3 What is Stop Word Removal and why is it important? TDS \u2013 Stop Words Google, Facebook, Amazon Easy Preprocessing 4 Explain Stemming. TDS \u2013 Stemming Google, Amazon, Microsoft Easy Preprocessing 5 Explain Lemmatization. Analytics Vidhya \u2013 Lemmatization Google, Facebook, Amazon Easy Preprocessing 6 What is the Bag-of-Words Model? TDS \u2013 Bag-of-Words Google, Facebook, Amazon Easy Text Representation 7 Explain TF-IDF and its applications. TDS \u2013 TF-IDF Google, Amazon, Microsoft Easy Feature Extraction 8 What are Word Embeddings? TDS \u2013 Word Embeddings Google, Facebook, Amazon Medium Embeddings 9 Explain the Word2Vec algorithm. TDS \u2013 Word2Vec Google, Amazon, Facebook Medium Embeddings 10 Explain GloVe embeddings. TDS \u2013 GloVe Google, Facebook, Amazon Medium Embeddings 11 What is FastText and how does it differ from Word2Vec? TDS \u2013 FastText Google, Facebook, Amazon Medium Embeddings 12 What is one-hot encoding in NLP? Analytics Vidhya \u2013 NLP Encoding Google, Amazon, Facebook Easy Text Representation 13 What is an n-gram Language Model? TDS \u2013 N-grams Google, Facebook, Amazon Medium Language Modeling 14 Explain Language Modeling. TDS \u2013 Language Modeling Google, Amazon, Microsoft Medium Language Modeling 15 How are Recurrent Neural Networks (RNNs) used in NLP? TDS \u2013 RNNs for NLP Google, Facebook, Amazon Medium Deep Learning, Sequence Models 16 Explain Long Short-Term Memory (LSTM) Networks in NLP. TDS \u2013 LSTM Google, Amazon, Facebook Medium Deep Learning, Sequence Models 17 What are Gated Recurrent Units (GRU) and their benefits? TDS \u2013 GRU Google, Facebook, Amazon Medium Deep Learning, Sequence Models 18 What is the Transformer architecture? TDS \u2013 Transformers Google, Facebook, Amazon Hard Deep Learning, Transformers 19 What is BERT and how does it work? TDS \u2013 BERT Google, Facebook, Amazon Hard Language Models, Transformers 20 What is GPT and what are its applications in NLP? TDS \u2013 GPT Google, Facebook, Amazon Hard Language Models, Transformers 21 Explain the Attention Mechanism in NLP. TDS \u2013 Attention Google, Amazon, Facebook Hard Deep Learning, Transformers 22 What is Self-Attention? TDS \u2013 Self-Attention Google, Facebook, Amazon Hard Deep Learning, Transformers 23 Explain Sequence-to-Sequence Models. TDS \u2013 Seq2Seq Google, Facebook, Amazon Medium Deep Learning, Generation 24 What is Machine Translation? TDS \u2013 Machine Translation Google, Amazon, Facebook Medium Applications 25 Explain Sentiment Analysis. Analytics Vidhya \u2013 Sentiment Analysis Google, Facebook, Amazon Easy Applications 26 What is Named Entity Recognition (NER)? TDS \u2013 NER Google, Amazon, Facebook Easy Applications 27 What is Part-of-Speech Tagging? TDS \u2013 POS Tagging Google, Facebook, Amazon Easy Linguistic Processing 28 Explain Dependency Parsing. TDS \u2013 Dependency Parsing Google, Amazon, Microsoft Medium Parsing 29 What is Constituency Parsing? TDS \u2013 Constituency Parsing Google, Facebook, Amazon Medium Parsing 30 Explain Semantic Role Labeling. TDS \u2013 Semantic Role Labeling Google, Amazon, Facebook Hard Parsing, Semantics 31 What is Text Classification? Analytics Vidhya \u2013 Text Classification Google, Facebook, Amazon Easy Applications 32 What is Topic Modeling? TDS \u2013 Topic Modeling Google, Amazon, Facebook Medium Unsupervised Learning 33 Explain Latent Dirichlet Allocation (LDA). TDS \u2013 LDA Google, Amazon, Facebook Medium Topic Modeling 34 Explain Latent Semantic Analysis (LSA). TDS \u2013 LSA Google, Facebook, Amazon Medium Topic Modeling 35 What is Text Summarization? Analytics Vidhya \u2013 Summarization Google, Facebook, Amazon Medium Applications 36 Differentiate between Extractive and Abstractive Summarization. TDS \u2013 Summarization Google, Amazon, Facebook Hard Applications 37 What are Language Generation Models? TDS \u2013 Language Generation Google, Facebook, Amazon Hard Generation 38 Explain Sequence Labeling. TDS \u2013 Sequence Labeling Google, Amazon, Facebook Medium Applications 39 What is a Conditional Random Field (CRF) in NLP? TDS \u2013 CRF Google, Facebook, Amazon Hard Sequence Modeling 40 What is Word Sense Disambiguation? TDS \u2013 WSD Google, Amazon, Facebook Hard Semantics 41 Explain the concept of Perplexity in Language Models. TDS \u2013 Perplexity Google, Facebook, Amazon Medium Language Modeling 42 What is Text Normalization? Analytics Vidhya \u2013 NLP Preprocessing Google, Amazon, Facebook Easy Preprocessing 43 What is Noise Removal in Text Processing? TDS \u2013 NLP Preprocessing Google, Facebook, Amazon Easy Preprocessing 44 Explain the importance of punctuation in NLP. TDS \u2013 NLP Basics Google, Amazon, Facebook Easy Preprocessing 45 What is Document Classification? Analytics Vidhya \u2013 Document Classification Google, Facebook, Amazon Easy Applications 46 Explain the Vector Space Model. TDS \u2013 Vector Space Google, Amazon, Facebook Medium Text Representation 47 What is Cosine Similarity in Text Analysis? TDS \u2013 Cosine Similarity Google, Facebook, Amazon Medium Similarity Measures 48 What is Semantic Similarity? TDS \u2013 Semantic Similarity Google, Amazon, Facebook Medium Semantics 49 What is Text Clustering? TDS \u2013 Text Clustering Google, Facebook, Amazon Medium Unsupervised Learning 50 Explain Hierarchical Clustering for Text. TDS \u2013 Hierarchical Clustering Google, Amazon, Facebook Medium Unsupervised Learning 51 What is DBSCAN in the context of NLP? TDS \u2013 DBSCAN Google, Facebook, Amazon Medium Unsupervised Learning 52 Explain the process of Fine-tuning Pre-trained Language Models. TDS \u2013 Fine-tuning NLP Google, Amazon, Facebook Hard Transfer Learning 53 What is Transfer Learning in NLP? Analytics Vidhya \u2013 Transfer Learning Google, Facebook, Amazon Medium Transfer Learning 54 What is Zero-Shot Classification in NLP? TDS \u2013 Zero-Shot Learning Google, Amazon, Facebook Hard Transfer Learning 55 What is Few-Shot Learning in NLP? TDS \u2013 Few-Shot Learning Google, Facebook, Amazon Hard Transfer Learning 56 Explain Adversarial Attacks on NLP Models. TDS \u2013 Adversarial NLP Google, Facebook, Amazon Hard Security, Robustness 57 Discuss Bias in NLP Models. TDS \u2013 NLP Bias Google, Amazon, Facebook Hard Ethics, Fairness 58 What are Ethical Considerations in NLP? Analytics Vidhya \u2013 Ethical NLP Google, Facebook, Amazon Hard Ethics 59 What is Language Detection? TDS \u2013 Language Detection Google, Amazon, Facebook Easy Applications 60 Explain Transliteration in NLP. TDS \u2013 Transliteration Google, Facebook, Amazon Medium Applications 61 What is Language Identification? Analytics Vidhya \u2013 NLP Basics Google, Amazon, Facebook Easy Applications 62 Explain Query Expansion in Information Retrieval. TDS \u2013 Information Retrieval Google, Facebook, Amazon Medium IR, NLP 63 What is Textual Entailment? TDS \u2013 Textual Entailment Google, Amazon, Facebook Hard Semantics 64 What is Natural Language Inference (NLI)? TDS \u2013 NLI Google, Facebook, Amazon Hard Semantics 65 What are Dialog Systems in NLP? Analytics Vidhya \u2013 Dialog Systems Google, Facebook, Amazon Medium Conversational AI 66 Explain Chatbot Architecture. TDS \u2013 Chatbots Google, Amazon, Facebook Medium Conversational AI 67 What is Intent Detection in Chatbots? TDS \u2013 Intent Detection Google, Facebook, Amazon Medium Conversational AI 68 What is Slot Filling in Conversational Agents? TDS \u2013 Slot Filling Google, Amazon, Facebook Medium Conversational AI 69 Explain Conversation Modeling. TDS \u2013 Conversation Modeling Google, Facebook, Amazon Hard Conversational AI 70 How is Sentiment Analysis performed using lexicons? Analytics Vidhya \u2013 Sentiment Analysis Google, Facebook, Amazon Easy Applications 71 Explain deep learning techniques for sentiment analysis. TDS \u2013 Deep Sentiment Google, Amazon, Facebook Medium Deep Learning, Applications 72 What is Sequence-to-Sequence Learning for Chatbots? TDS \u2013 Seq2Seq Chatbots Google, Facebook, Amazon Hard Conversational AI 73 Explain the role of Attention in Machine Translation. TDS \u2013 Attention in MT Google, Amazon, Facebook Hard Deep Learning, Translation 74 What is Multi-Head Attention? TDS \u2013 Multi-Head Attention Google, Facebook, Amazon Hard Transformers 75 Explain the Encoder-Decoder Architecture. TDS \u2013 Encoder-Decoder Google, Amazon, Facebook Hard Deep Learning, Transformers 76 What is Beam Search in NLP? TDS \u2013 Beam Search Google, Facebook, Amazon Medium Decoding, Generation 77 Explain Back-Translation for Data Augmentation. TDS \u2013 Back-Translation Google, Amazon, Facebook Hard Data Augmentation 78 How does GPT generate text? TDS \u2013 GPT Generation Google, Facebook, Amazon Hard Language Models, Generation 79 What is Fine-tuning in Language Models? TDS \u2013 Fine-tuning Google, Facebook, Amazon Hard Transfer Learning 80 What is a Context Window in Language Models? TDS \u2013 Context Window Google, Amazon, Facebook Medium Language Modeling 81 Explain the Transformer Decoder. TDS \u2013 Transformer Decoder Google, Facebook, Amazon Hard Transformers 82 Discuss the importance of Embedding Layers in NLP. TDS \u2013 Embedding Layers Google, Facebook, Amazon Medium Deep Learning, Embeddings 83 What is Positional Encoding in Transformers? TDS \u2013 Positional Encoding Google, Facebook, Amazon Medium Transformers 84 What is Masked Language Modeling? TDS \u2013 Masked LM Google, Facebook, Amazon Hard Transformers, Pre-training 85 Explain Next Sentence Prediction in BERT. TDS \u2013 Next Sentence Prediction Google, Facebook, Amazon Hard BERT, Pre-training 86 What are Pre-trained Language Models? Analytics Vidhya \u2013 Pre-trained Models Google, Facebook, Amazon Easy Transfer Learning 87 Explain Open-Domain Question Answering in NLP. TDS \u2013 Question Answering Google, Facebook, Amazon Hard Applications, QA 88 What is Retrieval-Based NLP? TDS \u2013 Retrieval-Based Google, Facebook, Amazon Medium Applications, QA 89 Explain Extractive Question Answering. TDS \u2013 Extractive QA Google, Facebook, Amazon Hard Applications, QA 90 What is Abstractive Question Answering? TDS \u2013 Abstractive QA Google, Facebook, Amazon Hard Applications, QA 91 What is Machine Reading Comprehension? TDS \u2013 MRC Google, Facebook, Amazon Hard Applications, QA 92 What are Attention Heads in Transformers? TDS \u2013 Attention Heads Google, Facebook, Amazon Hard Transformers 93 Explain Sequence Transduction. TDS \u2013 Sequence Transduction Google, Facebook, Amazon Hard Deep Learning, Generation 94 Discuss the role of GPUs in NLP model training. Analytics Vidhya \u2013 NLP Infrastructure Google, Facebook, Amazon Medium Infrastructure 95 What is Subword Tokenization (BPE, SentencePiece)? TDS \u2013 Subword Tokenization Google, Facebook, Amazon Medium Preprocessing, Tokenization 96 What is a Language Corpus and why is it important? Analytics Vidhya \u2013 Language Corpora Google, Facebook, Amazon Easy NLP Resources 97 What are the challenges in Low-Resource Languages? TDS \u2013 Low-Resource NLP Google, Facebook, Amazon Hard Applications, Ethics 98 How do you handle Out-of-Vocabulary words in NLP? TDS \u2013 OOV Handling Google, Facebook, Amazon Medium Preprocessing, Embeddings 99 What are Transformer Variants and how do they differ? TDS \u2013 Transformer Variants Google, Facebook, Amazon Hard Transformers, Models 100 What are the Future Trends in Natural Language Processing? Analytics Vidhya \u2013 Future of NLP Google, Facebook, Amazon Medium Trends, Research"},{"location":"Interview-Questions/Natural-Language-Processing/#questions-asked-in-google-interview","title":"Questions asked in Google interview","text":"<ul> <li>What is Natural Language Processing?  </li> <li>Explain Tokenization.  </li> <li>What is TF-IDF and its applications.  </li> <li>What are Word Embeddings?  </li> <li>What is BERT and how does it work?  </li> <li>Explain the Attention Mechanism.  </li> <li>What is Machine Translation?  </li> <li>Explain Text Summarization.  </li> <li>What is Sentiment Analysis?  </li> <li>What is Named Entity Recognition (NER)?</li> </ul>"},{"location":"Interview-Questions/Natural-Language-Processing/#questions-asked-in-facebook-interview","title":"Questions asked in Facebook interview","text":"<ul> <li>Explain Tokenization.  </li> <li>What is Stop Word Removal?  </li> <li>Explain Stemming and Lemmatization.  </li> <li>What is the Bag-of-Words Model?  </li> <li>What are Word Embeddings (Word2Vec/GloVe/FastText)?  </li> <li>Explain the Transformer architecture.  </li> <li>What is GPT and its applications in NLP?  </li> <li>Explain the Attention Mechanism.  </li> <li>What is Sequence-to-Sequence Modeling?  </li> <li>What are Dialog Systems in NLP?</li> </ul>"},{"location":"Interview-Questions/Natural-Language-Processing/#questions-asked-in-amazon-interview","title":"Questions asked in Amazon interview","text":"<ul> <li>What is Natural Language Processing?  </li> <li>Explain TF-IDF and its applications.  </li> <li>What is Text Classification?  </li> <li>What is Topic Modeling (LDA/LSA)?  </li> <li>Explain Sentiment Analysis.  </li> <li>What is Named Entity Recognition (NER)?  </li> <li>Explain Language Modeling.  </li> <li>What is Transfer Learning in NLP?  </li> <li>What is Fine-tuning Pre-trained Language Models?  </li> <li>What are Pre-trained Language Models?</li> </ul>"},{"location":"Interview-Questions/Natural-Language-Processing/#questions-asked-in-microsoft-interview","title":"Questions asked in Microsoft interview","text":"<ul> <li>What is Natural Language Processing?  </li> <li>Explain Language Modeling and Perplexity.  </li> <li>What is the Transformer architecture?  </li> <li>What is BERT and how does it work?  </li> <li>Explain Dependency Parsing.  </li> <li>What is Text Summarization?  </li> <li>Explain Question Answering systems.  </li> <li>What is Subword Tokenization?  </li> <li>How do you handle Out-of-Vocabulary words?  </li> <li>Discuss challenges in low-resource languages.</li> </ul>"},{"location":"Interview-Questions/Natural-Language-Processing/#questions-asked-in-other-interviews","title":"Questions asked in other interviews","text":"<p>Uber / Flipkart / Ola: - Explain the Encoder-Decoder Architecture. - What is Beam Search in NLP? - How does GPT generate text? - What is Fine-tuning in Language Models?</p> <p>Swiggy / Paytm / OYO: - What is Noise Removal in Text Processing? - Explain Named Entity Recognition (NER). - What are Ethical Considerations in NLP? - How do you handle bias in NLP models?</p> <p>WhatsApp / Slack / Airbnb: - What is Natural Language Inference (NLI)? - Explain the Attention Mechanism. - What are Dialog Systems in NLP? - Discuss the future trends in NLP.</p>"},{"location":"Interview-Questions/Probability/","title":"Probability Interview Questions","text":"<p>This document provides a curated list of common probability interview questions frequently asked in technical interviews. It covers basic probability concepts, probability distributions, key theorems, and real-world applications. Use the practice links to explore detailed explanations and examples.</p> Sno Question Title Practice Links Companies Asking Difficulty Topics 1 Basic Probability Concepts: Definitions of Sample Space, Event, Outcome Wikipedia: Probability Google, Amazon, Microsoft Easy Fundamental Concepts 2 Conditional Probability and Independence Khan Academy: Conditional Probability Google, Facebook, Amazon Medium Conditional Probability, Independence 3 Bayes\u2019 Theorem: Statement and Application Wikipedia: Bayes' Theorem Google, Amazon, Microsoft Medium Bayesian Inference 4 Law of Total Probability Wikipedia: Law of Total Probability Google, Facebook Medium Theoretical Probability 5 Expected Value and Variance Khan Academy: Expected Value Google, Amazon, Facebook Medium Random Variables, Moments 6 Probability Distributions: Discrete vs. Continuous Wikipedia: Probability Distribution Google, Amazon, Microsoft Easy Distributions 7 Binomial Distribution: Definition and Applications Khan Academy: Binomial Distribution Amazon, Facebook Medium Discrete Distributions 8 Poisson Distribution: Characteristics and Uses Wikipedia: Poisson Distribution Google, Amazon Medium Discrete Distributions 9 Exponential Distribution: Properties and Applications Wikipedia: Exponential Distribution Google, Amazon Medium Continuous Distributions 10 Normal Distribution and the Central Limit Theorem Khan Academy: Normal Distribution Google, Microsoft, Facebook Medium Continuous Distributions, CLT 11 Law of Large Numbers Wikipedia: Law of Large Numbers Google, Amazon Medium Statistical Convergence 12 Covariance and Correlation: Definitions and Differences Khan Academy: Covariance and Correlation Google, Facebook Medium Statistics, Dependency 13 Moment Generating Functions (MGFs) Wikipedia: Moment-generating function Amazon, Microsoft Hard Random Variables, Advanced Concepts 14 Markov Chains: Basics and Applications Wikipedia: Markov chain Google, Amazon, Facebook Hard Stochastic Processes 15 Introduction to Stochastic Processes Wikipedia: Stochastic process Google, Microsoft Hard Advanced Probability 16 Difference Between Independent and Mutually Exclusive Events Wikipedia: Independent events Google, Facebook Easy Fundamental Concepts 17 Geometric Distribution: Concept and Use Cases Wikipedia: Geometric distribution Amazon, Microsoft Medium Discrete Distributions 18 Hypergeometric Distribution: When to Use It Wikipedia: Hypergeometric distribution Google, Amazon Medium Discrete Distributions 19 Confidence Intervals: Definition and Calculation Khan Academy: Confidence intervals Microsoft, Facebook Medium Inferential Statistics 20 Hypothesis Testing: p-values, Type I and Type II Errors Khan Academy: Hypothesis testing Google, Amazon, Facebook Medium Inferential Statistics 21 Chi-Squared Test: Basics and Applications Wikipedia: Chi-squared test Amazon, Microsoft Medium Inferential Statistics 22 Permutations and Combinations Khan Academy: Permutations and Combinations Google, Facebook Easy Combinatorics 23 The Birthday Problem and Its Implications Wikipedia: Birthday problem Google, Amazon Medium Probability Puzzles 24 The Monty Hall Problem Wikipedia: Monty Hall problem Google, Facebook Medium Probability Puzzles, Conditional Probability 25 Marginal vs. Conditional Probabilities Khan Academy: Conditional Probability Google, Amazon Medium Theoretical Concepts 26 Real-World Application of Bayes\u2019 Theorem Towards Data Science: Bayes\u2019 Theorem Applications Google, Amazon Medium Bayesian Inference 27 Probability Mass Function (PMF) vs. Probability Density Function (PDF) Wikipedia: Probability density function Amazon, Facebook Medium Distributions 28 Cumulative Distribution Function (CDF): Definition and Uses Wikipedia: Cumulative distribution function Google, Microsoft Medium Distributions 29 Determining Independence of Events Khan Academy: Independent Events Google, Amazon Easy Fundamental Concepts 30 Entropy in Information Theory Wikipedia: Entropy (information theory) Google, Facebook Hard Information Theory, Probability 31 Joint Probability Distributions Khan Academy: Joint Probability Microsoft, Amazon Medium Multivariate Distributions 32 Conditional Expectation Wikipedia: Conditional expectation Google, Facebook Hard Advanced Concepts 33 Sampling Methods: With and Without Replacement Khan Academy: Sampling Amazon, Microsoft Easy Sampling, Combinatorics 34 Risk Modeling Using Probability Investopedia: Risk Analysis Google, Amazon Medium Applications, Finance 35 In-Depth: Central Limit Theorem and Its Importance Khan Academy: Central Limit Theorem Google, Microsoft Medium Theoretical Concepts, Distributions 36 Variance under Linear Transformations Wikipedia: Variance Amazon, Facebook Hard Advanced Statistics 37 Quantiles: Definition and Interpretation Khan Academy: Percentiles Google, Amazon Medium Descriptive Statistics 38 Common Probability Puzzles and Brain Teasers Brilliant.org: Probability Puzzles Google, Facebook Medium Puzzles, Recreational Mathematics 39 Real-World Applications of Probability in Data Science Towards Data Science (Search for probability applications in DS) Google, Amazon, Facebook Medium Applications, Data Science 40 Advanced Topic: Introduction to Stochastic Calculus Wikipedia: Stochastic calculus Microsoft, Amazon Hard Advanced Probability, Finance"},{"location":"Interview-Questions/Probability/#questions-asked-in-google-interview","title":"Questions asked in Google interview","text":"<ul> <li>Bayes\u2019 Theorem: Statement and Application  </li> <li>Conditional Probability and Independence  </li> <li>The Birthday Problem  </li> <li>The Monty Hall Problem  </li> <li>Normal Distribution and the Central Limit Theorem  </li> <li>Law of Large Numbers  </li> </ul>"},{"location":"Interview-Questions/Probability/#questions-asked-in-facebook-interview","title":"Questions asked in Facebook interview","text":"<ul> <li>Conditional Probability and Independence  </li> <li>Bayes\u2019 Theorem  </li> <li>Chi-Squared Test  </li> <li>The Monty Hall Problem  </li> <li>Entropy in Information Theory  </li> </ul>"},{"location":"Interview-Questions/Probability/#questions-asked-in-amazon-interview","title":"Questions asked in Amazon interview","text":"<ul> <li>Basic Probability Concepts  </li> <li>Bayes\u2019 Theorem  </li> <li>Expected Value and Variance  </li> <li>Binomial and Poisson Distributions  </li> <li>Permutations and Combinations  </li> <li>Real-World Applications of Bayes\u2019 Theorem  </li> </ul>"},{"location":"Interview-Questions/Probability/#questions-asked-in-microsoft-interview","title":"Questions asked in Microsoft interview","text":"<ul> <li>Bayes\u2019 Theorem  </li> <li>Markov Chains  </li> <li>Stochastic Processes  </li> <li>Central Limit Theorem  </li> <li>Variance under Linear Transformations  </li> </ul>"},{"location":"Interview-Questions/Probability/#custom-questions","title":"Custom Questions","text":""},{"location":"Interview-Questions/Probability/#average-score-on-a-dice-role-of-at-most-3-times","title":"Average score on a dice role of at most 3 times","text":"<p>Question</p> <p>Consider a fair 6-sided dice.  Your aim is to get the highest score you can, in at-most 3 roles.</p> <p>A score is defined as the number that appears on the face of the dice facing up after the role.  You can role at most 3 times but every time you role it is up to you to decide whether you want to role again.</p> <p>The last score will be counted as your final score.</p> <ul> <li>Find the average score if you rolled the dice only once?</li> <li>Find the average score that you can get with at most 3 roles?</li> <li>If the dice is fair, why is the average score for at most 3 roles and 1 role not the same?</li> </ul> Hint 1 <p>Find what is the expected score on single role</p> <p>And for cases when scores of single role &lt; <code>expected score on single role</code>  is when you will go for next role</p> <p>Eg: if expected score of single role comes out to be 4.5,  you will only role next turn for 1,2,3,4 and not for 5,6</p> Answer <p>If you role a fair dice once you can get:</p> Score Probability 1 \u2159 2 \u2159 3 \u2159 4 \u2159 5 \u2159 6 \u2159 <p>So your average score with one role is: </p> <p><code>sum of(score * scores's probability)</code> = (1+2+3+4+5+6)*(\u2159) = (21/6) = 3.5</p> <p>The average score if you rolled the dice only once is 3.5</p> <p>For at most 3 roles, let's try back-tracking. Let's say just did your second role and you have to decide whether to do your 3<sup>rd</sup> role!</p> <p>We just found out if we role dice once on average we can expect score of 3.5. So we will only role the 3<sup>rd</sup> time if score on 2<sup>nd</sup> role is less than 3.5 i.e (1,2 or 3)</p> <p>Possibilities</p> 2<sup>nd</sup> role score Probability 3<sup>rd</sup> role score Probability 1 \u2159 3.5 \u2159 2 \u2159 3.5 \u2159 3 \u2159 3.5 \u2159 4 \u2159 NA We won't role 5 \u2159 NA 3<sup>rd</sup> time if we 6 \u2159 NA get score &gt;3 on 2<sup>nd</sup> <p>So if we had 2 roles, average score would be:</p> <pre><code>[We role again if current score is less than 3.4]\n(3.5)*(1/6) + (3.5)*(1/6) + (3.5)*(1/6) \n+\n(4)*(1/6) + (5)*(1/6) + (6)*(1/6) [Decide not to role again]\n=\n1.75 + 2.5 = 4.25\n</code></pre> <p>The average score if you rolled the dice twice is 4.25</p> <p>So now if we look from the perspective of first role. We will only role again if our score is less than 4.25 i.e 1,2,3 or 4</p> <p>Possibilities</p> 1<sup>st</sup> role score Probability 2<sup>nd</sup> and 3<sup>rd</sup> role score Probability 1 \u2159 4.25 \u2159 2 \u2159 4.25 \u2159 3 \u2159 4.25 \u2159 4 \u2159 4.25 \u2159 5 \u2159 NA We won't role again if we 6 \u2159 NA get score &gt;4.25 on 1<sup>st</sup> <p>So if we had 3 roles, average score would be:</p> <p><pre><code>[We role again if current score is less than 4.25]\n(4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) \n+\n(5)*(1/6) + (6)*(1/6) [[Decide not to role again]\n=\n17/6 + 11/6 = 4.66\n</code></pre> The average score if you rolled the dice only once is 4.66</p> <p>The average score for at most 3 roles and 1 role is not the same because although the dice is fair the event of rolling the dice is no longer independent. The scores would have been the same if we rolled the dice 2<sup>nd</sup> and 3<sup>rd</sup> time without considering what we got in the last roll i.e. if the event of rolling the dice was independent.</p>"},{"location":"Interview-Questions/System-design/","title":"System Design Interview Questions (DS &amp; ML)","text":"<p>This document provides a curated list of system design questions tailored for Data Science and Machine Learning interviews. The questions focus on designing scalable, robust, and maintainable systems\u2014from end-to-end ML pipelines and data ingestion frameworks to model serving, monitoring, and MLOps architectures. Use the practice links provided to dive deeper into each topic.</p> Sno Question Title Practice Links Companies Asking Difficulty Topics 1 Design an End-to-End Machine Learning Pipeline Towards Data Science Google, Amazon, Facebook Medium ML Pipeline, MLOps 2 Design a Scalable Data Ingestion &amp; Processing System for ML Medium Amazon, Google, Microsoft Hard Data Engineering, Scalability 3 Design a Recommendation System Towards Data Science Google, Amazon, Facebook Medium Recommender Systems, Personalization 4 Design a Fraud Detection System Medium Amazon, Facebook, PayPal Hard Real-Time Analytics, Anomaly Detection 5 Design a Feature Store for Machine Learning Towards Data Science Google, Amazon, Microsoft Medium Data Preprocessing, Feature Engineering 6 Design an Online ML Model Serving Architecture Towards Data Science Google, Amazon, Facebook Hard Model Deployment, Real-Time Serving 7 Design a Continuous Model Retraining and Monitoring System Medium Google, Microsoft, Amazon Hard MLOps, Automation 8 Design an A/B Testing Framework for ML Models Towards Data Science Google, Facebook, Amazon Medium Experimentation, Evaluation 9 Design a Distributed ML Training System Towards Data Science Google, Amazon, Microsoft Hard Distributed Systems, Deep Learning 10 Design a Real-Time Prediction Serving System Towards Data Science Amazon, Google, Facebook Hard Model Serving, Real-Time Processing 11 Design a System for Anomaly Detection in Streaming Data Medium Amazon, Google, Facebook Hard Streaming Data, Anomaly Detection 12 Design a Real-Time Personalization System for E-Commerce Medium Amazon, Facebook, Uber Medium Personalization, Real-Time Analytics 13 Design a Data Versioning and Model Versioning System Towards Data Science Google, Amazon, Microsoft Medium MLOps, Version Control 14 Design a System to Ensure Fairness and Transparency in ML Predictions Medium Google, Facebook, Amazon Hard Ethics, Model Interpretability 15 Design a Data Governance and Compliance System for ML Towards Data Science Microsoft, Google, Amazon Hard Data Governance, Compliance 16 Design an MLOps Pipeline for End-to-End Automation Towards Data Science Google, Amazon, Facebook Hard MLOps, Automation 17 Design a System for Real-Time Prediction Serving with Low Latency Medium Google, Amazon, Microsoft Hard Model Serving, Scalability 18 Design a Scalable Data Warehouse for ML-Driven Analytics Towards Data Science Google, Amazon, Facebook Medium Data Warehousing, Analytics 19 Design a System for Hyperparameter Tuning at Scale Medium Google, Amazon, Microsoft Hard Optimization, Automation 20 Design an Event-Driven Architecture for ML Pipelines Towards Data Science Amazon, Google, Facebook Medium Event-Driven, Real-Time Processing 21 Design a System for Multimodal Data Processing in Machine Learning Towards Data Science Google, Amazon, Facebook Hard Data Integration, Deep Learning 22 Design a System to Handle High-Volume Streaming Data for ML Towards Data Science Amazon, Google, Microsoft Hard Streaming, Scalability 23 Design a Secure and Scalable ML Infrastructure Towards Data Science Google, Amazon, Facebook Hard Security, Scalability 24 Design a Scalable Feature Engineering Pipeline Towards Data Science Google, Amazon, Microsoft Medium Feature Engineering, Scalability 25 Design a System for Experimentation and A/B Testing in Data Science Towards Data Science Google, Amazon, Facebook Medium Experimentation, Analytics 26 Design an Architecture for a Data Lake Tailored for ML Applications Towards Data Science Amazon, Google, Microsoft Medium Data Lakes, Data Engineering 27 Design a Fault-Tolerant Machine Learning System Medium Google, Amazon, Facebook Hard Reliability, Distributed Systems 28 Design a System for Scalable Deep Learning Inference Towards Data Science Google, Amazon, Microsoft Hard Deep Learning, Inference 29 Design a Collaborative Platform for Data Science Projects Towards Data Science Google, Amazon, Facebook Medium Collaboration, Platform Design 30 Design a System for Model Monitoring and Logging Towards Data Science Google, Amazon, Microsoft Medium MLOps, Monitoring"},{"location":"Interview-Questions/System-design/#questions-asked-in-google-interview","title":"Questions asked in Google interview","text":"<ul> <li>Design an End-to-End Machine Learning Pipeline  </li> <li>Design a Real-Time Prediction Serving System  </li> <li>Design a Continuous Model Retraining and Monitoring System  </li> <li>Design a System for Hyperparameter Tuning at Scale  </li> <li>Design a Secure and Scalable ML Infrastructure  </li> </ul>"},{"location":"Interview-Questions/System-design/#questions-asked-in-amazon-interview","title":"Questions asked in Amazon interview","text":"<ul> <li>Design a Scalable Data Ingestion &amp; Processing System for ML  </li> <li>Design a Recommendation System  </li> <li>Design a Fraud Detection System  </li> <li>Design an MLOps Pipeline for End-to-End Automation  </li> <li>Design a System to Handle High-Volume Streaming Data for ML  </li> </ul>"},{"location":"Interview-Questions/System-design/#questions-asked-in-facebook-interview","title":"Questions asked in Facebook interview","text":"<ul> <li>Design an End-to-End Machine Learning Pipeline  </li> <li>Design an Online ML Model Serving Architecture  </li> <li>Design a Real-Time Personalization System for E-Commerce  </li> <li>Design a System for Model Monitoring and Logging  </li> <li>Design a System for Multimodal Data Processing in ML  </li> </ul>"},{"location":"Interview-Questions/System-design/#questions-asked-in-microsoft-interview","title":"Questions asked in Microsoft interview","text":"<ul> <li>Design a Data Versioning and Model Versioning System  </li> <li>Design a Scalable Data Warehouse for ML-Driven Analytics  </li> <li>Design a Distributed ML Training System  </li> <li>Design a System for Real-Time Prediction Serving with Low Latency  </li> <li>Design a System for Secure and Scalable ML Infrastructure  </li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/","title":"Data Structures and Algorithms (DSA)","text":"<p>This document provides a curated list of Data Structures and Algorithms (DSA) questions commonly asked in technical interviews.  It covers a wide range of difficulty levels and topics.</p> <p>This is updated frequently but right now this is the most exhaustive list of type of questions being asked.</p> Sno Problem Title Practice Links Companies Asking Difficulty Topics 1 Two Number Sum LeetCode Two Sum Google, Facebook, Amazon Easy Array, Hashing 2 Reverse Linked List LeetCode Reverse Linked List Amazon, Facebook, Microsoft Easy Linked List 3 Valid Parentheses LeetCode Valid Parentheses Amazon, Facebook, Google Easy Stack, String 4 Binary Search LeetCode Binary Search Google, Facebook, Amazon Easy Array, Binary Search 5 Merge Two Sorted Arrays LeetCode Merge Sorted Array Google, Microsoft, Amazon Easy Array, Two Pointers 6 Meeting Rooms LeetCode Meeting Rooms II Microsoft, Google Medium Array, Sorting, Interval Scheduling 7 Climbing Stairs LeetCode Climbing Stairs Amazon, Facebook, Google Easy Dynamic Programming 8 Valid Anagram LeetCode Valid Anagram Google, Amazon Easy String, Hashing 9 Longest Substring Without Repeating Characters LeetCode Longest Substring Without Repeating Characters Amazon, Facebook, Google Medium String, Hashing, Sliding Window 10 Maximum Subarray (Kadane's Algorithm) LeetCode Maximum Subarray Google, Amazon, Facebook Medium Array, Dynamic Programming 11 Word Ladder LeetCode Word Ladder Google, Amazon, Facebook Very Hard Graph, BFS, String Transformation 12 4Sum (Four Number Sum) LeetCode 4Sum Amazon, Facebook, Google Hard Array, Hashing, Two Pointers 13 Median of Two Sorted Arrays LeetCode Median of Two Sorted Arrays Google, Amazon, Microsoft Hard Array, Binary Search 14 Longest Increasing Subsequence LeetCode Longest Increasing Subsequence Google, Facebook, Amazon Hard Array, Dynamic Programming 15 Longest Palindromic Substring LeetCode Longest Palindromic Substring Amazon, Google Hard String, Dynamic Programming 16 Design LRU Cache LeetCode LRU Cache Amazon, Facebook, Google, Microsoft Hard Design, Hashing, Linked List 17 Top K Frequent Elements LeetCode Top K Frequent Elements Google, Facebook, Amazon Medium Array, Hashing, Heap 18 Find Peak Element LeetCode Find Peak Element Google, Facebook, Amazon Medium Array, Binary Search 19 Candy (Min Rewards) LeetCode Candy Amazon, Facebook, Google Hard Array, Greedy 20 Array of Products LeetCode Product of Array Except Self Amazon, Google Medium Array, Prefix/Suffix Products 21 First Duplicate Value LeetCode Find the Duplicate Number Google, Facebook Medium Array, Hashing 22 Validate Subsequence GFG Validate Subsequence Amazon, Google, Microsoft Easy Array, Two Pointers 23 Nth Fibonacci LeetCode Fibonacci Number Google, Facebook, Microsoft Easy Recursion, Dynamic Programming 24 Spiral Traverse LeetCode Spiral Matrix Facebook, Amazon, Google Medium Matrix, Simulation 25 Subarray Sort GFG Minimum Unsorted Subarray Google, Uber Hard Array, Two Pointers 26 Largest Range GFG Largest Range Google, Amazon Hard Array, Hashing 27 Diagonal Traverse LeetCode Diagonal Traverse Google, Facebook Medium Array, Simulation 28 Longest Peak GFG Longest Peak Google, Uber Medium Array, Dynamic Programming 29 Product Sum GFG Product Sum Amazon, Facebook, Google Easy Array, Recursion 30 Merge Two Sorted Lists LeetCode Merge Two Sorted Lists Google, Amazon, Facebook Medium Linked List, Recursion 31 Binary Tree Level Order Traversal LeetCode Level Order Traversal Amazon, Google, Microsoft Easy Tree, BFS 32 Longest Valid Parentheses LeetCode Longest Valid Parentheses Facebook, Google, Amazon Medium String, Stack, Dynamic Programming 33 Word Break LeetCode Word Break Amazon, Google, Facebook Hard Dynamic Programming, String 34 Find Median from Data Stream LeetCode Find Median from Data Stream Facebook, Amazon, Google Hard Heap, Data Structures 35 Longest Repeating Character Replacement LeetCode Longest Repeating Character Replacement Google, Amazon, Facebook Hard String, Sliding Window, Greedy 36 Kth Largest Element in an Array LeetCode Kth Largest Element Google, Amazon, Facebook Medium Heap, Sorting 37 River Sizes GFG River Sizes Facebook, Google Very Hard Graph, DFS/BFS, Matrix 38 Youngest Common Ancestor LeetCode Lowest Common Ancestor Google, Microsoft Very Hard Tree, Ancestor Tracking 39 BST Construction LeetCode Validate BST Facebook, Amazon, Google Very Hard Tree, Binary Search Tree 40 Invert Binary Tree LeetCode Invert Binary Tree Amazon, Facebook, Google Very Hard Tree, Recursion 41 Validate BST LeetCode Validate BST Google, Amazon Very Hard Tree, Binary Search Tree 42 Node Depths GFG Sum of Node Depths Google, Facebook Very Hard Tree, Recursion 43 Branch Sums GFG Branch Sums Amazon, Facebook, Google Very Hard Tree, Recursion 44 Find Successor LeetCode Inorder Successor Facebook, Amazon, Google Very Hard Tree, BST, Inorder Traversal 45 Binary Tree Diameter GFG Diameter of Binary Tree Google, Uber Very Hard Tree, Recursion 46 Lowest Common Ancestor LeetCode Lowest Common Ancestor Amazon, Facebook, Google Very Hard Tree, Recursion 47 Dijkstra's Algorithm LeetCode Network Delay Time Google, Amazon Very Hard Graph, Shortest Paths, Greedy 48 Topological Sort GFG Topological Sort Google, Microsoft, Amazon Very Hard Graph, DFS/BFS, Sorting 49 Knapsack Problem LeetCode Coin Change 2 Facebook, Amazon, Google Very Hard Dynamic Programming, Knapsack 50 Disk Stacking GFG Disk Stacking Google, Facebook Very Hard Dynamic Programming, Sorting 51 Numbers In Pi N/A Google, Facebook Very Hard Dynamic Programming, String Processing 52 Longest Common Subsequence LeetCode Longest Common Subsequence Amazon, Google, Microsoft Very Hard Dynamic Programming, Strings 53 Min Number of Jumps LeetCode Min Number of Jumps Google, Facebook, Amazon Very Hard Dynamic Programming, Greedy 54 Water Area (Trapping Rain Water) LeetCode Trapping Rain Water Google, Amazon, Facebook Very Hard Array, Two Pointers, Greedy 55 Minimum Characters For Palindrome GFG Minimum Characters For Palindrome Amazon, Google Very Hard String, Dynamic Programming, KMP 56 Regular Expression Matching LeetCode Regular Expression Matching Google, Amazon, Facebook Very Hard Dynamic Programming, Strings, Recursion 57 Wildcard Matching LeetCode Wildcard Matching Amazon, Google Very Hard Dynamic Programming, Strings 58 Group Anagrams LeetCode Group Anagrams Google, Amazon, Facebook Medium Array, Hashing 59 Longest Consecutive Sequence LeetCode Longest Consecutive Sequence Facebook, Google, Amazon Hard Array, Hashing 60 Maximum Product Subarray LeetCode Maximum Product Subarray Amazon, Google, Facebook Medium Array, Dynamic Programming 61 Sum of Two Integers (Bit Manipulation) LeetCode Sum of Two Integers Google, Amazon, Facebook Medium Bit Manipulation 62 Course Schedule LeetCode Course Schedule Amazon, Facebook, Google Medium Graph, DFS/BFS 63 Add Two Numbers (Linked List) LeetCode Add Two Numbers Google, Facebook, Amazon Medium Linked List, Math 64 Reverse Words in a String LeetCode Reverse Words in a String Google, Amazon, Facebook Medium String, Two Pointers 65 Intersection of Two Arrays LeetCode Intersection of Two Arrays Amazon, Google, Facebook Easy Array, Hashing 66 Find All Duplicates in an Array LeetCode Find All Duplicates Facebook, Google, Amazon Medium Array, Hashing 67 Majority Element LeetCode Majority Element Google, Amazon Easy Array, Hashing, Boyer-Moore 68 Rotate Array LeetCode Rotate Array Amazon, Google, Facebook Medium Array, Two Pointers 69 Spiral Matrix II LeetCode Spiral Matrix II Google, Facebook, Amazon Medium Matrix, Simulation 70 Search in Rotated Sorted Array LeetCode Search in Rotated Sorted Array Google, Amazon, Facebook Medium Array, Binary Search 71 Design a URL Shortener LeetCode Design TinyURL Uber, Airbnb, Flipkart Medium Design, Hashing, Strings 72 Implement Autocomplete System GFG Autocomplete System Amazon, Google, Swiggy Hard Trie, Design, Strings 73 Design Twitter Feed LeetCode Design Twitter Twitter, Flipkart, Ola Medium Design, Heap, Linked List 74 Implement LFU Cache GFG LFU Cache Amazon, Paytm, Flipkart Hard Design, Hashing 75 Design a Rate Limiter N/A Uber, Ola, Swiggy Medium Design, Algorithms 76 Serialize and Deserialize Binary Tree LeetCode Serialize and Deserialize Binary Tree Amazon, Microsoft, Swiggy Hard Tree, DFS, Design 77 Design a File System LeetCode Design File System Google, Flipkart, Amazon Hard Design, Trie 78 Implement Magic Dictionary LeetCode Implement Magic Dictionary Facebook, Microsoft, Paytm Medium Trie, Design 79 Longest Substring with At Most K Distinct Characters LeetCode Longest Substring with At Most K Distinct Characters Amazon, Google Medium String, Sliding Window 80 Subarray Sum Equals K LeetCode Subarray Sum Equals K Microsoft, Amazon, Flipkart Medium Array, Hashing, Prefix Sum 81 Merge k Sorted Lists LeetCode Merge k Sorted Lists Google, Facebook, Amazon Hard Heap, Linked List 82 Longest Increasing Path in a Matrix LeetCode Longest Increasing Path Google, Microsoft Hard DFS, DP, Matrix 83 Design a Stock Price Fluctuation Tracker LeetCode Stock Price Fluctuation Amazon, Flipkart, Paytm Medium Design, Heap 84 Implement a Trie LeetCode Implement Trie Amazon, Google, Microsoft Medium Trie, Design 85 Design a Chat System Medium: Chat System Design (free article) WhatsApp, Slack, Swiggy Hard Design, Messaging 86 Design an Elevator System N/A OYO, Ola, Flipkart Hard Design, System Design 87 Implement a Sudoku Solver LeetCode Sudoku Solver Google, Microsoft, Amazon Hard Backtracking, Recursion 88 Find All Anagrams in a String LeetCode Find All Anagrams in a String Facebook, Google Medium String, Sliding Window, Hashing 89 Design Twitter-like Feed LeetCode Design Twitter Twitter, Facebook, Uber Medium Design, Heap, Linked List 90 Longest Palindromic Subsequence LeetCode Longest Palindromic Subsequence Amazon, Google Medium DP, String 91 Clone Graph LeetCode Clone Graph Amazon, Google Medium Graph, DFS/BFS 92 Design a Data Structure for the Stock Span Problem LeetCode Online Stock Span Amazon, Microsoft, Paytm Medium Stack, Array, Design 93 Design a Stack That Supports getMin() LeetCode Min Stack Facebook, Amazon, Google Easy Stack, Design 94 Convert Sorted Array to Binary Search Tree LeetCode Sorted Array to BST Facebook, Google Easy Tree, Recursion 95 Meeting Rooms II LeetCode Meeting Rooms II Microsoft, Google Medium Array, Heap, Sorting 96 Search in Rotated Sorted Array LeetCode Search in Rotated Sorted Array Google, Amazon, Facebook Medium Array, Binary Search 97 Design a URL Shortener LeetCode Design TinyURL Uber, Airbnb, Flipkart Medium Design, Hashing, Strings 98 Implement Autocomplete System GFG Autocomplete System Amazon, Google, Swiggy Hard Trie, Design, Strings 99 Design Twitter Feed LeetCode Design Twitter Twitter, Flipkart, Ola Medium Design, Heap, Linked List 100 Implement LFU Cache GFG LFU Cache Amazon, Paytm, Flipkart Hard Design, Hashing"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-google-interview","title":"Questions asked in Google interview","text":"<ul> <li>Two Number Sum</li> <li>Valid Parentheses</li> <li>Binary Search</li> <li>Merge Two Sorted Arrays</li> <li>Meeting Rooms</li> <li>Climbing Stairs</li> <li>Valid Anagram</li> <li>Longest Substring Without Repeating Characters</li> <li>Maximum Subarray (Kadane's Algorithm)</li> <li>Word Ladder</li> <li>4Sum (Four Number Sum)</li> <li>Median of Two Sorted Arrays</li> <li>Longest Increasing Subsequence</li> <li>Longest Palindromic Substring</li> <li>Design LRU Cache</li> <li>Top K Frequent Elements</li> <li>Find Peak Element</li> <li>Candy (Min Rewards)</li> <li>Array of Products</li> <li>First Duplicate Value</li> <li>Validate Subsequence</li> <li>Nth Fibonacci</li> <li>Spiral Traverse</li> <li>Largest Range</li> <li>Diagonal Traverse</li> <li>Longest Peak</li> <li>Product Sum</li> <li>Merge Two Sorted Lists</li> <li>Binary Tree Level Order Traversal</li> <li>Longest Valid Parentheses</li> <li>Word Break</li> <li>Find Median from Data Stream</li> <li>Longest Repeating Character Replacement</li> <li>Kth Largest Element in an Array</li> <li>River Sizes</li> <li>Youngest Common Ancestor</li> <li>BST Construction</li> <li>Invert Binary Tree</li> <li>Validate BST</li> <li>Node Depths</li> <li>Branch Sums</li> <li>Find Successor</li> <li>Binary Tree Diameter</li> <li>Lowest Common Ancestor</li> <li>Dijkstra's Algorithm</li> <li>Topological Sort</li> <li>Knapsack Problem</li> <li>Disk Stacking</li> <li>Numbers In Pi</li> <li>Longest Common Subsequence</li> <li>Min Number of Jumps</li> <li>Water Area (Trapping Rain Water)</li> <li>Minimum Characters For Palindrome</li> <li>Regular Expression Matching</li> <li>Wildcard Matching</li> <li>Group Anagrams</li> <li>Longest Consecutive Sequence</li> <li>Maximum Product Subarray</li> <li>Sum of Two Integers (Bit Manipulation)</li> <li>Course Schedule</li> <li>Add Two Numbers (Linked List)</li> <li>Reverse Words in a String</li> <li>Intersection of Two Arrays</li> <li>Find All Duplicates in an Array</li> <li>Majority Element</li> <li>Rotate Array</li> <li>Spiral Matrix II</li> <li>Search in Rotated Sorted Array</li> <li>Implement Autocomplete System</li> <li>Design a File System</li> <li>Longest Substring with At Most K Distinct Characters</li> <li>Merge k Sorted Lists</li> <li>Longest Increasing Path in a Matrix</li> <li>Implement a Trie</li> <li>Implement a Sudoku Solver</li> <li>Find All Anagrams in a String</li> <li>Longest Palindromic Subsequence</li> <li>Clone Graph</li> <li>Design a Stack That Supports getMin()</li> <li>Convert Sorted Array to Binary Search Tree</li> <li>Meeting Rooms II</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-facebook-interview","title":"Questions asked in Facebook interview","text":"<ul> <li>Two Number Sum</li> <li>Reverse Linked List</li> <li>Valid Parentheses</li> <li>Binary Search</li> <li>Merge Two Sorted Arrays</li> <li>Climbing Stairs</li> <li>Longest Substring Without Repeating Characters</li> <li>Maximum Subarray (Kadane's Algorithm)</li> <li>Word Ladder</li> <li>4Sum (Four Number Sum)</li> <li>Longest Increasing Subsequence</li> <li>Design LRU Cache</li> <li>Top K Frequent Elements</li> <li>Find Peak Element</li> <li>Candy (Min Rewards)</li> <li>Array of Products</li> <li>First Duplicate Value</li> <li>Word Break</li> <li>Spiral Traverse</li> <li>Diagonal Traverse</li> <li>Product Sum</li> <li>Merge Two Sorted Lists</li> <li>Binary Tree Level Order Traversal</li> <li>Longest Valid Parentheses</li> <li>Find Median from Data Stream</li> <li>Longest Repeating Character Replacement</li> <li>Kth Largest Element in an Array</li> <li>River Sizes</li> <li>BST Construction</li> <li>Invert Binary Tree</li> <li>Node Depths</li> <li>Branch Sums</li> <li>Find Successor</li> <li>Lowest Common Ancestor</li> <li>Dijkstra's Algorithm</li> <li>Knapsack Problem</li> <li>Disk Stacking</li> <li>Numbers In Pi</li> <li>Longest Common Subsequence</li> <li>Min Number of Jumps</li> <li>Water Area (Trapping Rain Water)</li> <li>Regular Expression Matching</li> <li>Wildcard Matching</li> <li>Group Anagrams</li> <li>Longest Consecutive Sequence</li> <li>Maximum Product Subarray</li> <li>Sum of Two Integers (Bit Manipulation)</li> <li>Add Two Numbers (Linked List)</li> <li>Reverse Words in a String</li> <li>Intersection of Two Arrays</li> <li>Find All Duplicates in an Array</li> <li>Rotate Array</li> <li>Spiral Matrix II</li> <li>Search in Rotated Sorted Array</li> <li>Design a Stack That Supports getMin()</li> <li>Convert Sorted Array to Binary Search Tree</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-amazon-interview","title":"Questions asked in Amazon interview","text":"<ul> <li>Two Number Sum</li> <li>Valid Parentheses</li> <li>Binary Search</li> <li>Merge Two Sorted Arrays</li> <li>Climbing Stairs</li> <li>Valid Anagram</li> <li>Longest Substring Without Repeating Characters</li> <li>Maximum Subarray (Kadane's Algorithm)</li> <li>Word Ladder</li> <li>4Sum (Four Number Sum)</li> <li>Median of Two Sorted Arrays</li> <li>Longest Increasing Subsequence</li> <li>Longest Palindromic Substring</li> <li>Design LRU Cache</li> <li>Top K Frequent Elements</li> <li>Find Peak Element</li> <li>Candy (Min Rewards)</li> <li>Array of Products</li> <li>First Duplicate Value</li> <li>Validate Subsequence</li> <li>Nth Fibonacci</li> <li>Spiral Traverse</li> <li>Largest Range</li> <li>Diagonal Traverse</li> <li>Longest Peak</li> <li>Product Sum</li> <li>Merge Two Sorted Lists</li> <li>Binary Tree Level Order Traversal</li> <li>Longest Valid Parentheses</li> <li>Word Break</li> <li>Find Median from Data Stream</li> <li>Longest Repeating Character Replacement</li> <li>Kth Largest Element in an Array</li> <li>River Sizes</li> <li>BST Construction</li> <li>Invert Binary Tree</li> <li>Validate BST</li> <li>Branch Sums</li> <li>Find Successor</li> <li>Lowest Common Ancestor</li> <li>Dijkstra's Algorithm</li> <li>Topological Sort</li> <li>Knapsack Problem</li> <li>Disk Stacking</li> <li>Numbers In Pi</li> <li>Longest Common Subsequence</li> <li>Min Number of Jumps</li> <li>Water Area (Trapping Rain Water)</li> <li>Minimum Characters For Palindrome</li> <li>Regular Expression Matching</li> <li>Wildcard Matching</li> <li>Group Anagrams</li> <li>Longest Consecutive Sequence</li> <li>Maximum Product Subarray</li> <li>Sum of Two Integers (Bit Manipulation)</li> <li>Course Schedule</li> <li>Add Two Numbers (Linked List)</li> <li>Reverse Words in a String</li> <li>Intersection of Two Arrays</li> <li>Find All Duplicates in an Array</li> <li>Majority Element</li> <li>Rotate Array</li> <li>Spiral Matrix II</li> <li>Search in Rotated Sorted Array</li> <li>Design a URL Shortener</li> <li>Implement Autocomplete System</li> <li>Design a File System</li> <li>Longest Substring with At Most K Distinct Characters</li> <li>Merge k Sorted Lists</li> <li>Implement a Trie</li> <li>Implement a Sudoku Solver</li> <li>Find All Anagrams in a String</li> <li>Longest Palindromic Subsequence</li> <li>Clone Graph</li> <li>Design a Stack That Supports getMin()</li> <li>Meeting Rooms II</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-microsoft-interview","title":"Questions asked in Microsoft interview","text":"<ul> <li>Reverse Linked List</li> <li>Merge Two Sorted Arrays</li> <li>Meeting Rooms</li> <li>Median of Two Sorted Arrays</li> <li>Nth Fibonacci</li> <li>Binary Tree Level Order Traversal</li> <li>Find Median from Data Stream</li> <li>Topological Sort</li> <li>Youngest Common Ancestor</li> <li>Longest Increasing Path in a Matrix</li> <li>Implement a Trie</li> <li>Implement a Sudoku Solver</li> <li>Convert Sorted Array to Binary Search Tree</li> <li>Meeting Rooms II</li> <li>Course Schedule</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-uber-interview","title":"Questions asked in Uber interview","text":"<ul> <li>Subarray Sort</li> <li>Longest Peak</li> <li>Binary Tree Diameter</li> <li>Design Twitter-like Feed</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-swiggy-interview","title":"Questions asked in Swiggy interview","text":"<ul> <li>Implement Autocomplete System</li> <li>Design a Rate Limiter</li> <li>Serialize and Deserialize Binary Tree</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-flipkart-interview","title":"Questions asked in Flipkart interview","text":"<ul> <li>Design a URL Shortener</li> <li>Design Twitter Feed</li> <li>Design a File System</li> <li>Subarray Sum Equals K</li> <li>Design an Elevator System</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-ola-interview","title":"Questions asked in Ola interview","text":"<ul> <li>Design Twitter Feed</li> <li>Design an Elevator System</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-paytm-interview","title":"Questions asked in Paytm interview","text":"<ul> <li>Implement LFU Cache</li> <li>Design a Data Structure for the Stock Span Problem</li> <li>Implement Magic Dictionary</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-oyo-interview","title":"Questions asked in OYO interview","text":"<ul> <li>Design an Elevator System</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-whatsapp-interview","title":"Questions asked in WhatsApp interview","text":"<ul> <li>Design a Chat System</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-slack-interview","title":"Questions asked in Slack interview","text":"<ul> <li>Design a Chat System</li> </ul>"},{"location":"Interview-Questions/data-structures-algorithms/#questions-asked-in-airbnb-interview","title":"Questions asked in Airbnb interview","text":"<ul> <li>Design a URL Shortener</li> </ul>"}]}