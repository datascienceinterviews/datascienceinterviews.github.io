<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Comprehensive guide to Support Vector Machines with mathematical intuition, kernel tricks, implementations, and interview questions."><meta name=author content="Kuldeep Singh Sidhu"><link href=../Random%20Forest/ rel=prev><link href=../Unbalanced%2C%20Skewed%20data/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.50"><title>Support Vector Machines (SVM) - Data Science Interview preparation</title><link rel=stylesheet href=../../assets/stylesheets/main.a40c8224.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-EVGNTG49J7"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-EVGNTG49J7",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-EVGNTG49J7",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#support-vector-machines-svm class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <!-- Add announcement here, including arbitrary HTML --> üëÄ This project is in early stages of development. <strong> ü§ó Please <a href=/Contribute>contribute content</a> if possible! ü§ù</strong><br> <small>ü´µ You can <b> <a href=/Contribute>SUBMIT</a></b> simple text/markdown content, I will format it! üôå</small> <meta name=google-adsense-account content=ca-pub-4988388949365963> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4988388949365963" crossorigin=anonymous></script> </div> </aside> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Data Science Interview preparation" class="md-header__button md-logo" aria-label="Data Science Interview preparation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science Interview preparation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Support Vector Machines (SVM) </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Data Science Interview preparation" class="md-nav__button md-logo" aria-label="Data Science Interview preparation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> Data Science Interview preparation </label> <div class=md-nav__source> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> üè° Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> üë®üèø‚Äçüè´ Interview Questions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> üë®üèø‚Äçüè´ Interview Questions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Interview-Questions/data-structures-algorithms/ class=md-nav__link> <span class=md-ellipsis> DSA (Data Structures & Algorithms) </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Machine-Learning/ class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/System-design/ class=md-nav__link> <span class=md-ellipsis> System Design </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Natural-Language-Processing/ class=md-nav__link> <span class=md-ellipsis> Natural Language Processing (NLP) </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/Probability/ class=md-nav__link> <span class=md-ellipsis> Probability </span> </a> </li> <li class=md-nav__item> <a href=../../Interview-Questions/SQL-Interview-Questions/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> üìù Cheat Sheets </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> üìù Cheat Sheets </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Cheat-Sheets/Django/ class=md-nav__link> <span class=md-ellipsis> Django </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Flask/ class=md-nav__link> <span class=md-ellipsis> Flask </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Hypothesis-Tests/ class=md-nav__link> <span class=md-ellipsis> Hypothesis Tests </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Keras/ class=md-nav__link> <span class=md-ellipsis> Keras </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/PySpark/ class=md-nav__link> <span class=md-ellipsis> PySpark </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/PyTorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/RegEx/ class=md-nav__link> <span class=md-ellipsis> Regular Expressions (RegEx) </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Sk-learn/ class=md-nav__link> <span class=md-ellipsis> Scikit Learn </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/SQL/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/tensorflow/ class=md-nav__link> <span class=md-ellipsis> TensorFlow </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> ‚Äçüéì ML Topics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> ‚Äçüéì ML Topics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../ARIMA/ class=md-nav__link> <span class=md-ellipsis> ARIMA </span> </a> </li> <li class=md-nav__item> <a href=../Activation%20functions/ class=md-nav__link> <span class=md-ellipsis> Activation functions </span> </a> </li> <li class=md-nav__item> <a href=../Collaborative%20Filtering/ class=md-nav__link> <span class=md-ellipsis> Collaborative Filtering </span> </a> </li> <li class=md-nav__item> <a href=../Confusion%20Matrix/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix </span> </a> </li> <li class=md-nav__item> <a href=../DBSCAN/ class=md-nav__link> <span class=md-ellipsis> DBSCAN </span> </a> </li> <li class=md-nav__item> <a href=../Decision%20Trees/ class=md-nav__link> <span class=md-ellipsis> Decision Trees </span> </a> </li> <li class=md-nav__item> <a href=../Gradient%20Boosting/ class=md-nav__link> <span class=md-ellipsis> Gradient Boosting </span> </a> </li> <li class=md-nav__item> <a href=../K-means%20clustering/ class=md-nav__link> <span class=md-ellipsis> K-means clustering </span> </a> </li> <li class=md-nav__item> <a href=../Linear%20Regression/ class=md-nav__link> <span class=md-ellipsis> Linear Regression </span> </a> </li> <li class=md-nav__item> <a href=../Logistic%20Regression/ class=md-nav__link> <span class=md-ellipsis> Logistic Regression </span> </a> </li> <li class=md-nav__item> <a href=../Loss%20Function%20MAE%2C%20RMSE/ class=md-nav__link> <span class=md-ellipsis> Loss Function MAE, RMSE </span> </a> </li> <li class=md-nav__item> <a href=../Neural%20Networks/ class=md-nav__link> <span class=md-ellipsis> Neural Networks </span> </a> </li> <li class=md-nav__item> <a href=../Normal%20Distribution/ class=md-nav__link> <span class=md-ellipsis> Normal Distribution </span> </a> </li> <li class=md-nav__item> <a href=../Normalization%20Regularisation/ class=md-nav__link> <span class=md-ellipsis> Normalization Regularisation </span> </a> </li> <li class=md-nav__item> <a href=../Overfitting%2C%20Underfitting/ class=md-nav__link> <span class=md-ellipsis> Overfitting, Underfitting </span> </a> </li> <li class=md-nav__item> <a href=../PCA/ class=md-nav__link> <span class=md-ellipsis> PCA </span> </a> </li> <li class=md-nav__item> <a href=../Random%20Forest/ class=md-nav__link> <span class=md-ellipsis> Random Forest </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Support Vector Machines </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Support Vector Machines </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> </span> </a> </li> <li class=md-nav__item> <a href=#intuition class=md-nav__link> <span class=md-ellipsis> &gt;ÔøΩ Intuition </span> </a> <nav class=md-nav aria-label=">ÔøΩ Intuition"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#how-svm-works class=md-nav__link> <span class=md-ellipsis> How SVM Works </span> </a> </li> <li class=md-nav__item> <a href=#mathematical-foundation class=md-nav__link> <span class=md-ellipsis> Mathematical Foundation </span> </a> <nav class=md-nav aria-label="Mathematical Foundation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-linear-svm-hard-margin class=md-nav__link> <span class=md-ellipsis> 1. Linear SVM - Hard Margin </span> </a> </li> <li class=md-nav__item> <a href=#2-soft-margin-svm class=md-nav__link> <span class=md-ellipsis> 2. Soft Margin SVM </span> </a> </li> <li class=md-nav__item> <a href=#3-dual-formulation-lagrangian class=md-nav__link> <span class=md-ellipsis> 3. Dual Formulation (Lagrangian) </span> </a> </li> <li class=md-nav__item> <a href=#4-kernel-trick class=md-nav__link> <span class=md-ellipsis> 4. Kernel Trick </span> </a> </li> <li class=md-nav__item> <a href=#5-support-vector-regression-svr class=md-nav__link> <span class=md-ellipsis> 5. Support Vector Regression (SVR) </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#implementation-using-libraries class=md-nav__link> <span class=md-ellipsis> =" Implementation using Libraries </span> </a> <nav class=md-nav aria-label="=" implementation using libraries&quot;> <ul class=md-nav__list> <li class=md-nav__item> <a href=#scikit-learn-implementation class=md-nav__link> <span class=md-ellipsis> Scikit-learn Implementation </span> </a> </li> <li class=md-nav__item> <a href=#decision-boundary-visualization class=md-nav__link> <span class=md-ellipsis> Decision Boundary Visualization </span> </a> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> Hyperparameter Tuning </span> </a> </li> <li class=md-nav__item> <a href=#support-vector-regression-svr class=md-nav__link> <span class=md-ellipsis> Support Vector Regression (SVR) </span> </a> </li> <li class=md-nav__item> <a href=#multi-class-classification class=md-nav__link> <span class=md-ellipsis> Multi-class Classification </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#from-scratch-implementation class=md-nav__link> <span class=md-ellipsis> ÔøΩ From Scratch Implementation </span> </a> </li> <li class=md-nav__item> <a href=#assumptions-and-limitations class=md-nav__link> <span class=md-ellipsis> ÔøΩ Assumptions and Limitations </span> </a> <nav class=md-nav aria-label="ÔøΩ Assumptions and Limitations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-assumptions class=md-nav__link> <span class=md-ellipsis> Key Assumptions </span> </a> </li> <li class=md-nav__item> <a href=#limitations class=md-nav__link> <span class=md-ellipsis> Limitations </span> </a> </li> <li class=md-nav__item> <a href=#comparison-with-other-algorithms class=md-nav__link> <span class=md-ellipsis> Comparison with Other Algorithms </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#interview-questions class=md-nav__link> <span class=md-ellipsis> ‚ùì Interview Questions </span> </a> </li> <li class=md-nav__item> <a href=#examples class=md-nav__link> <span class=md-ellipsis> &gt;ÔøΩ Examples </span> </a> <nav class=md-nav aria-label=">ÔøΩ Examples"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#real-world-example-text-classification class=md-nav__link> <span class=md-ellipsis> Real-world Example: Text Classification </span> </a> </li> <li class=md-nav__item> <a href=#image-classification-example class=md-nav__link> <span class=md-ellipsis> Image Classification Example </span> </a> </li> <li class=md-nav__item> <a href=#regression-example-with-support-vector-regression-svr class=md-nav__link> <span class=md-ellipsis> Regression Example with Support Vector Regression (SVR) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> <span class=md-ellipsis> üìö References </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Unbalanced%2C%20Skewed%20data/ class=md-nav__link> <span class=md-ellipsis> Unbalanced, Skewed data </span> </a> </li> <li class=md-nav__item> <a href=../kNN/ class=md-nav__link> <span class=md-ellipsis> kNN </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> üë®üèæ‚Äçüíª Online Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> üë®üèæ‚Äçüíª Online Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Online-Material/Online-Material-for-Learning/ class=md-nav__link> <span class=md-ellipsis> Online Study Material </span> </a> </li> <li class=md-nav__item> <a href=../../Online-Material/popular-resources/ class=md-nav__link> <span class=md-ellipsis> Popular Blogs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../projects/ class=md-nav__link> <span class=md-ellipsis> üì≥ Projects </span> </a> </li> <li class=md-nav__item> <a href=../../Contribute/ class=md-nav__link> <span class=md-ellipsis> ü§ù Contribute </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> </span> </a> </li> <li class=md-nav__item> <a href=#intuition class=md-nav__link> <span class=md-ellipsis> &gt;ÔøΩ Intuition </span> </a> <nav class=md-nav aria-label=">ÔøΩ Intuition"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#how-svm-works class=md-nav__link> <span class=md-ellipsis> How SVM Works </span> </a> </li> <li class=md-nav__item> <a href=#mathematical-foundation class=md-nav__link> <span class=md-ellipsis> Mathematical Foundation </span> </a> <nav class=md-nav aria-label="Mathematical Foundation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-linear-svm-hard-margin class=md-nav__link> <span class=md-ellipsis> 1. Linear SVM - Hard Margin </span> </a> </li> <li class=md-nav__item> <a href=#2-soft-margin-svm class=md-nav__link> <span class=md-ellipsis> 2. Soft Margin SVM </span> </a> </li> <li class=md-nav__item> <a href=#3-dual-formulation-lagrangian class=md-nav__link> <span class=md-ellipsis> 3. Dual Formulation (Lagrangian) </span> </a> </li> <li class=md-nav__item> <a href=#4-kernel-trick class=md-nav__link> <span class=md-ellipsis> 4. Kernel Trick </span> </a> </li> <li class=md-nav__item> <a href=#5-support-vector-regression-svr class=md-nav__link> <span class=md-ellipsis> 5. Support Vector Regression (SVR) </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#implementation-using-libraries class=md-nav__link> <span class=md-ellipsis> =" Implementation using Libraries </span> </a> <nav class=md-nav aria-label="=" implementation using libraries&quot;> <ul class=md-nav__list> <li class=md-nav__item> <a href=#scikit-learn-implementation class=md-nav__link> <span class=md-ellipsis> Scikit-learn Implementation </span> </a> </li> <li class=md-nav__item> <a href=#decision-boundary-visualization class=md-nav__link> <span class=md-ellipsis> Decision Boundary Visualization </span> </a> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> Hyperparameter Tuning </span> </a> </li> <li class=md-nav__item> <a href=#support-vector-regression-svr class=md-nav__link> <span class=md-ellipsis> Support Vector Regression (SVR) </span> </a> </li> <li class=md-nav__item> <a href=#multi-class-classification class=md-nav__link> <span class=md-ellipsis> Multi-class Classification </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#from-scratch-implementation class=md-nav__link> <span class=md-ellipsis> ÔøΩ From Scratch Implementation </span> </a> </li> <li class=md-nav__item> <a href=#assumptions-and-limitations class=md-nav__link> <span class=md-ellipsis> ÔøΩ Assumptions and Limitations </span> </a> <nav class=md-nav aria-label="ÔøΩ Assumptions and Limitations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-assumptions class=md-nav__link> <span class=md-ellipsis> Key Assumptions </span> </a> </li> <li class=md-nav__item> <a href=#limitations class=md-nav__link> <span class=md-ellipsis> Limitations </span> </a> </li> <li class=md-nav__item> <a href=#comparison-with-other-algorithms class=md-nav__link> <span class=md-ellipsis> Comparison with Other Algorithms </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#interview-questions class=md-nav__link> <span class=md-ellipsis> ‚ùì Interview Questions </span> </a> </li> <li class=md-nav__item> <a href=#examples class=md-nav__link> <span class=md-ellipsis> &gt;ÔøΩ Examples </span> </a> <nav class=md-nav aria-label=">ÔøΩ Examples"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#real-world-example-text-classification class=md-nav__link> <span class=md-ellipsis> Real-world Example: Text Classification </span> </a> </li> <li class=md-nav__item> <a href=#image-classification-example class=md-nav__link> <span class=md-ellipsis> Image Classification Example </span> </a> </li> <li class=md-nav__item> <a href=#regression-example-with-support-vector-regression-svr class=md-nav__link> <span class=md-ellipsis> Regression Example with Support Vector Regression (SVR) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> <span class=md-ellipsis> üìö References </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href="https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/edit/master/docs/Machine-Learning/Support Vector Machines.md" title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href="https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/raw/master/docs/Machine-Learning/Support Vector Machines.md" title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=support-vector-machines-svm>‚öîÔ∏è Support Vector Machines (SVM)</h1> <p>Support Vector Machines are powerful supervised learning algorithms that find the optimal decision boundary by maximizing the margin between classes, capable of handling both linear and non-linear classification and regression problems through kernel methods.</p> <p><strong>Resources:</strong> <a href=https://scikit-learn.org/stable/modules/svm.html>Scikit-learn SVM</a> | <a href=https://link.springer.com/article/10.1007/BF00994018>Support Vector Networks Paper</a> | <a href=https://web.stanford.edu/~hastie/ElemStatLearn/ >Elements of Statistical Learning - Chapter 12</a></p> <h2 id=_1></h2> <p> Summary</p> <p>Support Vector Machine (SVM) is a discriminative classifier that finds the optimal hyperplane to separate different classes by maximizing the margin (distance) between the closest points of each class. The algorithm focuses on the most informative data points (support vectors) rather than using all training data, making it efficient and robust.</p> <p><strong>Key characteristics:</strong> - <strong>Maximum margin classifier</strong>: Finds the hyperplane with largest margin - <strong>Support vector focus</strong>: Only depends on support vectors, not all training data - <strong>Kernel trick</strong>: Can handle non-linear decision boundaries using kernel functions - <strong>Regularization</strong>: Built-in regularization through the C parameter - <strong>Versatile</strong>: Works for classification, regression, and outlier detection - <strong>Memory efficient</strong>: Stores only support vectors, not entire dataset</p> <p><strong>Applications:</strong> - Text classification and sentiment analysis - Image classification and computer vision - Bioinformatics and gene classification<br> - Handwriting recognition - Face detection and recognition - Document classification - Spam email filtering - Medical diagnosis - Financial market analysis</p> <p><strong>Types:</strong> - <strong>Linear SVM</strong>: For linearly separable data - <strong>Soft Margin SVM</strong>: Handles non-separable data with slack variables - <strong>Kernel SVM</strong>: Non-linear classification using kernel methods - <strong>SVR (Support Vector Regression)</strong>: For regression tasks - <strong>One-Class SVM</strong>: For anomaly detection and novelty detection</p> <h2 id=intuition>&gt;ÔøΩ Intuition</h2> <h3 id=how-svm-works>How SVM Works</h3> <p>Imagine you're trying to separate two groups of people in a room. Instead of just drawing any line between them, SVM finds the "widest corridor" that separates the groups. The people standing closest to this corridor (support vectors) determine where the boundary should be. Everyone else could leave the room, and the boundary would stay the same.</p> <p>For non-linearly separable data, SVM uses the "kernel trick" - it projects the data into a higher-dimensional space where a linear separator can be found, then maps the decision boundary back to the original space.</p> <h3 id=mathematical-foundation>Mathematical Foundation</h3> <h4 id=1-linear-svm-hard-margin>1. Linear SVM - Hard Margin</h4> <p>For a binary classification problem with training data <span class=arithmatex>\(\{(x_i, y_i)\}_{i=1}^n\)</span> where <span class=arithmatex>\(y_i \in \{-1, +1\}\)</span>:</p> <p><strong>Decision boundary</strong>: <span class=arithmatex>\(w^T x + b = 0\)</span></p> <p><strong>Classification rule</strong>: <span class=arithmatex>\(f(x) = \text{sign}(w^T x + b)\)</span></p> <p><strong>Margin</strong>: The distance from the hyperplane to the nearest data point is <span class=arithmatex>\(\frac{1}{||w||}\)</span></p> <p><strong>Optimization problem</strong> (Hard Margin): <span class=arithmatex>\(<span class=arithmatex>\(\min_{w,b} \frac{1}{2}||w||^2\)</span>\)</span></p> <p><strong>Subject to</strong>: <span class=arithmatex>\(y_i(w^T x_i + b) \geq 1, \quad \forall i = 1,...,n\)</span></p> <h4 id=2-soft-margin-svm>2. Soft Margin SVM</h4> <p>For non-separable data, introduce slack variables <span class=arithmatex>\(\xi_i \geq 0\)</span>:</p> <p><strong>Optimization problem</strong> (Soft Margin): <span class=arithmatex>\(<span class=arithmatex>\(\min_{w,b,\xi} \frac{1}{2}||w||^2 + C\sum_{i=1}^n \xi_i\)</span>\)</span></p> <p><strong>Subject to</strong>: - <span class=arithmatex>\(y_i(w^T x_i + b) \geq 1 - \xi_i, \quad \forall i\)</span> - <span class=arithmatex>\(\xi_i \geq 0, \quad \forall i\)</span></p> <p>Where <span class=arithmatex>\(C\)</span> is the regularization parameter controlling the trade-off between margin maximization and training error minimization.</p> <h4 id=3-dual-formulation-lagrangian>3. Dual Formulation (Lagrangian)</h4> <p>The primal problem is converted to dual form using Lagrange multipliers <span class=arithmatex>\(\alpha_i\)</span>:</p> <p><strong>Dual optimization problem</strong>: <span class=arithmatex>\(<span class=arithmatex>\(\max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2}\sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j x_i^T x_j\)</span>\)</span></p> <p><strong>Subject to</strong>: - <span class=arithmatex>\(0 \leq \alpha_i \leq C, \quad \forall i\)</span> - <span class=arithmatex>\(\sum_{i=1}^n \alpha_i y_i = 0\)</span></p> <p><strong>Decision function</strong>: <span class=arithmatex>\(<span class=arithmatex>\(f(x) = \text{sign}\left(\sum_{i=1}^n \alpha_i y_i x_i^T x + b\right)\)</span>\)</span></p> <h4 id=4-kernel-trick>4. Kernel Trick</h4> <p>Replace the dot product <span class=arithmatex>\(x_i^T x_j\)</span> with a kernel function <span class=arithmatex>\(K(x_i, x_j)\)</span>:</p> <p><strong>Decision function with kernels</strong>: <span class=arithmatex>\(<span class=arithmatex>\(f(x) = \text{sign}\left(\sum_{i=1}^n \alpha_i y_i K(x_i, x) + b\right)\)</span>\)</span></p> <p><strong>Common kernel functions</strong>:</p> <p><strong>Linear</strong>: <span class=arithmatex>\(K(x, z) = x^T z\)</span></p> <p><strong>Polynomial</strong>: <span class=arithmatex>\(K(x, z) = (x^T z + c)^d\)</span></p> <p><strong>RBF (Radial Basis Function)</strong>: <span class=arithmatex>\(K(x, z) = \exp\left(-\gamma ||x - z||^2\right)\)</span></p> <p><strong>Sigmoid</strong>: <span class=arithmatex>\(K(x, z) = \tanh(\gamma x^T z + c)\)</span></p> <h4 id=5-support-vector-regression-svr>5. Support Vector Regression (SVR)</h4> <p>For regression, use <span class=arithmatex>\(\varepsilon\)</span>-insensitive loss:</p> <p><strong>Optimization problem</strong>: <span class=arithmatex>\(<span class=arithmatex>\(\min_{w,b,\xi,\xi^*} \frac{1}{2}||w||^2 + C\sum_{i=1}^n (\xi_i + \xi_i^*)\)</span>\)</span></p> <p><strong>Subject to</strong>: - <span class=arithmatex>\(y_i - w^T x_i - b \leq \varepsilon + \xi_i\)</span> - <span class=arithmatex>\(w^T x_i + b - y_i \leq \varepsilon + \xi_i^*\)</span> - <span class=arithmatex>\(\xi_i, \xi_i^* \geq 0\)</span></p> <h2 id=implementation-using-libraries>=" Implementation using Libraries</h2> <h3 id=scikit-learn-implementation>Scikit-learn Implementation</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn</span><span class=w> </span><span class=kn>import</span> <span class=n>datasets</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVC</span><span class=p>,</span> <span class=n>SVR</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span><span class=p>,</span> <span class=n>GridSearchCV</span><span class=p>,</span> <span class=n>cross_val_score</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>classification_report</span><span class=p>,</span> <span class=n>confusion_matrix</span><span class=p>,</span> <span class=n>accuracy_score</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>mean_squared_error</span><span class=p>,</span> <span class=n>r2_score</span>
<span class=kn>import</span><span class=w> </span><span class=nn>seaborn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>sns</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>make_classification</span><span class=p>,</span> <span class=n>make_regression</span>

<span class=c1># Classification Example with Iris Dataset</span>
<span class=n>iris</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_iris</span><span class=p>()</span>
<span class=n>X_iris</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>[:,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span>  <span class=c1># Use only first 2 features for visualization</span>
<span class=n>y_iris</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span>

<span class=c1># Binary classification (setosa vs non-setosa)</span>
<span class=n>y_binary</span> <span class=o>=</span> <span class=p>(</span><span class=n>y_iris</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>

<span class=c1># Split data</span>
<span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
    <span class=n>X_iris</span><span class=p>,</span> <span class=n>y_binary</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y_binary</span>
<span class=p>)</span>

<span class=c1># Standardize features (important for SVM)</span>
<span class=n>scaler</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
<span class=n>X_train_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span>
<span class=n>X_test_scaled</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;SVM Classification Example:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training data shape: </span><span class=si>{</span><span class=n>X_train_scaled</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test data shape: </span><span class=si>{</span><span class=n>X_test_scaled</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Train different SVM models</span>
<span class=n>svm_models</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;Linear SVM&#39;</span><span class=p>:</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;linear&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
    <span class=s1>&#39;RBF SVM&#39;</span><span class=p>:</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
    <span class=s1>&#39;Polynomial SVM&#39;</span><span class=p>:</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;poly&#39;</span><span class=p>,</span> <span class=n>degree</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
    <span class=s1>&#39;Sigmoid SVM&#39;</span><span class=p>:</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
<span class=p>}</span>

<span class=n>results</span> <span class=o>=</span> <span class=p>{}</span>
<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>model</span> <span class=ow>in</span> <span class=n>svm_models</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=c1># Train model</span>
    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>

    <span class=c1># Predictions</span>
    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>)</span>

    <span class=c1># Evaluate</span>
    <span class=n>accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
    <span class=n>results</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
        <span class=s1>&#39;model&#39;</span><span class=p>:</span> <span class=n>model</span><span class=p>,</span>
        <span class=s1>&#39;accuracy&#39;</span><span class=p>:</span> <span class=n>accuracy</span><span class=p>,</span>
        <span class=s1>&#39;n_support&#39;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>),</span>
        <span class=s1>&#39;support_vectors&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>support_vectors_</span>
    <span class=p>}</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2> Results:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Accuracy: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of support vectors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Detailed analysis of best model (RBF SVM)</span>
<span class=n>best_model</span> <span class=o>=</span> <span class=n>results</span><span class=p>[</span><span class=s1>&#39;RBF SVM&#39;</span><span class=p>][</span><span class=s1>&#39;model&#39;</span><span class=p>]</span>
<span class=n>y_pred_best</span> <span class=o>=</span> <span class=n>best_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Detailed Results for RBF SVM:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Classification Report:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred_best</span><span class=p>))</span>

<span class=c1># Confusion matrix</span>
<span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred_best</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>cm</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;d&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Confusion Matrix - RBF SVM&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Label&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted Label&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <h3 id=decision-boundary-visualization>Decision Boundary Visualization</h3> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>plot_svm_decision_boundary</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>title</span><span class=p>,</span> <span class=n>scaler</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Plot SVM decision boundary with support vectors&quot;&quot;&quot;</span>
    <span class=k>if</span> <span class=n>scaler</span><span class=p>:</span>
        <span class=n>X</span> <span class=o>=</span> <span class=n>scaler</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>

    <span class=c1># Create mesh for decision boundary</span>
    <span class=n>h</span> <span class=o>=</span> <span class=mf>0.01</span>  <span class=c1># Step size in mesh</span>
    <span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span> <span class=o>=</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
    <span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span> <span class=o>=</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
    <span class=n>xx</span><span class=p>,</span> <span class=n>yy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span><span class=p>,</span> <span class=n>h</span><span class=p>),</span>
                        <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span><span class=p>,</span> <span class=n>h</span><span class=p>))</span>

    <span class=c1># Predict on mesh</span>
    <span class=n>mesh_points</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>c_</span><span class=p>[</span><span class=n>xx</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span> <span class=n>yy</span><span class=o>.</span><span class=n>ravel</span><span class=p>()]</span>
    <span class=n>Z</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>mesh_points</span><span class=p>)</span>
    <span class=n>Z</span> <span class=o>=</span> <span class=n>Z</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>xx</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>

    <span class=c1># Plot decision boundary</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>contourf</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>RdYlBu</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>contour</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z</span><span class=p>,</span> <span class=n>colors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linewidths</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>

    <span class=c1># Plot data points</span>
    <span class=n>colors</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=s1>&#39;blue&#39;</span><span class=p>]</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>color</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>colors</span><span class=p>):</span>
        <span class=n>idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>y</span> <span class=o>==</span> <span class=n>i</span><span class=p>)</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>X</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>c</span><span class=o>=</span><span class=n>color</span><span class=p>,</span> 
                   <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Class </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>

    <span class=c1># Highlight support vectors</span>
    <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=s1>&#39;support_vectors_&#39;</span><span class=p>):</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_vectors_</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>model</span><span class=o>.</span><span class=n>support_vectors_</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span>
                   <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>facecolors</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>,</span> <span class=n>edgecolors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
                   <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Support Vectors&#39;</span><span class=p>)</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Feature 1 (standardized)&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Feature 2 (standardized)&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=n>title</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Plot decision boundaries for different kernels</span>
<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=n>results</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=n>plot_svm_decision_boundary</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>result</span><span class=p>[</span><span class=s1>&#39;model&#39;</span><span class=p>],</span> 
                              <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s1> - Decision Boundary&#39;</span><span class=p>,</span> <span class=n>scaler</span><span class=p>)</span>
</code></pre></div> <h3 id=hyperparameter-tuning>Hyperparameter Tuning</h3> <div class=highlight><pre><span></span><code><span class=c1># Comprehensive hyperparameter tuning for RBF SVM</span>
<span class=n>param_grid</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>],</span>
    <span class=s1>&#39;gamma&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=s1>&#39;auto&#39;</span><span class=p>,</span> <span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
    <span class=s1>&#39;kernel&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;rbf&#39;</span><span class=p>]</span>
<span class=p>}</span>

<span class=c1># Grid search with cross-validation</span>
<span class=n>grid_search</span> <span class=o>=</span> <span class=n>GridSearchCV</span><span class=p>(</span>
    <span class=n>SVC</span><span class=p>(</span><span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>),</span>
    <span class=n>param_grid</span><span class=p>,</span>
    <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
    <span class=n>scoring</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span>
    <span class=n>n_jobs</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
    <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span>
<span class=p>)</span>

<span class=n>grid_search</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_scaled</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Hyperparameter Tuning Results:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best parameters: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_params_</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best cross-validation score: </span><span class=si>{</span><span class=n>grid_search</span><span class=o>.</span><span class=n>best_score_</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Evaluate best model</span>
<span class=n>best_svm</span> <span class=o>=</span> <span class=n>grid_search</span><span class=o>.</span><span class=n>best_estimator_</span>
<span class=n>y_pred_tuned</span> <span class=o>=</span> <span class=n>best_svm</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_scaled</span><span class=p>)</span>
<span class=n>tuned_accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred_tuned</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test accuracy with best parameters: </span><span class=si>{</span><span class=n>tuned_accuracy</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of support vectors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>best_svm</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize hyperparameter effects</span>
<span class=n>results_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>grid_search</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>)</span>

<span class=c1># Heatmap of C vs gamma performance</span>
<span class=n>pivot_table</span> <span class=o>=</span> <span class=n>results_df</span><span class=o>.</span><span class=n>pivot_table</span><span class=p>(</span>
    <span class=n>values</span><span class=o>=</span><span class=s1>&#39;mean_test_score&#39;</span><span class=p>,</span>
    <span class=n>index</span><span class=o>=</span><span class=s1>&#39;param_gamma&#39;</span><span class=p>,</span> 
    <span class=n>columns</span><span class=o>=</span><span class=s1>&#39;param_C&#39;</span>
<span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>pivot_table</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;.3f&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;viridis&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;SVM Performance: C vs Gamma&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;C (Regularization)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Gamma (Kernel coefficient)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <h3 id=support-vector-regression-svr>Support Vector Regression (SVR)</h3> <div class=highlight><pre><span></span><code><span class=c1># Generate regression dataset</span>
<span class=n>X_reg</span><span class=p>,</span> <span class=n>y_reg</span> <span class=o>=</span> <span class=n>make_regression</span><span class=p>(</span>
    <span class=n>n_samples</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span> <span class=n>n_features</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>noise</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> 
    <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
<span class=p>)</span>

<span class=c1># Split data</span>
<span class=n>X_train_reg</span><span class=p>,</span> <span class=n>X_test_reg</span><span class=p>,</span> <span class=n>y_train_reg</span><span class=p>,</span> <span class=n>y_test_reg</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
    <span class=n>X_reg</span><span class=p>,</span> <span class=n>y_reg</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
<span class=p>)</span>

<span class=c1># Standardize</span>
<span class=n>scaler_reg</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
<span class=n>X_train_reg_scaled</span> <span class=o>=</span> <span class=n>scaler_reg</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train_reg</span><span class=p>)</span>
<span class=n>X_test_reg_scaled</span> <span class=o>=</span> <span class=n>scaler_reg</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test_reg</span><span class=p>)</span>

<span class=c1># Train SVR models</span>
<span class=n>svr_models</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;Linear SVR&#39;</span><span class=p>:</span> <span class=n>SVR</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;linear&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=mf>0.1</span><span class=p>),</span>
    <span class=s1>&#39;RBF SVR&#39;</span><span class=p>:</span> <span class=n>SVR</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=mf>0.1</span><span class=p>),</span>
    <span class=s1>&#39;Polynomial SVR&#39;</span><span class=p>:</span> <span class=n>SVR</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;poly&#39;</span><span class=p>,</span> <span class=n>degree</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
<span class=p>}</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Support Vector Regression Results:&quot;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>model</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>svr_models</span><span class=o>.</span><span class=n>items</span><span class=p>()):</span>
    <span class=c1># Train model</span>
    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_reg_scaled</span><span class=p>,</span> <span class=n>y_train_reg</span><span class=p>)</span>

    <span class=c1># Predictions</span>
    <span class=n>y_pred_reg</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>)</span>

    <span class=c1># Evaluate</span>
    <span class=n>mse</span> <span class=o>=</span> <span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_test_reg</span><span class=p>,</span> <span class=n>y_pred_reg</span><span class=p>)</span>
    <span class=n>rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mse</span><span class=p>)</span>
    <span class=n>r2</span> <span class=o>=</span> <span class=n>r2_score</span><span class=p>(</span><span class=n>y_test_reg</span><span class=p>,</span> <span class=n>y_pred_reg</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: RMSE = </span><span class=si>{</span><span class=n>rmse</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, RÔøΩ = </span><span class=si>{</span><span class=n>r2</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, Support Vectors = </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># Plot results</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>

    <span class=c1># Sort data for smooth line plotting</span>
    <span class=n>X_plot</span> <span class=o>=</span> <span class=n>X_test_reg_scaled</span>
    <span class=n>sort_idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>X_plot</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>])</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>,</span> <span class=n>y_test_reg</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Actual&#39;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>,</span> <span class=n>y_pred_reg</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Predicted&#39;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>X_plot</span><span class=p>[</span><span class=n>sort_idx</span><span class=p>],</span> <span class=n>y_pred_reg</span><span class=p>[</span><span class=n>sort_idx</span><span class=p>],</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>

    <span class=c1># Highlight support vectors</span>
    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
        <span class=n>support_X</span> <span class=o>=</span> <span class=n>X_train_reg_scaled</span><span class=p>[</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>]</span>
        <span class=n>support_y</span> <span class=o>=</span> <span class=n>y_train_reg</span><span class=p>[</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>]</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>support_X</span><span class=p>,</span> <span class=n>support_y</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>facecolors</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>,</span> 
                   <span class=n>edgecolors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Support Vectors&#39;</span><span class=p>)</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Feature (standardized)&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Target&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=se>\n</span><span class=s1>RÔøΩ = </span><span class=si>{</span><span class=n>r2</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <h3 id=multi-class-classification>Multi-class Classification</h3> <div class=highlight><pre><span></span><code><span class=c1># Multi-class classification with full iris dataset</span>
<span class=n>X_multi</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span>
<span class=n>y_multi</span> <span class=o>=</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span>

<span class=n>X_train_multi</span><span class=p>,</span> <span class=n>X_test_multi</span><span class=p>,</span> <span class=n>y_train_multi</span><span class=p>,</span> <span class=n>y_test_multi</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
    <span class=n>X_multi</span><span class=p>,</span> <span class=n>y_multi</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y_multi</span>
<span class=p>)</span>

<span class=c1># Standardize</span>
<span class=n>scaler_multi</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
<span class=n>X_train_multi_scaled</span> <span class=o>=</span> <span class=n>scaler_multi</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train_multi</span><span class=p>)</span>
<span class=n>X_test_multi_scaled</span> <span class=o>=</span> <span class=n>scaler_multi</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test_multi</span><span class=p>)</span>

<span class=c1># Train multi-class SVM</span>
<span class=n>svm_multi</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
<span class=n>svm_multi</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_multi_scaled</span><span class=p>,</span> <span class=n>y_train_multi</span><span class=p>)</span>

<span class=c1># Predictions</span>
<span class=n>y_pred_multi</span> <span class=o>=</span> <span class=n>svm_multi</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_multi_scaled</span><span class=p>)</span>

<span class=c1># Evaluate</span>
<span class=n>accuracy_multi</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test_multi</span><span class=p>,</span> <span class=n>y_pred_multi</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Multi-class Classification Results:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Accuracy: </span><span class=si>{</span><span class=n>accuracy_multi</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total support vectors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>svm_multi</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Support vectors per class: </span><span class=si>{</span><span class=n>svm_multi</span><span class=o>.</span><span class=n>n_support_</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Classification Report:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test_multi</span><span class=p>,</span> <span class=n>y_pred_multi</span><span class=p>,</span> 
                          <span class=n>target_names</span><span class=o>=</span><span class=n>iris</span><span class=o>.</span><span class=n>target_names</span><span class=p>))</span>

<span class=c1># Confusion matrix</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>cm_multi</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test_multi</span><span class=p>,</span> <span class=n>y_pred_multi</span><span class=p>)</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>cm_multi</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;d&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>,</span>
            <span class=n>xticklabels</span><span class=o>=</span><span class=n>iris</span><span class=o>.</span><span class=n>target_names</span><span class=p>,</span>
            <span class=n>yticklabels</span><span class=o>=</span><span class=n>iris</span><span class=o>.</span><span class=n>target_names</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Multi-class SVM - Confusion Matrix&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Label&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted Label&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <h2 id=from-scratch-implementation>ÔøΩ From Scratch Implementation</h2> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>make_classification</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>

<span class=k>class</span><span class=w> </span><span class=nc>SVMFromScratch</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;linear&#39;</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=n>degree</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Support Vector Machine implementation from scratch</span>

<span class=sd>        Parameters:</span>
<span class=sd>        C: Regularization parameter</span>
<span class=sd>        kernel: Kernel function (&#39;linear&#39;, &#39;rbf&#39;, &#39;poly&#39;)</span>
<span class=sd>        gamma: Kernel coefficient for RBF and polynomial kernels</span>
<span class=sd>        degree: Degree for polynomial kernel</span>
<span class=sd>        max_iter: Maximum number of iterations</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>C</span> <span class=o>=</span> <span class=n>C</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>kernel</span> <span class=o>=</span> <span class=n>kernel</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>=</span> <span class=n>gamma</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>degree</span> <span class=o>=</span> <span class=n>degree</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>max_iter</span> <span class=o>=</span> <span class=n>max_iter</span>

        <span class=c1># Model parameters</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>support_vectors</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>support_vector_labels</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>support_vector_alpha</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>b</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>X_train</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>y_train</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_kernel_function</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Compute kernel function between two vectors&quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>kernel</span> <span class=o>==</span> <span class=s1>&#39;linear&#39;</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>)</span>

        <span class=k>elif</span> <span class=bp>self</span><span class=o>.</span><span class=n>kernel</span> <span class=o>==</span> <span class=s1>&#39;rbf&#39;</span><span class=p>:</span>
            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>==</span> <span class=s1>&#39;scale&#39;</span><span class=p>:</span>
                <span class=n>gamma</span> <span class=o>=</span> <span class=mf>1.0</span> <span class=o>/</span> <span class=p>(</span><span class=n>x1</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>x1</span><span class=p>))</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>gamma</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span>
            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>gamma</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>x1</span> <span class=o>-</span> <span class=n>x2</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span>

        <span class=k>elif</span> <span class=bp>self</span><span class=o>.</span><span class=n>kernel</span> <span class=o>==</span> <span class=s1>&#39;poly&#39;</span><span class=p>:</span>
            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>==</span> <span class=s1>&#39;scale&#39;</span><span class=p>:</span>
                <span class=n>gamma</span> <span class=o>=</span> <span class=mf>1.0</span> <span class=o>/</span> <span class=p>(</span><span class=n>x1</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>x1</span><span class=p>))</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>gamma</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span>
            <span class=k>return</span> <span class=p>(</span><span class=n>gamma</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>**</span> <span class=bp>self</span><span class=o>.</span><span class=n>degree</span>

        <span class=k>else</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;Unsupported kernel type&quot;</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_compute_kernel_matrix</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X1</span><span class=p>,</span> <span class=n>X2</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Compute kernel matrix between two sets of points&quot;&quot;&quot;</span>
        <span class=n>n1</span><span class=p>,</span> <span class=n>n2</span> <span class=o>=</span> <span class=n>X1</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>X2</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>kernel_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>n1</span><span class=p>,</span> <span class=n>n2</span><span class=p>))</span>

        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n1</span><span class=p>):</span>
            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n2</span><span class=p>):</span>
                <span class=n>kernel_matrix</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_kernel_function</span><span class=p>(</span><span class=n>X1</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>X2</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>

        <span class=k>return</span> <span class=n>kernel_matrix</span>

    <span class=k>def</span><span class=w> </span><span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Train SVM using SMO (Sequential Minimal Optimization) algorithm</span>
<span class=sd>        Simplified implementation</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>n_samples</span><span class=p>,</span> <span class=n>n_features</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>X_train</span> <span class=o>=</span> <span class=n>X</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>y_train</span> <span class=o>=</span> <span class=n>y</span>

        <span class=c1># Convert labels to -1 and 1</span>
        <span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>y</span> <span class=o>&lt;=</span> <span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

        <span class=c1># Initialize alpha</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>n_samples</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>b</span> <span class=o>=</span> <span class=mi>0</span>

        <span class=c1># Compute kernel matrix</span>
        <span class=n>K</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_compute_kernel_matrix</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span>

        <span class=c1># SMO algorithm (simplified)</span>
        <span class=k>for</span> <span class=n>iteration</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>max_iter</span><span class=p>):</span>
            <span class=n>alpha_prev</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>)</span>

            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_samples</span><span class=p>):</span>
                <span class=c1># Calculate prediction for point j</span>
                <span class=n>prediction_j</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=n>y</span> <span class=o>*</span> <span class=n>K</span><span class=p>[:,</span> <span class=n>j</span><span class=p>])</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>b</span>

                <span class=c1># Calculate error</span>
                <span class=n>E_j</span> <span class=o>=</span> <span class=n>prediction_j</span> <span class=o>-</span> <span class=n>y</span><span class=p>[</span><span class=n>j</span><span class=p>]</span>

                <span class=c1># Check KKT conditions</span>
                <span class=k>if</span> <span class=p>(</span><span class=n>y</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=n>E_j</span> <span class=o>&lt;</span> <span class=o>-</span><span class=mf>1e-3</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>C</span><span class=p>)</span> <span class=ow>or</span> \
                   <span class=p>(</span><span class=n>y</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=n>E_j</span> <span class=o>&gt;</span> <span class=mf>1e-3</span> <span class=ow>and</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>):</span>

                    <span class=c1># Select second alpha randomly</span>
                    <span class=n>i</span> <span class=o>=</span> <span class=n>j</span>
                    <span class=k>while</span> <span class=n>i</span> <span class=o>==</span> <span class=n>j</span><span class=p>:</span>
                        <span class=n>i</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>)</span>

                    <span class=c1># Calculate prediction and error for point i</span>
                    <span class=n>prediction_i</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=n>y</span> <span class=o>*</span> <span class=n>K</span><span class=p>[:,</span> <span class=n>i</span><span class=p>])</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>b</span>
                    <span class=n>E_i</span> <span class=o>=</span> <span class=n>prediction_i</span> <span class=o>-</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>

                    <span class=c1># Save old alphas</span>
                    <span class=n>alpha_i_old</span><span class=p>,</span> <span class=n>alpha_j_old</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span>

                    <span class=c1># Compute bounds</span>
                    <span class=k>if</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>!=</span> <span class=n>y</span><span class=p>[</span><span class=n>j</span><span class=p>]:</span>
                        <span class=n>L</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
                        <span class=n>H</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>C</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>C</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
                    <span class=k>else</span><span class=p>:</span>
                        <span class=n>L</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>C</span><span class=p>)</span>
                        <span class=n>H</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>C</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>

                    <span class=k>if</span> <span class=n>L</span> <span class=o>==</span> <span class=n>H</span><span class=p>:</span>
                        <span class=k>continue</span>

                    <span class=c1># Compute eta</span>
                    <span class=n>eta</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>K</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span> <span class=o>-</span> <span class=n>K</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>K</span><span class=p>[</span><span class=n>j</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span>
                    <span class=k>if</span> <span class=n>eta</span> <span class=o>&gt;=</span> <span class=mi>0</span><span class=p>:</span>
                        <span class=k>continue</span>

                    <span class=c1># Update alpha_j</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>-</span> <span class=p>(</span><span class=n>y</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>E_i</span> <span class=o>-</span> <span class=n>E_j</span><span class=p>))</span> <span class=o>/</span> <span class=n>eta</span>

                    <span class=c1># Clip alpha_j</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>L</span><span class=p>,</span> <span class=nb>min</span><span class=p>(</span><span class=n>H</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]))</span>

                    <span class=k>if</span> <span class=nb>abs</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>-</span> <span class=n>alpha_j_old</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mf>1e-5</span><span class=p>:</span>
                        <span class=k>continue</span>

                    <span class=c1># Update alpha_i</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>+</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>y</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>alpha_j_old</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>

                    <span class=c1># Update bias</span>
                    <span class=n>b1</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>b</span> <span class=o>-</span> <span class=n>E_i</span> <span class=o>-</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>alpha_i_old</span><span class=p>)</span> <span class=o>*</span> <span class=n>K</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>i</span><span class=p>]</span> <span class=o>-</span> \
                         <span class=n>y</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>-</span> <span class=n>alpha_j_old</span><span class=p>)</span> <span class=o>*</span> <span class=n>K</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span>

                    <span class=n>b2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>b</span> <span class=o>-</span> <span class=n>E_j</span> <span class=o>-</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>alpha_i_old</span><span class=p>)</span> <span class=o>*</span> <span class=n>K</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span> <span class=o>-</span> \
                         <span class=n>y</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>-</span> <span class=n>alpha_j_old</span><span class=p>)</span> <span class=o>*</span> <span class=n>K</span><span class=p>[</span><span class=n>j</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span>

                    <span class=k>if</span> <span class=mi>0</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>C</span><span class=p>:</span>
                        <span class=bp>self</span><span class=o>.</span><span class=n>b</span> <span class=o>=</span> <span class=n>b1</span>
                    <span class=k>elif</span> <span class=mi>0</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>C</span><span class=p>:</span>
                        <span class=bp>self</span><span class=o>.</span><span class=n>b</span> <span class=o>=</span> <span class=n>b2</span>
                    <span class=k>else</span><span class=p>:</span>
                        <span class=bp>self</span><span class=o>.</span><span class=n>b</span> <span class=o>=</span> <span class=p>(</span><span class=n>b1</span> <span class=o>+</span> <span class=n>b2</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span>

            <span class=c1># Check convergence</span>
            <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>allclose</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>,</span> <span class=n>alpha_prev</span><span class=p>,</span> <span class=n>atol</span><span class=o>=</span><span class=mf>1e-5</span><span class=p>):</span>
                <span class=k>break</span>

        <span class=c1># Identify support vectors</span>
        <span class=n>support_vector_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>&gt;</span> <span class=mf>1e-5</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>support_vectors</span> <span class=o>=</span> <span class=n>X</span><span class=p>[</span><span class=n>support_vector_indices</span><span class=p>]</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>support_vector_labels</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>support_vector_indices</span><span class=p>]</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>support_vector_alpha</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>[</span><span class=n>support_vector_indices</span><span class=p>]</span>

        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training completed in </span><span class=si>{</span><span class=n>iteration</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=mi>1</span><span class=si>}</span><span class=s2> iterations&quot;</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of support vectors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>support_vector_indices</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Make predictions on new data&quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>support_vectors</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;Model has not been trained yet&quot;</span><span class=p>)</span>

        <span class=n>n_samples</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>predictions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>n_samples</span><span class=p>)</span>

        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_samples</span><span class=p>):</span>
            <span class=n>prediction</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>support_vectors</span><span class=p>)):</span>
                <span class=n>prediction</span> <span class=o>+=</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>support_vector_alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> 
                             <span class=bp>self</span><span class=o>.</span><span class=n>support_vector_labels</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> 
                             <span class=bp>self</span><span class=o>.</span><span class=n>_kernel_function</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>support_vectors</span><span class=p>[</span><span class=n>j</span><span class=p>]))</span>
            <span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>prediction</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>b</span>

        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>predictions</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>decision_function</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Return decision function values&quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>support_vectors</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;Model has not been trained yet&quot;</span><span class=p>)</span>

        <span class=n>n_samples</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>decisions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>n_samples</span><span class=p>)</span>

        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_samples</span><span class=p>):</span>
            <span class=n>decision</span> <span class=o>=</span> <span class=mi>0</span>
            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>support_vectors</span><span class=p>)):</span>
                <span class=n>decision</span> <span class=o>+=</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>support_vector_alpha</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> 
                           <span class=bp>self</span><span class=o>.</span><span class=n>support_vector_labels</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> 
                           <span class=bp>self</span><span class=o>.</span><span class=n>_kernel_function</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>support_vectors</span><span class=p>[</span><span class=n>j</span><span class=p>]))</span>
            <span class=n>decisions</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>decision</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>b</span>

        <span class=k>return</span> <span class=n>decisions</span>

<span class=c1># Demonstration with synthetic dataset</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=c1># Generate synthetic dataset</span>
<span class=n>X_demo</span><span class=p>,</span> <span class=n>y_demo</span> <span class=o>=</span> <span class=n>make_classification</span><span class=p>(</span>
    <span class=n>n_samples</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span> <span class=n>n_features</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>n_redundant</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_informative</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
    <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>n_clusters_per_class</span><span class=o>=</span><span class=mi>1</span>
<span class=p>)</span>

<span class=c1># Convert to binary classification</span>
<span class=n>y_demo</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>y_demo</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

<span class=c1># Split data</span>
<span class=n>X_train_demo</span><span class=p>,</span> <span class=n>X_test_demo</span><span class=p>,</span> <span class=n>y_train_demo</span><span class=p>,</span> <span class=n>y_test_demo</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
    <span class=n>X_demo</span><span class=p>,</span> <span class=n>y_demo</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
<span class=p>)</span>

<span class=c1># Standardize</span>
<span class=n>scaler_demo</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
<span class=n>X_train_demo_scaled</span> <span class=o>=</span> <span class=n>scaler_demo</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train_demo</span><span class=p>)</span>
<span class=n>X_test_demo_scaled</span> <span class=o>=</span> <span class=n>scaler_demo</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test_demo</span><span class=p>)</span>

<span class=c1># Train custom SVM</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training Custom SVM:&quot;</span><span class=p>)</span>
<span class=n>svm_custom</span> <span class=o>=</span> <span class=n>SVMFromScratch</span><span class=p>(</span><span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
<span class=n>svm_custom</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_demo_scaled</span><span class=p>,</span> <span class=n>y_train_demo</span><span class=p>)</span>

<span class=c1># Predictions</span>
<span class=n>y_pred_custom</span> <span class=o>=</span> <span class=n>svm_custom</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_demo_scaled</span><span class=p>)</span>

<span class=c1># Compare with sklearn</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVC</span>
<span class=n>svm_sklearn</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
<span class=n>svm_sklearn</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_demo_scaled</span><span class=p>,</span> <span class=n>y_train_demo</span><span class=p>)</span>
<span class=n>y_pred_sklearn</span> <span class=o>=</span> <span class=n>svm_sklearn</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_demo_scaled</span><span class=p>)</span>

<span class=c1># Evaluate</span>
<span class=n>accuracy_custom</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>y_pred_custom</span> <span class=o>==</span> <span class=n>y_test_demo</span><span class=p>)</span>
<span class=n>accuracy_sklearn</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>y_pred_sklearn</span> <span class=o>==</span> <span class=n>y_test_demo</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Comparison Results:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Custom SVM accuracy: </span><span class=si>{</span><span class=n>accuracy_custom</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Sklearn SVM accuracy: </span><span class=si>{</span><span class=n>accuracy_sklearn</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Difference: </span><span class=si>{</span><span class=nb>abs</span><span class=p>(</span><span class=n>accuracy_custom</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>accuracy_sklearn</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize results</span>
<span class=k>def</span><span class=w> </span><span class=nf>plot_svm_comparison</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>svm_custom</span><span class=p>,</span> <span class=n>svm_sklearn</span><span class=p>,</span> <span class=n>title_custom</span><span class=p>,</span> <span class=n>title_sklearn</span><span class=p>):</span>
    <span class=n>fig</span><span class=p>,</span> <span class=p>(</span><span class=n>ax1</span><span class=p>,</span> <span class=n>ax2</span><span class=p>)</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>

    <span class=c1># Create mesh</span>
    <span class=n>h</span> <span class=o>=</span> <span class=mf>0.01</span>
    <span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span> <span class=o>=</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
    <span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span> <span class=o>=</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
    <span class=n>xx</span><span class=p>,</span> <span class=n>yy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span><span class=p>,</span> <span class=n>h</span><span class=p>),</span>
                        <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span><span class=p>,</span> <span class=n>h</span><span class=p>))</span>
    <span class=n>mesh_points</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>c_</span><span class=p>[</span><span class=n>xx</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span> <span class=n>yy</span><span class=o>.</span><span class=n>ravel</span><span class=p>()]</span>

    <span class=c1># Plot custom SVM</span>
    <span class=n>Z_custom</span> <span class=o>=</span> <span class=n>svm_custom</span><span class=o>.</span><span class=n>decision_function</span><span class=p>(</span><span class=n>mesh_points</span><span class=p>)</span>
    <span class=n>Z_custom</span> <span class=o>=</span> <span class=n>Z_custom</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>xx</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>

    <span class=n>ax1</span><span class=o>.</span><span class=n>contourf</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z_custom</span><span class=p>,</span> <span class=n>levels</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>RdYlBu</span><span class=p>)</span>
    <span class=n>ax1</span><span class=o>.</span><span class=n>contour</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z_custom</span><span class=p>,</span> <span class=n>levels</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>colors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linewidths</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>

    <span class=c1># Plot data points</span>
    <span class=n>colors</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=s1>&#39;blue&#39;</span><span class=p>]</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>color</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>([</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]):</span>
        <span class=n>idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>y</span> <span class=o>==</span> <span class=n>color</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>ax1</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>X</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>c</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> 
                   <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Class </span><span class=si>{</span><span class=n>color</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>

    <span class=c1># Highlight support vectors</span>
    <span class=k>if</span> <span class=n>svm_custom</span><span class=o>.</span><span class=n>support_vectors</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>ax1</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>svm_custom</span><span class=o>.</span><span class=n>support_vectors</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>svm_custom</span><span class=o>.</span><span class=n>support_vectors</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span>
                   <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>facecolors</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>,</span> <span class=n>edgecolors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
                   <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Support Vectors&#39;</span><span class=p>)</span>

    <span class=n>ax1</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=n>title_custom</span><span class=p>)</span>
    <span class=n>ax1</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>ax1</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

    <span class=c1># Plot sklearn SVM</span>
    <span class=n>Z_sklearn</span> <span class=o>=</span> <span class=n>svm_sklearn</span><span class=o>.</span><span class=n>decision_function</span><span class=p>(</span><span class=n>mesh_points</span><span class=p>)</span>
    <span class=n>Z_sklearn</span> <span class=o>=</span> <span class=n>Z_sklearn</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>xx</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>

    <span class=n>ax2</span><span class=o>.</span><span class=n>contourf</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z_sklearn</span><span class=p>,</span> <span class=n>levels</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>RdYlBu</span><span class=p>)</span>
    <span class=n>ax2</span><span class=o>.</span><span class=n>contour</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z_sklearn</span><span class=p>,</span> <span class=n>levels</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>colors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linewidths</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>

    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>color</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>([</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]):</span>
        <span class=n>idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>y</span> <span class=o>==</span> <span class=n>color</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>ax2</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>X</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>c</span><span class=o>=</span><span class=n>colors</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>marker</span><span class=o>=</span><span class=s1>&#39;o&#39;</span><span class=p>,</span> 
                   <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Class </span><span class=si>{</span><span class=n>color</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>

    <span class=c1># Highlight support vectors</span>
    <span class=n>ax2</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>svm_sklearn</span><span class=o>.</span><span class=n>support_vectors_</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>svm_sklearn</span><span class=o>.</span><span class=n>support_vectors_</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span>
               <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>facecolors</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>,</span> <span class=n>edgecolors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
               <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Support Vectors&#39;</span><span class=p>)</span>

    <span class=n>ax2</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=n>title_sklearn</span><span class=p>)</span>
    <span class=n>ax2</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>ax2</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=n>plot_svm_comparison</span><span class=p>(</span><span class=n>X_train_demo_scaled</span><span class=p>,</span> <span class=n>y_train_demo</span><span class=p>,</span> <span class=n>svm_custom</span><span class=p>,</span> <span class=n>svm_sklearn</span><span class=p>,</span>
                   <span class=sa>f</span><span class=s1>&#39;Custom SVM (Acc: </span><span class=si>{</span><span class=n>accuracy_custom</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>,</span>
                   <span class=sa>f</span><span class=s1>&#39;Sklearn SVM (Acc: </span><span class=si>{</span><span class=n>accuracy_sklearn</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
</code></pre></div> <h2 id=assumptions-and-limitations>ÔøΩ Assumptions and Limitations</h2> <h3 id=key-assumptions>Key Assumptions</h3> <ol> <li><strong>Margin maximization is optimal</strong>: Assumes that maximizing margin leads to better generalization</li> <li><strong>Support vector sufficiency</strong>: Only support vectors matter for the decision boundary</li> <li><strong>Kernel validity</strong>: Chosen kernel should satisfy Mercer's conditions</li> <li><strong>Feature scaling</strong>: SVM is sensitive to feature scales (assumes standardized features)</li> <li><strong>Data quality</strong>: Assumes training data is representative of test distribution</li> </ol> <h3 id=limitations>Limitations</h3> <ol> <li><strong>Computational complexity</strong>: O(nÔøΩ) training complexity for SMO algorithm</li> <li><strong>Impact</strong>: Slow on large datasets (&gt;10,000 samples)</li> <li> <p><strong>Solution</strong>: Use approximate methods, sub-sampling, or linear SVM</p> </li> <li> <p><strong>Memory requirements</strong>: Stores support vectors and kernel matrix</p> </li> <li><strong>Impact</strong>: Memory issues with large datasets or complex kernels</li> <li> <p><strong>Solution</strong>: Use linear kernels, feature selection, or incremental learning</p> </li> <li> <p><strong>No probabilistic output</strong>: Standard SVM provides only class predictions</p> </li> <li> <p><strong>Solution</strong>: Use Platt scaling or cross-validation for probability estimates</p> </li> <li> <p><strong>Sensitive to feature scaling</strong>: Different scales can dominate the kernel</p> </li> <li> <p><strong>Solution</strong>: Always standardize features before training</p> </li> <li> <p><strong>Hyperparameter sensitivity</strong>: Performance heavily depends on C and kernel parameters</p> </li> <li> <p><strong>Solution</strong>: Use cross-validation for hyperparameter tuning</p> </li> <li> <p><strong>Limited interpretability</strong>: Kernel SVMs create complex decision boundaries</p> </li> <li><strong>Alternative</strong>: Use linear SVM or other interpretable models when needed</li> </ol> <h3 id=comparison-with-other-algorithms>Comparison with Other Algorithms</h3> <table> <thead> <tr> <th>Algorithm</th> <th>Training Speed</th> <th>Prediction Speed</th> <th>Memory Usage</th> <th>Interpretability</th> <th>Non-linear Capability</th> </tr> </thead> <tbody> <tr> <td>SVM</td> <td>Slow (O(nÔøΩ))</td> <td>Fast</td> <td>High</td> <td>Low (kernel)</td> <td>High</td> </tr> <tr> <td>Logistic Regression</td> <td>Fast</td> <td>Very Fast</td> <td>Low</td> <td>High</td> <td>Low</td> </tr> <tr> <td>Random Forest</td> <td>Medium</td> <td>Medium</td> <td>Medium</td> <td>Medium</td> <td>High</td> </tr> <tr> <td>Neural Networks</td> <td>Slow</td> <td>Fast</td> <td>High</td> <td>Very Low</td> <td>Very High</td> </tr> <tr> <td>k-NN</td> <td>Very Fast</td> <td>Slow</td> <td>Medium</td> <td>High</td> <td>High</td> </tr> <tr> <td>Naive Bayes</td> <td>Very Fast</td> <td>Very Fast</td> <td>Low</td> <td>High</td> <td>Low</td> </tr> </tbody> </table> <p><strong>When to use SVM:</strong> -  High-dimensional data -  Clear margin of separation exists<br> -  More features than samples -  Non-linear relationships (with kernels) -  Robust to outliers needed</p> <p><strong>When to avoid SVM:</strong> - L Very large datasets (&gt;100k samples) - L Noisy data with overlapping classes - L Need probability estimates - L Real-time prediction requirements - L Interpretability is crucial</p> <h2 id=interview-questions>‚ùì Interview Questions</h2> <details class=question> <summary>Explain the mathematical intuition behind SVM and the concept of margin maximization.</summary> <p><strong>Answer:</strong> SVM finds the hyperplane that separates classes with maximum margin:</p> <p><strong>Mathematical foundation</strong>: 1. <strong>Decision boundary</strong>: <span class=arithmatex>\(w^T x + b = 0\)</span> 2. <strong>Margin</strong>: Distance from hyperplane to nearest points = <span class=arithmatex>\(\frac{1}{||w||}\)</span> 3. <strong>Optimization</strong>: Maximize margin = Minimize <span class=arithmatex>\(\frac{1}{2}||w||^2\)</span> 4. <strong>Constraints</strong>: Ensure correct classification: <span class=arithmatex>\(y_i(w^T x_i + b) \geq 1\)</span></p> <p><strong>Intuition</strong>: - Larger margins ÔøΩ better generalization (statistical learning theory) - Only support vectors (points on margin) determine decision boundary - All other points could be removed without changing the model</p> <p><strong>Why maximize margin?</strong> - Provides robustness against small perturbations - Reduces VC dimension ÔøΩ better generalization bounds - Unique solution (convex optimization problem)</p> </details> <details class=question> <summary>What is the kernel trick and how does it enable SVM to handle non-linear data?</summary> <p><strong>Answer:</strong> The kernel trick allows SVM to handle non-linear data without explicitly computing high-dimensional transformations:</p> <p><strong>The trick</strong>: 1. <strong>Replace dot products</strong> in dual formulation with kernel function: <span class=arithmatex>\(x_i^T x_j ÔøΩ K(x_i, x_j)\)</span> 2. <strong>Implicit mapping</strong>: <span class=arithmatex>\(K(x_i, x_j) = ÔøΩ(x_i)^T ÔøΩ(x_j)\)</span> where ÔøΩ maps to higher dimension 3. <strong>No explicit computation</strong> of ÔøΩ(x) needed</p> <p><strong>Popular kernels</strong>: <div class=highlight><pre><span></span><code><span class=c1># Linear: K(x,z) = x^T z</span>
<span class=c1># Polynomial: K(x,z) = (x^T z + c)^d</span>
<span class=c1># RBF: K(x,z) = exp(-ÔøΩ||x-z||ÔøΩ)</span>
<span class=c1># Sigmoid: K(x,z) = tanh(ÔøΩx^T z + c)</span>
</code></pre></div></p> <p><strong>Example</strong>: RBF kernel maps data to infinite-dimensional space, allowing separation of any finite dataset</p> <p><strong>Advantages</strong>: - Computational efficiency (no explicit mapping) - Handles complex non-linear relationships - Mathematical elegance through Mercer's theorem</p> <p><strong>Limitations</strong>: - Kernel choice is crucial - Interpretability decreases - Hyperparameter tuning becomes more complex</p> </details> <details class=question> <summary>How do you choose appropriate hyperparameters (C, gamma, kernel) for SVM?</summary> <p><strong>Answer:</strong> Systematic approach to SVM hyperparameter tuning:</p> <p><strong>Key hyperparameters</strong>:</p> <p><strong>1. Regularization parameter C</strong>: - <strong>Small C</strong>: Soft margin, more misclassifications allowed, prevents overfitting - <strong>Large C</strong>: Hard margin, fewer misclassifications, risk of overfitting - <strong>Typical range</strong>: [0.1, 1, 10, 100, 1000]</p> <p><strong>2. Kernel parameter gamma (for RBF/poly)</strong>: - <strong>Small gamma</strong>: Far-reaching influence, smoother boundaries - <strong>Large gamma</strong>: Close influence, complex boundaries, overfitting risk - <strong>Typical values</strong>: ['scale', 'auto', 0.001, 0.01, 0.1, 1]</p> <p><strong>3. Kernel selection</strong>: <div class=highlight><pre><span></span><code><span class=c1># Linear: Good for high-dimensional, linearly separable data</span>
<span class=c1># RBF: Default choice, good for most non-linear problems</span>
<span class=c1># Polynomial: Specific polynomial relationships</span>
<span class=c1># Sigmoid: Neural network-like behavior</span>
</code></pre></div></p> <p><strong>Tuning strategy</strong>: <div class=highlight><pre><span></span><code><span class=c1># Grid search with cross-validation</span>
<span class=n>param_grid</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>],</span>
    <span class=s1>&#39;gamma&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
    <span class=s1>&#39;kernel&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=s1>&#39;poly&#39;</span><span class=p>,</span> <span class=s1>&#39;linear&#39;</span><span class=p>]</span>
<span class=p>}</span>
<span class=n>GridSearchCV</span><span class=p>(</span><span class=n>SVC</span><span class=p>(),</span> <span class=n>param_grid</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</code></pre></div></p> <p><strong>Best practices</strong>: - Start with default parameters - Use cross-validation for unbiased estimates - Consider computational constraints - Validate on separate test set</p> </details> <details class=question> <summary>What's the difference between hard margin and soft margin SVM?</summary> <p><strong>Answer:</strong> Key differences in handling non-separable data:</p> <p><strong>Hard Margin SVM</strong>: - <strong>Assumption</strong>: Data is linearly separable - <strong>Constraint</strong>: All points correctly classified: <span class=arithmatex>\(y_i(w^T x_i + b) \geq 1\)</span> - <strong>Objective</strong>: <span class=arithmatex>\(\min \frac{1}{2}||w||^2\)</span> - <strong>Problem</strong>: No solution exists if data isn't separable - <strong>Use case</strong>: Clean, separable data</p> <p><strong>Soft Margin SVM</strong>: - <strong>Assumption</strong>: Data may have noise/overlap - <strong>Slack variables</strong>: <span class=arithmatex>\(ÔøΩ_i e 0\)</span> allow constraint violations - <strong>Modified constraints</strong>: <span class=arithmatex>\(y_i(w^T x_i + b) \geq 1 - ÔøΩ_i\)</span> - <strong>Objective</strong>: <span class=arithmatex>\(\min \frac{1}{2}||w||^2 + C\sum ÔøΩ_i\)</span> - <strong>Trade-off</strong>: Margin maximization vs. training error</p> <p><strong>C parameter controls</strong>: - $C ÔøΩ $: Approaches hard margin (no violations) - <span class=arithmatex>\(C ÔøΩ 0\)</span>: Allows many violations (maximum margin)</p> <p><strong>Practical impact</strong>: <div class=highlight><pre><span></span><code><span class=c1># Hard margin equivalent</span>
<span class=n>SVC</span><span class=p>(</span><span class=n>C</span><span class=o>=</span><span class=mf>1e6</span><span class=p>)</span>  <span class=c1># Very large C</span>

<span class=c1># Soft margin</span>
<span class=n>SVC</span><span class=p>(</span><span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>   <span class=c1># Balanced trade-off</span>
</code></pre></div></p> <p><strong>When to use</strong>: - <strong>Hard margin</strong>: Perfect data, small datasets - <strong>Soft margin</strong>: Real-world data (recommended)</p> </details> <details class=question> <summary>How does SVM handle multi-class classification?</summary> <p><strong>Answer:</strong> SVM is inherently binary, but extends to multi-class using two main strategies:</p> <p><strong>1. One-vs-Rest (OvR)</strong>: - Train K binary classifiers (K = number of classes) - Each classifier: "Class i vs All other classes" - Prediction: Class with highest decision function score - <strong>Pros</strong>: Simple, efficient - <strong>Cons</strong>: Imbalanced datasets per classifier</p> <div class=highlight><pre><span></span><code><span class=c1># Automatic in sklearn</span>
<span class=n>SVC</span><span class=p>()</span>  <span class=c1># Uses OvR by default</span>

<span class=c1># Explicit</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.multiclass</span><span class=w> </span><span class=kn>import</span> <span class=n>OneVsRestClassifier</span>
<span class=n>OneVsRestClassifier</span><span class=p>(</span><span class=n>SVC</span><span class=p>())</span>
</code></pre></div> <p><strong>2. One-vs-One (OvO)</strong>: - Train K(K-1)/2 binary classifiers - Each classifier: "Class i vs Class j" - Prediction: Majority voting among all classifiers - <strong>Pros</strong>: Balanced datasets, often more accurate - <strong>Cons</strong>: More classifiers to train</p> <div class=highlight><pre><span></span><code><span class=c1># In sklearn</span>
<span class=n>SVC</span><span class=p>(</span><span class=n>decision_function_shape</span><span class=o>=</span><span class=s1>&#39;ovo&#39;</span><span class=p>)</span>

<span class=c1># Explicit</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.multiclass</span><span class=w> </span><span class=kn>import</span> <span class=n>OneVsOneClassifier</span>
<span class=n>OneVsOneClassifier</span><span class=p>(</span><span class=n>SVC</span><span class=p>())</span>
</code></pre></div> <p><strong>Comparison</strong>: | Aspect | OvR | OvO | |--------|-----|-----| | <strong>Classifiers</strong> | K | K(K-1)/2 | | <strong>Training time</strong> | Faster | Slower | | <strong>Prediction time</strong> | Faster | Slower | | <strong>Accuracy</strong> | Good | Often better | | <strong>Memory</strong> | Less | More |</p> <p><strong>Decision function</strong>: - OvR: Use raw scores from each classifier - OvO: Aggregate pairwise comparisons</p> </details> <details class=question> <summary>What are the advantages and disadvantages of different SVM kernels?</summary> <p><strong>Answer:</strong> Comprehensive comparison of SVM kernels:</p> <p><strong>Linear Kernel</strong>: <span class=arithmatex>\(K(x,z) = x^T z\)</span></p> <p><strong>Advantages</strong>: -  Fast training and prediction -  Interpretable (weights have meaning) -  Good for high-dimensional data -  Less prone to overfitting -  No hyperparameters to tune</p> <p><strong>Disadvantages</strong>: - L Only linear decision boundaries - L Poor for complex non-linear relationships</p> <p><strong>Use when</strong>: Text classification, high-dimensional data, linear relationships</p> <p><strong>RBF (Gaussian) Kernel</strong>: <span class=arithmatex>\(K(x,z) = \exp(-\gamma||x-z||^2)\)</span></p> <p><strong>Advantages</strong>: -  Handles non-linear relationships -  Universal approximator -  Works well as default choice -  Smooth decision boundaries</p> <p><strong>Disadvantages</strong>: - L Requires hyperparameter tuning (ÔøΩ) - L Can overfit with large ÔøΩ - L Less interpretable - L Slower than linear</p> <p><strong>Use when</strong>: Non-linear data, default choice for most problems</p> <p><strong>Polynomial Kernel</strong>: <span class=arithmatex>\(K(x,z) = (x^T z + c)^d\)</span></p> <p><strong>Advantages</strong>: -  Good for specific polynomial relationships -  Interpretable degree parameter -  Can capture interactions</p> <p><strong>Disadvantages</strong>: - L Computationally expensive for high degrees - L Numerical instability - L Less general than RBF - L Multiple hyperparameters</p> <p><strong>Use when</strong>: Known polynomial relationships in data</p> <p><strong>Sigmoid Kernel</strong>: <span class=arithmatex>\(K(x,z) = \tanh(\gamma x^T z + c)\)</span></p> <p><strong>Advantages</strong>: -  Neural network-like behavior -  S-shaped decision boundaries</p> <p><strong>Disadvantages</strong>: - L Not positive semi-definite (violates Mercer's condition) - L Can be unstable - L Often outperformed by RBF - L Limited practical use</p> <p><strong>Selection guidelines</strong>: 1. Start with RBF (default choice) 2. Try linear if high-dimensional 3. Use polynomial for specific domain knowledge 4. Avoid sigmoid unless specific need</p> </details> <details class=question> <summary>How do you handle imbalanced datasets with SVM?</summary> <p><strong>Answer:</strong> Several strategies for handling class imbalance in SVM:</p> <p><strong>1. Class weight balancing</strong>: <div class=highlight><pre><span></span><code><span class=c1># Automatic balancing</span>
<span class=n>SVC</span><span class=p>(</span><span class=n>class_weight</span><span class=o>=</span><span class=s1>&#39;balanced&#39;</span><span class=p>)</span>

<span class=c1># Manual weights</span>
<span class=n>SVC</span><span class=p>(</span><span class=n>class_weight</span><span class=o>=</span><span class=p>{</span><span class=mi>0</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>:</span> <span class=mi>10</span><span class=p>})</span>  <span class=c1># 10x weight for minority class</span>

<span class=c1># Effect: Increases penalty for misclassifying minority class</span>
</code></pre></div></p> <p><strong>2. Resampling techniques</strong>: <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>imblearn.over_sampling</span><span class=w> </span><span class=kn>import</span> <span class=n>SMOTE</span>
<span class=kn>from</span><span class=w> </span><span class=nn>imblearn.under_sampling</span><span class=w> </span><span class=kn>import</span> <span class=n>RandomUnderSampler</span>

<span class=c1># Oversample minority class</span>
<span class=n>smote</span> <span class=o>=</span> <span class=n>SMOTE</span><span class=p>()</span>
<span class=n>X_balanced</span><span class=p>,</span> <span class=n>y_balanced</span> <span class=o>=</span> <span class=n>smote</span><span class=o>.</span><span class=n>fit_resample</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>

<span class=c1># Undersample majority class  </span>
<span class=n>undersampler</span> <span class=o>=</span> <span class=n>RandomUnderSampler</span><span class=p>()</span>
<span class=n>X_balanced</span><span class=p>,</span> <span class=n>y_balanced</span> <span class=o>=</span> <span class=n>undersampler</span><span class=o>.</span><span class=n>fit_resample</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</code></pre></div></p> <p><strong>3. Threshold adjustment</strong>: <div class=highlight><pre><span></span><code><span class=c1># Use decision function for custom thresholds</span>
<span class=n>scores</span> <span class=o>=</span> <span class=n>svm</span><span class=o>.</span><span class=n>decision_function</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
<span class=c1># Instead of scores &gt; 0, use scores &gt; custom_threshold</span>
<span class=n>predictions</span> <span class=o>=</span> <span class=p>(</span><span class=n>scores</span> <span class=o>&gt;</span> <span class=n>optimal_threshold</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</code></pre></div></p> <p><strong>4. Cost-sensitive learning</strong>: - Modify C parameter per class - Different misclassification costs <div class=highlight><pre><span></span><code><span class=c1># Higher C for minority class</span>
<span class=n>SVC</span><span class=p>(</span><span class=n>C</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>class_weight</span><span class=o>=</span><span class=p>{</span><span class=mi>0</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>:</span> <span class=mi>5</span><span class=p>})</span>
</code></pre></div></p> <p><strong>5. Evaluation metrics</strong>: <div class=highlight><pre><span></span><code><span class=c1># Don&#39;t use accuracy for imbalanced data</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>precision_recall_fscore_support</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>roc_auc_score</span>

<span class=c1># Use precision, recall, F1-score, AUC</span>
<span class=n>precision</span><span class=p>,</span> <span class=n>recall</span><span class=p>,</span> <span class=n>f1</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>precision_recall_fscore_support</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
<span class=n>auc</span> <span class=o>=</span> <span class=n>roc_auc_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>decision_scores</span><span class=p>)</span>
</code></pre></div></p> <p><strong>Best practices</strong>: - Combine multiple techniques - Use stratified cross-validation - Focus on minority class performance - Consider ensemble methods as alternative</p> </details> <details class=question> <summary>Explain the computational complexity of SVM training and prediction.</summary> <p><strong>Answer:</strong> Detailed complexity analysis:</p> <p><strong>Training Complexity</strong>:</p> <p><strong>SMO Algorithm</strong> (most common): - <strong>Time</strong>: O(nÔøΩ) to O(nÔøΩ) depending on data - <strong>Average case</strong>: O(nÔøΩÔøΩÔøΩ) for most datasets - <strong>Worst case</strong>: O(nÔøΩ) for very difficult datasets - <strong>Space</strong>: O(nÔøΩ) for kernel matrix storage</p> <p><strong>Factors affecting training time</strong>: <div class=highlight><pre><span></span><code><span class=c1># Dataset size (most important)</span>
<span class=n>n_samples</span> <span class=o>=</span> <span class=mi>1000</span>    <span class=c1># Fast</span>
<span class=n>n_samples</span> <span class=o>=</span> <span class=mi>100000</span>  <span class=c1># Very slow</span>

<span class=c1># Kernel complexity</span>
<span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;linear&#39;</span>     <span class=c1># Fastest</span>
<span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span>        <span class=c1># Medium  </span>
<span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;poly&#39;</span>       <span class=c1># Slower</span>

<span class=c1># Hyperparameters</span>
<span class=n>C</span><span class=o>=</span><span class=mf>0.1</span>              <span class=c1># Faster (more violations allowed)</span>
<span class=n>C</span><span class=o>=</span><span class=mi>1000</span>             <span class=c1># Slower (strict constraints)</span>
</code></pre></div></p> <p><strong>Prediction Complexity</strong>: - <strong>Time</strong>: O(n_support_vectors ÔøΩ n_features) - <strong>Typical</strong>: Much faster than training - <strong>Linear kernel</strong>: O(n_features) - very fast - <strong>Non-linear</strong>: O(n_sv ÔøΩ n_features) - depends on support vectors</p> <p><strong>Memory Requirements</strong>: <div class=highlight><pre><span></span><code><span class=c1># Kernel matrix: n ÔøΩ n ÔøΩ 8 bytes (for RBF/poly)</span>
<span class=n>memory_gb</span> <span class=o>=</span> <span class=p>(</span><span class=n>n_samples</span> <span class=o>**</span> <span class=mi>2</span> <span class=o>*</span> <span class=mi>8</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1024</span><span class=o>**</span><span class=mi>3</span><span class=p>)</span>

<span class=c1># For 10,000 samples: ~0.75 GB</span>
<span class=c1># For 100,000 samples: ~75 GB (impractical)</span>
</code></pre></div></p> <p><strong>Scalability solutions</strong>: 1. <strong>Linear SVM</strong>: Use for n &gt; 10,000 2. <strong>Sampling</strong>: Train on subset of data 3. <strong>Online SVM</strong>: Incremental learning algorithms 4. <strong>Approximate methods</strong>: NystrÔøΩm approximation 5. <strong>Alternative algorithms</strong>: Random Forest, XGBoost for large data</p> <p><strong>Practical guidelines</strong>: - n &lt; 1,000: Any kernel works - 1,000 &lt; n &lt; 10,000: RBF with tuning - n &gt; 10,000: Consider linear SVM or alternatives - n &gt; 100,000: Use other algorithms</p> </details> <details class=question> <summary>How do you interpret and visualize SVM results?</summary> <p><strong>Answer:</strong> Multiple approaches for SVM interpretation:</p> <p><strong>1. Decision boundaries (2D visualization)</strong>: <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>plot_svm_boundary</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>model</span><span class=p>):</span>
    <span class=c1># Create mesh</span>
    <span class=n>h</span> <span class=o>=</span> <span class=mf>0.01</span>
    <span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span> <span class=o>=</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
    <span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span> <span class=o>=</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>+</span> <span class=mi>1</span>
    <span class=n>xx</span><span class=p>,</span> <span class=n>yy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>x_min</span><span class=p>,</span> <span class=n>x_max</span><span class=p>,</span> <span class=n>h</span><span class=p>),</span>
                        <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>y_min</span><span class=p>,</span> <span class=n>y_max</span><span class=p>,</span> <span class=n>h</span><span class=p>))</span>

    <span class=c1># Predict on mesh</span>
    <span class=n>Z</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>c_</span><span class=p>[</span><span class=n>xx</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span> <span class=n>yy</span><span class=o>.</span><span class=n>ravel</span><span class=p>()])</span>
    <span class=n>Z</span> <span class=o>=</span> <span class=n>Z</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>xx</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>

    <span class=c1># Plot boundary and margins</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>contourf</span><span class=p>(</span><span class=n>xx</span><span class=p>,</span> <span class=n>yy</span><span class=p>,</span> <span class=n>Z</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>X</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>c</span><span class=o>=</span><span class=n>y</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;viridis&#39;</span><span class=p>)</span>

    <span class=c1># Highlight support vectors</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_vectors_</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> 
               <span class=n>model</span><span class=o>.</span><span class=n>support_vectors_</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>],</span>
               <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>facecolors</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>,</span> <span class=n>edgecolors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>
</code></pre></div></p> <p><strong>2. Support vector analysis</strong>: <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of support vectors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Support vector ratio: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>X_train</span><span class=p>)</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Support vectors per class: </span><span class=si>{</span><span class=n>model</span><span class=o>.</span><span class=n>n_support_</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># High ratio might indicate:</span>
<span class=c1># - Complex decision boundary</span>
<span class=c1># - Noisy data  </span>
<span class=c1># - Need for different kernel/parameters</span>
</code></pre></div></p> <p><strong>3. Feature importance (linear kernel only)</strong>: <div class=highlight><pre><span></span><code><span class=k>if</span> <span class=n>model</span><span class=o>.</span><span class=n>kernel</span> <span class=o>==</span> <span class=s1>&#39;linear&#39;</span><span class=p>:</span>
    <span class=c1># Coefficients indicate feature importance</span>
    <span class=n>feature_importance</span> <span class=o>=</span> <span class=nb>abs</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>coef_</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>barh</span><span class=p>(</span><span class=n>feature_names</span><span class=p>,</span> <span class=n>feature_importance</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Linear SVM Feature Importance&#39;</span><span class=p>)</span>
</code></pre></div></p> <p><strong>4. Decision function analysis</strong>: <div class=highlight><pre><span></span><code><span class=c1># Distance from hyperplane</span>
<span class=n>decision_scores</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>decision_function</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>

<span class=c1># Confidence interpretation</span>
<span class=c1># |score| &gt; 1: High confidence</span>
<span class=c1># |score| &lt; 1: Low confidence (near boundary)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>decision_scores</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Decision boundary&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;orange&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Margin&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;orange&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
</code></pre></div></p> <p><strong>5. Hyperparameter sensitivity analysis</strong>: <div class=highlight><pre><span></span><code><span class=c1># Plot performance vs hyperparameters</span>
<span class=n>C_values</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>]</span>
<span class=n>scores</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>C</span> <span class=ow>in</span> <span class=n>C_values</span><span class=p>:</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>(</span><span class=n>C</span><span class=o>=</span><span class=n>C</span><span class=p>,</span> <span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>)</span>
    <span class=n>score</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
    <span class=n>scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>score</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>C_values</span><span class=p>,</span> <span class=n>scores</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;C (log scale)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xscale</span><span class=p>(</span><span class=s1>&#39;log&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Cross-validation accuracy&#39;</span><span class=p>)</span>
</code></pre></div></p> <p><strong>6. Error analysis</strong>: <div class=highlight><pre><span></span><code><span class=c1># Analyze misclassified points</span>
<span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
<span class=n>misclassified</span> <span class=o>=</span> <span class=n>X_test</span><span class=p>[</span><span class=n>y_test</span> <span class=o>!=</span> <span class=n>y_pred</span><span class=p>]</span>

<span class=c1># Are they near the decision boundary?</span>
<span class=n>decision_scores_errors</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>decision_function</span><span class=p>(</span><span class=n>misclassified</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Average distance from boundary: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=nb>abs</span><span class=p>(</span><span class=n>decision_scores_errors</span><span class=p>))</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div></p> </details> <h2 id=examples>&gt;ÔøΩ Examples</h2> <h3 id=real-world-example-text-classification>Real-world Example: Text Classification</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>fetch_20newsgroups</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.feature_extraction.text</span><span class=w> </span><span class=kn>import</span> <span class=n>TfidfVectorizer</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVC</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span><span class=p>,</span> <span class=n>cross_val_score</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>classification_report</span><span class=p>,</span> <span class=n>confusion_matrix</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.pipeline</span><span class=w> </span><span class=kn>import</span> <span class=n>Pipeline</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>import</span><span class=w> </span><span class=nn>seaborn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>sns</span>

<span class=c1># Load text dataset (subset of 20 newsgroups)</span>
<span class=n>categories</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;alt.atheism&#39;</span><span class=p>,</span> <span class=s1>&#39;soc.religion.christian&#39;</span><span class=p>,</span> <span class=s1>&#39;comp.graphics&#39;</span><span class=p>,</span> <span class=s1>&#39;sci.med&#39;</span><span class=p>]</span>
<span class=n>newsgroups</span> <span class=o>=</span> <span class=n>fetch_20newsgroups</span><span class=p>(</span>
    <span class=n>subset</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>,</span>
    <span class=n>categories</span><span class=o>=</span><span class=n>categories</span><span class=p>,</span> 
    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
    <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
    <span class=n>remove</span><span class=o>=</span><span class=p>(</span><span class=s1>&#39;headers&#39;</span><span class=p>,</span> <span class=s1>&#39;footers&#39;</span><span class=p>,</span> <span class=s1>&#39;quotes&#39;</span><span class=p>)</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Text Classification with SVM&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Dataset shape: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>data</span><span class=p>)</span><span class=si>}</span><span class=s2> documents&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Categories: </span><span class=si>{</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Class distribution:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>name</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>):</span>
    <span class=n>count</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target</span> <span class=o>==</span> <span class=n>i</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>count</span><span class=si>}</span><span class=s2> documents&quot;</span><span class=p>)</span>

<span class=c1># Split data</span>
<span class=n>X_text</span><span class=p>,</span> <span class=n>X_test_text</span><span class=p>,</span> <span class=n>y_text</span><span class=p>,</span> <span class=n>y_test_text</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
    <span class=n>newsgroups</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=n>newsgroups</span><span class=o>.</span><span class=n>target</span><span class=p>,</span> 
    <span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target</span>
<span class=p>)</span>

<span class=c1># Create pipeline with TF-IDF and SVM</span>
<span class=n>text_pipeline</span> <span class=o>=</span> <span class=n>Pipeline</span><span class=p>([</span>
    <span class=p>(</span><span class=s1>&#39;tfidf&#39;</span><span class=p>,</span> <span class=n>TfidfVectorizer</span><span class=p>(</span>
        <span class=n>max_features</span><span class=o>=</span><span class=mi>10000</span><span class=p>,</span>      <span class=c1># Limit vocabulary</span>
        <span class=n>min_df</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>                <span class=c1># Ignore rare words  </span>
        <span class=n>max_df</span><span class=o>=</span><span class=mf>0.95</span><span class=p>,</span>             <span class=c1># Ignore too common words</span>
        <span class=n>stop_words</span><span class=o>=</span><span class=s1>&#39;english&#39;</span><span class=p>,</span>     <span class=c1># Remove stop words</span>
        <span class=n>ngram_range</span><span class=o>=</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>       <span class=c1># Use unigrams and bigrams</span>
    <span class=p>)),</span>
    <span class=p>(</span><span class=s1>&#39;svm&#39;</span><span class=p>,</span> <span class=n>SVC</span><span class=p>(</span>
        <span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;linear&#39;</span><span class=p>,</span>         <span class=c1># Linear works well for text</span>
        <span class=n>C</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
        <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
    <span class=p>))</span>
<span class=p>])</span>

<span class=c1># Train model</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Training SVM text classifier...&quot;</span><span class=p>)</span>
<span class=n>text_pipeline</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_text</span><span class=p>,</span> <span class=n>y_text</span><span class=p>)</span>

<span class=c1># Predictions</span>
<span class=n>y_pred_text</span> <span class=o>=</span> <span class=n>text_pipeline</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_text</span><span class=p>)</span>

<span class=c1># Evaluate</span>
<span class=n>accuracy_text</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>y_pred_text</span> <span class=o>==</span> <span class=n>y_test_text</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test accuracy: </span><span class=si>{</span><span class=n>accuracy_text</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Detailed classification report</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Classification Report:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>classification_report</span><span class=p>(</span><span class=n>y_test_text</span><span class=p>,</span> <span class=n>y_pred_text</span><span class=p>,</span> 
                          <span class=n>target_names</span><span class=o>=</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>))</span>

<span class=c1># Confusion matrix</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>cm_text</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_test_text</span><span class=p>,</span> <span class=n>y_pred_text</span><span class=p>)</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>cm_text</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;d&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>,</span>
            <span class=n>xticklabels</span><span class=o>=</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>,</span>
            <span class=n>yticklabels</span><span class=o>=</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Text Classification - Confusion Matrix&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Category&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted Category&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>rotation</span><span class=o>=</span><span class=mi>45</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>(</span><span class=n>rotation</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Feature importance analysis (most important words)</span>
<span class=n>feature_names</span> <span class=o>=</span> <span class=n>text_pipeline</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;tfidf&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>()</span>
<span class=n>svm_model</span> <span class=o>=</span> <span class=n>text_pipeline</span><span class=o>.</span><span class=n>named_steps</span><span class=p>[</span><span class=s1>&#39;svm&#39;</span><span class=p>]</span>

<span class=c1># For each class, show most important features</span>
<span class=n>n_features</span> <span class=o>=</span> <span class=mi>10</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>category</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>):</span>
    <span class=k>if</span> <span class=nb>hasattr</span><span class=p>(</span><span class=n>svm_model</span><span class=p>,</span> <span class=s1>&#39;coef_&#39;</span><span class=p>):</span>
        <span class=c1># Get coefficients for this class (one-vs-rest)</span>
        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>svm_model</span><span class=o>.</span><span class=n>classes_</span><span class=p>)</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>
            <span class=n>coef</span> <span class=o>=</span> <span class=n>svm_model</span><span class=o>.</span><span class=n>coef_</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=mi>1</span> <span class=k>else</span> <span class=o>-</span><span class=n>svm_model</span><span class=o>.</span><span class=n>coef_</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>coef</span> <span class=o>=</span> <span class=n>svm_model</span><span class=o>.</span><span class=n>coef_</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>

        <span class=c1># Get top features</span>
        <span class=n>top_positive_indices</span> <span class=o>=</span> <span class=n>coef</span><span class=o>.</span><span class=n>argsort</span><span class=p>()[</span><span class=o>-</span><span class=n>n_features</span><span class=p>:][::</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
        <span class=n>top_negative_indices</span> <span class=o>=</span> <span class=n>coef</span><span class=o>.</span><span class=n>argsort</span><span class=p>()[:</span><span class=n>n_features</span><span class=p>]</span>

        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Most important features for &#39;</span><span class=si>{</span><span class=n>category</span><span class=si>}</span><span class=s2>&#39;:&quot;</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Positive indicators:&quot;</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>top_positive_indices</span><span class=p>:</span>
            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>feature_names</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>coef</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Negative indicators:&quot;</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>top_negative_indices</span><span class=p>:</span>
            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>feature_names</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>coef</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Cross-validation performance</span>
<span class=n>cv_scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>text_pipeline</span><span class=p>,</span> <span class=n>X_text</span><span class=p>,</span> <span class=n>y_text</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Cross-validation scores: </span><span class=si>{</span><span class=n>cv_scores</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean CV accuracy: </span><span class=si>{</span><span class=n>cv_scores</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> (+/- </span><span class=si>{</span><span class=n>cv_scores</span><span class=o>.</span><span class=n>std</span><span class=p>()</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>2</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>

<span class=c1># Example predictions with confidence</span>
<span class=n>sample_texts</span> <span class=o>=</span> <span class=p>[</span>
    <span class=s2>&quot;I believe in God and Jesus Christ&quot;</span><span class=p>,</span>
    <span class=s2>&quot;The graphics card is not working properly&quot;</span><span class=p>,</span>
    <span class=s2>&quot;This medical treatment showed promising results&quot;</span><span class=p>,</span>
    <span class=s2>&quot;There is no scientific evidence for the existence of God&quot;</span>
<span class=p>]</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Example Predictions:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>text</span> <span class=ow>in</span> <span class=n>sample_texts</span><span class=p>:</span>
    <span class=n>prediction</span> <span class=o>=</span> <span class=n>text_pipeline</span><span class=o>.</span><span class=n>predict</span><span class=p>([</span><span class=n>text</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
    <span class=n>decision_score</span> <span class=o>=</span> <span class=n>text_pipeline</span><span class=o>.</span><span class=n>decision_function</span><span class=p>([</span><span class=n>text</span><span class=p>])</span>
    <span class=n>predicted_category</span> <span class=o>=</span> <span class=n>newsgroups</span><span class=o>.</span><span class=n>target_names</span><span class=p>[</span><span class=n>prediction</span><span class=p>]</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Text: &#39;</span><span class=si>{</span><span class=n>text</span><span class=p>[:</span><span class=mi>50</span><span class=p>]</span><span class=si>}</span><span class=s2>...&#39;&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Predicted: </span><span class=si>{</span><span class=n>predicted_category</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Decision scores: </span><span class=si>{</span><span class=n>decision_score</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <h3 id=image-classification-example>Image Classification Example</h3> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>fetch_olivetti_faces</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.decomposition</span><span class=w> </span><span class=kn>import</span> <span class=n>PCA</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVC</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>accuracy_score</span><span class=p>,</span> <span class=n>classification_report</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Load face recognition dataset</span>
<span class=n>faces</span> <span class=o>=</span> <span class=n>fetch_olivetti_faces</span><span class=p>(</span><span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
<span class=n>X_faces</span> <span class=o>=</span> <span class=n>faces</span><span class=o>.</span><span class=n>data</span>
<span class=n>y_faces</span> <span class=o>=</span> <span class=n>faces</span><span class=o>.</span><span class=n>target</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Face Recognition with SVM&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Dataset shape: </span><span class=si>{</span><span class=n>X_faces</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of people: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>y_faces</span><span class=p>))</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Image dimensions: 64x64 pixels&quot;</span><span class=p>)</span>

<span class=c1># Visualize some sample faces</span>
<span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>ax</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>axes</span><span class=o>.</span><span class=n>flat</span><span class=p>):</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>X_faces</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>)</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Person </span><span class=si>{</span><span class=n>y_faces</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
    <span class=n>ax</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=s1>&#39;Sample Face Images&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Split data</span>
<span class=n>X_train_faces</span><span class=p>,</span> <span class=n>X_test_faces</span><span class=p>,</span> <span class=n>y_train_faces</span><span class=p>,</span> <span class=n>y_test_faces</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
    <span class=n>X_faces</span><span class=p>,</span> <span class=n>y_faces</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.25</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span> <span class=n>stratify</span><span class=o>=</span><span class=n>y_faces</span>
<span class=p>)</span>

<span class=c1># Apply PCA for dimensionality reduction (faces are high-dimensional)</span>
<span class=n>n_components</span> <span class=o>=</span> <span class=mi>150</span>  <span class=c1># Reduce from 4096 to 150 dimensions</span>
<span class=n>pca_faces</span> <span class=o>=</span> <span class=n>PCA</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=n>n_components</span><span class=p>,</span> <span class=n>whiten</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
<span class=n>X_train_pca</span> <span class=o>=</span> <span class=n>pca_faces</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train_faces</span><span class=p>)</span>
<span class=n>X_test_pca</span> <span class=o>=</span> <span class=n>pca_faces</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test_faces</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Dimensionality reduction:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Original dimensions: </span><span class=si>{</span><span class=n>X_train_faces</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Reduced dimensions: </span><span class=si>{</span><span class=n>X_train_pca</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Variance explained: </span><span class=si>{</span><span class=n>pca_faces</span><span class=o>.</span><span class=n>explained_variance_ratio_</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Train SVM classifier</span>
<span class=n>svm_faces</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.005</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
<span class=n>svm_faces</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_pca</span><span class=p>,</span> <span class=n>y_train_faces</span><span class=p>)</span>

<span class=c1># Predictions</span>
<span class=n>y_pred_faces</span> <span class=o>=</span> <span class=n>svm_faces</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_pca</span><span class=p>)</span>

<span class=c1># Evaluate</span>
<span class=n>accuracy_faces</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test_faces</span><span class=p>,</span> <span class=n>y_pred_faces</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Face Recognition Results:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Accuracy: </span><span class=si>{</span><span class=n>accuracy_faces</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of support vectors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>svm_faces</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Support vector ratio: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>svm_faces</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>X_train_pca</span><span class=p>)</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize some predictions</span>
<span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>9</span><span class=p>))</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>ax</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>axes</span><span class=o>.</span><span class=n>flat</span><span class=p>):</span>
    <span class=k>if</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>X_test_faces</span><span class=p>):</span>
        <span class=c1># Show original image</span>
        <span class=n>ax</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>X_test_faces</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>)</span>

        <span class=c1># Get prediction and confidence</span>
        <span class=n>true_label</span> <span class=o>=</span> <span class=n>y_test_faces</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> 
        <span class=n>pred_label</span> <span class=o>=</span> <span class=n>y_pred_faces</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
        <span class=n>decision_score</span> <span class=o>=</span> <span class=n>svm_faces</span><span class=o>.</span><span class=n>decision_function</span><span class=p>([</span><span class=n>X_test_pca</span><span class=p>[</span><span class=n>i</span><span class=p>]])</span>
        <span class=n>confidence</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>decision_score</span><span class=p>)</span>

        <span class=c1># Color border based on correctness</span>
        <span class=n>color</span> <span class=o>=</span> <span class=s1>&#39;green&#39;</span> <span class=k>if</span> <span class=n>true_label</span> <span class=o>==</span> <span class=n>pred_label</span> <span class=k>else</span> <span class=s1>&#39;red&#39;</span>
        <span class=n>ax</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;True: </span><span class=si>{</span><span class=n>true_label</span><span class=si>}</span><span class=s1>, Pred: </span><span class=si>{</span><span class=n>pred_label</span><span class=si>}</span><span class=se>\n</span><span class=s1>Conf: </span><span class=si>{</span><span class=n>confidence</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> 
                    <span class=n>color</span><span class=o>=</span><span class=n>color</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
        <span class=n>ax</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>

        <span class=c1># Add border</span>
        <span class=k>for</span> <span class=n>spine</span> <span class=ow>in</span> <span class=n>ax</span><span class=o>.</span><span class=n>spines</span><span class=o>.</span><span class=n>values</span><span class=p>():</span>
            <span class=n>spine</span><span class=o>.</span><span class=n>set_color</span><span class=p>(</span><span class=n>color</span><span class=p>)</span>
            <span class=n>spine</span><span class=o>.</span><span class=n>set_linewidth</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>ax</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=s1>&#39;Face Recognition Predictions (Green=Correct, Red=Incorrect)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Analyze errors</span>
<span class=n>incorrect_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>y_test_faces</span> <span class=o>!=</span> <span class=n>y_pred_faces</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Error Analysis:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total errors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>incorrect_indices</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>incorrect_indices</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
    <span class=c1># Show decision scores for incorrect predictions</span>
    <span class=n>incorrect_scores</span> <span class=o>=</span> <span class=n>svm_faces</span><span class=o>.</span><span class=n>decision_function</span><span class=p>(</span><span class=n>X_test_pca</span><span class=p>[</span><span class=n>incorrect_indices</span><span class=p>])</span>
    <span class=n>avg_incorrect_confidence</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>incorrect_scores</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>

    <span class=n>correct_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>y_test_faces</span> <span class=o>==</span> <span class=n>y_pred_faces</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
    <span class=n>correct_scores</span> <span class=o>=</span> <span class=n>svm_faces</span><span class=o>.</span><span class=n>decision_function</span><span class=p>(</span><span class=n>X_test_pca</span><span class=p>[</span><span class=n>correct_indices</span><span class=p>])</span>
    <span class=n>avg_correct_confidence</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>correct_scores</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Average confidence for correct predictions: </span><span class=si>{</span><span class=n>avg_correct_confidence</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Average confidence for incorrect predictions: </span><span class=si>{</span><span class=n>avg_incorrect_confidence</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># Plot confidence distribution</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>correct_scores</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>bins</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> 
             <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Correct predictions&#39;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;green&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>incorrect_scores</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>bins</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> 
             <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Incorrect predictions&#39;</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Maximum Decision Score (Confidence)&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Frequency&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Confidence Distribution: Correct vs Incorrect Predictions&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Hyperparameter sensitivity analysis</span>
<span class=n>C_values</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>]</span>
<span class=n>gamma_values</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.005</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>]</span>

<span class=n>results_grid</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=nb>len</span><span class=p>(</span><span class=n>C_values</span><span class=p>),</span> <span class=nb>len</span><span class=p>(</span><span class=n>gamma_values</span><span class=p>)))</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Hyperparameter sensitivity analysis:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>C</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>C_values</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>j</span><span class=p>,</span> <span class=n>gamma</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>gamma_values</span><span class=p>):</span>
        <span class=n>svm_temp</span> <span class=o>=</span> <span class=n>SVC</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=n>C</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=n>gamma</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
        <span class=n>svm_temp</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_pca</span><span class=p>,</span> <span class=n>y_train_faces</span><span class=p>)</span>
        <span class=n>score</span> <span class=o>=</span> <span class=n>svm_temp</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_pca</span><span class=p>,</span> <span class=n>y_test_faces</span><span class=p>)</span>
        <span class=n>results_grid</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>score</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;C=</span><span class=si>{</span><span class=n>C</span><span class=si>:</span><span class=s2>4</span><span class=si>}</span><span class=s2>, gamma=</span><span class=si>{</span><span class=n>gamma</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize hyperparameter effects</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>results_grid</span><span class=p>,</span> 
           <span class=n>xticklabels</span><span class=o>=</span><span class=p>[</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>g</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>&#39;</span> <span class=k>for</span> <span class=n>g</span> <span class=ow>in</span> <span class=n>gamma_values</span><span class=p>],</span>
           <span class=n>yticklabels</span><span class=o>=</span><span class=n>C_values</span><span class=p>,</span>
           <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>fmt</span><span class=o>=</span><span class=s1>&#39;.3f&#39;</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;viridis&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Face Recognition Accuracy: C vs Gamma&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Gamma&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;C&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <h3 id=regression-example-with-support-vector-regression-svr>Regression Example with Support Vector Regression (SVR)</h3> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.svm</span><span class=w> </span><span class=kn>import</span> <span class=n>SVR</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>make_regression</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>mean_squared_error</span><span class=p>,</span> <span class=n>r2_score</span><span class=p>,</span> <span class=n>mean_absolute_error</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Generate synthetic regression dataset with noise</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
<span class=n>X_reg</span><span class=p>,</span> <span class=n>y_reg</span> <span class=o>=</span> <span class=n>make_regression</span><span class=p>(</span>
    <span class=n>n_samples</span><span class=o>=</span><span class=mi>300</span><span class=p>,</span> 
    <span class=n>n_features</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> 
    <span class=n>noise</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
    <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
<span class=p>)</span>

<span class=c1># Add some outliers</span>
<span class=n>outlier_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>X_reg</span><span class=p>),</span> <span class=n>size</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span> <span class=n>replace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=n>y_reg</span><span class=p>[</span><span class=n>outlier_indices</span><span class=p>]</span> <span class=o>+=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>

<span class=c1># Sort for plotting</span>
<span class=n>sort_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>X_reg</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>])</span>
<span class=n>X_reg_sorted</span> <span class=o>=</span> <span class=n>X_reg</span><span class=p>[</span><span class=n>sort_indices</span><span class=p>]</span>
<span class=n>y_reg_sorted</span> <span class=o>=</span> <span class=n>y_reg</span><span class=p>[</span><span class=n>sort_indices</span><span class=p>]</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Support Vector Regression Example&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Dataset shape: </span><span class=si>{</span><span class=n>X_reg</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Target range: [</span><span class=si>{</span><span class=n>y_reg</span><span class=o>.</span><span class=n>min</span><span class=p>()</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>y_reg</span><span class=o>.</span><span class=n>max</span><span class=p>()</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>]&quot;</span><span class=p>)</span>

<span class=c1># Split data</span>
<span class=n>X_train_reg</span><span class=p>,</span> <span class=n>X_test_reg</span><span class=p>,</span> <span class=n>y_train_reg</span><span class=p>,</span> <span class=n>y_test_reg</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>(</span>
    <span class=n>X_reg</span><span class=p>,</span> <span class=n>y_reg</span><span class=p>,</span> <span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span>
<span class=p>)</span>

<span class=c1># Standardize features</span>
<span class=n>scaler_svr</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>
<span class=n>X_train_reg_scaled</span> <span class=o>=</span> <span class=n>scaler_svr</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X_train_reg</span><span class=p>)</span>
<span class=n>X_test_reg_scaled</span> <span class=o>=</span> <span class=n>scaler_svr</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_test_reg</span><span class=p>)</span>

<span class=c1># Train different SVR models</span>
<span class=n>svr_models</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;Linear SVR&#39;</span><span class=p>:</span> <span class=n>SVR</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;linear&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=mf>0.1</span><span class=p>),</span>
    <span class=s1>&#39;RBF SVR&#39;</span><span class=p>:</span> <span class=n>SVR</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>&#39;scale&#39;</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=mf>0.1</span><span class=p>),</span>
    <span class=s1>&#39;Polynomial SVR&#39;</span><span class=p>:</span> <span class=n>SVR</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;poly&#39;</span><span class=p>,</span> <span class=n>degree</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
<span class=p>}</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>

<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>name</span><span class=p>,</span> <span class=n>model</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>svr_models</span><span class=o>.</span><span class=n>items</span><span class=p>()):</span>
    <span class=c1># Train model</span>
    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_reg_scaled</span><span class=p>,</span> <span class=n>y_train_reg</span><span class=p>)</span>

    <span class=c1># Predictions</span>
    <span class=n>y_pred_train</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_train_reg_scaled</span><span class=p>)</span>
    <span class=n>y_pred_test</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>)</span>

    <span class=c1># Evaluate</span>
    <span class=n>train_r2</span> <span class=o>=</span> <span class=n>r2_score</span><span class=p>(</span><span class=n>y_train_reg</span><span class=p>,</span> <span class=n>y_pred_train</span><span class=p>)</span>
    <span class=n>test_r2</span> <span class=o>=</span> <span class=n>r2_score</span><span class=p>(</span><span class=n>y_test_reg</span><span class=p>,</span> <span class=n>y_pred_test</span><span class=p>)</span>
    <span class=n>test_rmse</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_test_reg</span><span class=p>,</span> <span class=n>y_pred_test</span><span class=p>))</span>
    <span class=n>test_mae</span> <span class=o>=</span> <span class=n>mean_absolute_error</span><span class=p>(</span><span class=n>y_test_reg</span><span class=p>,</span> <span class=n>y_pred_test</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2> Results:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Train RÔøΩ: </span><span class=si>{</span><span class=n>train_r2</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test RÔøΩ: </span><span class=si>{</span><span class=n>test_r2</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test RMSE: </span><span class=si>{</span><span class=n>test_rmse</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test MAE: </span><span class=si>{</span><span class=n>test_mae</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Support vectors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>X_train_reg_scaled</span><span class=p>)</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%)&quot;</span><span class=p>)</span>

    <span class=c1># Plot results</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>

    <span class=c1># Create smooth line for predictions</span>
    <span class=n>X_plot</span> <span class=o>=</span> <span class=n>scaler_svr</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>X_reg_sorted</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
    <span class=n>y_plot</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_plot</span><span class=p>)</span>

    <span class=c1># Plot data points</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_train_reg_scaled</span><span class=p>,</span> <span class=n>y_train_reg</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>,</span> 
                <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Training data&#39;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>,</span> <span class=n>y_test_reg</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> 
                <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Test data&#39;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>

    <span class=c1># Plot prediction line</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>X_plot</span><span class=p>,</span> <span class=n>y_plot</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;green&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;SVR prediction&#39;</span><span class=p>)</span>

    <span class=c1># Highlight support vectors</span>
    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
        <span class=n>support_X</span> <span class=o>=</span> <span class=n>X_train_reg_scaled</span><span class=p>[</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>]</span>
        <span class=n>support_y</span> <span class=o>=</span> <span class=n>y_train_reg</span><span class=p>[</span><span class=n>model</span><span class=o>.</span><span class=n>support_</span><span class=p>]</span>
        <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>support_X</span><span class=p>,</span> <span class=n>support_y</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>facecolors</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>,</span> 
                   <span class=n>edgecolors</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Support vectors&#39;</span><span class=p>)</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Feature (standardized)&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Target&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=se>\n</span><span class=s1>RÔøΩ = </span><span class=si>{</span><span class=n>test_r2</span><span class=si>:</span><span class=s1>.3f</span><span class=si>}</span><span class=s1>, RMSE = </span><span class=si>{</span><span class=n>test_rmse</span><span class=si>:</span><span class=s1>.1f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Plot residuals analysis</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
<span class=n>best_model</span> <span class=o>=</span> <span class=n>svr_models</span><span class=p>[</span><span class=s1>&#39;RBF SVR&#39;</span><span class=p>]</span>  <span class=c1># Use RBF as best model</span>
<span class=n>y_pred_best</span> <span class=o>=</span> <span class=n>best_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>)</span>
<span class=n>residuals</span> <span class=o>=</span> <span class=n>y_test_reg</span> <span class=o>-</span> <span class=n>y_pred_best</span>

<span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>y_pred_best</span><span class=p>,</span> <span class=n>residuals</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted Values&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Residuals&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Residual Plot (RBF SVR)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Plot actual vs predicted</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>y_test_reg</span><span class=p>,</span> <span class=n>y_pred_best</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=n>y_test_reg</span><span class=o>.</span><span class=n>min</span><span class=p>(),</span> <span class=n>y_test_reg</span><span class=o>.</span><span class=n>max</span><span class=p>()],</span> 
         <span class=p>[</span><span class=n>y_test_reg</span><span class=o>.</span><span class=n>min</span><span class=p>(),</span> <span class=n>y_test_reg</span><span class=o>.</span><span class=n>max</span><span class=p>()],</span> <span class=s1>&#39;r--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Actual Values&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Predicted Values&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Actual vs Predicted (RBF SVR)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Plot epsilon-tube visualization</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>6</span><span class=p>)</span>
<span class=n>epsilon</span> <span class=o>=</span> <span class=n>best_model</span><span class=o>.</span><span class=n>epsilon</span>

<span class=c1># Sort data for smooth plotting</span>
<span class=n>sort_idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>])</span>
<span class=n>X_sorted</span> <span class=o>=</span> <span class=n>X_test_reg_scaled</span><span class=p>[</span><span class=n>sort_idx</span><span class=p>]</span>
<span class=n>y_pred_sorted</span> <span class=o>=</span> <span class=n>y_pred_best</span><span class=p>[</span><span class=n>sort_idx</span><span class=p>]</span>

<span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>,</span> <span class=n>y_test_reg</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>,</span> 
           <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Test data&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>X_sorted</span><span class=p>,</span> <span class=n>y_pred_sorted</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;green&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> 
         <span class=n>label</span><span class=o>=</span><span class=s1>&#39;SVR prediction&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>fill_between</span><span class=p>(</span><span class=n>X_sorted</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>y_pred_sorted</span> <span class=o>-</span> <span class=n>epsilon</span><span class=p>,</span> <span class=n>y_pred_sorted</span> <span class=o>+</span> <span class=n>epsilon</span><span class=p>,</span>
                <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;yellow&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;ÔøΩ-tube (ÔøΩ=</span><span class=si>{</span><span class=n>epsilon</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Feature (standardized)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Target&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;SVR with ÔøΩ-insensitive Loss&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Hyperparameter tuning for SVR</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>SVR Hyperparameter Analysis:&quot;</span><span class=p>)</span>

<span class=c1># Test different epsilon values</span>
<span class=n>epsilon_values</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>]</span>
<span class=n>C_values</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>]</span>

<span class=n>best_score</span> <span class=o>=</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>inf</span>
<span class=n>best_params</span> <span class=o>=</span> <span class=p>{}</span>

<span class=k>for</span> <span class=n>epsilon</span> <span class=ow>in</span> <span class=n>epsilon_values</span><span class=p>:</span>
    <span class=k>for</span> <span class=n>C</span> <span class=ow>in</span> <span class=n>C_values</span><span class=p>:</span>
        <span class=n>svr_temp</span> <span class=o>=</span> <span class=n>SVR</span><span class=p>(</span><span class=n>kernel</span><span class=o>=</span><span class=s1>&#39;rbf&#39;</span><span class=p>,</span> <span class=n>C</span><span class=o>=</span><span class=n>C</span><span class=p>,</span> <span class=n>epsilon</span><span class=o>=</span><span class=n>epsilon</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=s1>&#39;scale&#39;</span><span class=p>)</span>
        <span class=n>svr_temp</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train_reg_scaled</span><span class=p>,</span> <span class=n>y_train_reg</span><span class=p>)</span>
        <span class=n>score</span> <span class=o>=</span> <span class=n>svr_temp</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X_test_reg_scaled</span><span class=p>,</span> <span class=n>y_test_reg</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>score</span> <span class=o>&gt;</span> <span class=n>best_score</span><span class=p>:</span>
            <span class=n>best_score</span> <span class=o>=</span> <span class=n>score</span>
            <span class=n>best_params</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=n>C</span><span class=p>,</span> <span class=s1>&#39;epsilon&#39;</span><span class=p>:</span> <span class=n>epsilon</span><span class=p>}</span>

        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;C=</span><span class=si>{</span><span class=n>C</span><span class=si>:</span><span class=s2>4</span><span class=si>}</span><span class=s2>, ÔøΩ=</span><span class=si>{</span><span class=n>epsilon</span><span class=si>:</span><span class=s2>4.2f</span><span class=si>}</span><span class=s2>: RÔøΩ = </span><span class=si>{</span><span class=n>score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, &quot;</span>
              <span class=sa>f</span><span class=s2>&quot;Support vectors: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>svr_temp</span><span class=o>.</span><span class=n>support_</span><span class=p>)</span><span class=si>:</span><span class=s2>3d</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Best parameters: </span><span class=si>{</span><span class=n>best_params</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Best RÔøΩ score: </span><span class=si>{</span><span class=n>best_score</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <h2 id=references>üìö References</h2> <ul> <li><strong>Original Papers:</strong></li> <li><a href=https://link.springer.com/article/10.1007/BF00994018>Support-Vector Networks</a> by Cortes &amp; Vapnik (1995)</li> <li><a href=https://www.springer.com/gp/book/9780387987804>The Nature of Statistical Learning Theory</a> by Vladimir Vapnik (1995)</li> <li> <p><a href=https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/smo-book.pdf>SMO Algorithm</a> by John Platt (1998)</p> </li> <li> <p><strong>Books:</strong></p> </li> <li><a href=https://web.stanford.edu/~hastie/ElemStatLearn/ >The Elements of Statistical Learning</a> by Hastie, Tibshirani, and Friedman - Chapter 12</li> <li><a href=https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf>Pattern Recognition and Machine Learning</a> by Christopher Bishop - Chapter 7</li> <li> <p><a href=https://mitpress.mit.edu/books/learning-kernels>Learning with Kernels</a> by SchÔøΩlkopf and Smola</p> </li> <li> <p><strong>Documentation:</strong></p> </li> <li><a href=https://scikit-learn.org/stable/modules/svm.html>Scikit-learn SVM Guide</a></li> <li><a href=https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html>Scikit-learn SVC</a></li> <li> <p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html>Scikit-learn SVR</a></p> </li> <li> <p><strong>Tutorials and Guides:</strong></p> </li> <li><a href=http://cs229.stanford.edu/notes/cs229-notes3.pdf>SVM Tutorial - Andrew Ng</a></li> <li><a href=https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47>Understanding SVM</a></li> <li> <p><a href=http://people.cs.uchicago.edu/~niyogi/papersps/NiyogiKernelMethods.pdf>Kernel Methods Tutorial</a></p> </li> <li> <p><strong>Advanced Topics:</strong></p> </li> <li><a href=https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html>One-Class SVM</a> for anomaly detection</li> <li><a href=https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html>Nu-SVM</a> alternative parameterization</li> <li> <p><a href=https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html>Linear SVM</a> for large datasets</p> </li> <li> <p><strong>Research Papers:</strong></p> </li> <li>SchÔøΩlkopf, B., &amp; Smola, A. J. (2002). Learning with kernels: Support vector machines</li> <li>Chang, C. C., &amp; Lin, C. J. (2011). LIBSVM: A library for support vector machines</li> <li> <p>Fan, R. E., Chang, K. W., Hsieh, C. J., Wang, X. R., &amp; Lin, C. J. (2008). LIBLINEAR: A library for large linear classification</p> </li> <li> <p><strong>Online Courses:</strong></p> </li> <li><a href=http://cs229.stanford.edu/ >Machine Learning Course - Stanford CS229</a></li> <li><a href=https://www.coursera.org/learn/machine-learning>SVM in Machine Learning - Coursera</a></li> <li> <p><a href=https://www.edx.org/course/statistical-learning>Statistical Learning - edX</a></p> </li> <li> <p><strong>Implementations:</strong></p> </li> <li><a href=https://scikit-learn.org/stable/ >scikit-learn</a> (Python)</li> <li><a href=https://www.csie.ntu.edu.tw/~cjlin/libsvm/ >LIBSVM</a> (C++, multiple language bindings)</li> <li><a href=https://cran.r-project.org/web/packages/e1071/index.html>e1071</a> (R package)</li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2020 - <script>document.write(/\d{4}/.exec(Date())[0])</script> ‚Ä¢ <strong>Kuldeep Singh Sidhu</strong> ‚Ä¢ <u><a href=https://choosealicense.com/licenses/agpl-3.0/ target=‚Äù_blank‚Äù>License</a></u> ‚Ä¢ <u><a href=/privacy>Privacy Policy</a></u> ‚Ä¢ <u><a href=/contact>Contact</a></u> ‚Ä¢ </div> </div> <div class=md-social> <a href=https://github.com/singhsidhukuldeep/ target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M8 0c4.42 0 8 3.58 8 8a8.01 8.01 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27s-1.36.09-2 .27c-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8"/></svg> </a> <a href=https://linkedin.com/in/singhsidhukuldeep target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href=https://twitter.com/kuldeep_s_s target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> <a href=https://stackoverflow.com/u/7182350/ target=_blank rel=noopener title=stackoverflow.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 384 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M290.7 311 95 269.7 86.8 309l195.7 41zm51-87L188.2 95.7l-25.5 30.8 153.5 128.3zm-31.2 39.7L129.2 179l-16.7 36.5L293.7 300zM262 32l-32 24 119.3 160.3 32-24zm20.5 328h-200v39.7h200zm39.7 80H42.7V320h-40v160h359.5V320h-40z"/></svg> </a> <a href=https://huggingface.co/singhsidhukuldeep target=_blank rel=noopener title=huggingface.co class=md-social__link> <svg width=500 height=463 viewbox="0 0 500 463" fill=none xmlns=http://www.w3.org/2000/svg> <path fill=white d="M496.592 369.699C500.563 381.093 499.61 393.227 494.315 403.778C490.503 411.48 485.05 417.441 478.379 422.769C470.331 429.099 460.324 434.48 448.253 439.65C433.852 445.77 416.274 451.52 408.226 453.63C387.63 458.958 367.829 462.334 347.762 462.493C319.066 462.756 294.34 456.004 276.762 438.753C267.656 439.861 258.443 440.494 249.178 440.494C240.389 440.494 231.706 439.967 223.076 438.912C205.445 456.057 180.825 462.756 152.234 462.493C132.168 462.334 112.366 458.958 91.7177 453.63C83.7229 451.52 66.145 445.77 51.7439 439.65C39.6723 434.48 29.6656 429.099 21.6708 422.769C14.9467 417.441 9.49334 411.48 5.68127 403.778C0.439661 393.227 -0.566304 381.093 3.45755 369.699C-0.248631 360.994 -1.20165 351.024 1.71035 339.998C3.03399 334.987 5.20476 330.344 7.95792 326.229C7.37552 324.067 6.89901 321.851 6.58134 319.424C4.56941 304.97 9.59923 291.781 19.0765 281.547C23.7357 276.43 28.7655 272.895 34.0071 270.627C30.1421 254.273 28.1302 237.445 28.1302 220.247C28.1302 98.5969 127.085 0 249.178 0C291.111 0 330.343 11.6058 363.805 31.8633C369.84 35.5561 375.77 39.5126 381.436 43.7329C384.242 45.8431 387.048 48.006 389.748 50.2744C392.501 52.49 395.201 54.8112 397.796 57.1851C405.632 64.3069 412.991 71.9562 419.715 80.133C421.992 82.8235 424.163 85.6194 426.28 88.4681C430.569 94.1128 434.54 99.9685 438.193 106.035C443.752 115.109 448.623 124.604 452.859 134.469C455.665 141.064 458.101 147.816 460.271 154.727C463.501 165.067 465.99 175.723 467.684 186.696C468.213 190.336 468.69 194.028 469.06 197.721C469.802 205.107 470.225 212.598 470.225 220.247C470.225 237.234 468.213 253.904 464.454 269.994C470.278 272.262 475.784 275.955 480.92 281.547C490.397 291.781 495.427 305.022 493.415 319.477C493.098 321.851 492.621 324.067 492.039 326.229C494.792 330.344 496.963 334.987 498.286 339.998C501.198 351.024 500.245 360.994 496.592 369.699Z"/> <path fill=black d="M433.839 221.75C433.839 120.838 351.531 39.0323 250 39.0323C148.469 39.0323 66.1613 120.838 66.1613 221.75C66.1613 322.662 148.469 404.468 250 404.468C351.531 404.468 433.839 322.662 433.839 221.75ZM45 221.75C45 109.222 136.782 18 250 18C363.218 18 455 109.222 455 221.75C455 334.278 363.218 425.5 250 425.5C136.782 425.5 45 334.278 45 221.75Z"/> <path fill=white d="M250 405.5C352.173 405.5 435 323.232 435 221.75C435 120.268 352.173 38 250 38C147.827 38 65 120.268 65 221.75C65 323.232 147.827 405.5 250 405.5Z"/> <path fill=white d="M202.198 404.174C216.789 383.118 215.755 367.316 195.735 347.627C175.715 327.943 164.062 299.145 164.062 299.145C164.062 299.145 159.709 282.419 149.794 283.958C139.88 285.497 132.6 310.492 153.368 325.783C174.135 341.069 149.232 351.456 141.242 337.099C133.252 322.741 111.435 285.831 100.121 278.772C88.8117 271.713 80.8483 275.668 83.5151 290.218C86.182 304.769 133.48 340.036 128.878 347.668C124.276 355.296 108.058 338.7 108.058 338.7C108.058 338.7 57.3079 293.255 46.2587 305.097C35.2096 316.94 54.641 326.863 82.3328 343.359C110.03 359.85 112.177 364.206 108.248 370.446C104.314 376.685 43.1836 325.971 37.4417 347.47C31.705 368.969 99.8291 375.209 95.6247 390.051C91.4203 404.899 47.6372 361.958 38.6823 378.689C29.7221 395.425 100.465 415.088 101.038 415.234C123.889 421.067 181.924 433.426 202.198 404.174Z"/> <path fill=black d="M90.9935 255C82.4744 255 74.8603 258.477 69.551 264.784C66.2675 268.69 62.8367 274.986 62.5578 284.414C58.985 283.394 55.5489 282.824 52.3391 282.824C44.183 282.824 36.8163 285.93 31.6069 291.573C24.9137 298.815 21.9407 307.715 23.2351 316.62C23.8508 320.861 25.2768 324.663 27.4079 328.182C22.9142 331.795 19.6044 336.826 18.0047 342.876C16.7524 347.619 15.4685 357.497 22.1722 367.673C21.746 368.337 21.3461 369.027 20.9725 369.733C16.9418 377.336 16.684 385.927 20.2411 393.928C25.6346 406.054 39.0368 415.608 65.0625 425.863C81.2536 432.242 96.0661 436.321 96.1976 436.357C117.603 441.874 136.962 444.677 153.721 444.677C184.525 444.677 206.578 435.301 219.27 416.811C239.697 387.036 236.776 359.803 210.346 333.552C195.717 319.026 185.993 297.607 183.967 292.906C179.884 278.986 169.086 263.513 151.138 263.513H151.133C149.622 263.513 148.096 263.633 146.592 263.869C138.73 265.097 131.858 269.595 126.949 276.361C121.65 269.814 116.504 264.606 111.847 261.667C104.827 257.243 97.813 255 90.9935 255ZM90.9935 275.917C93.6771 275.917 96.9553 277.051 100.57 279.331C111.794 286.406 133.452 323.403 141.382 337.793C144.039 342.614 148.581 344.654 152.669 344.654C160.783 344.654 167.118 336.638 153.411 326.451C132.8 311.124 140.03 286.072 149.87 284.529C150.301 284.461 150.727 284.43 151.138 284.43C160.083 284.43 164.03 299.751 164.03 299.751C164.03 299.751 175.595 328.616 195.465 348.346C215.334 368.08 216.36 383.919 201.879 405.024C192.002 419.415 173.096 421.292 153.721 421.292C133.626 421.292 112.99 417.772 101.445 414.796C100.877 414.65 30.7019 396.255 39.5946 379.48C41.089 376.661 43.5516 375.532 46.6509 375.532C59.1744 375.532 81.9535 394.054 91.746 394.054C93.935 394.054 95.5662 392.371 96.1976 390.112C100.555 374.522 32.6646 369.738 38.3633 348.189C39.3683 344.377 42.094 342.829 45.9248 342.834C62.4737 342.834 99.6021 371.756 107.385 371.756C107.979 371.756 108.405 371.584 108.637 371.218C112.536 364.964 110.74 359.872 83.257 343.343C55.7738 326.808 36.1428 317.588 47.114 305.718C48.3768 304.347 50.1659 303.741 52.3391 303.741C69.0248 303.746 108.447 339.398 108.447 339.398C108.447 339.398 119.087 350.395 125.523 350.395C127.001 350.395 128.259 349.815 129.111 348.382C133.673 340.737 86.7366 305.388 84.0898 290.804C82.2955 280.921 85.3474 275.917 90.9935 275.917Z"/> <path fill=white d="M296.9 404.174C282.31 383.118 283.343 367.316 303.363 347.627C323.383 327.943 335.037 299.145 335.037 299.145C335.037 299.145 339.39 282.419 349.304 283.958C359.219 285.497 366.498 310.492 345.731 325.783C324.963 341.069 349.866 351.456 357.856 337.099C365.846 322.741 387.663 285.831 398.978 278.772C410.287 271.713 418.25 275.668 415.583 290.218C412.916 304.769 365.618 340.036 370.22 347.668C374.822 355.296 391.041 338.7 391.041 338.7C391.041 338.7 441.791 293.255 452.84 305.097C463.889 316.94 444.457 326.863 416.766 343.359C389.068 359.85 386.921 364.206 390.85 370.446C394.784 376.685 455.915 325.971 461.657 347.47C467.393 368.969 399.269 375.209 403.474 390.051C407.678 404.899 451.461 361.958 460.416 378.689C469.376 395.425 398.633 415.088 398.06 415.234C375.209 421.067 317.175 433.426 296.9 404.174Z"/> <path fill=black d="M408.105 255C416.624 255 424.238 258.477 429.547 264.784C432.831 268.69 436.262 274.986 436.541 284.414C440.113 283.394 443.549 282.824 446.759 282.824C454.915 282.824 462.282 285.93 467.491 291.573C474.185 298.815 477.158 307.715 475.863 316.62C475.248 320.861 473.822 324.663 471.69 328.182C476.184 331.795 479.494 336.826 481.094 342.876C482.346 347.619 483.63 357.497 476.926 367.673C477.352 368.337 477.752 369.027 478.126 369.733C482.157 377.336 482.414 385.927 478.857 393.928C473.464 406.054 460.062 415.608 434.036 425.863C417.845 432.242 403.032 436.321 402.901 436.357C381.495 441.874 362.136 444.677 345.377 444.677C314.573 444.677 292.52 435.301 279.829 416.811C259.402 387.036 262.322 359.803 288.753 333.552C303.381 319.026 313.105 297.607 315.131 292.906C319.214 278.986 330.012 263.513 347.961 263.513H347.966C349.476 263.513 351.002 263.633 352.507 263.869C360.368 265.097 367.24 269.595 372.15 276.361C377.449 269.814 382.595 264.606 387.252 261.667C394.271 257.243 401.285 255 408.105 255ZM408.105 275.917C405.421 275.917 402.143 277.051 398.528 279.331C387.304 286.406 365.646 323.403 357.716 337.793C355.059 342.614 350.518 344.654 346.429 344.654C338.315 344.654 331.98 336.638 345.687 326.451C366.299 311.124 359.069 286.072 349.229 284.529C348.797 284.461 348.371 284.43 347.961 284.43C339.015 284.43 335.069 299.751 335.069 299.751C335.069 299.751 323.503 328.616 303.634 348.346C283.764 368.08 282.738 383.919 297.219 405.024C307.096 419.415 326.002 421.292 345.377 421.292C365.472 421.292 386.108 417.772 397.653 414.796C398.221 414.65 468.397 396.255 459.504 379.48C458.009 376.661 455.547 375.532 452.447 375.532C439.924 375.532 417.145 394.054 407.352 394.054C405.163 394.054 403.532 392.371 402.901 390.112C398.543 374.522 466.434 369.738 460.735 348.189C459.73 344.377 457.004 342.829 453.174 342.834C436.625 342.834 399.496 371.756 391.714 371.756C391.119 371.756 390.693 371.584 390.461 371.218C386.562 364.964 388.358 359.872 415.841 343.343C443.325 326.808 462.956 317.588 451.984 305.718C450.722 304.347 448.932 303.741 446.759 303.741C430.074 303.746 390.651 339.398 390.651 339.398C390.651 339.398 380.011 350.395 373.576 350.395C372.097 350.395 370.84 349.815 369.987 348.382C365.425 340.737 412.362 305.388 415.009 290.804C416.803 280.921 413.751 275.917 408.105 275.917Z"/> <path fill=#0E1116 d="M319.277 228.901C319.277 205.236 288.585 241.304 250.637 241.465C212.692 241.306 182 205.238 182 228.901C182 244.591 189.507 270.109 209.669 285.591C213.681 271.787 235.726 260.729 238.877 262.317C243.364 264.578 243.112 270.844 250.637 276.365C258.163 270.844 257.911 264.58 262.398 262.317C265.551 260.729 287.594 271.787 291.605 285.591C311.767 270.109 319.275 244.591 319.275 228.903L319.277 228.901Z"/> <path fill=#FF323D d="M262.4 262.315C257.913 264.576 258.165 270.842 250.639 276.363C243.114 270.842 243.366 264.578 238.879 262.315C235.726 260.727 213.683 271.785 209.672 285.589C219.866 293.417 233.297 298.678 250.627 298.806C250.631 298.806 250.635 298.806 250.641 298.806C250.646 298.806 250.65 298.806 250.656 298.806C267.986 298.68 281.417 293.417 291.611 285.589C287.6 271.785 265.555 260.727 262.404 262.315H262.4Z"/> <path fill=black d="M373 196C382.389 196 390 188.389 390 179C390 169.611 382.389 162 373 162C363.611 162 356 169.611 356 179C356 188.389 363.611 196 373 196Z"/> <path fill=black d="M128 196C137.389 196 145 188.389 145 179C145 169.611 137.389 162 128 162C118.611 162 111 169.611 111 179C111 188.389 118.611 196 128 196Z"/> <path fill=#0E1116 d="M313.06 171.596C319.796 173.968 322.476 187.779 329.281 184.171C342.167 177.337 347.06 161.377 340.208 148.524C333.356 135.671 317.354 130.792 304.467 137.626C291.58 144.46 286.688 160.419 293.54 173.272C296.774 179.339 307.039 169.475 313.06 171.596Z"/> <path fill=#0E1116 d="M188.554 171.596C181.818 173.968 179.138 187.779 172.334 184.171C159.447 177.337 154.555 161.377 161.407 148.524C168.259 135.671 184.26 130.792 197.147 137.626C210.034 144.46 214.926 160.419 208.074 173.272C204.84 179.339 194.575 169.475 188.554 171.596Z"/> </svg> </a> <a href=http://kuldeepsinghsidhu.com target=_blank rel=noopener title=kuldeepsinghsidhu.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0M5.78 8.75a9.64 9.64 0 0 0 1.363 4.177q.383.64.857 1.215c.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a10 10 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.51 6.51 0 0 0 4.666 5.5q-.184-.271-.352-.552c-.715-1.192-1.437-2.874-1.581-4.948m-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948q.18-.295.353-.552a6.51 6.51 0 0 0-4.666 5.5m10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948q-.18.296-.353.552a6.51 6.51 0 0 0 4.666-5.5Zm2.733-1.5a6.51 6.51 0 0 0-4.666-5.5q.184.272.353.552c.714 1.192 1.436 2.874 1.58 4.948Z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "search.highlight", "search.share", "search.suggest", "content.tooltips", "navigation.instant.progress", "navigation.path", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.60a45f97.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../javascripts/xfile.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>