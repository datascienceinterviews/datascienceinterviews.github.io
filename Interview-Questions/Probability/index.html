<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A curated list of probability interview questions for data science and technical interviews"><meta name=author content="Kuldeep Singh Sidhu"><link href=../Natural-Language-Processing/ rel=prev><link href=../AB-testing/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.50"><title>Probability Interview Questions - Data Science Interview preparation</title><link rel=stylesheet href=../../assets/stylesheets/main.a40c8224.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-EVGNTG49J7"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-EVGNTG49J7",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-EVGNTG49J7",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#probability-interview-questions class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <!-- Add announcement here, including arbitrary HTML --> üëÄ This project is in early stages of development. <strong> ü§ó Please <a href=/Contribute>contribute content</a> if possible! ü§ù</strong><br> <small>ü´µ You can <b> <a href=/Contribute>SUBMIT</a></b> simple text/markdown content, I will format it! üôå</small> <meta name=google-adsense-account content=ca-pub-4988388949365963> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4988388949365963" crossorigin=anonymous></script> </div> </aside> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Data Science Interview preparation" class="md-header__button md-logo" aria-label="Data Science Interview preparation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science Interview preparation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Probability Interview Questions </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Data Science Interview preparation" class="md-nav__button md-logo" aria-label="Data Science Interview preparation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> Data Science Interview preparation </label> <div class=md-nav__source> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> üè° Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> üë®üèø‚Äçüè´ Interview Questions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> üë®üèø‚Äçüè´ Interview Questions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../flashcards/ class=md-nav__link> <span class=md-ellipsis> üìá Flashcards </span> </a> </li> <li class=md-nav__item> <a href=../data-structures-algorithms/ class=md-nav__link> <span class=md-ellipsis> DSA (Data Structures & Algorithms) </span> </a> </li> <li class=md-nav__item> <a href=../Machine-Learning/ class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class=md-nav__item> <a href=../System-design/ class=md-nav__link> <span class=md-ellipsis> System Design </span> </a> </li> <li class=md-nav__item> <a href=../Natural-Language-Processing/ class=md-nav__link> <span class=md-ellipsis> Natural Language Processing (NLP) </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Probability </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Probability </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#premium-interview-questions class=md-nav__link> <span class=md-ellipsis> Premium Interview Questions </span> </a> <nav class=md-nav aria-label="Premium Interview Questions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-is-bayes-theorem-explain-with-an-example-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bayes' Theorem? Explain with an Example - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-conditional-probability-vs-independence-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Conditional Probability vs Independence - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-law-of-total-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Law of Total Probability? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-expected-value-and-its-properties-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Expected Value and Its Properties - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-variance-how-is-it-related-to-standard-deviation-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Variance? How is it Related to Standard Deviation? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-central-limit-theorem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Central Limit Theorem - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-normal-distribution-state-its-properties-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Normal Distribution? State its Properties - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-binomial-distribution-amazon-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Binomial Distribution - Amazon, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-poisson-distribution-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Poisson Distribution? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-exponential-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Exponential Distribution - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-geometric-distribution-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Geometric Distribution? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-birthday-problem-calculate-the-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Birthday Problem? Calculate the Probability - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-monty-hall-problem-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Monty Hall Problem - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-covariance-and-correlation-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Covariance and Correlation? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-law-of-large-numbers-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Law of Large Numbers - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-pdf-vs-pmf-vs-cdf-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is a PDF vs PMF vs CDF? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-confidence-interval-how-to-interpret-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Confidence Interval? How to Interpret It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-hypothesis-testing-null-alternative-p-value-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Hypothesis Testing: Null, Alternative, p-value - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-power-in-hypothesis-testing-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Power in Hypothesis Testing? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-permutations-vs-combinations-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Permutations vs Combinations - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-negative-binomial-distribution-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Negative Binomial Distribution? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-beta-distribution-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Beta Distribution? - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-gamma-distribution-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Gamma Distribution? - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-markov-chain-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Markov Chain? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-entropy-in-information-theory-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Entropy in Information Theory? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-are-joint-and-marginal-distributions-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What are Joint and Marginal Distributions? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-chi-squared-distribution-and-test-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Chi-Squared Distribution and Test? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-t-distribution-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the t-Distribution? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-uniform-distribution-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Uniform Distribution? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-sampling-with-vs-without-replacement-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Sampling With vs Without Replacement - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-hypergeometric-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Hypergeometric Distribution? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-f-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the F-Distribution? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#how-do-you-calculate-sample-size-for-ab-tests-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> How Do You Calculate Sample Size for A/B Tests? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-bayesian-vs-frequentist-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bayesian vs Frequentist Probability? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-multiple-comparisons-problem-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Multiple Comparisons Problem? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-bootstrap-sampling-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bootstrap Sampling? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#average-score-on-a-dice-role-of-at-most-3-times class=md-nav__link> <span class=md-ellipsis> Average score on a dice role of at most 3 times </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-coupon-collector-problem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Coupon Collector Problem - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-simpsons-paradox-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Simpson's Paradox? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-are-quantiles-and-percentiles-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What Are Quantiles and Percentiles? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-difference-between-standard-deviation-and-standard-error-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Difference Between Standard Deviation and Standard Error? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-moment-generating-function-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is Moment Generating Function? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-waiting-time-paradox-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Waiting Time Paradox? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#how-do-you-estimate-probability-from-rare-events-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> How Do You Estimate Probability from Rare Events? - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#quick-reference-100-interview-questions class=md-nav__link> <span class=md-ellipsis> Quick Reference: 100+ Interview Questions </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-google-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Google interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-facebook-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Facebook interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-amazon-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Amazon interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-microsoft-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Microsoft interview </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../AB-testing/ class=md-nav__link> <span class=md-ellipsis> A/B Testing </span> </a> </li> <li class=md-nav__item> <a href=../SQL-Interview-Questions/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../Scikit-Learn/ class=md-nav__link> <span class=md-ellipsis> Scikit-Learn </span> </a> </li> <li class=md-nav__item> <a href=../LangChain/ class=md-nav__link> <span class=md-ellipsis> LangChain </span> </a> </li> <li class=md-nav__item> <a href=../LangGraph/ class=md-nav__link> <span class=md-ellipsis> LangGraph </span> </a> </li> <li class=md-nav__item> <a href=../Interview-Question-Resources/ class=md-nav__link> <span class=md-ellipsis> Interview Question Resources </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> üìù Cheat Sheets </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> üìù Cheat Sheets </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Cheat-Sheets/Django/ class=md-nav__link> <span class=md-ellipsis> Django </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Flask/ class=md-nav__link> <span class=md-ellipsis> Flask </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Hypothesis-Tests/ class=md-nav__link> <span class=md-ellipsis> Hypothesis Tests </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Keras/ class=md-nav__link> <span class=md-ellipsis> Keras </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/PySpark/ class=md-nav__link> <span class=md-ellipsis> PySpark </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/PyTorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/RegEx/ class=md-nav__link> <span class=md-ellipsis> Regular Expressions (RegEx) </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Sk-learn/ class=md-nav__link> <span class=md-ellipsis> Scikit Learn </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/SQL/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/tensorflow/ class=md-nav__link> <span class=md-ellipsis> TensorFlow </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> ‚Äçüéì ML Topics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> ‚Äçüéì ML Topics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Machine-Learning/ARIMA/ class=md-nav__link> <span class=md-ellipsis> ARIMA </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Activation%20functions/ class=md-nav__link> <span class=md-ellipsis> Activation functions </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Collaborative%20Filtering/ class=md-nav__link> <span class=md-ellipsis> Collaborative Filtering </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Confusion%20Matrix/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/DBSCAN/ class=md-nav__link> <span class=md-ellipsis> DBSCAN </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Decision%20Trees/ class=md-nav__link> <span class=md-ellipsis> Decision Trees </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Gradient%20Boosting/ class=md-nav__link> <span class=md-ellipsis> Gradient Boosting </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/K-means%20clustering/ class=md-nav__link> <span class=md-ellipsis> K-means clustering </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Linear%20Regression/ class=md-nav__link> <span class=md-ellipsis> Linear Regression </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Logistic%20Regression/ class=md-nav__link> <span class=md-ellipsis> Logistic Regression </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Loss%20Function%20MAE%2C%20RMSE/ class=md-nav__link> <span class=md-ellipsis> Loss Function MAE, RMSE </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Neural%20Networks/ class=md-nav__link> <span class=md-ellipsis> Neural Networks </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Normal%20Distribution/ class=md-nav__link> <span class=md-ellipsis> Normal Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Normalization%20Regularisation/ class=md-nav__link> <span class=md-ellipsis> Normalization Regularisation </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Overfitting%2C%20Underfitting/ class=md-nav__link> <span class=md-ellipsis> Overfitting, Underfitting </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/PCA/ class=md-nav__link> <span class=md-ellipsis> PCA </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Random%20Forest/ class=md-nav__link> <span class=md-ellipsis> Random Forest </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Support%20Vector%20Machines/ class=md-nav__link> <span class=md-ellipsis> Support Vector Machines </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Unbalanced%2C%20Skewed%20data/ class=md-nav__link> <span class=md-ellipsis> Unbalanced, Skewed data </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/kNN/ class=md-nav__link> <span class=md-ellipsis> kNN </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> üë®üèæ‚Äçüíª Online Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> üë®üèæ‚Äçüíª Online Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Online-Material/Online-Material-for-Learning/ class=md-nav__link> <span class=md-ellipsis> Online Study Material </span> </a> </li> <li class=md-nav__item> <a href=../../Online-Material/popular-resources/ class=md-nav__link> <span class=md-ellipsis> Popular Blogs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../projects/ class=md-nav__link> <span class=md-ellipsis> üì≥ Projects </span> </a> </li> <li class=md-nav__item> <a href=../../Contribute/ class=md-nav__link> <span class=md-ellipsis> ü§ù Contribute </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#premium-interview-questions class=md-nav__link> <span class=md-ellipsis> Premium Interview Questions </span> </a> <nav class=md-nav aria-label="Premium Interview Questions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-is-bayes-theorem-explain-with-an-example-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bayes' Theorem? Explain with an Example - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-conditional-probability-vs-independence-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Conditional Probability vs Independence - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-law-of-total-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Law of Total Probability? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-expected-value-and-its-properties-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Expected Value and Its Properties - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-variance-how-is-it-related-to-standard-deviation-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Variance? How is it Related to Standard Deviation? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-central-limit-theorem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Central Limit Theorem - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-normal-distribution-state-its-properties-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Normal Distribution? State its Properties - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-binomial-distribution-amazon-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Binomial Distribution - Amazon, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-poisson-distribution-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Poisson Distribution? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-exponential-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Exponential Distribution - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-geometric-distribution-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Geometric Distribution? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-birthday-problem-calculate-the-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Birthday Problem? Calculate the Probability - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-monty-hall-problem-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Monty Hall Problem - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-covariance-and-correlation-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Covariance and Correlation? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-law-of-large-numbers-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Law of Large Numbers - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-pdf-vs-pmf-vs-cdf-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is a PDF vs PMF vs CDF? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-confidence-interval-how-to-interpret-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Confidence Interval? How to Interpret It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-hypothesis-testing-null-alternative-p-value-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Hypothesis Testing: Null, Alternative, p-value - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-power-in-hypothesis-testing-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Power in Hypothesis Testing? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-permutations-vs-combinations-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Permutations vs Combinations - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-negative-binomial-distribution-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Negative Binomial Distribution? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-beta-distribution-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Beta Distribution? - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-gamma-distribution-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Gamma Distribution? - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-markov-chain-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Markov Chain? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-entropy-in-information-theory-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Entropy in Information Theory? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-are-joint-and-marginal-distributions-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What are Joint and Marginal Distributions? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-chi-squared-distribution-and-test-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Chi-Squared Distribution and Test? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-t-distribution-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the t-Distribution? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-uniform-distribution-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Uniform Distribution? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-sampling-with-vs-without-replacement-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Sampling With vs Without Replacement - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-hypergeometric-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Hypergeometric Distribution? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-f-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the F-Distribution? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#how-do-you-calculate-sample-size-for-ab-tests-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> How Do You Calculate Sample Size for A/B Tests? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-bayesian-vs-frequentist-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bayesian vs Frequentist Probability? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-multiple-comparisons-problem-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Multiple Comparisons Problem? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-bootstrap-sampling-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bootstrap Sampling? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#average-score-on-a-dice-role-of-at-most-3-times class=md-nav__link> <span class=md-ellipsis> Average score on a dice role of at most 3 times </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-coupon-collector-problem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Coupon Collector Problem - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-simpsons-paradox-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Simpson's Paradox? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-are-quantiles-and-percentiles-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What Are Quantiles and Percentiles? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-difference-between-standard-deviation-and-standard-error-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Difference Between Standard Deviation and Standard Error? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-moment-generating-function-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is Moment Generating Function? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-waiting-time-paradox-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Waiting Time Paradox? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#how-do-you-estimate-probability-from-rare-events-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> How Do You Estimate Probability from Rare Events? - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#quick-reference-100-interview-questions class=md-nav__link> <span class=md-ellipsis> Quick Reference: 100+ Interview Questions </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-google-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Google interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-facebook-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Facebook interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-amazon-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Amazon interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-microsoft-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Microsoft interview </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/edit/master/docs/Interview-Questions/Probability.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/raw/master/docs/Interview-Questions/Probability.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=probability-interview-questions>Probability Interview Questions</h1> <!-- ![Total Questions](https://img.shields.io/badge/Total%20Questions-1-blue?style=flat&labelColor=black&color=blue)
![Unanswered Questions](https://img.shields.io/badge/Unanswered%20Questions-0-blue?style=flat&labelColor=black&color=yellow)
![Answered Questions](https://img.shields.io/badge/Answered%20Questions-1-blue?style=flat&labelColor=black&color=success) --> <p>This document provides a curated list of common probability interview questions frequently asked in technical interviews. It covers basic probability concepts, probability distributions, key theorems, and real-world applications. Use the practice links to explore detailed explanations and examples.</p> <hr> <h2 id=premium-interview-questions>Premium Interview Questions</h2> <h3 id=what-is-bayes-theorem-explain-with-an-example-google-amazon-interview-question>What is Bayes' Theorem? Explain with an Example - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Bayes</code>, <code>Conditional Probability</code>, <code>Inference</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Bayes' Theorem:</strong></p> <div class=arithmatex>\[P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}\]</div> <p><strong>Components:</strong></p> <table> <thead> <tr> <th>Term</th> <th>Name</th> <th>Meaning</th> </tr> </thead> <tbody> <tr> <td>P(A|B)</td> <td>Posterior</td> <td>Probability of A given B</td> </tr> <tr> <td>P(B|A)</td> <td>Likelihood</td> <td>Probability of B given A</td> </tr> <tr> <td>P(A)</td> <td>Prior</td> <td>Initial probability of A</td> </tr> <tr> <td>P(B)</td> <td>Evidence</td> <td>Total probability of B</td> </tr> </tbody> </table> <p><strong>Medical Test Example:</strong></p> <ul> <li>Disease prevalence: P(Disease) = 1%</li> <li>Test sensitivity: P(Positive|Disease) = 99%</li> <li>Test specificity: P(Negative|No Disease) = 95%</li> </ul> <p><strong>What's P(Disease|Positive)?</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Prior</span>
<span class=n>p_disease</span> <span class=o>=</span> <span class=mf>0.01</span>
<span class=n>p_no_disease</span> <span class=o>=</span> <span class=mf>0.99</span>

<span class=c1># Likelihood</span>
<span class=n>p_pos_given_disease</span> <span class=o>=</span> <span class=mf>0.99</span>
<span class=n>p_pos_given_no_disease</span> <span class=o>=</span> <span class=mf>0.05</span>  <span class=c1># False positive rate</span>

<span class=c1># Evidence: P(Positive)</span>
<span class=n>p_positive</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_pos_given_disease</span> <span class=o>*</span> <span class=n>p_disease</span> <span class=o>+</span> 
              <span class=n>p_pos_given_no_disease</span> <span class=o>*</span> <span class=n>p_no_disease</span><span class=p>)</span>
<span class=c1># = 0.99 * 0.01 + 0.05 * 0.99 = 0.0099 + 0.0495 = 0.0594</span>

<span class=c1># Posterior</span>
<span class=n>p_disease_given_pos</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_pos_given_disease</span> <span class=o>*</span> <span class=n>p_disease</span><span class=p>)</span> <span class=o>/</span> <span class=n>p_positive</span>
<span class=c1># = 0.0099 / 0.0594 ‚âà 0.167 or 16.7%</span>
</code></pre></div> <p><strong>Insight:</strong> Even with 99% accurate test, only 16.7% chance of disease!</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding of conditional probability.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Writes formula without hesitation</li> <li>Explains base rate fallacy</li> <li>Shows numerical calculation</li> <li>Relates to real applications (spam, medical)</li> </ul> </div> </details> <hr> <h3 id=explain-conditional-probability-vs-independence-google-meta-interview-question>Explain Conditional Probability vs Independence - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Conditional Probability</code>, <code>Independence</code>, <code>Fundamentals</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Conditional Probability:</strong></p> <p>Probability of A given B has occurred:</p> <div class=arithmatex>\[P(A|B) = \frac{P(A \cap B)}{P(B)}\]</div> <p><strong>Independence:</strong></p> <p>Events A and B are independent if:</p> <div class=arithmatex>\[P(A|B) = P(A) \quad \text{or equivalently} \quad P(A \cap B) = P(A) \cdot P(B)\]</div> <p><strong>Example - Card Drawing:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Drawing from a deck</span>
<span class=c1># A = First card is Hearts</span>
<span class=c1># B = Second card is Hearts</span>

<span class=c1># WITH replacement (independent):</span>
<span class=n>p_a</span> <span class=o>=</span> <span class=mi>13</span><span class=o>/</span><span class=mi>52</span>  <span class=c1># = 1/4</span>
<span class=n>p_b_given_a</span> <span class=o>=</span> <span class=mi>13</span><span class=o>/</span><span class=mi>52</span>  <span class=c1># Same, deck reset</span>
<span class=n>p_both</span> <span class=o>=</span> <span class=p>(</span><span class=mi>13</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>13</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>=</span> <span class=mi>1</span><span class=o>/</span><span class=mi>16</span>

<span class=c1># WITHOUT replacement (dependent):</span>
<span class=n>p_a</span> <span class=o>=</span> <span class=mi>13</span><span class=o>/</span><span class=mi>52</span>
<span class=n>p_b_given_a</span> <span class=o>=</span> <span class=mi>12</span><span class=o>/</span><span class=mi>51</span>  <span class=c1># One heart removed</span>
<span class=n>p_both</span> <span class=o>=</span> <span class=p>(</span><span class=mi>13</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>12</span><span class=o>/</span><span class=mi>51</span><span class=p>)</span> <span class=err>‚âà</span> <span class=mf>0.059</span>
</code></pre></div> <p><strong>Key Differences:</strong></p> <table> <thead> <tr> <th>Independent</th> <th>Dependent</th> </tr> </thead> <tbody> <tr> <td>P(A‚à©B) = P(A)¬∑P(B)</td> <td>P(A‚à©B) ‚â† P(A)¬∑P(B)</td> </tr> <tr> <td>Knowing B doesn't change P(A)</td> <td>Knowing B changes P(A)</td> </tr> <tr> <td>Coin flips, dice rolls</td> <td>Card draws w/o replacement</td> </tr> </tbody> </table> <p><strong>Common Confusion:</strong> Independent ‚â† Mutually exclusive!</p> <ul> <li>Mutually exclusive: P(A‚à©B) = 0 (can't both occur)</li> <li>Independent: P(A‚à©B) = P(A)¬∑P(B) (outcomes don't affect each other)</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Fundamental probability concepts.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Clearly distinguishes conditional from joint</li> <li>Knows independence vs mutually exclusive</li> <li>Uses correct notation</li> <li>Provides intuitive examples</li> </ul> </div> </details> <hr> <h3 id=what-is-the-law-of-total-probability-google-amazon-interview-question>What is the Law of Total Probability? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Total Probability</code>, <code>Partition</code>, <code>Bayes</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Law of Total Probability:</strong></p> <p>If B‚ÇÅ, B‚ÇÇ, ..., B‚Çô partition the sample space:</p> <div class=arithmatex>\[P(A) = \sum_{i=1}^{n} P(A|B_i) \cdot P(B_i)\]</div> <p><strong>Intuition:</strong> Break complex probability into simpler conditional pieces.</p> <p><strong>Example - Product Defects:</strong></p> <p>Three factories produce parts: - Factory A: 50% of parts, 2% defect rate - Factory B: 30% of parts, 3% defect rate<br> - Factory C: 20% of parts, 5% defect rate</p> <p><strong>What's P(Defective)?</strong></p> <div class=highlight><pre><span></span><code><span class=n>p_a</span><span class=p>,</span> <span class=n>p_b</span><span class=p>,</span> <span class=n>p_c</span> <span class=o>=</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.2</span>  <span class=c1># Factory proportions</span>
<span class=n>d_a</span><span class=p>,</span> <span class=n>d_b</span><span class=p>,</span> <span class=n>d_c</span> <span class=o>=</span> <span class=mf>0.02</span><span class=p>,</span> <span class=mf>0.03</span><span class=p>,</span> <span class=mf>0.05</span>  <span class=c1># Defect rates</span>

<span class=n>p_defective</span> <span class=o>=</span> <span class=p>(</span><span class=n>d_a</span> <span class=o>*</span> <span class=n>p_a</span> <span class=o>+</span> <span class=n>d_b</span> <span class=o>*</span> <span class=n>p_b</span> <span class=o>+</span> <span class=n>d_c</span> <span class=o>*</span> <span class=n>p_c</span><span class=p>)</span>
<span class=c1># = 0.02*0.5 + 0.03*0.3 + 0.05*0.2</span>
<span class=c1># = 0.01 + 0.009 + 0.01</span>
<span class=c1># = 0.029 or 2.9%</span>
</code></pre></div> <p><strong>Follow-up: Given defective, which factory? (Bayes)</strong></p> <div class=highlight><pre><span></span><code><span class=c1># P(Factory A | Defective)</span>
<span class=n>p_a_given_defective</span> <span class=o>=</span> <span class=p>(</span><span class=n>d_a</span> <span class=o>*</span> <span class=n>p_a</span><span class=p>)</span> <span class=o>/</span> <span class=n>p_defective</span>
<span class=c1># = 0.01 / 0.029 ‚âà 0.345 or 34.5%</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Breaking down complex probabilities.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows it requires exhaustive, mutually exclusive partition</li> <li>Uses as setup for Bayes' theorem</li> <li>Can apply to real scenarios</li> <li>Shows clear calculation</li> </ul> </div> </details> <hr> <h3 id=explain-expected-value-and-its-properties-google-amazon-interview-question>Explain Expected Value and Its Properties - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Expected Value</code>, <code>Mean</code>, <code>Random Variables</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Expected Value (Mean):</strong></p> <div class=arithmatex>\[E[X] = \sum_x x \cdot P(X=x) \quad \text{(discrete)}\]</div> <div class=arithmatex>\[E[X] = \int_{-\infty}^{\infty} x \cdot f(x) \, dx \quad \text{(continuous)}\]</div> <p><strong>Key Properties:</strong></p> <table> <thead> <tr> <th>Property</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Linearity</td> <td>E[aX + b] = a¬∑E[X] + b</td> </tr> <tr> <td>Sum</td> <td>E[X + Y] = E[X] + E[Y] (always!)</td> </tr> <tr> <td>Product (independent)</td> <td>E[XY] = E[X]¬∑E[Y]</td> </tr> <tr> <td>Constant</td> <td>E[c] = c</td> </tr> </tbody> </table> <p><strong>Example - Dice:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Fair 6-sided die</span>
<span class=n>E_X</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>x</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=mi>6</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>7</span><span class=p>))</span>
<span class=c1># = (1 + 2 + 3 + 4 + 5 + 6) / 6 = 21/6 = 3.5</span>
</code></pre></div> <p><strong>Casino Example:</strong></p> <p>Bet $1, win $35 if dice shows 6, lose otherwise:</p> <div class=highlight><pre><span></span><code><span class=c1># X = profit</span>
<span class=n>p_win</span> <span class=o>=</span> <span class=mi>1</span><span class=o>/</span><span class=mi>6</span>
<span class=n>p_lose</span> <span class=o>=</span> <span class=mi>5</span><span class=o>/</span><span class=mi>6</span>

<span class=n>E_X</span> <span class=o>=</span> <span class=mi>35</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=mi>6</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>5</span><span class=o>/</span><span class=mi>6</span><span class=p>)</span>
<span class=c1># = 35/6 - 5/6 = 30/6 = 5</span>
<span class=c1># Expected profit = $5 per game (very favorable!)</span>

<span class=c1># Real casino: win $5 (not $35)</span>
<span class=n>E_X</span> <span class=o>=</span> <span class=mi>5</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=mi>6</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>5</span><span class=o>/</span><span class=mi>6</span><span class=p>)</span> <span class=o>=</span> <span class=mi>5</span><span class=o>/</span><span class=mi>6</span> <span class=o>-</span> <span class=mi>5</span><span class=o>/</span><span class=mi>6</span> <span class=o>=</span> <span class=mi>0</span>
<span class=c1># Fair game</span>
</code></pre></div> <p><strong>Why Linearity Matters:</strong></p> <p>E[X‚ÇÅ + X‚ÇÇ + ... + X‚Çô] = E[X‚ÇÅ] + E[X‚ÇÇ] + ... + E[X‚Çô]</p> <p>Works even when X·µ¢ are dependent!</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Foundation of probability calculations.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows linearity works without independence</li> <li>Can calculate for discrete and continuous</li> <li>Applies to decision-making problems</li> <li>Distinguishes expected value from most likely value</li> </ul> </div> </details> <hr> <h3 id=what-is-variance-how-is-it-related-to-standard-deviation-google-meta-interview-question>What is Variance? How is it Related to Standard Deviation? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Variance</code>, <code>Standard Deviation</code>, <code>Spread</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Variance:</strong></p> <p>Measures spread of distribution around mean:</p> <div class=arithmatex>\[Var(X) = E[(X - \mu)^2] = E[X^2] - (E[X])^2\]</div> <p><strong>Standard Deviation:</strong></p> <div class=arithmatex>\[\sigma = \sqrt{Var(X)}\]</div> <p><strong>Properties:</strong></p> <table> <thead> <tr> <th>Property</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Variance of constant</td> <td>Var&copy; = 0</td> </tr> <tr> <td>Scaling</td> <td>Var(aX) = a¬≤¬∑Var(X)</td> </tr> <tr> <td>Shift</td> <td>Var(X + b) = Var(X)</td> </tr> <tr> <td>Sum (independent)</td> <td>Var(X + Y) = Var(X) + Var(Y)</td> </tr> <tr> <td>Sum (dependent)</td> <td>Var(X + Y) = Var(X) + Var(Y) + 2¬∑Cov(X,Y)</td> </tr> </tbody> </table> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Roll of fair die</span>
<span class=n>outcomes</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>]</span>
<span class=n>probs</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=o>/</span><span class=mi>6</span><span class=p>]</span> <span class=o>*</span> <span class=mi>6</span>

<span class=n>E_X</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>x</span> <span class=o>*</span> <span class=n>p</span> <span class=k>for</span> <span class=n>x</span><span class=p>,</span> <span class=n>p</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>outcomes</span><span class=p>,</span> <span class=n>probs</span><span class=p>))</span>  <span class=c1># 3.5</span>
<span class=n>E_X2</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>x</span><span class=o>**</span><span class=mi>2</span> <span class=o>*</span> <span class=n>p</span> <span class=k>for</span> <span class=n>x</span><span class=p>,</span> <span class=n>p</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>outcomes</span><span class=p>,</span> <span class=n>probs</span><span class=p>))</span>  <span class=c1># 15.17</span>

<span class=n>variance</span> <span class=o>=</span> <span class=n>E_X2</span> <span class=o>-</span> <span class=n>E_X</span><span class=o>**</span><span class=mi>2</span>  <span class=c1># 15.17 - 12.25 = 2.92</span>
<span class=n>std_dev</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>variance</span><span class=p>)</span>  <span class=c1># 1.71</span>
</code></pre></div> <p><strong>Why Standard Deviation?</strong></p> <ul> <li>Same units as original data (variance has squared units)</li> <li>Interpretable: ~68% of data within 1 std dev (normal)</li> <li>Used in confidence intervals, z-scores</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding of spread/uncertainty.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Uses E[X¬≤] - (E[X])¬≤ formula</li> <li>Knows covariance term for dependent variables</li> <li>Explains why œÉ has same units as X</li> <li>Can compute by hand</li> </ul> </div> </details> <hr> <h3 id=explain-the-central-limit-theorem-google-amazon-interview-question>Explain the Central Limit Theorem - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>CLT</code>, <code>Normal Distribution</code>, <code>Sampling</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Central Limit Theorem:</strong></p> <p>Sample means of any distribution approach normal as n ‚Üí ‚àû:</p> <div class=arithmatex>\[\bar{X}_n \xrightarrow{d} N\left(\mu, \frac{\sigma^2}{n}\right)\]</div> <p><strong>Key Points:</strong></p> <ol> <li>Works for ANY distribution (with finite variance)</li> <li>n ‚â• 30 is usually "large enough"</li> <li>More skewed ‚Üí need larger n</li> </ol> <p><strong>Why It Matters:</strong></p> <ul> <li>Enables confidence intervals</li> <li>Justifies z-tests and t-tests</li> <li>A/B testing relies on CLT</li> </ul> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Exponential distribution (highly skewed)</span>
<span class=n>population</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>100000</span><span class=p>)</span>

<span class=c1># Sample means (n=50)</span>
<span class=n>sample_means</span> <span class=o>=</span> <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>population</span><span class=p>,</span> <span class=mi>50</span><span class=p>))</span> 
                <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>)]</span>

<span class=c1># Sample means are normal even though population is exponential!</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>sample_means</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;Distribution of Sample Means (n=50)&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Standard Error:</strong></p> <div class=arithmatex>\[SE = \frac{\sigma}{\sqrt{n}}\]</div> <p>As sample size increases, sampling distribution narrows.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Core statistical foundation.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows it applies to means of any distribution</li> <li>Can state conditions (finite variance)</li> <li>Links to hypothesis testing</li> <li>Explains standard error formula</li> </ul> </div> </details> <hr> <h3 id=what-is-the-normal-distribution-state-its-properties-most-tech-companies-interview-question>What is the Normal Distribution? State its Properties - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Normal</code>, <code>Gaussian</code>, <code>Continuous Distribution</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Normal Distribution:</strong></p> <div class=arithmatex>\[f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</div> <p><strong>Key Properties:</strong></p> <table> <thead> <tr> <th>Property</th> <th>Value</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>Œº</td> </tr> <tr> <td>Variance</td> <td>œÉ¬≤</td> </tr> <tr> <td>Skewness</td> <td>0 (symmetric)</td> </tr> <tr> <td>Kurtosis</td> <td>3 (standard)</td> </tr> <tr> <td>Mode = Median = Mean</td> <td>Œº</td> </tr> </tbody> </table> <p><strong>Empirical Rule (68-95-99.7):</strong></p> <div class=highlight><pre><span></span><code>Œº ¬± 1œÉ ‚Üí 68.27% of data
Œº ¬± 2œÉ ‚Üí 95.45% of data
Œº ¬± 3œÉ ‚Üí 99.73% of data
</code></pre></div> <p><strong>Standard Normal (Z-score):</strong></p> <div class=arithmatex>\[Z = \frac{X - \mu}{\sigma} \sim N(0, 1)\]</div> <p><strong>Sum of Normals:</strong></p> <p>If X ~ N(Œº‚ÇÅ, œÉ‚ÇÅ¬≤) and Y ~ N(Œº‚ÇÇ, œÉ‚ÇÇ¬≤) are independent:</p> <p>X + Y ~ N(Œº‚ÇÅ + Œº‚ÇÇ, œÉ‚ÇÅ¬≤ + œÉ‚ÇÇ¬≤)</p> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># N(100, 15) - IQ distribution</span>
<span class=n>iq</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>15</span><span class=p>)</span>

<span class=c1># P(IQ &gt; 130)?</span>
<span class=n>p_above_130</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>iq</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>130</span><span class=p>)</span>  <span class=c1># ‚âà 0.0228 or 2.28%</span>

<span class=c1># What IQ is 95th percentile?</span>
<span class=n>iq_95</span> <span class=o>=</span> <span class=n>iq</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.95</span><span class=p>)</span>  <span class=c1># ‚âà 124.7</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Most important distribution knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows 68-95-99.7 rule</li> <li>Can standardize to Z-score</li> <li>Knows sum of normals is normal</li> <li>Uses scipy.stats for calculations</li> </ul> </div> </details> <hr> <h3 id=explain-the-binomial-distribution-amazon-meta-interview-question>Explain the Binomial Distribution - Amazon, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Binomial</code>, <code>Discrete</code>, <code>Bernoulli Trials</code> | <strong>Asked by:</strong> Amazon, Meta, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Binomial Distribution:</strong></p> <p>Number of successes in n independent Bernoulli trials:</p> <div class=arithmatex>\[P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\]</div> <p><strong>Parameters:</strong></p> <ul> <li>n = number of trials</li> <li>p = probability of success per trial</li> <li>k = number of successes</li> </ul> <p><strong>Formulas:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>E[X] = np</td> </tr> <tr> <td>Variance</td> <td>Var(X) = np(1-p)</td> </tr> <tr> <td>Mode</td> <td>floor((n+1)p) or floor((n+1)p)-1</td> </tr> </tbody> </table> <p><strong>Example - Quality Control:</strong></p> <p>10 items, 5% defect rate. P(exactly 2 defective)?</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>binom</span>
<span class=kn>from</span><span class=w> </span><span class=nn>math</span><span class=w> </span><span class=kn>import</span> <span class=n>comb</span>

<span class=n>n</span><span class=p>,</span> <span class=n>p</span><span class=p>,</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>10</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mi>2</span>

<span class=c1># Manual calculation</span>
<span class=n>p_2</span> <span class=o>=</span> <span class=n>comb</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mf>0.05</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mf>0.95</span><span class=o>**</span><span class=mi>8</span><span class=p>)</span>
<span class=c1># = 45 * 0.0025 * 0.6634 ‚âà 0.0746</span>

<span class=c1># Using scipy</span>
<span class=n>p_2</span> <span class=o>=</span> <span class=n>binom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.05</span><span class=p>)</span>

<span class=c1># P(at least 1 defective)?</span>
<span class=n>p_at_least_1</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>binom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.05</span><span class=p>)</span>
<span class=c1># = 1 - 0.5987 ‚âà 0.401</span>
</code></pre></div> <p><strong>Normal Approximation (n large):</strong></p> <p>If np ‚â• 5 and n(1-p) ‚â• 5:</p> <p>X ~ N(np, np(1-p)) approximately</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Core discrete distribution.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>States conditions (fixed n, independent, same p)</li> <li>Knows mean = np without derivation</li> <li>Uses complement for "at least" problems</li> <li>Knows normal approximation conditions</li> </ul> </div> </details> <hr> <h3 id=what-is-the-poisson-distribution-when-to-use-it-google-amazon-interview-question>What is the Poisson Distribution? When to Use It? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Poisson</code>, <code>Discrete</code>, <code>Rare Events</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Poisson Distribution:</strong></p> <p>Models count of events in fixed interval (time, space):</p> <div class=arithmatex>\[P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}\]</div> <p><strong>Parameters:</strong></p> <ul> <li>Œª = rate (expected count per interval)</li> <li>k = actual count (0, 1, 2, ...)</li> </ul> <p><strong>Special Property:</strong></p> <p>E[X] = Var(X) = Œª</p> <p><strong>When to Use:</strong></p> <ol> <li>Events occur independently</li> <li>Rate is constant</li> <li>Events are "rare" (compared to opportunities)</li> </ol> <p><strong>Examples:</strong> - Website visits per minute - Typos per page - Goals in a soccer game - Radioactive decays per second</p> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>poisson</span>

<span class=c1># 4 customers per hour on average</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mi>4</span>

<span class=c1># P(exactly 6 customers)?</span>
<span class=n>p_6</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>  <span class=c1># ‚âà 0.104</span>

<span class=c1># P(at most 2 customers)?</span>
<span class=n>p_le_2</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>  <span class=c1># ‚âà 0.238</span>

<span class=c1># P(more than 5)?</span>
<span class=n>p_gt_5</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>poisson</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>  <span class=c1># ‚âà 0.215</span>
</code></pre></div> <p><strong>Poisson as Binomial Limit:</strong></p> <p>When n ‚Üí ‚àû, p ‚Üí 0, np = Œª: Binomial(n, p) ‚Üí Poisson(Œª)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Count data modeling.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>States E[X] = Var(X) = Œª</li> <li>Gives real-world examples</li> <li>Knows Poisson-Binomial relationship</li> <li>Uses for rate-based problems</li> </ul> </div> </details> <hr> <h3 id=explain-the-exponential-distribution-google-amazon-interview-question>Explain the Exponential Distribution - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Exponential</code>, <code>Continuous</code>, <code>Waiting Time</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Exponential Distribution:</strong></p> <p>Models time between Poisson events (waiting time):</p> <div class=arithmatex>\[f(x) = \lambda e^{-\lambda x}, \quad x \geq 0\]</div> <p><strong>Parameters:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>1/Œª</td> </tr> <tr> <td>Variance</td> <td>1/Œª¬≤</td> </tr> <tr> <td>Median</td> <td>ln(2)/Œª</td> </tr> </tbody> </table> <p><strong>Memoryless Property:</strong></p> <div class=arithmatex>\[P(X &gt; s + t | X &gt; s) = P(X &gt; t)\]</div> <p>"Past doesn't affect future" - unique to exponential!</p> <p><strong>Example:</strong></p> <p>Bus arrives every 10 minutes on average (Œª = 0.1/min):</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>expon</span>

<span class=c1># Œª = 0.1, scale = 1/Œª = 10</span>
<span class=n>wait_time</span> <span class=o>=</span> <span class=n>expon</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>

<span class=c1># P(wait &lt; 5 minutes)?</span>
<span class=n>p_lt_5</span> <span class=o>=</span> <span class=n>wait_time</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>5</span><span class=p>)</span>  <span class=c1># ‚âà 0.393</span>

<span class=c1># P(wait &gt; 15 minutes)?</span>
<span class=n>p_gt_15</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>wait_time</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>15</span><span class=p>)</span>  <span class=c1># ‚âà 0.223</span>

<span class=c1># Mean wait time</span>
<span class=n>mean_wait</span> <span class=o>=</span> <span class=n>wait_time</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># 10 minutes</span>
</code></pre></div> <p><strong>Relationship with Poisson:</strong></p> <ul> <li>If counts per time ~ Poisson(Œª)</li> <li>Then time between events ~ Exponential(Œª)</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Continuous distribution for waiting.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows memoryless property and its implications</li> <li>Connects to Poisson process</li> <li>Can calculate probabilities</li> <li>Gives practical examples</li> </ul> </div> </details> <hr> <h3 id=what-is-the-geometric-distribution-amazon-microsoft-interview-question>What is the Geometric Distribution? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Geometric</code>, <code>Discrete</code>, <code>First Success</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Geometric Distribution:</strong></p> <p>Number of trials until first success:</p> <div class=arithmatex>\[P(X = k) = (1-p)^{k-1} p, \quad k = 1, 2, 3, ...\]</div> <p><strong>Formulas:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>1/p</td> </tr> <tr> <td>Variance</td> <td>(1-p)/p¬≤</td> </tr> <tr> <td>Mode</td> <td>1</td> </tr> </tbody> </table> <p><strong>Memoryless (like Exponential):</strong></p> <p>P(X &gt; m + n | X &gt; m) = P(X &gt; n)</p> <p><strong>Example - Interview Success:</strong></p> <p>30% chance of passing each interview:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>geom</span>

<span class=n>p</span> <span class=o>=</span> <span class=mf>0.3</span>

<span class=c1># P(pass on exactly 3rd interview)?</span>
<span class=n>p_3rd</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=c1># = (0.7)^2 * 0.3 = 0.147</span>

<span class=c1># Expected interviews until first pass?</span>
<span class=n>expected</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=mf>0.3</span>  <span class=c1># ‚âà 3.33 interviews</span>

<span class=c1># P(need more than 5 interviews)?</span>
<span class=n>p_gt_5</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>geom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=c1># = (0.7)^5 ‚âà 0.168</span>
</code></pre></div> <p><strong>Alternative Definition:</strong></p> <p>Some texts define as failures before first success (k = 0, 1, 2, ...)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> First success modeling.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows two common definitions</li> <li>Calculates E[X] = 1/p intuitively</li> <li>Connects to negative binomial</li> <li>Uses memoryless property</li> </ul> </div> </details> <hr> <h3 id=what-is-the-birthday-problem-calculate-the-probability-google-amazon-interview-question>What is the Birthday Problem? Calculate the Probability - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Birthday Problem</code>, <code>Combinatorics</code>, <code>Probability Puzzle</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Birthday Problem:</strong></p> <p>What's the probability that in a group of n people, at least 2 share a birthday?</p> <p><strong>Approach - Complement:</strong></p> <p>P(at least 2 share) = 1 - P(all different birthdays)</p> <div class=arithmatex>\[P(\text{all different}) = \frac{365}{365} \cdot \frac{364}{365} \cdot \frac{363}{365} \cdot ... \cdot \frac{365-n+1}{365}\]</div> <p><strong>Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>birthday_probability</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;P(at least 2 share birthday in group of n)&quot;&quot;&quot;</span>
    <span class=n>p_all_different</span> <span class=o>=</span> <span class=mf>1.0</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
        <span class=n>p_all_different</span> <span class=o>*=</span> <span class=p>(</span><span class=mi>365</span> <span class=o>-</span> <span class=n>i</span><span class=p>)</span> <span class=o>/</span> <span class=mi>365</span>
    <span class=k>return</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>p_all_different</span>

<span class=c1># Results:</span>
<span class=c1># n=23: 50.7% (famous result!)</span>
<span class=c1># n=50: 97.0%</span>
<span class=c1># n=70: 99.9%</span>

<span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>70</span><span class=p>]:</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;n=</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>birthday_probability</span><span class=p>(</span><span class=n>n</span><span class=p>)</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Why So Counter-Intuitive?</strong></p> <ul> <li>We think: 23 people, 365 days ‚Üí small chance</li> <li>Reality: C(23,2) = 253 pairs to compare!</li> </ul> <p><strong>Generalized Version:</strong></p> <p>P(collision in hash table) follows same logic - birthday attack in cryptography.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Complement probability, combinatorics.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Uses complement approach</li> <li>Knows n=23 gives ~50%</li> <li>Can generalize to other collision problems</li> <li>Explains why intuition fails</li> </ul> </div> </details> <hr> <h3 id=explain-the-monty-hall-problem-google-meta-interview-question>Explain the Monty Hall Problem - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Monty Hall</code>, <code>Conditional Probability</code>, <code>Puzzle</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>The Setup:</strong></p> <ul> <li>3 doors: 1 car, 2 goats</li> <li>You pick a door (say Door 1)</li> <li>Host (who knows what's behind each) opens another door showing a goat</li> <li>Should you switch?</li> </ul> <p><strong>Answer: YES - Switch gives &#8532; chance!</strong></p> <p><strong>Intuition:</strong></p> <div class=highlight><pre><span></span><code>Initial pick: P(Car) = 1/3
Other doors:  P(Car) = 2/3

After host reveals goat:
- Your door still has P = 1/3
- Remaining door gets all 2/3
</code></pre></div> <p><strong>Simulation Proof:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>random</span>

<span class=k>def</span><span class=w> </span><span class=nf>monty_hall</span><span class=p>(</span><span class=n>switch</span><span class=p>,</span> <span class=n>n_simulations</span><span class=o>=</span><span class=mi>100000</span><span class=p>):</span>
    <span class=n>wins</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_simulations</span><span class=p>):</span>
        <span class=n>car</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
        <span class=n>choice</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>

        <span class=c1># Host opens a goat door (not your choice, not car)</span>
        <span class=n>goat_doors</span> <span class=o>=</span> <span class=p>[</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span> <span class=k>if</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>choice</span> <span class=ow>and</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>car</span><span class=p>]</span>
        <span class=n>host_opens</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>goat_doors</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>switch</span><span class=p>:</span>
            <span class=c1># Switch to remaining door</span>
            <span class=n>choice</span> <span class=o>=</span> <span class=p>[</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span> <span class=k>if</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>choice</span> <span class=ow>and</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>host_opens</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>

        <span class=k>if</span> <span class=n>choice</span> <span class=o>==</span> <span class=n>car</span><span class=p>:</span>
            <span class=n>wins</span> <span class=o>+=</span> <span class=mi>1</span>

    <span class=k>return</span> <span class=n>wins</span> <span class=o>/</span> <span class=n>n_simulations</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Stay:   </span><span class=si>{</span><span class=n>monty_hall</span><span class=p>(</span><span class=n>switch</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>   <span class=c1># ~33.3%</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Switch: </span><span class=si>{</span><span class=n>monty_hall</span><span class=p>(</span><span class=n>switch</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>    <span class=c1># ~66.7%</span>
</code></pre></div> <p><strong>Key Insight:</strong></p> <p>Host's action is not random - he MUST reveal a goat. This transfers information.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Conditional probability reasoning.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Gives correct answer (switch = &#8532;)</li> <li>Explains WHY (host's constraint)</li> <li>Can simulate or prove mathematically</li> <li>Addresses common misconceptions</li> </ul> </div> </details> <hr> <h3 id=what-is-covariance-and-correlation-google-meta-interview-question>What is Covariance and Correlation? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Covariance</code>, <code>Correlation</code>, <code>Dependency</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Covariance:</strong></p> <p>Measures joint variability of two variables:</p> <div class=arithmatex>\[Cov(X, Y) = E[(X - \mu_X)(Y - \mu_Y)] = E[XY] - E[X]E[Y]\]</div> <p><strong>Correlation (Pearson):</strong></p> <p>Standardized covariance, range [-1, 1]:</p> <div class=arithmatex>\[\rho_{XY} = \frac{Cov(X, Y)}{\sigma_X \sigma_Y}\]</div> <p><strong>Interpretation:</strong></p> <table> <thead> <tr> <th>Value</th> <th>Meaning</th> </tr> </thead> <tbody> <tr> <td>œÅ = 1</td> <td>Perfect positive linear</td> </tr> <tr> <td>œÅ = 0</td> <td>No linear relationship</td> </tr> <tr> <td>œÅ = -1</td> <td>Perfect negative linear</td> </tr> </tbody> </table> <p><strong>Important Properties:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Covariance</span>
<span class=n>Cov</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span> <span class=o>=</span> <span class=n>Var</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
<span class=n>Cov</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span> <span class=o>=</span> <span class=n>Cov</span><span class=p>(</span><span class=n>Y</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span>  <span class=c1># Symmetric</span>
<span class=n>Cov</span><span class=p>(</span><span class=n>aX</span> <span class=o>+</span> <span class=n>b</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span> <span class=o>=</span> <span class=n>a¬∑Cov</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span>

<span class=c1># Correlation</span>
<span class=n>Corr</span><span class=p>(</span><span class=n>aX</span> <span class=o>+</span> <span class=n>b</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span> <span class=o>=</span> <span class=n>sign</span><span class=p>(</span><span class=n>a</span><span class=p>)</span> <span class=err>¬∑</span> <span class=n>Corr</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span>  <span class=c1># Unaffected by linear transform</span>
</code></pre></div> <p><strong>Python Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>

<span class=n>cov_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cov</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
<span class=n>cov_xy</span> <span class=o>=</span> <span class=n>cov_matrix</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>  <span class=c1># Covariance</span>

<span class=n>corr_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>corrcoef</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
<span class=n>corr_xy</span> <span class=o>=</span> <span class=n>corr_matrix</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>  <span class=c1># Correlation</span>
</code></pre></div> <p><strong>Warning:</strong></p> <p>Correlation ‚â† Causation Correlation = 0 does NOT mean independence!</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding relationship measures.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows correlation is dimensionless</li> <li>States correlation measures LINEAR relationship only</li> <li>Knows correlation = 0 ‚â† independence</li> <li>Can distinguish correlation from causation</li> </ul> </div> </details> <hr> <h3 id=explain-the-law-of-large-numbers-google-amazon-interview-question>Explain the Law of Large Numbers - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>LLN</code>, <code>Convergence</code>, <code>Sampling</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Law of Large Numbers:</strong></p> <p>Sample mean converges to population mean as sample size ‚Üí ‚àû:</p> <div class=arithmatex>\[\bar{X}_n \xrightarrow{p} \mu \quad \text{as} \quad n \to \infty\]</div> <p><strong>Two Forms:</strong></p> <table> <thead> <tr> <th>Weak LLN</th> <th>Strong LLN</th> </tr> </thead> <tbody> <tr> <td>Convergence in probability</td> <td>Almost sure convergence</td> </tr> <tr> <td>P(|XÃÑ‚Çô - Œº| &gt; Œµ) ‚Üí 0</td> <td>P(XÃÑ‚Çô ‚Üí Œº) = 1</td> </tr> </tbody> </table> <p><strong>Intuition:</strong></p> <p>More samples ‚Üí better estimate of true mean</p> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Fair coin: P(Heads) = 0.5</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=n>flips</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mi>10000</span><span class=p>)</span>
<span class=n>running_mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>flips</span><span class=p>)</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10001</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>running_mean</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;True Mean&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Flips&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Running Mean&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Law of Large Numbers: Coin Flips&#39;</span><span class=p>)</span>
</code></pre></div> <p><strong>Key Distinction from CLT:</strong></p> <table> <thead> <tr> <th>LLN</th> <th>CLT</th> </tr> </thead> <tbody> <tr> <td>Sample mean ‚Üí population mean</td> <td>Sample mean distribution ‚Üí Normal</td> </tr> <tr> <td>About convergence to a value</td> <td>About shape of distribution</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Asymptotic behavior understanding.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Distinguishes LLN from CLT</li> <li>Knows weak vs strong forms</li> <li>Explains practical implications</li> <li>Shows convergence concept</li> </ul> </div> </details> <hr> <h3 id=what-is-a-pdf-vs-pmf-vs-cdf-most-tech-companies-interview-question>What is a PDF vs PMF vs CDF? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>PDF</code>, <code>PMF</code>, <code>CDF</code>, <code>Distributions</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Probability Mass Function (PMF):</strong></p> <p>For discrete random variables:</p> <div class=arithmatex>\[P(X = x) = p(x)\]</div> <p>Properties: - p(x) ‚â• 0 - Œ£p(x) = 1</p> <p><strong>Probability Density Function (PDF):</strong></p> <p>For continuous random variables:</p> <div class=arithmatex>\[P(a &lt; X &lt; b) = \int_a^b f(x) dx\]</div> <p>Properties: - f(x) ‚â• 0 - ‚à´f(x)dx = 1 - P(X = a) = 0 for any exact value!</p> <p><strong>Cumulative Distribution Function (CDF):</strong></p> <p>For both discrete and continuous:</p> <div class=arithmatex>\[F(x) = P(X \leq x)\]</div> <p>Properties: - F(-‚àû) = 0, F(+‚àû) = 1 - Monotonically non-decreasing - F'(x) = f(x) for continuous</p> <p><strong>Visual Comparison:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Discrete: Binomial PMF and CDF</span>
<span class=n>x_discrete</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>11</span><span class=p>)</span>
<span class=n>pmf</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>binom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>x_discrete</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
<span class=n>cdf_discrete</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>binom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>x_discrete</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>

<span class=c1># Continuous: Normal PDF and CDF</span>
<span class=n>x_continuous</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=n>pdf</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_continuous</span><span class=p>)</span>
<span class=n>cdf_continuous</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>x_continuous</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Distribution fundamentals.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows PDF ‚â† probability (can exceed 1)</li> <li>Uses CDF for probability calculations</li> <li>Knows F'(x) = f(x) relationship</li> <li>Distinguishes discrete from continuous</li> </ul> </div> </details> <hr> <h3 id=what-is-a-confidence-interval-how-to-interpret-it-google-amazon-interview-question>What is a Confidence Interval? How to Interpret It? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Confidence Interval</code>, <code>Inference</code>, <code>Uncertainty</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Confidence Interval:</strong></p> <p>Range that likely contains true population parameter:</p> <div class=arithmatex>\[CI = \text{estimate} \pm \text{margin of error}\]</div> <p><strong>For Mean (known œÉ):</strong></p> <div class=arithmatex>\[CI = \bar{x} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}\]</div> <p><strong>For Mean (unknown œÉ):</strong></p> <div class=arithmatex>\[CI = \bar{x} \pm t_{\alpha/2, n-1} \cdot \frac{s}{\sqrt{n}}\]</div> <p><strong>Common z-values:</strong></p> <table> <thead> <tr> <th>Confidence</th> <th>z-value</th> </tr> </thead> <tbody> <tr> <td>90%</td> <td>1.645</td> </tr> <tr> <td>95%</td> <td>1.96</td> </tr> <tr> <td>99%</td> <td>2.576</td> </tr> </tbody> </table> <p><strong>Correct Interpretation:</strong></p> <p>‚úÖ "95% of such intervals contain the true mean" ‚ùå "95% probability the true mean is in this interval"</p> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>]</span>

<span class=c1># 95% CI for mean</span>
<span class=n>mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
<span class=n>se</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>sem</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  <span class=c1># Standard error</span>
<span class=n>ci</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>t</span><span class=o>.</span><span class=n>interval</span><span class=p>(</span><span class=mf>0.95</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>loc</span><span class=o>=</span><span class=n>mean</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>se</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: (</span><span class=si>{</span><span class=n>ci</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Width Factors:</strong></p> <ul> <li>Higher confidence ‚Üí wider CI</li> <li>Larger n ‚Üí narrower CI</li> <li>More variability ‚Üí wider CI</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Statistical inference understanding.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Correct frequentist interpretation</li> <li>Knows t vs z distribution choice</li> <li>Understands factors affecting width</li> <li>Can calculate by hand</li> </ul> </div> </details> <hr> <h3 id=explain-hypothesis-testing-null-alternative-p-value-google-amazon-interview-question>Explain Hypothesis Testing: Null, Alternative, p-value - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Hypothesis Testing</code>, <code>p-value</code>, <code>Significance</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Hypothesis Testing Framework:</strong></p> <table> <thead> <tr> <th>Component</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>H‚ÇÄ (Null)</td> <td>Default assumption (no effect)</td> </tr> <tr> <td>H‚ÇÅ (Alternative)</td> <td>What we want to prove</td> </tr> <tr> <td>Œ± (Significance)</td> <td>False positive threshold (usually 0.05)</td> </tr> <tr> <td>p-value</td> <td>P(data | H‚ÇÄ true)</td> </tr> </tbody> </table> <p><strong>Decision Rule:</strong></p> <ul> <li>If p-value ‚â§ Œ±: Reject H‚ÇÄ</li> <li>If p-value &gt; Œ±: Fail to reject H‚ÇÄ</li> </ul> <p><strong>Types of Errors:</strong></p> <table> <thead> <tr> <th>Error</th> <th>Description</th> <th>Name</th> </tr> </thead> <tbody> <tr> <td>Type I</td> <td>Reject H‚ÇÄ when true</td> <td>False Positive</td> </tr> <tr> <td>Type II</td> <td>Accept H‚ÇÄ when false</td> <td>False Negative</td> </tr> </tbody> </table> <p><strong>Example - A/B Test:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># Control: 100 conversions out of 1000</span>
<span class=c1># Treatment: 120 conversions out of 1000</span>

<span class=n>control_conv</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>control_n</span> <span class=o>=</span> <span class=mi>1000</span>
<span class=n>treatment_conv</span> <span class=o>=</span> <span class=mi>120</span>
<span class=n>treatment_n</span> <span class=o>=</span> <span class=mi>1000</span>

<span class=c1># H‚ÇÄ: p1 = p2 (no difference)</span>
<span class=c1># H‚ÇÅ: p1 ‚â† p2 (difference exists)</span>

<span class=c1># Two-proportion z-test</span>
<span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.proportion</span><span class=w> </span><span class=kn>import</span> <span class=n>proportions_ztest</span>

<span class=n>stat</span><span class=p>,</span> <span class=n>pvalue</span> <span class=o>=</span> <span class=n>proportions_ztest</span><span class=p>(</span>
    <span class=p>[</span><span class=n>control_conv</span><span class=p>,</span> <span class=n>treatment_conv</span><span class=p>],</span>
    <span class=p>[</span><span class=n>control_n</span><span class=p>,</span> <span class=n>treatment_n</span><span class=p>]</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>pvalue</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># If p &lt; 0.05, reject H‚ÇÄ ‚Üí significant difference</span>
</code></pre></div> <p><strong>p-value Misconceptions:</strong></p> <p>‚ùå p-value = P(H‚ÇÄ is true) ‚úÖ p-value = P(observing this data or more extreme | H‚ÇÄ true)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Core statistical testing knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Correct p-value interpretation</li> <li>Knows Type I vs Type II errors</li> <li>Understands "fail to reject" vs "accept"</li> <li>Can set up hypotheses correctly</li> </ul> </div> </details> <hr> <h3 id=what-is-power-in-hypothesis-testing-google-meta-interview-question>What is Power in Hypothesis Testing? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Power</code>, <code>Type II Error</code>, <code>Sample Size</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Power:</strong></p> <p>Probability of correctly rejecting H‚ÇÄ when it's false:</p> <div class=arithmatex>\[\text{Power} = 1 - \beta = P(\text{Reject } H_0 | H_0 \text{ is false})\]</div> <p><strong>Factors Affecting Power:</strong></p> <table> <thead> <tr> <th>Factor</th> <th>Effect on Power</th> </tr> </thead> <tbody> <tr> <td>Effect size ‚Üë</td> <td>Power ‚Üë</td> </tr> <tr> <td>Sample size ‚Üë</td> <td>Power ‚Üë</td> </tr> <tr> <td>Œ± ‚Üë</td> <td>Power ‚Üë</td> </tr> <tr> <td>Variance ‚Üì</td> <td>Power ‚Üë</td> </tr> </tbody> </table> <p><strong>Typical Target: Power = 0.80</strong></p> <p><strong>Power Analysis - Sample Size Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.power</span><span class=w> </span><span class=kn>import</span> <span class=n>TTestIndPower</span>

<span class=c1># Parameters</span>
<span class=n>effect_size</span> <span class=o>=</span> <span class=mf>0.5</span>  <span class=c1># Cohen&#39;s d (medium effect)</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>
<span class=n>power</span> <span class=o>=</span> <span class=mf>0.80</span>

<span class=c1># Calculate required sample size</span>
<span class=n>analysis</span> <span class=o>=</span> <span class=n>TTestIndPower</span><span class=p>()</span>
<span class=n>n</span> <span class=o>=</span> <span class=n>analysis</span><span class=o>.</span><span class=n>solve_power</span><span class=p>(</span>
    <span class=n>effect_size</span><span class=o>=</span><span class=n>effect_size</span><span class=p>,</span>
    <span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>,</span>
    <span class=n>power</span><span class=o>=</span><span class=n>power</span><span class=p>,</span>
    <span class=n>ratio</span><span class=o>=</span><span class=mi>1</span>  <span class=c1># Equal group sizes</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Required n per group: </span><span class=si>{</span><span class=n>n</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># ~64 per group for medium effect</span>
</code></pre></div> <p><strong>Effect Size (Cohen's d):</strong></p> <div class=arithmatex>\[d = \frac{\mu_1 - \mu_2}{\sigma}\]</div> <table> <thead> <tr> <th>d</th> <th>Interpretation</th> </tr> </thead> <tbody> <tr> <td>0.2</td> <td>Small</td> </tr> <tr> <td>0.5</td> <td>Medium</td> </tr> <tr> <td>0.8</td> <td>Large</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Experimental design knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows power = 1 - Œ≤</li> <li>Can perform power analysis</li> <li>Understands sample size trade-offs</li> <li>Uses effect size appropriately</li> </ul> </div> </details> <hr> <h3 id=explain-permutations-vs-combinations-most-tech-companies-interview-question>Explain Permutations vs Combinations - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Combinatorics</code>, <code>Counting</code>, <code>Fundamentals</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Permutations (Order Matters):</strong></p> <div class=arithmatex>\[P(n, r) = \frac{n!}{(n-r)!}\]</div> <p><strong>Combinations (Order Doesn't Matter):</strong></p> <div class=arithmatex>\[C(n, r) = \binom{n}{r} = \frac{n!}{r!(n-r)!}\]</div> <p><strong>Key Relationship:</strong></p> <div class=arithmatex>\[P(n, r) = C(n, r) \cdot r!\]</div> <p><strong>Examples:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>math</span><span class=w> </span><span class=kn>import</span> <span class=n>factorial</span><span class=p>,</span> <span class=n>comb</span><span class=p>,</span> <span class=n>perm</span>

<span class=c1># 5 people, select 3 for positions (President, VP, Secretary)</span>
<span class=c1># Order matters ‚Üí Permutation</span>
<span class=n>positions</span> <span class=o>=</span> <span class=n>perm</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># = 5 √ó 4 √ó 3 = 60</span>

<span class=c1># 5 people, select 3 for a committee</span>
<span class=c1># Order doesn&#39;t matter ‚Üí Combination</span>
<span class=n>committee</span> <span class=o>=</span> <span class=n>comb</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># = 10</span>

<span class=c1># Relationship</span>
<span class=k>assert</span> <span class=n>perm</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span> <span class=o>==</span> <span class=n>comb</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span> <span class=o>*</span> <span class=n>factorial</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
<span class=c1># 60 = 10 √ó 6</span>
</code></pre></div> <p><strong>With Repetition:</strong></p> <table> <thead> <tr> <th>Type</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Permutation with repetition</td> <td>n ≥</td> </tr> <tr> <td>Combination with repetition</td> <td>C(n+r-1, r)</td> </tr> </tbody> </table> <div class=highlight><pre><span></span><code><span class=c1># 4-digit PIN (0-9): 10^4 = 10000</span>
<span class=c1># Choose 3 scoops from 5 flavors (repeats OK): C(5+3-1, 3) = C(7,3) = 35</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Basic counting principles.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Immediate recognition of order relevance</li> <li>Knows formulas without derivation</li> <li>Distinguishes with vs without replacement</li> <li>Gives intuitive examples</li> </ul> </div> </details> <hr> <h3 id=what-is-the-negative-binomial-distribution-amazon-microsoft-interview-question>What is the Negative Binomial Distribution? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Negative Binomial</code>, <code>Discrete</code>, <code>Failures</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Negative Binomial Distribution:</strong></p> <p>Number of trials until rth success:</p> <div class=arithmatex>\[P(X = k) = \binom{k-1}{r-1} p^r (1-p)^{k-r}\]</div> <p><strong>Alternative: Number of failures before rth success (Y = X - r)</strong></p> <p><strong>Parameters:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>r/p</td> </tr> <tr> <td>Variance</td> <td>r(1-p)/p¬≤</td> </tr> </tbody> </table> <p><strong>Special Case:</strong></p> <p>When r = 1: Negative Binomial ‚Üí Geometric</p> <p><strong>Example - Quality Control:</strong></p> <p>Need 3 good widgets. P(good) = 0.8. Expected total inspections?</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>nbinom</span>

<span class=n>r</span><span class=p>,</span> <span class=n>p</span> <span class=o>=</span> <span class=mi>3</span><span class=p>,</span> <span class=mf>0.8</span>

<span class=c1># Expected trials until 3 successes</span>
<span class=n>expected_trials</span> <span class=o>=</span> <span class=n>r</span> <span class=o>/</span> <span class=n>p</span>  <span class=c1># = 3 / 0.8 = 3.75</span>

<span class=c1># P(need exactly 5 trials)?</span>
<span class=c1># 5 trials, 3 successes, 2 failures</span>
<span class=n>p_5</span> <span class=o>=</span> <span class=n>nbinom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>  <span class=c1># k = failures</span>
<span class=c1># = C(4,2) * 0.8^3 * 0.2^2 = 0.0512</span>

<span class=c1># P(need at most 4 trials)?</span>
<span class=n>p_le_4</span> <span class=o>=</span> <span class=n>nbinom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>  <span class=c1># ‚â§1 failure</span>
</code></pre></div> <p><strong>Applications:</strong></p> <ul> <li>Number of sales calls until quota</li> <li>Waiting for multiple events</li> <li>Overdispersed count data</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Generalized geometric distribution.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows relationship to geometric</li> <li>Handles both parameterizations</li> <li>Calculates mean = r/p</li> <li>Gives practical applications</li> </ul> </div> </details> <hr> <h3 id=what-is-the-beta-distribution-amazon-google-interview-question>What is the Beta Distribution? - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Beta</code>, <code>Continuous</code>, <code>Bayesian</code> | <strong>Asked by:</strong> Amazon, Google, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Beta Distribution:</strong></p> <p>Models probabilities (values in [0, 1]):</p> <div class=arithmatex>\[f(x; \alpha, \beta) = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha, \beta)}\]</div> <p><strong>Parameters:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>Œ± / (Œ± + Œ≤)</td> </tr> <tr> <td>Mode</td> <td>(Œ±-1) / (Œ±+Œ≤-2) for Œ±,Œ≤ &gt; 1</td> </tr> <tr> <td>Variance</td> <td>Œ±Œ≤ / [(Œ±+Œ≤)¬≤(Œ±+Œ≤+1)]</td> </tr> </tbody> </table> <p><strong>Special Cases:</strong></p> <table> <thead> <tr> <th>Œ±</th> <th>Œ≤</th> <th>Shape</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>1</td> <td>Uniform</td> </tr> <tr> <td>0.5</td> <td>0.5</td> <td>U-shaped</td> </tr> <tr> <td>2</td> <td>5</td> <td>Left-skewed</td> </tr> <tr> <td>5</td> <td>2</td> <td>Right-skewed</td> </tr> </tbody> </table> <p><strong>Bayesian Application:</strong></p> <p>Prior for probability p, with binomial likelihood:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>beta</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Prior: Beta(2, 2) - slight preference for 0.5</span>
<span class=c1># Observed: 7 successes, 3 failures</span>
<span class=c1># Posterior: Beta(2+7, 2+3) = Beta(9, 5)</span>

<span class=n>prior_alpha</span><span class=p>,</span> <span class=n>prior_beta</span> <span class=o>=</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span>
<span class=n>successes</span><span class=p>,</span> <span class=n>failures</span> <span class=o>=</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>3</span>

<span class=n>post_alpha</span> <span class=o>=</span> <span class=n>prior_alpha</span> <span class=o>+</span> <span class=n>successes</span>
<span class=n>post_beta</span> <span class=o>=</span> <span class=n>prior_beta</span> <span class=o>+</span> <span class=n>failures</span>

<span class=n>posterior</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=n>post_alpha</span><span class=p>,</span> <span class=n>post_beta</span><span class=p>)</span>

<span class=n>mean</span> <span class=o>=</span> <span class=n>posterior</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># 9/14 ‚âà 0.643</span>
<span class=n>ci</span> <span class=o>=</span> <span class=n>posterior</span><span class=o>.</span><span class=n>interval</span><span class=p>(</span><span class=mf>0.95</span><span class=p>)</span>  <span class=c1># 95% credible interval</span>
</code></pre></div> <p><strong>Why Use Beta?</strong></p> <ul> <li>Conjugate prior for binomial</li> <li>Posterior is also Beta</li> <li>Flexible shape for [0,1] data</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Bayesian statistics foundation.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows it models probabilities</li> <li>Uses as prior in Bayesian inference</li> <li>Understands conjugacy</li> <li>Can update with observed data</li> </ul> </div> </details> <hr> <h3 id=what-is-the-gamma-distribution-amazon-google-interview-question>What is the Gamma Distribution? - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Gamma</code>, <code>Continuous</code>, <code>Waiting</code> | <strong>Asked by:</strong> Amazon, Google, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Gamma Distribution:</strong></p> <p>Generalized exponential - time until kth event:</p> <div class=arithmatex>\[f(x; k, \theta) = \frac{x^{k-1}e^{-x/\theta}}{\theta^k \Gamma(k)}\]</div> <p><strong>Parameters:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>kŒ∏</td> </tr> <tr> <td>Variance</td> <td>kŒ∏¬≤</td> </tr> <tr> <td>Mode</td> <td>(k-1)Œ∏ for k ‚â• 1</td> </tr> </tbody> </table> <p><strong>Special Cases:</strong></p> <table> <thead> <tr> <th>Distribution</th> <th>Gamma Parameters</th> </tr> </thead> <tbody> <tr> <td>Exponential</td> <td>k = 1</td> </tr> <tr> <td>Chi-squared</td> <td>k = ŒΩ/2, Œ∏ = 2</td> </tr> <tr> <td>Erlang</td> <td>k ‚àà integers</td> </tr> </tbody> </table> <p><strong>Application:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>gamma</span>

<span class=c1># Phone calls: avg 3 per hour (Œª=3)</span>
<span class=c1># Time until 5th call?</span>

<span class=n>k</span> <span class=o>=</span> <span class=mi>5</span>  <span class=c1># 5th event</span>
<span class=n>theta</span> <span class=o>=</span> <span class=mi>1</span><span class=o>/</span><span class=mi>3</span>  <span class=c1># Scale = 1/rate</span>

<span class=n>waiting</span> <span class=o>=</span> <span class=n>gamma</span><span class=p>(</span><span class=n>a</span><span class=o>=</span><span class=n>k</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>theta</span><span class=p>)</span>

<span class=c1># Expected wait</span>
<span class=n>expected</span> <span class=o>=</span> <span class=n>waiting</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># = 5 * (1/3) = 1.67 hours</span>

<span class=c1># P(wait &gt; 2 hours)?</span>
<span class=n>p_gt_2</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>waiting</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</code></pre></div> <p><strong>Relationship to Poisson:</strong></p> <ul> <li>Poisson: count in fixed time</li> <li>Gamma: time until kth count</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced distribution knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows exponential is Gamma(1, Œ∏)</li> <li>Connects to Poisson process</li> <li>Uses for waiting time problems</li> <li>Knows chi-squared is special gamma</li> </ul> </div> </details> <hr> <h3 id=what-is-a-markov-chain-google-amazon-interview-question>What is a Markov Chain? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Markov Chain</code>, <code>Stochastic Process</code>, <code>Probability</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Markov Chain:</strong></p> <p>Stochastic process with memoryless property:</p> <div class=arithmatex>\[P(X_{n+1} = j | X_n = i, X_{n-1}, ..., X_0) = P(X_{n+1} = j | X_n = i)\]</div> <p>"Future depends only on present, not past"</p> <p><strong>Components:</strong></p> <ul> <li>States: Finite or infinite set</li> <li>Transition probabilities: P(i ‚Üí j)</li> <li>Transition matrix: P where P·µ¢‚±º = P(i ‚Üí j)</li> </ul> <p><strong>Example - Weather:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># States: Sunny (0), Rainy (1)</span>
<span class=c1># P[i,j] = probability of going from i to j</span>
<span class=n>P</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>],</span>  <span class=c1># Sunny ‚Üí Sunny=0.8, Rainy=0.2</span>
    <span class=p>[</span><span class=mf>0.4</span><span class=p>,</span> <span class=mf>0.6</span><span class=p>]</span>   <span class=c1># Rainy ‚Üí Sunny=0.4, Rainy=0.6</span>
<span class=p>])</span>

<span class=c1># After n steps from initial state</span>
<span class=k>def</span><span class=w> </span><span class=nf>state_after_n_steps</span><span class=p>(</span><span class=n>P</span><span class=p>,</span> <span class=n>initial</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>matrix_power</span><span class=p>(</span><span class=n>P</span><span class=p>,</span> <span class=n>n</span><span class=p>)[</span><span class=n>initial</span><span class=p>]</span>

<span class=c1># Stationary distribution (œÄ = œÄP)</span>
<span class=n>eigenvalues</span><span class=p>,</span> <span class=n>eigenvectors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>eig</span><span class=p>(</span><span class=n>P</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
<span class=n>stationary</span> <span class=o>=</span> <span class=n>eigenvectors</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>real</span>
<span class=n>stationary</span> <span class=o>=</span> <span class=n>stationary</span> <span class=o>/</span> <span class=n>stationary</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
<span class=c1># [0.667, 0.333] - long-run: 66.7% sunny</span>
</code></pre></div> <p><strong>Key Properties:</strong></p> <ul> <li>Irreducible: Can reach any state from any other</li> <li>Aperiodic: No fixed cycles</li> <li>Ergodic: Irreducible + aperiodic ‚Üí unique stationary dist</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Stochastic modeling knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>States memoryless property clearly</li> <li>Can write transition matrix</li> <li>Knows stationary distribution concept</li> <li>Gives PageRank as application</li> </ul> </div> </details> <hr> <h3 id=what-is-entropy-in-information-theory-google-meta-interview-question>What is Entropy in Information Theory? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Entropy</code>, <code>Information Theory</code>, <code>Uncertainty</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Shannon Entropy:</strong></p> <p>Measures uncertainty/information content:</p> <div class=arithmatex>\[H(X) = -\sum_x P(x) \log_2 P(x)\]</div> <p><strong>Properties:</strong></p> <table> <thead> <tr> <th>Distribution</th> <th>Entropy</th> </tr> </thead> <tbody> <tr> <td>Uniform</td> <td>Maximum (log‚ÇÇn for n outcomes)</td> </tr> <tr> <td>Deterministic</td> <td>0 (no uncertainty)</td> </tr> <tr> <td>Binary (p=0.5)</td> <td>1 bit</td> </tr> </tbody> </table> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>def</span><span class=w> </span><span class=nf>entropy</span><span class=p>(</span><span class=n>probs</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Calculate Shannon entropy in bits&quot;&quot;&quot;</span>
    <span class=n>probs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span>
    <span class=n>probs</span> <span class=o>=</span> <span class=n>probs</span><span class=p>[</span><span class=n>probs</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>]</span>  <span class=c1># Avoid log(0)</span>
    <span class=k>return</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>probs</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log2</span><span class=p>(</span><span class=n>probs</span><span class=p>))</span>

<span class=c1># Fair coin: maximum entropy</span>
<span class=n>fair_coin</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>([</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>])</span>  <span class=c1># 1.0 bit</span>

<span class=c1># Biased coin</span>
<span class=n>biased</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>([</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>])</span>  <span class=c1># 0.47 bits</span>

<span class=c1># Fair die</span>
<span class=n>fair_die</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>([</span><span class=mi>1</span><span class=o>/</span><span class=mi>6</span><span class=p>]</span> <span class=o>*</span> <span class=mi>6</span><span class=p>)</span>  <span class=c1># 2.58 bits</span>
</code></pre></div> <p><strong>Cross-Entropy (ML Loss):</strong></p> <div class=arithmatex>\[H(p, q) = -\sum_x p(x) \log q(x)\]</div> <p><strong>KL Divergence:</strong></p> <div class=arithmatex>\[D_{KL}(p||q) = H(p, q) - H(p)\]</div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Information theory fundamentals.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows entropy measures uncertainty</li> <li>Uses log‚ÇÇ for bits, ln for nats</li> <li>Connects to ML cross-entropy loss</li> <li>Understands maximum entropy principle</li> </ul> </div> </details> <hr> <h3 id=what-are-joint-and-marginal-distributions-google-amazon-interview-question>What are Joint and Marginal Distributions? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Joint Distribution</code>, <code>Marginal</code>, <code>Multivariate</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Joint Distribution:</strong></p> <p>Probability distribution over multiple variables:</p> <div class=arithmatex>\[P(X=x, Y=y) = P(X=x \cap Y=y)\]</div> <p><strong>Marginal Distribution:</strong></p> <p>Distribution of single variable from joint:</p> <div class=arithmatex>\[P(X=x) = \sum_y P(X=x, Y=y)\]</div> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Joint PMF of X and Y</span>
<span class=n>joint</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>],</span>  <span class=c1># X=0</span>
    <span class=p>[</span><span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>],</span>  <span class=c1># X=1</span>
    <span class=p>[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>]</span> <span class=c1># X=2</span>
<span class=p>])</span>
<span class=c1># Columns: Y=0, Y=1, Y=2</span>

<span class=c1># Marginal of X (sum over Y)</span>
<span class=n>marginal_x</span> <span class=o>=</span> <span class=n>joint</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [0.4, 0.5, 0.1]</span>

<span class=c1># Marginal of Y (sum over X)</span>
<span class=n>marginal_y</span> <span class=o>=</span> <span class=n>joint</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># [0.3, 0.45, 0.25]</span>

<span class=c1># Conditional P(Y|X=1)</span>
<span class=n>conditional_y_given_x1</span> <span class=o>=</span> <span class=n>joint</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>/</span> <span class=n>marginal_x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
<span class=c1># [0.4, 0.4, 0.2]</span>
</code></pre></div> <p><strong>Independence Check:</strong></p> <p>X and Y independent iff: P(X=x, Y=y) = P(X=x) ¬∑ P(Y=y) for all x, y</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Multivariate probability.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows marginalization = summing out</li> <li>Can derive conditional from joint</li> <li>Checks independence via product rule</li> <li>Extends to continuous case</li> </ul> </div> </details> <hr> <h3 id=what-is-the-chi-squared-distribution-and-test-amazon-microsoft-interview-question>What is the Chi-Squared Distribution and Test? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Chi-Squared</code>, <code>Hypothesis Testing</code>, <code>Categorical</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Chi-Squared Distribution:</strong></p> <p>Sum of squared standard normals:</p> <div class=arithmatex>\[\chi^2_k = Z_1^2 + Z_2^2 + ... + Z_k^2\]</div> <p>where Z·µ¢ ~ N(0,1) and k = degrees of freedom</p> <p><strong>Chi-Squared Test for Independence:</strong></p> <p>Tests if two categorical variables are independent:</p> <div class=arithmatex>\[\chi^2 = \sum \frac{(O - E)^2}{E}\]</div> <ul> <li>O = observed frequency</li> <li>E = expected frequency (under independence)</li> </ul> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chi2_contingency</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Observed: Gender vs Product Preference</span>
<span class=n>observed</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=mi>30</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span>  <span class=c1># Male: A, B, C</span>
    <span class=p>[</span><span class=mi>20</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>   <span class=c1># Female: A, B, C</span>
<span class=p>])</span>

<span class=n>chi2</span><span class=p>,</span> <span class=n>p_value</span><span class=p>,</span> <span class=n>dof</span><span class=p>,</span> <span class=n>expected</span> <span class=o>=</span> <span class=n>chi2_contingency</span><span class=p>(</span><span class=n>observed</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Chi-squared: </span><span class=si>{</span><span class=n>chi2</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Degrees of freedom: </span><span class=si>{</span><span class=n>dof</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># If p &lt; 0.05: Reject H‚ÇÄ ‚Üí Variables are dependent</span>
</code></pre></div> <p><strong>Chi-Squared Goodness of Fit:</strong></p> <p>Tests if data follows expected distribution:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chisquare</span>

<span class=n>observed</span> <span class=o>=</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>32</span><span class=p>]</span>  <span class=c1># Dice rolls</span>
<span class=n>expected</span> <span class=o>=</span> <span class=p>[</span><span class=mi>25</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>25</span><span class=p>]</span>   <span class=c1># Fair die</span>

<span class=n>stat</span><span class=p>,</span> <span class=n>p</span> <span class=o>=</span> <span class=n>chisquare</span><span class=p>(</span><span class=n>observed</span><span class=p>,</span> <span class=n>expected</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Categorical data analysis.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows œá¬≤ tests independence/goodness-of-fit</li> <li>Calculates expected under null</li> <li>Uses at least 5 per cell rule</li> <li>Interprets p-value correctly</li> </ul> </div> </details> <hr> <h3 id=what-is-the-t-distribution-when-to-use-it-google-amazon-interview-question>What is the t-Distribution? When to Use It? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>t-Distribution</code>, <code>Small Samples</code>, <code>Inference</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>t-Distribution:</strong></p> <p>For inference when œÉ is unknown (uses sample s):</p> <div class=arithmatex>\[t = \frac{\bar{X} - \mu}{s / \sqrt{n}}\]</div> <p><strong>Properties:</strong></p> <table> <thead> <tr> <th>Property</th> <th>Value</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>0 (for ŒΩ &gt; 1)</td> </tr> <tr> <td>Variance</td> <td>ŒΩ/(ŒΩ-2) for ŒΩ &gt; 2</td> </tr> <tr> <td>Shape</td> <td>Bell-shaped, heavier tails than Normal</td> </tr> <tr> <td>DOF ‚Üí ‚àû</td> <td>Converges to N(0,1)</td> </tr> </tbody> </table> <p><strong>When to Use:</strong></p> <table> <thead> <tr> <th>Use t</th> <th>Use z</th> </tr> </thead> <tbody> <tr> <td>œÉ unknown</td> <td>œÉ known</td> </tr> <tr> <td>Small n (&lt; 30)</td> <td>Large n (n ‚â• 30)</td> </tr> <tr> <td>Population ~normal</td> <td>CLT applies</td> </tr> </tbody> </table> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># t-test: is population mean = 100?</span>
<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>102</span><span class=p>,</span> <span class=mi>98</span><span class=p>,</span> <span class=mi>105</span><span class=p>,</span> <span class=mi>99</span><span class=p>,</span> <span class=mi>103</span><span class=p>,</span> <span class=mi>101</span><span class=p>,</span> <span class=mi>97</span><span class=p>,</span> <span class=mi>104</span><span class=p>]</span>

<span class=c1># One-sample t-test</span>
<span class=n>t_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>ttest_1samp</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>

<span class=c1># Critical value for 95% CI (df = n-1)</span>
<span class=n>t_crit</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>t</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.975</span><span class=p>,</span> <span class=n>df</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>

<span class=c1># Two-sample t-test</span>
<span class=n>group1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>]</span>
<span class=n>group2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>]</span>
<span class=n>t_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>ttest_ind</span><span class=p>(</span><span class=n>group1</span><span class=p>,</span> <span class=n>group2</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Small sample inference.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows to use t when œÉ unknown</li> <li>States heavier tails than normal</li> <li>Uses correct degrees of freedom</li> <li>Knows t ‚Üí z as n ‚Üí ‚àû</li> </ul> </div> </details> <hr> <h3 id=what-is-the-uniform-distribution-most-tech-companies-interview-question>What is the Uniform Distribution? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Uniform</code>, <code>Continuous</code>, <code>Random</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Continuous Uniform Distribution:</strong></p> <p>Equal probability over interval [a, b]:</p> <div class=arithmatex>\[f(x) = \frac{1}{b-a}, \quad a \leq x \leq b\]</div> <p><strong>Properties:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>(a + b) / 2</td> </tr> <tr> <td>Variance</td> <td>(b - a)¬≤ / 12</td> </tr> <tr> <td>CDF</td> <td>(x - a) / (b - a)</td> </tr> </tbody> </table> <p><strong>Discrete Uniform:</strong></p> <div class=arithmatex>\[P(X = k) = \frac{1}{n}\]</div> <p>for k in {1, 2, ..., n}</p> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>uniform</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Uniform[0, 1]</span>
<span class=n>U</span> <span class=o>=</span> <span class=n>uniform</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=c1># Generate random samples</span>
<span class=n>samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>

<span class=c1># Uniform[2, 8]</span>
<span class=n>U</span> <span class=o>=</span> <span class=n>uniform</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>6</span><span class=p>)</span>  <span class=c1># loc=a, scale=b-a</span>
<span class=n>U</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># 5.0</span>
<span class=n>U</span><span class=o>.</span><span class=n>var</span><span class=p>()</span>   <span class=c1># 3.0</span>
</code></pre></div> <p><strong>Inverse Transform Sampling:</strong></p> <p>If U ~ Uniform(0,1), then F‚Åª¬π(U) has distribution F:</p> <div class=highlight><pre><span></span><code><span class=c1># Generate exponential from uniform</span>
<span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>exponential_samples</span> <span class=o>=</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>u</span><span class=p>)</span>  <span class=c1># Inverse CDF of Exp(1)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Basic distribution knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows mean = (a+b)/2</li> <li>Uses for random number generation</li> <li>Knows inverse transform method</li> <li>Distinguishes continuous vs discrete</li> </ul> </div> </details> <hr> <h3 id=explain-sampling-with-vs-without-replacement-most-tech-companies-interview-question>Explain Sampling With vs Without Replacement - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Sampling</code>, <code>Replacement</code>, <code>Combinatorics</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>With Replacement:</strong></p> <ul> <li>Each item can be selected multiple times</li> <li>Trials are independent</li> <li>Probabilities remain constant</li> </ul> <p><strong>Without Replacement:</strong></p> <ul> <li>Each item selected at most once</li> <li>Trials are dependent</li> <li>Probabilities change after each selection</li> </ul> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>population</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>]</span>

<span class=c1># With replacement - same item can appear multiple times</span>
<span class=n>with_rep</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>population</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>replace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=c1># Possible: [3, 3, 1]</span>

<span class=c1># Without replacement - unique items only</span>
<span class=n>without_rep</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>population</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>replace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=c1># Possible: [4, 1, 3] but never [3, 3, 1]</span>
</code></pre></div> <p><strong>Probability Differences:</strong></p> <p>Drawing 2 red cards from deck:</p> <div class=highlight><pre><span></span><code><span class=c1># With replacement</span>
<span class=n>p_with</span> <span class=o>=</span> <span class=p>(</span><span class=mi>26</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>26</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>=</span> <span class=mf>0.25</span>

<span class=c1># Without replacement  </span>
<span class=n>p_without</span> <span class=o>=</span> <span class=p>(</span><span class=mi>26</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>25</span><span class=o>/</span><span class=mi>51</span><span class=p>)</span> <span class=err>‚âà</span> <span class=mf>0.245</span>
</code></pre></div> <p><strong>When Each is Used:</strong></p> <table> <thead> <tr> <th>With Replacement</th> <th>Without Replacement</th> </tr> </thead> <tbody> <tr> <td>Bootstrap sampling</td> <td>Survey sampling</td> </tr> <tr> <td>Dice rolling</td> <td>Lottery</td> </tr> <tr> <td>Monte Carlo</td> <td>Card dealing</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Sampling concepts.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows independence implications</li> <li>Can calculate both scenarios</li> <li>Mentions hypergeometric for without</li> <li>Knows bootstrap uses with replacement</li> </ul> </div> </details> <hr> <h3 id=what-is-the-hypergeometric-distribution-google-amazon-interview-question>What is the Hypergeometric Distribution? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Hypergeometric</code>, <code>Sampling</code>, <code>Without Replacement</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Hypergeometric Distribution:</strong></p> <p>Successes in n draws without replacement:</p> <div class=arithmatex>\[P(X = k) = \frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}}\]</div> <ul> <li>N = population size</li> <li>K = successes in population</li> <li>n = sample size</li> <li>k = successes in sample</li> </ul> <p><strong>Example - Quality Control:</strong></p> <p>Lot of 100 items, 10 defective. Sample 15 without replacement.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>hypergeom</span>

<span class=n>N</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>n</span> <span class=o>=</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>15</span>

<span class=c1># P(exactly 2 defective)?</span>
<span class=n>p_2</span> <span class=o>=</span> <span class=n>hypergeom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>M</span><span class=o>=</span><span class=n>N</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=n>K</span><span class=p>,</span> <span class=n>N</span><span class=o>=</span><span class=n>n</span><span class=p>)</span>

<span class=c1># Expected defectives</span>
<span class=n>expected</span> <span class=o>=</span> <span class=n>n</span> <span class=o>*</span> <span class=n>K</span> <span class=o>/</span> <span class=n>N</span>  <span class=c1># = 15 * 10/100 = 1.5</span>

<span class=c1># P(at least 1 defective)?</span>
<span class=n>p_at_least_1</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>hypergeom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>M</span><span class=o>=</span><span class=n>N</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=n>K</span><span class=p>,</span> <span class=n>N</span><span class=o>=</span><span class=n>n</span><span class=p>)</span>
</code></pre></div> <p><strong>Comparison with Binomial:</strong></p> <table> <thead> <tr> <th>Hypergeometric</th> <th>Binomial</th> </tr> </thead> <tbody> <tr> <td>Without replacement</td> <td>With replacement</td> </tr> <tr> <td>p changes</td> <td>p constant</td> </tr> <tr> <td>Var &lt; np(1-p)</td> <td>Var = np(1-p)</td> </tr> </tbody> </table> <p><strong>For large N, hypergeometric ‚âà binomial</strong></p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Finite population sampling.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows formula intuitively</li> <li>Compares to binomial</li> <li>Uses for quality control problems</li> <li>Knows approximation for large N</li> </ul> </div> </details> <hr> <h3 id=what-is-the-f-distribution-google-amazon-interview-question>What is the F-Distribution? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>F-Distribution</code>, <code>ANOVA</code>, <code>Variance Comparison</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>F-Distribution:</strong></p> <p>Ratio of two chi-squared distributions:</p> <div class=arithmatex>\[F = \frac{\chi^2_1 / d_1}{\chi^2_2 / d_2}\]</div> <p><strong>Use Cases:</strong></p> <ol> <li>ANOVA (compare group means)</li> <li>Comparing variances</li> <li>Regression overall significance</li> </ol> <p><strong>F-Test for Variance:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Compare variances of two samples</span>
<span class=n>sample1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>]</span>
<span class=n>sample2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>19</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>35</span><span class=p>]</span>

<span class=n>var1</span><span class=p>,</span> <span class=n>var2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>sample1</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>sample2</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>f_stat</span> <span class=o>=</span> <span class=n>var1</span> <span class=o>/</span> <span class=n>var2</span>
<span class=n>df1</span><span class=p>,</span> <span class=n>df2</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>sample1</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>sample2</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span>

<span class=n>p_value</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=nb>min</span><span class=p>(</span>
    <span class=n>stats</span><span class=o>.</span><span class=n>f</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>f_stat</span><span class=p>,</span> <span class=n>df1</span><span class=p>,</span> <span class=n>df2</span><span class=p>),</span>
    <span class=mi>1</span> <span class=o>-</span> <span class=n>stats</span><span class=o>.</span><span class=n>f</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>f_stat</span><span class=p>,</span> <span class=n>df1</span><span class=p>,</span> <span class=n>df2</span><span class=p>)</span>
<span class=p>)</span>
</code></pre></div> <p><strong>One-Way ANOVA:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>f_oneway</span>

<span class=n>group1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>85</span><span class=p>,</span> <span class=mi>90</span><span class=p>,</span> <span class=mi>88</span><span class=p>,</span> <span class=mi>92</span><span class=p>,</span> <span class=mi>87</span><span class=p>]</span>
<span class=n>group2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>78</span><span class=p>,</span> <span class=mi>82</span><span class=p>,</span> <span class=mi>80</span><span class=p>,</span> <span class=mi>79</span><span class=p>,</span> <span class=mi>81</span><span class=p>]</span>
<span class=n>group3</span> <span class=o>=</span> <span class=p>[</span><span class=mi>91</span><span class=p>,</span> <span class=mi>95</span><span class=p>,</span> <span class=mi>89</span><span class=p>,</span> <span class=mi>94</span><span class=p>,</span> <span class=mi>92</span><span class=p>]</span>

<span class=n>f_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>f_oneway</span><span class=p>(</span><span class=n>group1</span><span class=p>,</span> <span class=n>group2</span><span class=p>,</span> <span class=n>group3</span><span class=p>)</span>
<span class=c1># If p &lt; 0.05: At least one group mean differs</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced statistical tests.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows F = ratio of variances</li> <li>Uses for ANOVA and regression</li> <li>Understands two df parameters</li> <li>Can interpret F-stat and p-value</li> </ul> </div> </details> <hr> <h3 id=how-do-you-calculate-sample-size-for-ab-tests-google-meta-interview-question>How Do You Calculate Sample Size for A/B Tests? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>A/B Testing</code>, <code>Sample Size</code>, <code>Power</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Sample Size Formula (Two Proportions):</strong></p> <div class=arithmatex>\[n = \frac{2(z_{\alpha/2} + z_{\beta})^2 \bar{p}(1-\bar{p})}{\delta^2}\]</div> <p>where: - Œ¥ = minimum detectable effect - pÃÑ = average proportion - Œ± = significance level (usually 0.05) - 1-Œ≤ = power (usually 0.80)</p> <p><strong>Python Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.power</span><span class=w> </span><span class=kn>import</span> <span class=n>NormalIndPower</span>
<span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.proportion</span><span class=w> </span><span class=kn>import</span> <span class=n>proportion_effectsize</span>

<span class=c1># Current conversion: 10%</span>
<span class=c1># Want to detect: 2% absolute lift (to 12%)</span>
<span class=n>p1</span><span class=p>,</span> <span class=n>p2</span> <span class=o>=</span> <span class=mf>0.10</span><span class=p>,</span> <span class=mf>0.12</span>

<span class=c1># Effect size</span>
<span class=n>effect_size</span> <span class=o>=</span> <span class=n>proportion_effectsize</span><span class=p>(</span><span class=n>p1</span><span class=p>,</span> <span class=n>p2</span><span class=p>)</span>

<span class=c1># Power analysis</span>
<span class=n>power_analysis</span> <span class=o>=</span> <span class=n>NormalIndPower</span><span class=p>()</span>
<span class=n>n_per_group</span> <span class=o>=</span> <span class=n>power_analysis</span><span class=o>.</span><span class=n>solve_power</span><span class=p>(</span>
    <span class=n>effect_size</span><span class=o>=</span><span class=n>effect_size</span><span class=p>,</span>
    <span class=n>alpha</span><span class=o>=</span><span class=mf>0.05</span><span class=p>,</span>
    <span class=n>power</span><span class=o>=</span><span class=mf>0.80</span><span class=p>,</span>
    <span class=n>ratio</span><span class=o>=</span><span class=mi>1</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Required per group: </span><span class=si>{</span><span class=n>n_per_group</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># ~3,600 per group for 2% lift detection</span>
</code></pre></div> <p><strong>Rule of Thumb:</strong></p> <p>For 80% power, 5% significance: - 1% absolute lift: ~15,000 per group - 2% absolute lift: ~3,800 per group - 5% absolute lift: ~600 per group</p> <p><strong>Factors:</strong></p> <table> <thead> <tr> <th>Factor</th> <th>Effect on n</th> </tr> </thead> <tbody> <tr> <td>Smaller effect ‚Üí</td> <td>Larger n</td> </tr> <tr> <td>Higher power ‚Üí</td> <td>Larger n</td> </tr> <tr> <td>Lower Œ± ‚Üí</td> <td>Larger n</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Experimental design skills.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows key inputs (effect, power, Œ±)</li> <li>Uses standard library for calculation</li> <li>Understands trade-offs</li> <li>Gives practical rule of thumb</li> </ul> </div> </details> <hr> <h3 id=what-is-bayesian-vs-frequentist-probability-google-amazon-interview-question>What is Bayesian vs Frequentist Probability? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Bayesian</code>, <code>Frequentist</code>, <code>Philosophy</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Frequentist:</strong></p> <ul> <li>Probability = long-run frequency</li> <li>Parameters are fixed (unknown constants)</li> <li>Inference via sampling distribution</li> <li>Uses p-values and confidence intervals</li> </ul> <p><strong>Bayesian:</strong></p> <ul> <li>Probability = degree of belief</li> <li>Parameters have distributions</li> <li>Inference via Bayes' theorem</li> <li>Uses posterior and credible intervals</li> </ul> <p><strong>Comparison:</strong></p> <table> <thead> <tr> <th>Aspect</th> <th>Frequentist</th> <th>Bayesian</th> </tr> </thead> <tbody> <tr> <td>Probability</td> <td>Long-run frequency</td> <td>Belief/uncertainty</td> </tr> <tr> <td>Parameters</td> <td>Fixed</td> <td>Random</td> </tr> <tr> <td>Prior info</td> <td>Not used</td> <td>Used explicitly</td> </tr> <tr> <td>Intervals</td> <td>95% CI: "95% of intervals contain true value"</td> <td>95% credible: "95% probability parameter in interval"</td> </tr> </tbody> </table> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Frequentist: p-value</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>ttest_1samp</span>
<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>52</span><span class=p>,</span> <span class=mi>48</span><span class=p>,</span> <span class=mi>55</span><span class=p>,</span> <span class=mi>49</span><span class=p>,</span> <span class=mi>51</span><span class=p>]</span>
<span class=n>t_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>ttest_1samp</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>

<span class=c1># Bayesian: posterior</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pymc</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pm</span>
<span class=k>with</span> <span class=n>pm</span><span class=o>.</span><span class=n>Model</span><span class=p>():</span>
    <span class=n>mu</span> <span class=o>=</span> <span class=n>pm</span><span class=o>.</span><span class=n>Normal</span><span class=p>(</span><span class=s1>&#39;mu&#39;</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>sigma</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>  <span class=c1># Prior</span>
    <span class=n>obs</span> <span class=o>=</span> <span class=n>pm</span><span class=o>.</span><span class=n>Normal</span><span class=p>(</span><span class=s1>&#39;obs&#39;</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=n>mu</span><span class=p>,</span> <span class=n>sigma</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>observed</span><span class=o>=</span><span class=n>data</span><span class=p>)</span>
    <span class=n>trace</span> <span class=o>=</span> <span class=n>pm</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=mi>1000</span><span class=p>)</span>
<span class=c1># 95% credible interval from posterior</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Statistical philosophy understanding.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Explains both paradigms fairly</li> <li>Knows interval interpretation difference</li> <li>Mentions when each is preferred</li> <li>Doesn't dogmatically favor one</li> </ul> </div> </details> <hr> <h3 id=what-is-the-multiple-comparisons-problem-google-meta-interview-question>What is the Multiple Comparisons Problem? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Multiple Testing</code>, <code>FWER</code>, <code>FDR</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>The Problem:</strong></p> <p>With many tests at Œ±=0.05, false positives accumulate:</p> <p>P(at least 1 false positive) = 1 - (1-Œ±)‚Åø</p> <ul> <li>20 tests: 64% chance of false positive</li> <li>100 tests: 99.4% chance!</li> </ul> <p><strong>Solutions:</strong></p> <p><strong>1. Bonferroni Correction (FWER):</strong></p> <p>Use Œ±/n for each test:</p> <div class=highlight><pre><span></span><code><span class=n>n_tests</span> <span class=o>=</span> <span class=mi>20</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>
<span class=n>bonferroni_alpha</span> <span class=o>=</span> <span class=n>alpha</span> <span class=o>/</span> <span class=n>n_tests</span>  <span class=c1># 0.0025</span>
</code></pre></div> <p>Conservative but controls family-wise error rate.</p> <p><strong>2. Benjamini-Hochberg (FDR):</strong></p> <p>Controls false discovery rate:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>false_discovery_control</span>

<span class=n>p_values</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.008</span><span class=p>,</span> <span class=mf>0.012</span><span class=p>,</span> <span class=mf>0.045</span><span class=p>,</span> <span class=mf>0.060</span><span class=p>,</span> <span class=mf>0.120</span><span class=p>]</span>

<span class=c1># Adjust p-values</span>
<span class=n>adjusted</span> <span class=o>=</span> <span class=n>false_discovery_control</span><span class=p>(</span><span class=n>p_values</span><span class=p>,</span> <span class=n>method</span><span class=o>=</span><span class=s1>&#39;bh&#39;</span><span class=p>)</span>

<span class=c1># Or manually:</span>
<span class=n>sorted_p</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>
<span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>p</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>sorted_p</span><span class=p>):</span>
    <span class=n>threshold</span> <span class=o>=</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span> <span class=o>*</span> <span class=n>alpha</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p=</span><span class=si>{</span><span class=n>p</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, threshold=</span><span class=si>{</span><span class=n>threshold</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>When to Use:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td>No correction</td> <td>Single pre-specified test</td> </tr> <tr> <td>Bonferroni</td> <td>Few tests, must avoid any FP</td> </tr> <tr> <td>BH</td> <td>Many tests, some FP acceptable</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Rigorous testing knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Explains why it's a problem</li> <li>Knows Bonferroni is conservative</li> <li>Uses FDR for exploratory analysis</li> <li>Applies to A/B testing scenarios</li> </ul> </div> </details> <hr> <h3 id=what-is-bootstrap-sampling-google-amazon-interview-question>What is Bootstrap Sampling? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Bootstrap</code>, <code>Resampling</code>, <code>Non-parametric</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Bootstrap:</strong></p> <p>Resampling with replacement to estimate sampling distribution.</p> <p><strong>Process:</strong></p> <ol> <li>Draw n samples with replacement from data</li> <li>Calculate statistic of interest</li> <li>Repeat B times (e.g., 10,000)</li> <li>Use distribution of statistics for inference</li> </ol> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>25</span><span class=p>]</span>
<span class=n>n_bootstrap</span> <span class=o>=</span> <span class=mi>10000</span>

<span class=c1># Bootstrap confidence interval for mean</span>
<span class=n>bootstrap_means</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_bootstrap</span><span class=p>):</span>
    <span class=n>sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>),</span> <span class=n>replace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=n>bootstrap_means</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>sample</span><span class=p>))</span>

<span class=c1># 95% CI (percentile method)</span>
<span class=n>ci_lower</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>bootstrap_means</span><span class=p>,</span> <span class=mf>2.5</span><span class=p>)</span>
<span class=n>ci_upper</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>bootstrap_means</span><span class=p>,</span> <span class=mf>97.5</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: (</span><span class=si>{</span><span class=n>ci_lower</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci_upper</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Use Cases:</strong></p> <ul> <li>Confidence intervals for any statistic</li> <li>Estimating standard errors</li> <li>When distribution unknown</li> <li>Complex statistics (median, ratios)</li> </ul> <p><strong>Types:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>Percentile</td> <td>Use quantiles directly</td> </tr> <tr> <td>Basic</td> <td>Reflect around estimate</td> </tr> <tr> <td>BCa</td> <td>Bias-corrected accelerated</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Modern statistical methods.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows to resample WITH replacement</li> <li>Uses for non-standard statistics</li> <li>Knows different CI methods</li> <li>Mentions computational cost</li> </ul> </div> </details> <hr> <h3 id=average-score-on-a-dice-role-of-at-most-3-times>Average score on a dice role of at most 3 times</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Probability</code>, <code>Expected Value</code>, <code>Game Theory</code> | <strong>Asked by:</strong> Jane Street, Hudson River Trading, Citadel</p> <details class=question> <summary>Full Question</summary> <p>Consider a fair 6-sided dice. Your aim is to get the highest score you can, in at-most 3 roles.</p> <p>A score is defined as the number that appears on the face of the dice facing up after the role. You can role at most 3 times but every time you role it is up to you to decide whether you want to role again.</p> <p>The last score will be counted as your final score.</p> <ul> <li>Find the average score if you rolled the dice only once?</li> <li>Find the average score that you can get with at most 3 roles?</li> <li>If the dice is fair, why is the average score for at most 3 roles and 1 role not the same?</li> </ul> </details> <details class=info> <summary>Hint 1</summary> <p>Find what is the expected score on single role</p> <p>And for cases when scores of single role &lt; <code>expected score on single role</code> is when you will go for next role</p> <p>Eg: if expected score of single role comes out to be 4.5, you will only role next turn for 1,2,3,4 and not for 5,6</p> </details> <details class=success> <summary>Answer</summary> <p>If you role a fair dice once you can get:</p> <table> <thead> <tr> <th style="text-align: center;">Score</th> <th style="text-align: center;">Probability</th> </tr> </thead> <tbody> <tr> <td style="text-align: center;">1</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">2</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">3</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">4</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">5</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">6</td> <td style="text-align: center;">&#8537;</td> </tr> </tbody> </table> <p>So your average score with one role is: </p> <p><code>sum of(score * scores's probability)</code> = (1+2+3+4+5+6)*(&#8537;) = (21/6) = 3.5</p> <p><strong>The average score if you rolled the dice only once is 3.5</strong></p> <p>For at most 3 roles, let's try back-tracking. Let's say just did your second role and you have to decide whether to do your 3<sup>rd</sup> role!</p> <p>We just found out if we role dice once on average we can expect score of 3.5. So we will only role the 3<sup>rd</sup> time if score on 2<sup>nd</sup> role is less than 3.5 i.e (1,2 or 3)</p> <p>Possibilities</p> <table> <thead> <tr> <th style="text-align: center;">2<sup>nd</sup> role score</th> <th style="text-align: center;">Probability</th> <th style="text-align: center;">3<sup>rd</sup> role score</th> <th style="text-align: center;">Probability</th> </tr> </thead> <tbody> <tr> <td style="text-align: center;">1</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">3.5</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">2</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">3.5</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">3</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">3.5</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">4</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">We won't role</td> </tr> <tr> <td style="text-align: center;">5</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">3<sup>rd</sup> time if we</td> </tr> <tr> <td style="text-align: center;">6</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">get score &gt;3 on 2<sup>nd</sup></td> </tr> </tbody> </table> <p>So if we had 2 roles, average score would be:</p> <div class=highlight><pre><span></span><code>[We role again if current score is less than 3.4]
(3.5)*(1/6) + (3.5)*(1/6) + (3.5)*(1/6) 
+
(4)*(1/6) + (5)*(1/6) + (6)*(1/6) [Decide not to role again]
=
1.75 + 2.5 = 4.25
</code></pre></div> <p>The average score if you rolled the dice twice is 4.25</p> <p>So now if we look from the perspective of first role. We will only role again if our score is less than 4.25 i.e 1,2,3 or 4</p> <p>Possibilities</p> <table> <thead> <tr> <th style="text-align: center;">1<sup>st</sup> role score</th> <th style="text-align: center;">Probability</th> <th style="text-align: center;">2<sup>nd</sup> role score (Exp)</th> <th style="text-align: center;">Probability/Note</th> </tr> </thead> <tbody> <tr> <td style="text-align: center;">1</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">4.25</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">2</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">4.25</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">3</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">4.25</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">4</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">4.25</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">5</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">We won't role again if we</td> </tr> <tr> <td style="text-align: center;">6</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">get score &gt;4.25 on 1<sup>st</sup></td> </tr> </tbody> </table> <p>So if we had 3 roles, average score would be:</p> <p><div class=highlight><pre><span></span><code>[We role again if current score is less than 4.25]
(4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) 
+
(5)*(1/6) + (6)*(1/6) [[Decide not to role again]
=
17/6 + 11/6 = 4.66
</code></pre></div> <strong>The average score if you rolled the dice only once is 4.66</strong></p> <p>The average score for at most 3 roles and 1 role is not the same because although the dice is fair the event of rolling the dice is no longer <strong>independent</strong>. The scores would have been the same if we rolled the dice 2<sup>nd</sup> and 3<sup>rd</sup> time without considering what we got in the last roll i.e. if the event of rolling the dice was independent.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Optimal stopping and backward induction.</p> </div> </details> <h3 id=explain-the-coupon-collector-problem-google-amazon-interview-question>Explain the Coupon Collector Problem - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Coupon Collector</code>, <code>Expected Value</code>, <code>Puzzle</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Problem:</strong></p> <p>How many items to collect before getting all n types? (Each type equally likely)</p> <p><strong>Expected Value:</strong></p> <div class=arithmatex>\[E[T] = n \cdot H_n = n \cdot \sum_{i=1}^{n} \frac{1}{i}\]</div> <p>where H‚Çô is the nth harmonic number.</p> <p><strong>Intuition:</strong></p> <p>After collecting k types, expected trials until new type = n/(n-k)</p> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>def</span><span class=w> </span><span class=nf>expected_trials</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Expected trials to collect all n types&quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=n>n</span> <span class=o>*</span> <span class=nb>sum</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span>

<span class=c1># 6 types (like Pokemon cards)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[trials]: </span><span class=si>{</span><span class=n>expected_trials</span><span class=p>(</span><span class=mi>6</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># ~14.7</span>

<span class=c1># Simulation</span>
<span class=k>def</span><span class=w> </span><span class=nf>simulate_coupon_collector</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>simulations</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>trials</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>simulations</span><span class=p>):</span>
        <span class=n>collected</span> <span class=o>=</span> <span class=nb>set</span><span class=p>()</span>
        <span class=n>count</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>collected</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>:</span>
            <span class=n>collected</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>
            <span class=n>count</span> <span class=o>+=</span> <span class=mi>1</span>
        <span class=n>trials</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>count</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>trials</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Simulated: </span><span class=si>{</span><span class=n>simulate_coupon_collector</span><span class=p>(</span><span class=mi>6</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Applications:</strong></p> <ul> <li>A/B testing (all user segments)</li> <li>Load testing (all code paths)</li> <li>Collecting rare items</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Probability puzzle solving.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Uses linearity of expectation</li> <li>Knows harmonic series result</li> <li>Can simulate to verify</li> <li>Applies to real scenarios</li> </ul> </div> </details> <hr> <h3 id=what-is-simpsons-paradox-google-meta-interview-question>What is Simpson's Paradox? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Simpson's Paradox</code>, <code>Confounding</code>, <code>Causality</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Simpson's Paradox:</strong></p> <p>Trend appears in subgroups but reverses when combined.</p> <p><strong>Classic Example - UC Berkeley Admissions:</strong></p> <table> <thead> <tr> <th></th> <th>Men Apply</th> <th>Men Admit</th> <th>Women Apply</th> <th>Women Admit</th> </tr> </thead> <tbody> <tr> <td>Overall</td> <td>8,442</td> <td>44%</td> <td>4,321</td> <td>35%</td> </tr> </tbody> </table> <p>Looks like discrimination against women!</p> <p>But by department:</p> <table> <thead> <tr> <th>Dept</th> <th>Men Apply</th> <th>Men %</th> <th>Women Apply</th> <th>Women %</th> </tr> </thead> <tbody> <tr> <td>A</td> <td>825</td> <td>62%</td> <td>108</td> <td>82%</td> </tr> <tr> <td>B</td> <td>560</td> <td>63%</td> <td>25</td> <td>68%</td> </tr> <tr> <td>C</td> <td>325</td> <td>37%</td> <td>593</td> <td>34%</td> </tr> </tbody> </table> <p>Women had HIGHER rates in each department!</p> <p><strong>Cause:</strong></p> <p>Women applied more to competitive departments.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>

<span class=c1># Weighted vs unweighted</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;dept&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;A&#39;</span><span class=p>,</span> <span class=s1>&#39;A&#39;</span><span class=p>,</span> <span class=s1>&#39;B&#39;</span><span class=p>,</span> <span class=s1>&#39;B&#39;</span><span class=p>],</span>
    <span class=s1>&#39;gender&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;M&#39;</span><span class=p>,</span> <span class=s1>&#39;F&#39;</span><span class=p>,</span> <span class=s1>&#39;M&#39;</span><span class=p>,</span> <span class=s1>&#39;F&#39;</span><span class=p>],</span>
    <span class=s1>&#39;applications&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>825</span><span class=p>,</span> <span class=mi>108</span><span class=p>,</span> <span class=mi>560</span><span class=p>,</span> <span class=mi>25</span><span class=p>],</span>
    <span class=s1>&#39;rate&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.62</span><span class=p>,</span> <span class=mf>0.82</span><span class=p>,</span> <span class=mf>0.63</span><span class=p>,</span> <span class=mf>0.68</span><span class=p>]</span>
<span class=p>})</span>

<span class=c1># Department is a confounding variable</span>
</code></pre></div> <p><strong>Lesson:</strong></p> <p>Always consider lurking/confounding variables before drawing conclusions.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Critical thinking about data.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Gives clear example</li> <li>Identifies confounding variable</li> <li>Knows when to aggregate vs stratify</li> <li>Relates to A/B testing concerns</li> </ul> </div> </details> <hr> <h3 id=what-are-quantiles-and-percentiles-most-tech-companies-interview-question>What Are Quantiles and Percentiles? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Quantiles</code>, <code>Percentiles</code>, <code>Descriptive</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Definitions:</strong></p> <ul> <li>Quantile: Values dividing distribution into intervals</li> <li>Percentile: Quantile expressed as percentage</li> <li>P-th percentile: Value below which P% of data falls</li> </ul> <p><strong>Common Quantiles:</strong></p> <table> <thead> <tr> <th>Name</th> <th>Divides Into</th> </tr> </thead> <tbody> <tr> <td>Median (Q2)</td> <td>2 equal parts</td> </tr> <tr> <td>Quartiles (Q1, Q2, Q3)</td> <td>4 equal parts</td> </tr> <tr> <td>Deciles</td> <td>10 equal parts</td> </tr> <tr> <td>Percentiles</td> <td>100 equal parts</td> </tr> </tbody> </table> <p><strong>Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>40</span><span class=p>]</span>

<span class=c1># Percentiles</span>
<span class=n>p25</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>25</span><span class=p>)</span>  <span class=c1># Q1</span>
<span class=n>p50</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>  <span class=c1># Median</span>
<span class=n>p75</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>75</span><span class=p>)</span>  <span class=c1># Q3</span>
<span class=n>p90</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>90</span><span class=p>)</span>  <span class=c1># 90th percentile</span>

<span class=c1># IQR (Interquartile Range)</span>
<span class=n>iqr</span> <span class=o>=</span> <span class=n>p75</span> <span class=o>-</span> <span class=n>p25</span>
</code></pre></div> <p><strong>Uses:</strong></p> <ul> <li>Latency: "p99 response time &lt; 100ms"</li> <li>Salaries: "In top 10% earners"</li> <li>Outlier detection: Beyond 1.5*IQR</li> </ul> <p><strong>Z-score to Percentile:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>norm</span>

<span class=c1># Z = 1.645 ‚Üí 95th percentile</span>
<span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mf>1.645</span><span class=p>)</span>  <span class=c1># ‚âà 0.95</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Basic statistical literacy.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows p50 = median</li> <li>Uses for SLA metrics</li> <li>Can convert z-scores to percentiles</li> <li>Understands IQR for robustness</li> </ul> </div> </details> <hr> <h3 id=what-is-the-difference-between-standard-deviation-and-standard-error-google-amazon-interview-question>What is the Difference Between Standard Deviation and Standard Error? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Standard Deviation</code>, <code>Standard Error</code>, <code>Sampling</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Standard Deviation (SD):</strong></p> <p>Measures spread of individual observations:</p> <div class=arithmatex>\[SD = \sqrt{\frac{\sum(x_i - \bar{x})^2}{n-1}}\]</div> <p><strong>Standard Error (SE):</strong></p> <p>Measures uncertainty in sample mean:</p> <div class=arithmatex>\[SE = \frac{SD}{\sqrt{n}}\]</div> <p><strong>Key Difference:</strong></p> <table> <thead> <tr> <th>SD</th> <th>SE</th> </tr> </thead> <tbody> <tr> <td>Describes data spread</td> <td>Describes estimate precision</td> </tr> <tr> <td>Doesn't depend on n (conceptually)</td> <td>Decreases with larger n</td> </tr> <tr> <td>Used for z-scores</td> <td>Used for confidence intervals</td> </tr> </tbody> </table> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>sem</span>

<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>]</span>

<span class=n>sd</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># Sample SD</span>
<span class=n>se</span> <span class=o>=</span> <span class=n>sem</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  <span class=c1># Standard error of mean</span>
<span class=c1># or se = sd / np.sqrt(len(data))</span>

<span class=n>mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=c1># 95% CI using SE</span>
<span class=n>ci</span> <span class=o>=</span> <span class=p>(</span><span class=n>mean</span> <span class=o>-</span> <span class=mf>1.96</span><span class=o>*</span><span class=n>se</span><span class=p>,</span> <span class=n>mean</span> <span class=o>+</span> <span class=mf>1.96</span><span class=o>*</span><span class=n>se</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;SD: </span><span class=si>{</span><span class=n>sd</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>   <span class=c1># ~2.21</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;SE: </span><span class=si>{</span><span class=n>se</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>   <span class=c1># ~0.70</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: </span><span class=si>{</span><span class=n>ci</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Intuition:</strong></p> <ul> <li>SD: "Typical distance of point from mean"</li> <li>SE: "Typical error in our estimate of the mean"</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Sampling variability understanding.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Clearly distinguishes the two concepts</li> <li>Knows SE = SD/‚àön</li> <li>Uses SE for confidence intervals</li> <li>Knows SE decreases with n</li> </ul> </div> </details> <hr> <h3 id=what-is-moment-generating-function-amazon-microsoft-interview-question>What is Moment Generating Function? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>MGF</code>, <code>Moments</code>, <code>Advanced</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Moment Generating Function (MGF):</strong></p> <div class=arithmatex>\[M_X(t) = E[e^{tX}] = \sum_x e^{tx} P(X=x)\]</div> <p><strong>Why "Moment Generating"?</strong></p> <p>nth moment = nth derivative at t=0:</p> <div class=arithmatex>\[E[X^n] = M_X^{(n)}(0)\]</div> <p><strong>Properties:</strong></p> <ol> <li>Uniquely determines distribution</li> <li>Sum of independent RVs: MGF = product of MGFs</li> <li>Linear transform: M_{aX+b}(t) = e^{bt} M_X(at)</li> </ol> <p><strong>Examples:</strong></p> <table> <thead> <tr> <th>Distribution</th> <th>MGF</th> </tr> </thead> <tbody> <tr> <td>Normal(Œº,œÉ¬≤)</td> <td>exp(Œºt + œÉ¬≤t¬≤/2)</td> </tr> <tr> <td>Exponential(Œª)</td> <td>Œª/(Œª-t) for t &lt; Œª</td> </tr> <tr> <td>Poisson(Œª)</td> <td>exp(Œª(e·µó-1))</td> </tr> <tr> <td>Binomial(n,p)</td> <td>(1-p+pe·µó)‚Åø</td> </tr> </tbody> </table> <p><strong>Deriving Moments:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># For Exponential(Œª=2): M(t) = 2/(2-t)</span>
<span class=c1># E[X] = M&#39;(0) = 2/(2-0)¬≤ = 1/2</span>
<span class=c1># E[X¬≤] = M&#39;&#39;(0) = 4/(2-0)¬≥ = 1/2</span>
<span class=c1># Var(X) = E[X¬≤] - (E[X])¬≤ = 1/2 - 1/4 = 1/4</span>
</code></pre></div> <p><strong>Application:</strong></p> <p>Proving CLT: MGF of sum ‚Üí MGF of normal</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced probability theory.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows moment derivation via derivatives</li> <li>Uses for proving sum distributions</li> <li>Knows MGF uniquely identifies distribution</li> <li>Can derive simple moments</li> </ul> </div> </details> <hr> <h3 id=what-is-the-waiting-time-paradox-google-amazon-interview-question>What is the Waiting Time Paradox? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Waiting Time</code>, <code>Inspection Paradox</code>, <code>Counter-intuitive</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>The Paradox:</strong></p> <p>Average wait for a bus can exceed half the average interval!</p> <p><strong>Explanation:</strong></p> <p>You're more likely to arrive during a LONG interval than a short one.</p> <p><strong>Mathematical:</strong></p> <p>For Poisson arrivals (rate Œª): - Average interval: 1/Œª - Expected wait: 1/Œª (same as full interval!)</p> <p>Due to memoryless property.</p> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Buses every 10 minutes on average (Poisson)</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mf>0.1</span>  <span class=c1># per minute</span>

<span class=c1># Simulate arrivals</span>
<span class=n>n_buses</span> <span class=o>=</span> <span class=mi>10000</span>
<span class=n>intervals</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>,</span> <span class=n>n_buses</span><span class=p>)</span>

<span class=c1># Arrive at random time within each interval</span>
<span class=n>random_fraction</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n_buses</span><span class=p>)</span>
<span class=n>wait_times</span> <span class=o>=</span> <span class=n>intervals</span> <span class=o>*</span> <span class=n>random_fraction</span>

<span class=n>avg_wait</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>wait_times</span><span class=p>)</span>
<span class=n>avg_interval</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>intervals</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Avg interval: </span><span class=si>{</span><span class=n>avg_interval</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> min&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Avg wait: </span><span class=si>{</span><span class=n>avg_wait</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> min&quot;</span><span class=p>)</span>
<span class=c1># Both approximately 10 minutes!</span>
</code></pre></div> <p><strong>Real-World:</strong></p> <p>If buses are scheduled (not Poisson), wait ‚âà interval/2. But with variability, wait increases due to "length-biased sampling."</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Counter-intuitive probability.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Explains length-biased sampling</li> <li>Connects to memoryless property</li> <li>Can simulate to demonstrate</li> <li>Knows scheduled vs random arrivals differ</li> </ul> </div> </details> <hr> <h3 id=how-do-you-estimate-probability-from-rare-events-google-amazon-interview-question>How Do You Estimate Probability from Rare Events? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Rare Events</code>, <code>Estimation</code>, <code>Confidence</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>The Challenge:</strong></p> <p>0 events in n trials. Is probability really 0?</p> <p><strong>Rule of Three:</strong></p> <p>If 0 events in n trials, 95% confident p &lt; 3/n</p> <div class=highlight><pre><span></span><code><span class=n>n</span> <span class=o>=</span> <span class=mi>1000</span>  <span class=c1># trials</span>
<span class=n>events</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># observed</span>

<span class=c1># 95% upper bound</span>
<span class=n>upper_bound</span> <span class=o>=</span> <span class=mi>3</span> <span class=o>/</span> <span class=n>n</span>  <span class=c1># 0.003 or 0.3%</span>
</code></pre></div> <p><strong>Bayesian Approach:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>beta</span>

<span class=c1># Prior: Beta(1, 1) = Uniform</span>
<span class=c1># Posterior: Beta(1 + k, 1 + n - k)</span>

<span class=n>n</span><span class=p>,</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>1000</span><span class=p>,</span> <span class=mi>0</span>
<span class=n>posterior</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>k</span><span class=p>,</span> <span class=mi>1</span> <span class=o>+</span> <span class=n>n</span> <span class=o>-</span> <span class=n>k</span><span class=p>)</span>

<span class=c1># 95% credible interval</span>
<span class=n>ci</span> <span class=o>=</span> <span class=n>posterior</span><span class=o>.</span><span class=n>interval</span><span class=p>(</span><span class=mf>0.95</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: (</span><span class=si>{</span><span class=n>ci</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s2>.5f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.5f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
<span class=c1># (0.0, 0.003)</span>

<span class=c1># With 3 events in 1000:</span>
<span class=n>posterior</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span> <span class=o>+</span> <span class=mi>1000</span> <span class=o>-</span> <span class=mi>3</span><span class=p>)</span>
<span class=n>mean_estimate</span> <span class=o>=</span> <span class=n>posterior</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># ‚âà 0.004</span>
</code></pre></div> <p><strong>Methods Comparison:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Estimate</th> <th>CI</th> </tr> </thead> <tbody> <tr> <td>MLE (k/n)</td> <td>0</td> <td>Undefined</td> </tr> <tr> <td>Rule of 3</td> <td>-</td> <td>(0, 0.003)</td> </tr> <tr> <td>Bayesian</td> <td>0.001</td> <td>(0, 0.003)</td> </tr> <tr> <td>Wilson</td> <td>0.0002</td> <td>(0, 0.002)</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Practical estimation skills.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows Rule of Three for quick bounds</li> <li>Uses Bayesian for proper intervals</li> <li>Doesn't report 0 as point estimate</li> <li>Mentions sample size requirements</li> </ul> </div> </details> <hr> <h2 id=quick-reference-100-interview-questions>Quick Reference: 100+ Interview Questions</h2> <table> <thead> <tr> <th>Sno</th> <th>Question Title</th> <th>Practice Links</th> <th>Companies Asking</th> <th>Difficulty</th> <th>Topics</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>Basic Probability Concepts: Definitions of Sample Space, Event, Outcome</td> <td><a href=https://en.wikipedia.org/wiki/Probability>Wikipedia: Probability</a></td> <td>Google, Amazon, Microsoft</td> <td>Easy</td> <td>Fundamental Concepts</td> </tr> <tr> <td>2</td> <td>Conditional Probability and Independence</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Conditional Probability</a></td> <td>Google, Facebook, Amazon</td> <td>Medium</td> <td>Conditional Probability, Independence</td> </tr> <tr> <td>3</td> <td>Bayes‚Äô Theorem: Statement and Application</td> <td><a href=https://en.wikipedia.org/wiki/Bayes%27_theorem>Wikipedia: Bayes' Theorem</a></td> <td>Google, Amazon, Microsoft</td> <td>Medium</td> <td>Bayesian Inference</td> </tr> <tr> <td>4</td> <td>Law of Total Probability</td> <td><a href=https://en.wikipedia.org/wiki/Law_of_total_probability>Wikipedia: Law of Total Probability</a></td> <td>Google, Facebook</td> <td>Medium</td> <td>Theoretical Probability</td> </tr> <tr> <td>5</td> <td>Expected Value and Variance</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Expected Value</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Random Variables, Moments</td> </tr> <tr> <td>6</td> <td>Probability Distributions: Discrete vs. Continuous</td> <td><a href=https://en.wikipedia.org/wiki/Probability_distribution>Wikipedia: Probability Distribution</a></td> <td>Google, Amazon, Microsoft</td> <td>Easy</td> <td>Distributions</td> </tr> <tr> <td>7</td> <td>Binomial Distribution: Definition and Applications</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library>Khan Academy: Binomial Distribution</a></td> <td>Amazon, Facebook</td> <td>Medium</td> <td>Discrete Distributions</td> </tr> <tr> <td>8</td> <td>Poisson Distribution: Characteristics and Uses</td> <td><a href=https://en.wikipedia.org/wiki/Poisson_distribution>Wikipedia: Poisson Distribution</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Discrete Distributions</td> </tr> <tr> <td>9</td> <td>Exponential Distribution: Properties and Applications</td> <td><a href=https://en.wikipedia.org/wiki/Exponential_distribution>Wikipedia: Exponential Distribution</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Continuous Distributions</td> </tr> <tr> <td>10</td> <td>Normal Distribution and the Central Limit Theorem</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data>Khan Academy: Normal Distribution</a></td> <td>Google, Microsoft, Facebook</td> <td>Medium</td> <td>Continuous Distributions, CLT</td> </tr> <tr> <td>11</td> <td>Law of Large Numbers</td> <td><a href=https://en.wikipedia.org/wiki/Law_of_large_numbers>Wikipedia: Law of Large Numbers</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Statistical Convergence</td> </tr> <tr> <td>12</td> <td>Covariance and Correlation: Definitions and Differences</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitatively>Khan Academy: Covariance and Correlation</a></td> <td>Google, Facebook</td> <td>Medium</td> <td>Statistics, Dependency</td> </tr> <tr> <td>13</td> <td>Moment Generating Functions (MGFs)</td> <td><a href=https://en.wikipedia.org/wiki/Moment-generating_function>Wikipedia: Moment-generating function</a></td> <td>Amazon, Microsoft</td> <td>Hard</td> <td>Random Variables, Advanced Concepts</td> </tr> <tr> <td>14</td> <td>Markov Chains: Basics and Applications</td> <td><a href=https://en.wikipedia.org/wiki/Markov_chain>Wikipedia: Markov chain</a></td> <td>Google, Amazon, Facebook</td> <td>Hard</td> <td>Stochastic Processes</td> </tr> <tr> <td>15</td> <td>Introduction to Stochastic Processes</td> <td><a href=https://en.wikipedia.org/wiki/Stochastic_process>Wikipedia: Stochastic process</a></td> <td>Google, Microsoft</td> <td>Hard</td> <td>Advanced Probability</td> </tr> <tr> <td>16</td> <td>Difference Between Independent and Mutually Exclusive Events</td> <td><a href=https://en.wikipedia.org/wiki/Independence_(probability_theory)>Wikipedia: Independent events</a></td> <td>Google, Facebook</td> <td>Easy</td> <td>Fundamental Concepts</td> </tr> <tr> <td>17</td> <td>Geometric Distribution: Concept and Use Cases</td> <td><a href=https://en.wikipedia.org/wiki/Geometric_distribution>Wikipedia: Geometric distribution</a></td> <td>Amazon, Microsoft</td> <td>Medium</td> <td>Discrete Distributions</td> </tr> <tr> <td>18</td> <td>Hypergeometric Distribution: When to Use It</td> <td><a href=https://en.wikipedia.org/wiki/Hypergeometric_distribution>Wikipedia: Hypergeometric distribution</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Discrete Distributions</td> </tr> <tr> <td>19</td> <td>Confidence Intervals: Definition and Calculation</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/confidence-intervals>Khan Academy: Confidence intervals</a></td> <td>Microsoft, Facebook</td> <td>Medium</td> <td>Inferential Statistics</td> </tr> <tr> <td>20</td> <td>Hypothesis Testing: p-values, Type I and Type II Errors</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/significance-tests>Khan Academy: Hypothesis testing</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Inferential Statistics</td> </tr> <tr> <td>21</td> <td>Chi-Squared Test: Basics and Applications</td> <td><a href=https://en.wikipedia.org/wiki/Chi-squared_test>Wikipedia: Chi-squared test</a></td> <td>Amazon, Microsoft</td> <td>Medium</td> <td>Inferential Statistics</td> </tr> <tr> <td>22</td> <td>Permutations and Combinations</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Permutations and Combinations</a></td> <td>Google, Facebook</td> <td>Easy</td> <td>Combinatorics</td> </tr> <tr> <td>23</td> <td>The Birthday Problem and Its Implications</td> <td><a href=https://en.wikipedia.org/wiki/Birthday_problem>Wikipedia: Birthday problem</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Probability Puzzles</td> </tr> <tr> <td>24</td> <td>The Monty Hall Problem</td> <td><a href=https://en.wikipedia.org/wiki/Monty_Hall_problem>Wikipedia: Monty Hall problem</a></td> <td>Google, Facebook</td> <td>Medium</td> <td>Probability Puzzles, Conditional Probability</td> </tr> <tr> <td>25</td> <td>Marginal vs. Conditional Probabilities</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Conditional Probability</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Theoretical Concepts</td> </tr> <tr> <td>26</td> <td>Real-World Application of Bayes‚Äô Theorem</td> <td><a href=https://towardsdatascience.com/bayes-theorem-in-machine-learning-6a8b5e9ad0f3>Towards Data Science: Bayes‚Äô Theorem Applications</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Bayesian Inference</td> </tr> <tr> <td>27</td> <td>Probability Mass Function (PMF) vs. Probability Density Function (PDF)</td> <td><a href=https://en.wikipedia.org/wiki/Probability_density_function>Wikipedia: Probability density function</a></td> <td>Amazon, Facebook</td> <td>Medium</td> <td>Distributions</td> </tr> <tr> <td>28</td> <td>Cumulative Distribution Function (CDF): Definition and Uses</td> <td><a href=https://en.wikipedia.org/wiki/Cumulative_distribution_function>Wikipedia: Cumulative distribution function</a></td> <td>Google, Microsoft</td> <td>Medium</td> <td>Distributions</td> </tr> <tr> <td>29</td> <td>Determining Independence of Events</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Independent Events</a></td> <td>Google, Amazon</td> <td>Easy</td> <td>Fundamental Concepts</td> </tr> <tr> <td>30</td> <td>Entropy in Information Theory</td> <td><a href=https://en.wikipedia.org/wiki/Entropy_(information_theory)>Wikipedia: Entropy (information theory)</a></td> <td>Google, Facebook</td> <td>Hard</td> <td>Information Theory, Probability</td> </tr> <tr> <td>31</td> <td>Joint Probability Distributions</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Joint Probability</a></td> <td>Microsoft, Amazon</td> <td>Medium</td> <td>Multivariate Distributions</td> </tr> <tr> <td>32</td> <td>Conditional Expectation</td> <td><a href=https://en.wikipedia.org/wiki/Conditional_expectation>Wikipedia: Conditional expectation</a></td> <td>Google, Facebook</td> <td>Hard</td> <td>Advanced Concepts</td> </tr> <tr> <td>33</td> <td>Sampling Methods: With and Without Replacement</td> <td><a href=https://www.khanacademy.org/math/statistics-probability>Khan Academy: Sampling</a></td> <td>Amazon, Microsoft</td> <td>Easy</td> <td>Sampling, Combinatorics</td> </tr> <tr> <td>34</td> <td>Risk Modeling Using Probability</td> <td><a href=https://www.investopedia.com/terms/r/risk-analysis.asp>Investopedia: Risk Analysis</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Applications, Finance</td> </tr> <tr> <td>35</td> <td>In-Depth: Central Limit Theorem and Its Importance</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data>Khan Academy: Central Limit Theorem</a></td> <td>Google, Microsoft</td> <td>Medium</td> <td>Theoretical Concepts, Distributions</td> </tr> <tr> <td>36</td> <td>Variance under Linear Transformations</td> <td><a href=https://en.wikipedia.org/wiki/Variance>Wikipedia: Variance</a></td> <td>Amazon, Facebook</td> <td>Hard</td> <td>Advanced Statistics</td> </tr> <tr> <td>37</td> <td>Quantiles: Definition and Interpretation</td> <td><a href=https://www.khanacademy.org/math/statistics-probability>Khan Academy: Percentiles</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Descriptive Statistics</td> </tr> <tr> <td>38</td> <td>Common Probability Puzzles and Brain Teasers</td> <td><a href=https://brilliant.org/wiki/probability/ >Brilliant.org: Probability Puzzles</a></td> <td>Google, Facebook</td> <td>Medium</td> <td>Puzzles, Recreational Mathematics</td> </tr> <tr> <td>39</td> <td>Real-World Applications of Probability in Data Science</td> <td><a href=https://towardsdatascience.com/ >Towards Data Science</a> <em>(Search for probability applications in DS)</em></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Applications, Data Science</td> </tr> <tr> <td>40</td> <td>Advanced Topic: Introduction to Stochastic Calculus</td> <td><a href=https://en.wikipedia.org/wiki/Stochastic_calculus>Wikipedia: Stochastic calculus</a></td> <td>Microsoft, Amazon</td> <td>Hard</td> <td>Advanced Probability, Finance</td> </tr> </tbody> </table> <hr> <h2 id=questions-asked-in-google-interview>Questions asked in Google interview</h2> <ul> <li>Bayes‚Äô Theorem: Statement and Application </li> <li>Conditional Probability and Independence </li> <li>The Birthday Problem </li> <li>The Monty Hall Problem </li> <li>Normal Distribution and the Central Limit Theorem </li> <li>Law of Large Numbers </li> </ul> <h2 id=questions-asked-in-facebook-interview>Questions asked in Facebook interview</h2> <ul> <li>Conditional Probability and Independence </li> <li>Bayes‚Äô Theorem </li> <li>Chi-Squared Test </li> <li>The Monty Hall Problem </li> <li>Entropy in Information Theory </li> </ul> <h2 id=questions-asked-in-amazon-interview>Questions asked in Amazon interview</h2> <ul> <li>Basic Probability Concepts </li> <li>Bayes‚Äô Theorem </li> <li>Expected Value and Variance </li> <li>Binomial and Poisson Distributions </li> <li>Permutations and Combinations </li> <li>Real-World Applications of Bayes‚Äô Theorem </li> </ul> <h2 id=questions-asked-in-microsoft-interview>Questions asked in Microsoft interview</h2> <ul> <li>Bayes‚Äô Theorem </li> <li>Markov Chains </li> <li>Stochastic Processes </li> <li>Central Limit Theorem </li> <li>Variance under Linear Transformations </li> </ul> <hr> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2020 - <script>document.write(/\d{4}/.exec(Date())[0])</script> ‚Ä¢ <strong>Kuldeep Singh Sidhu</strong> ‚Ä¢ <u><a href=https://choosealicense.com/licenses/agpl-3.0/ target=‚Äù_blank‚Äù>License</a></u> ‚Ä¢ <u><a href=/privacy>Privacy Policy</a></u> ‚Ä¢ <u><a href=/contact>Contact</a></u> ‚Ä¢ </div> </div> <div class=md-social> <a href=https://github.com/singhsidhukuldeep/ target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M8 0c4.42 0 8 3.58 8 8a8.01 8.01 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27s-1.36.09-2 .27c-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8"/></svg> </a> <a href=https://linkedin.com/in/singhsidhukuldeep target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href=https://twitter.com/kuldeep_s_s target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> <a href=https://stackoverflow.com/u/7182350/ target=_blank rel=noopener title=stackoverflow.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 384 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M290.7 311 95 269.7 86.8 309l195.7 41zm51-87L188.2 95.7l-25.5 30.8 153.5 128.3zm-31.2 39.7L129.2 179l-16.7 36.5L293.7 300zM262 32l-32 24 119.3 160.3 32-24zm20.5 328h-200v39.7h200zm39.7 80H42.7V320h-40v160h359.5V320h-40z"/></svg> </a> <a href=https://huggingface.co/singhsidhukuldeep target=_blank rel=noopener title=huggingface.co class=md-social__link> <svg width=500 height=463 viewbox="0 0 500 463" fill=none xmlns=http://www.w3.org/2000/svg> <path fill=white d="M496.592 369.699C500.563 381.093 499.61 393.227 494.315 403.778C490.503 411.48 485.05 417.441 478.379 422.769C470.331 429.099 460.324 434.48 448.253 439.65C433.852 445.77 416.274 451.52 408.226 453.63C387.63 458.958 367.829 462.334 347.762 462.493C319.066 462.756 294.34 456.004 276.762 438.753C267.656 439.861 258.443 440.494 249.178 440.494C240.389 440.494 231.706 439.967 223.076 438.912C205.445 456.057 180.825 462.756 152.234 462.493C132.168 462.334 112.366 458.958 91.7177 453.63C83.7229 451.52 66.145 445.77 51.7439 439.65C39.6723 434.48 29.6656 429.099 21.6708 422.769C14.9467 417.441 9.49334 411.48 5.68127 403.778C0.439661 393.227 -0.566304 381.093 3.45755 369.699C-0.248631 360.994 -1.20165 351.024 1.71035 339.998C3.03399 334.987 5.20476 330.344 7.95792 326.229C7.37552 324.067 6.89901 321.851 6.58134 319.424C4.56941 304.97 9.59923 291.781 19.0765 281.547C23.7357 276.43 28.7655 272.895 34.0071 270.627C30.1421 254.273 28.1302 237.445 28.1302 220.247C28.1302 98.5969 127.085 0 249.178 0C291.111 0 330.343 11.6058 363.805 31.8633C369.84 35.5561 375.77 39.5126 381.436 43.7329C384.242 45.8431 387.048 48.006 389.748 50.2744C392.501 52.49 395.201 54.8112 397.796 57.1851C405.632 64.3069 412.991 71.9562 419.715 80.133C421.992 82.8235 424.163 85.6194 426.28 88.4681C430.569 94.1128 434.54 99.9685 438.193 106.035C443.752 115.109 448.623 124.604 452.859 134.469C455.665 141.064 458.101 147.816 460.271 154.727C463.501 165.067 465.99 175.723 467.684 186.696C468.213 190.336 468.69 194.028 469.06 197.721C469.802 205.107 470.225 212.598 470.225 220.247C470.225 237.234 468.213 253.904 464.454 269.994C470.278 272.262 475.784 275.955 480.92 281.547C490.397 291.781 495.427 305.022 493.415 319.477C493.098 321.851 492.621 324.067 492.039 326.229C494.792 330.344 496.963 334.987 498.286 339.998C501.198 351.024 500.245 360.994 496.592 369.699Z"/> <path fill=black d="M433.839 221.75C433.839 120.838 351.531 39.0323 250 39.0323C148.469 39.0323 66.1613 120.838 66.1613 221.75C66.1613 322.662 148.469 404.468 250 404.468C351.531 404.468 433.839 322.662 433.839 221.75ZM45 221.75C45 109.222 136.782 18 250 18C363.218 18 455 109.222 455 221.75C455 334.278 363.218 425.5 250 425.5C136.782 425.5 45 334.278 45 221.75Z"/> <path fill=white d="M250 405.5C352.173 405.5 435 323.232 435 221.75C435 120.268 352.173 38 250 38C147.827 38 65 120.268 65 221.75C65 323.232 147.827 405.5 250 405.5Z"/> <path fill=white d="M202.198 404.174C216.789 383.118 215.755 367.316 195.735 347.627C175.715 327.943 164.062 299.145 164.062 299.145C164.062 299.145 159.709 282.419 149.794 283.958C139.88 285.497 132.6 310.492 153.368 325.783C174.135 341.069 149.232 351.456 141.242 337.099C133.252 322.741 111.435 285.831 100.121 278.772C88.8117 271.713 80.8483 275.668 83.5151 290.218C86.182 304.769 133.48 340.036 128.878 347.668C124.276 355.296 108.058 338.7 108.058 338.7C108.058 338.7 57.3079 293.255 46.2587 305.097C35.2096 316.94 54.641 326.863 82.3328 343.359C110.03 359.85 112.177 364.206 108.248 370.446C104.314 376.685 43.1836 325.971 37.4417 347.47C31.705 368.969 99.8291 375.209 95.6247 390.051C91.4203 404.899 47.6372 361.958 38.6823 378.689C29.7221 395.425 100.465 415.088 101.038 415.234C123.889 421.067 181.924 433.426 202.198 404.174Z"/> <path fill=black d="M90.9935 255C82.4744 255 74.8603 258.477 69.551 264.784C66.2675 268.69 62.8367 274.986 62.5578 284.414C58.985 283.394 55.5489 282.824 52.3391 282.824C44.183 282.824 36.8163 285.93 31.6069 291.573C24.9137 298.815 21.9407 307.715 23.2351 316.62C23.8508 320.861 25.2768 324.663 27.4079 328.182C22.9142 331.795 19.6044 336.826 18.0047 342.876C16.7524 347.619 15.4685 357.497 22.1722 367.673C21.746 368.337 21.3461 369.027 20.9725 369.733C16.9418 377.336 16.684 385.927 20.2411 393.928C25.6346 406.054 39.0368 415.608 65.0625 425.863C81.2536 432.242 96.0661 436.321 96.1976 436.357C117.603 441.874 136.962 444.677 153.721 444.677C184.525 444.677 206.578 435.301 219.27 416.811C239.697 387.036 236.776 359.803 210.346 333.552C195.717 319.026 185.993 297.607 183.967 292.906C179.884 278.986 169.086 263.513 151.138 263.513H151.133C149.622 263.513 148.096 263.633 146.592 263.869C138.73 265.097 131.858 269.595 126.949 276.361C121.65 269.814 116.504 264.606 111.847 261.667C104.827 257.243 97.813 255 90.9935 255ZM90.9935 275.917C93.6771 275.917 96.9553 277.051 100.57 279.331C111.794 286.406 133.452 323.403 141.382 337.793C144.039 342.614 148.581 344.654 152.669 344.654C160.783 344.654 167.118 336.638 153.411 326.451C132.8 311.124 140.03 286.072 149.87 284.529C150.301 284.461 150.727 284.43 151.138 284.43C160.083 284.43 164.03 299.751 164.03 299.751C164.03 299.751 175.595 328.616 195.465 348.346C215.334 368.08 216.36 383.919 201.879 405.024C192.002 419.415 173.096 421.292 153.721 421.292C133.626 421.292 112.99 417.772 101.445 414.796C100.877 414.65 30.7019 396.255 39.5946 379.48C41.089 376.661 43.5516 375.532 46.6509 375.532C59.1744 375.532 81.9535 394.054 91.746 394.054C93.935 394.054 95.5662 392.371 96.1976 390.112C100.555 374.522 32.6646 369.738 38.3633 348.189C39.3683 344.377 42.094 342.829 45.9248 342.834C62.4737 342.834 99.6021 371.756 107.385 371.756C107.979 371.756 108.405 371.584 108.637 371.218C112.536 364.964 110.74 359.872 83.257 343.343C55.7738 326.808 36.1428 317.588 47.114 305.718C48.3768 304.347 50.1659 303.741 52.3391 303.741C69.0248 303.746 108.447 339.398 108.447 339.398C108.447 339.398 119.087 350.395 125.523 350.395C127.001 350.395 128.259 349.815 129.111 348.382C133.673 340.737 86.7366 305.388 84.0898 290.804C82.2955 280.921 85.3474 275.917 90.9935 275.917Z"/> <path fill=white d="M296.9 404.174C282.31 383.118 283.343 367.316 303.363 347.627C323.383 327.943 335.037 299.145 335.037 299.145C335.037 299.145 339.39 282.419 349.304 283.958C359.219 285.497 366.498 310.492 345.731 325.783C324.963 341.069 349.866 351.456 357.856 337.099C365.846 322.741 387.663 285.831 398.978 278.772C410.287 271.713 418.25 275.668 415.583 290.218C412.916 304.769 365.618 340.036 370.22 347.668C374.822 355.296 391.041 338.7 391.041 338.7C391.041 338.7 441.791 293.255 452.84 305.097C463.889 316.94 444.457 326.863 416.766 343.359C389.068 359.85 386.921 364.206 390.85 370.446C394.784 376.685 455.915 325.971 461.657 347.47C467.393 368.969 399.269 375.209 403.474 390.051C407.678 404.899 451.461 361.958 460.416 378.689C469.376 395.425 398.633 415.088 398.06 415.234C375.209 421.067 317.175 433.426 296.9 404.174Z"/> <path fill=black d="M408.105 255C416.624 255 424.238 258.477 429.547 264.784C432.831 268.69 436.262 274.986 436.541 284.414C440.113 283.394 443.549 282.824 446.759 282.824C454.915 282.824 462.282 285.93 467.491 291.573C474.185 298.815 477.158 307.715 475.863 316.62C475.248 320.861 473.822 324.663 471.69 328.182C476.184 331.795 479.494 336.826 481.094 342.876C482.346 347.619 483.63 357.497 476.926 367.673C477.352 368.337 477.752 369.027 478.126 369.733C482.157 377.336 482.414 385.927 478.857 393.928C473.464 406.054 460.062 415.608 434.036 425.863C417.845 432.242 403.032 436.321 402.901 436.357C381.495 441.874 362.136 444.677 345.377 444.677C314.573 444.677 292.52 435.301 279.829 416.811C259.402 387.036 262.322 359.803 288.753 333.552C303.381 319.026 313.105 297.607 315.131 292.906C319.214 278.986 330.012 263.513 347.961 263.513H347.966C349.476 263.513 351.002 263.633 352.507 263.869C360.368 265.097 367.24 269.595 372.15 276.361C377.449 269.814 382.595 264.606 387.252 261.667C394.271 257.243 401.285 255 408.105 255ZM408.105 275.917C405.421 275.917 402.143 277.051 398.528 279.331C387.304 286.406 365.646 323.403 357.716 337.793C355.059 342.614 350.518 344.654 346.429 344.654C338.315 344.654 331.98 336.638 345.687 326.451C366.299 311.124 359.069 286.072 349.229 284.529C348.797 284.461 348.371 284.43 347.961 284.43C339.015 284.43 335.069 299.751 335.069 299.751C335.069 299.751 323.503 328.616 303.634 348.346C283.764 368.08 282.738 383.919 297.219 405.024C307.096 419.415 326.002 421.292 345.377 421.292C365.472 421.292 386.108 417.772 397.653 414.796C398.221 414.65 468.397 396.255 459.504 379.48C458.009 376.661 455.547 375.532 452.447 375.532C439.924 375.532 417.145 394.054 407.352 394.054C405.163 394.054 403.532 392.371 402.901 390.112C398.543 374.522 466.434 369.738 460.735 348.189C459.73 344.377 457.004 342.829 453.174 342.834C436.625 342.834 399.496 371.756 391.714 371.756C391.119 371.756 390.693 371.584 390.461 371.218C386.562 364.964 388.358 359.872 415.841 343.343C443.325 326.808 462.956 317.588 451.984 305.718C450.722 304.347 448.932 303.741 446.759 303.741C430.074 303.746 390.651 339.398 390.651 339.398C390.651 339.398 380.011 350.395 373.576 350.395C372.097 350.395 370.84 349.815 369.987 348.382C365.425 340.737 412.362 305.388 415.009 290.804C416.803 280.921 413.751 275.917 408.105 275.917Z"/> <path fill=#0E1116 d="M319.277 228.901C319.277 205.236 288.585 241.304 250.637 241.465C212.692 241.306 182 205.238 182 228.901C182 244.591 189.507 270.109 209.669 285.591C213.681 271.787 235.726 260.729 238.877 262.317C243.364 264.578 243.112 270.844 250.637 276.365C258.163 270.844 257.911 264.58 262.398 262.317C265.551 260.729 287.594 271.787 291.605 285.591C311.767 270.109 319.275 244.591 319.275 228.903L319.277 228.901Z"/> <path fill=#FF323D d="M262.4 262.315C257.913 264.576 258.165 270.842 250.639 276.363C243.114 270.842 243.366 264.578 238.879 262.315C235.726 260.727 213.683 271.785 209.672 285.589C219.866 293.417 233.297 298.678 250.627 298.806C250.631 298.806 250.635 298.806 250.641 298.806C250.646 298.806 250.65 298.806 250.656 298.806C267.986 298.68 281.417 293.417 291.611 285.589C287.6 271.785 265.555 260.727 262.404 262.315H262.4Z"/> <path fill=black d="M373 196C382.389 196 390 188.389 390 179C390 169.611 382.389 162 373 162C363.611 162 356 169.611 356 179C356 188.389 363.611 196 373 196Z"/> <path fill=black d="M128 196C137.389 196 145 188.389 145 179C145 169.611 137.389 162 128 162C118.611 162 111 169.611 111 179C111 188.389 118.611 196 128 196Z"/> <path fill=#0E1116 d="M313.06 171.596C319.796 173.968 322.476 187.779 329.281 184.171C342.167 177.337 347.06 161.377 340.208 148.524C333.356 135.671 317.354 130.792 304.467 137.626C291.58 144.46 286.688 160.419 293.54 173.272C296.774 179.339 307.039 169.475 313.06 171.596Z"/> <path fill=#0E1116 d="M188.554 171.596C181.818 173.968 179.138 187.779 172.334 184.171C159.447 177.337 154.555 161.377 161.407 148.524C168.259 135.671 184.26 130.792 197.147 137.626C210.034 144.46 214.926 160.419 208.074 173.272C204.84 179.339 194.575 169.475 188.554 171.596Z"/> </svg> </a> <a href=http://kuldeepsinghsidhu.com target=_blank rel=noopener title=kuldeepsinghsidhu.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0M5.78 8.75a9.64 9.64 0 0 0 1.363 4.177q.383.64.857 1.215c.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a10 10 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.51 6.51 0 0 0 4.666 5.5q-.184-.271-.352-.552c-.715-1.192-1.437-2.874-1.581-4.948m-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948q.18-.295.353-.552a6.51 6.51 0 0 0-4.666 5.5m10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948q-.18.296-.353.552a6.51 6.51 0 0 0 4.666-5.5Zm2.733-1.5a6.51 6.51 0 0 0-4.666-5.5q.184.272.353.552c.714 1.192 1.436 2.874 1.58 4.948Z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "search.highlight", "search.share", "search.suggest", "content.tooltips", "navigation.instant.progress", "navigation.path", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.60a45f97.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../javascripts/xfile.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>