<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="100+ probability and statistics interview questions - Bayes theorem, distributions, hypothesis testing, conditional probability, and brain teasers for data science interviews."><meta name=author content="Kuldeep Singh Sidhu"><link href=https://singhsidhukuldeep.github.io/Interview-Questions/Probability/ rel=canonical><link href=../Natural-Language-Processing/ rel=prev><link href=../AB-testing/ rel=next><link rel=icon href=https://repository-images.githubusercontent.com/275878203/13719500-bb75-11ea-8f3a-be2ffb87a6a2><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.50"><title>Probability & Statistics Interview Questions - Data Science Interview preparation</title><link rel=stylesheet href=../../assets/stylesheets/main.a40c8224.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-EVGNTG49J7"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-EVGNTG49J7",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-EVGNTG49J7",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#probability-interview-questions class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <!-- Add announcement here, including arbitrary HTML --> <style>
    @keyframes shake {
      0%, 100% { transform: translateX(0); }
      10%, 30%, 50%, 70%, 90% { transform: translateX(-2px); }
      20%, 40%, 60%, 80% { transform: translateX(2px); }
    }
    @keyframes glow {
      0%, 100% { text-shadow: 0 0 5px rgba(255, 165, 0, 0.5); }
      50% { text-shadow: 0 0 20px rgba(255, 165, 0, 0.8), 0 0 30px rgba(255, 140, 0, 0.6); }
    }
    .shake-text {
      display: inline-block;
      animation: shake 3s ease-in-out infinite;
    }
    .glow-link {
      animation: glow 2s ease-in-out infinite;
      font-weight: bold;
    }
  </style> <span class=shake-text>üöÄ <a href=/flashcards class=glow-link>Flashcards</a> feature is live!</span> <meta name=google-adsense-account content=ca-pub-4988388949365963> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4988388949365963" crossorigin=anonymous></script> </div> </aside> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Data Science Interview preparation" class="md-header__button md-logo" aria-label="Data Science Interview preparation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science Interview preparation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Probability & Statistics Interview Questions </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Data Science Interview preparation" class="md-nav__button md-logo" aria-label="Data Science Interview preparation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> Data Science Interview preparation </label> <div class=md-nav__source> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> üè° Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> üë®üèø‚Äçüè´ Interview Questions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> üë®üèø‚Äçüè´ Interview Questions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../flashcards/ class=md-nav__link> <span class=md-ellipsis> üìá Flashcards </span> </a> </li> <li class=md-nav__item> <a href=../data-structures-algorithms/ class=md-nav__link> <span class=md-ellipsis> DSA (Data Structures & Algorithms) </span> </a> </li> <li class=md-nav__item> <a href=../Machine-Learning/ class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class=md-nav__item> <a href=../System-design/ class=md-nav__link> <span class=md-ellipsis> System Design </span> </a> </li> <li class=md-nav__item> <a href=../Natural-Language-Processing/ class=md-nav__link> <span class=md-ellipsis> Natural Language Processing (NLP) </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Probability </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Probability </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#premium-interview-questions class=md-nav__link> <span class=md-ellipsis> Premium Interview Questions </span> </a> <nav class=md-nav aria-label="Premium Interview Questions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-is-bayes-theorem-explain-with-an-example-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bayes' Theorem? Explain with an Example - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-conditional-probability-vs-independence-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Conditional Probability vs Independence - Google, Meta Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#core-definitions class=md-nav__link> <span class=md-ellipsis> Core Definitions </span> </a> </li> <li class=md-nav__item> <a href=#conceptual-framework class=md-nav__link> <span class=md-ellipsis> Conceptual Framework </span> </a> </li> <li class=md-nav__item> <a href=#production-python-implementation class=md-nav__link> <span class=md-ellipsis> Production Python Implementation </span> </a> </li> <li class=md-nav__item> <a href=#comparison-tables class=md-nav__link> <span class=md-ellipsis> Comparison Tables </span> </a> <nav class=md-nav aria-label="Comparison Tables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#independence-vs-dependence-vs-mutual-exclusivity class=md-nav__link> <span class=md-ellipsis> Independence vs Dependence vs Mutual Exclusivity </span> </a> </li> <li class=md-nav__item> <a href=#real-company-applications class=md-nav__link> <span class=md-ellipsis> Real Company Applications </span> </a> </li> <li class=md-nav__item> <a href=#common-misconceptions class=md-nav__link> <span class=md-ellipsis> Common Misconceptions </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-law-of-total-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Law of Total Probability? - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#core-theorem class=md-nav__link> <span class=md-ellipsis> Core Theorem </span> </a> </li> <li class=md-nav__item> <a href=#conceptual-framework_1 class=md-nav__link> <span class=md-ellipsis> Conceptual Framework </span> </a> </li> <li class=md-nav__item> <a href=#production-python-implementation_1 class=md-nav__link> <span class=md-ellipsis> Production Python Implementation </span> </a> </li> <li class=md-nav__item> <a href=#comparison-tables_1 class=md-nav__link> <span class=md-ellipsis> Comparison Tables </span> </a> <nav class=md-nav aria-label="Comparison Tables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#law-of-total-probability-vs-related-concepts class=md-nav__link> <span class=md-ellipsis> Law of Total Probability vs Related Concepts </span> </a> </li> <li class=md-nav__item> <a href=#real-company-applications_1 class=md-nav__link> <span class=md-ellipsis> Real Company Applications </span> </a> </li> <li class=md-nav__item> <a href=#common-mistakes-vs-correct-approach class=md-nav__link> <span class=md-ellipsis> Common Mistakes vs Correct Approach </span> </a> </li> <li class=md-nav__item> <a href=#explain-expected-value-and-its-properties-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Expected Value and Its Properties - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#core-definitions_1 class=md-nav__link> <span class=md-ellipsis> Core Definitions </span> </a> </li> <li class=md-nav__item> <a href=#critical-properties-must-know class=md-nav__link> <span class=md-ellipsis> Critical Properties (Must Know) </span> </a> </li> <li class=md-nav__item> <a href=#production-python-implementation_2 class=md-nav__link> <span class=md-ellipsis> Production Python Implementation </span> </a> <nav class=md-nav aria-label="Production Python Implementation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-is-variance-how-is-it-related-to-standard-deviation-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Variance? How is it Related to Standard Deviation? - Google, Meta Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#core-definitions_2 class=md-nav__link> <span class=md-ellipsis> Core Definitions </span> </a> </li> <li class=md-nav__item> <a href=#variance-properties-framework class=md-nav__link> <span class=md-ellipsis> Variance Properties Framework </span> </a> <nav class=md-nav aria-label="Variance Properties Framework"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#explain-the-central-limit-theorem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Central Limit Theorem - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#formal-statement class=md-nav__link> <span class=md-ellipsis> Formal Statement </span> </a> </li> <li class=md-nav__item> <a href=#clt-workflow class=md-nav__link> <span class=md-ellipsis> CLT Workflow </span> </a> </li> <li class=md-nav__item> <a href=#production-python-implementation_3 class=md-nav__link> <span class=md-ellipsis> Production Python Implementation </span> </a> </li> <li class=md-nav__item> <a href=#comparison-tables_2 class=md-nav__link> <span class=md-ellipsis> Comparison Tables </span> </a> <nav class=md-nav aria-label="Comparison Tables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#clt-requirements-and-edge-cases class=md-nav__link> <span class=md-ellipsis> CLT Requirements and Edge Cases </span> </a> </li> <li class=md-nav__item> <a href=#sample-size-guidelines-by-distribution-shape class=md-nav__link> <span class=md-ellipsis> Sample Size Guidelines by Distribution Shape </span> </a> </li> <li class=md-nav__item> <a href=#real-company-applications_2 class=md-nav__link> <span class=md-ellipsis> Real Company Applications </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-normal-distribution-state-its-properties-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Normal Distribution? State its Properties - Most Tech Companies Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#probability-density-function class=md-nav__link> <span class=md-ellipsis> Probability Density Function </span> </a> </li> <li class=md-nav__item> <a href=#key-properties class=md-nav__link> <span class=md-ellipsis> Key Properties </span> </a> <nav class=md-nav aria-label="Key Properties"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#explain-the-binomial-distribution-amazon-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Binomial Distribution - Amazon, Meta Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#probability-mass-function-pmf class=md-nav__link> <span class=md-ellipsis> Probability Mass Function (PMF) </span> </a> </li> <li class=md-nav__item> <a href=#conditions-bins class=md-nav__link> <span class=md-ellipsis> Conditions (BINS) </span> </a> </li> <li class=md-nav__item> <a href=#key-formulas class=md-nav__link> <span class=md-ellipsis> Key Formulas </span> </a> <nav class=md-nav aria-label="Key Formulas"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-is-the-poisson-distribution-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Poisson Distribution? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-exponential-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Exponential Distribution - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-geometric-distribution-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Geometric Distribution? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-birthday-problem-calculate-the-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Birthday Problem? Calculate the Probability - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-monty-hall-problem-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Monty Hall Problem - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-covariance-and-correlation-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Covariance and Correlation? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-law-of-large-numbers-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Law of Large Numbers - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-pdf-vs-pmf-vs-cdf-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is a PDF vs PMF vs CDF? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-confidence-interval-how-to-interpret-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Confidence Interval? How to Interpret It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-hypothesis-testing-null-alternative-p-value-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Hypothesis Testing: Null, Alternative, p-value - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-power-in-hypothesis-testing-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Power in Hypothesis Testing? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-permutations-vs-combinations-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Permutations vs Combinations - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-negative-binomial-distribution-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Negative Binomial Distribution? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-beta-distribution-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Beta Distribution? - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-gamma-distribution-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Gamma Distribution? - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-markov-chain-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Markov Chain? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-entropy-in-information-theory-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Entropy in Information Theory? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-are-joint-and-marginal-distributions-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What are Joint and Marginal Distributions? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-chi-squared-distribution-and-test-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Chi-Squared Distribution and Test? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-t-distribution-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the t-Distribution? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-uniform-distribution-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Uniform Distribution? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-sampling-with-vs-without-replacement-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Sampling With vs Without Replacement - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-hypergeometric-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Hypergeometric Distribution? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-f-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the F-Distribution? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#how-do-you-calculate-sample-size-for-ab-tests-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> How Do You Calculate Sample Size for A/B Tests? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-bayesian-vs-frequentist-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bayesian vs Frequentist Probability? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-multiple-comparisons-problem-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Multiple Comparisons Problem? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-bootstrap-sampling-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bootstrap Sampling? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#average-score-on-a-dice-role-of-at-most-3-times-jane-street-hudson-river-trading-citadel-interview-question class=md-nav__link> <span class=md-ellipsis> Average score on a dice role of at most 3 times - Jane Street, Hudson River Trading, Citadel Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-coupon-collector-problem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Coupon Collector Problem - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-simpsons-paradox-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Simpson's Paradox? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-are-quantiles-and-percentiles-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What Are Quantiles and Percentiles? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-difference-between-standard-deviation-and-standard-error-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Difference Between Standard Deviation and Standard Error? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-moment-generating-function-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is Moment Generating Function? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-waiting-time-paradox-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Waiting Time Paradox? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#how-do-you-estimate-probability-from-rare-events-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> How Do You Estimate Probability from Rare Events? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-type-i-and-type-ii-errors-with-examples-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Type I and Type II Errors with Examples - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-likelihood-ratio-test-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Likelihood Ratio Test? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-bias-of-an-estimator-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Bias of an Estimator - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-maximum-likelihood-estimation-mle-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Maximum Likelihood Estimation (MLE)? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-weak-vs-strong-law-of-large-numbers-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Weak vs Strong Law of Large Numbers - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-chebyshevs-inequality-when-to-use-it-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is Chebyshev's Inequality? When to Use It? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-jensens-inequality-give-examples-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Jensen's Inequality? Give Examples - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-kullback-leibler-kl-divergence-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Kullback-Leibler (KL) Divergence - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-poisson-process-give-real-world-examples-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Poisson Process? Give Real-World Examples - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-memoryless-property-which-distributions-have-it-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Memoryless Property? Which Distributions Have It? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-difference-between-probability-and-odds-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Difference Between Probability and Odds - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-gamblers-fallacy-vs-hot-hand-fallacy-meta-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Gambler's Fallacy vs Hot Hand Fallacy? - Meta, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-martingale-give-an-example-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Martingale? Give an Example - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-walds-equation-walds-identity-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Wald's Equation (Wald's Identity) - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-rejection-sampling-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Rejection Sampling? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-importance-sampling-meta-google-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Importance Sampling - Meta, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-inverse-transform-method-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Inverse Transform Method? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-box-muller-transform-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is Box-Muller Transform? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-alias-method-for-discrete-sampling-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Alias Method for Discrete Sampling - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-stratified-sampling-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Stratified Sampling? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-coupon-collectors-variance-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Coupon Collector's Variance? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-chinese-restaurant-process-meta-google-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Chinese Restaurant Process - Meta, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-secretary-problem-optimal-stopping-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Secretary Problem (Optimal Stopping)? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-false-discovery-rate-fdr-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the False Discovery Rate (FDR)? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-bonferroni-correction-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Bonferroni Correction - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-two-child-problem-boy-girl-paradox-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Two-Child Problem (Boy-Girl Paradox)? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-st-petersburg-paradox-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the St. Petersburg Paradox - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-gamblers-ruin-problem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Gambler's Ruin Problem? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-benfords-law-meta-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Benford's Law - Meta, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-hyperparameter-tuning-problem-in-bayesian-terms-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Hyperparameter Tuning Problem in Bayesian Terms? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-sufficient-statistic-give-examples-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Sufficient Statistic? Give Examples - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-rao-blackwell-theorem-google-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Rao-Blackwell Theorem - Google, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-simpsons-paradox-provide-examples-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is Simpson's Paradox? Provide Examples - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-delta-method-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Delta Method - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-likelihood-ratio-in-hypothesis-testing-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Likelihood Ratio in Hypothesis Testing? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-bootstrap-method-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Bootstrap Method - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-curse-of-dimensionality-in-probability-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Curse of Dimensionality in Probability? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-pitman-koopman-darmois-theorem-google-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Pitman-Koopman-Darmois Theorem - Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-cramer-rao-lower-bound-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Cram√©r-Rao Lower Bound? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-difference-between-joint-marginal-and-conditional-distributions-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Difference Between Joint, Marginal, and Conditional Distributions? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-expectation-maximization-em-algorithm-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Expectation-Maximization (EM) Algorithm - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-rejection-sampling-vs-importance-sampling-meta-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is Rejection Sampling vs Importance Sampling? - Meta, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-poisson-distribution-and-its-applications-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Poisson Distribution and Its Applications - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-law-of-total-probability-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Law of Total Probability? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-geometric-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Geometric Distribution - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-power-analysis-in-hypothesis-testing-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is Power Analysis in Hypothesis Testing? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-negative-binomial-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Negative Binomial Distribution - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-exponential-distribution-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Exponential Distribution? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-variance-reduction-techniques-in-monte-carlo-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Variance Reduction Techniques in Monte Carlo - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-chi-square-distribution-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Chi-Square Distribution? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-multiple-comparisons-problem-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Multiple Comparisons Problem - Most Tech Companies Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#quick-reference-100-interview-questions class=md-nav__link> <span class=md-ellipsis> Quick Reference: 100+ Interview Questions </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-google-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Google interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-facebook-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Facebook interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-amazon-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Amazon interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-microsoft-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Microsoft interview </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../AB-testing/ class=md-nav__link> <span class=md-ellipsis> A/B Testing </span> </a> </li> <li class=md-nav__item> <a href=../SQL-Interview-Questions/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../Scikit-Learn/ class=md-nav__link> <span class=md-ellipsis> Scikit-Learn </span> </a> </li> <li class=md-nav__item> <a href=../LangChain/ class=md-nav__link> <span class=md-ellipsis> LangChain </span> </a> </li> <li class=md-nav__item> <a href=../LangGraph/ class=md-nav__link> <span class=md-ellipsis> LangGraph </span> </a> </li> <li class=md-nav__item> <a href=../Interview-Question-Resources/ class=md-nav__link> <span class=md-ellipsis> Interview Question Resources </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> üìù Cheat Sheets </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> üìù Cheat Sheets </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Cheat-Sheets/Django/ class=md-nav__link> <span class=md-ellipsis> Django </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Flask/ class=md-nav__link> <span class=md-ellipsis> Flask </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Hypothesis-Tests/ class=md-nav__link> <span class=md-ellipsis> Hypothesis Tests </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Keras/ class=md-nav__link> <span class=md-ellipsis> Keras </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/LangChain-LangGraph/ class=md-nav__link> <span class=md-ellipsis> LangChain & LangGraph </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/PySpark/ class=md-nav__link> <span class=md-ellipsis> PySpark </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/PyTorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/RegEx/ class=md-nav__link> <span class=md-ellipsis> Regular Expressions (RegEx) </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Sk-learn/ class=md-nav__link> <span class=md-ellipsis> Scikit Learn </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/SQL/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/tensorflow/ class=md-nav__link> <span class=md-ellipsis> TensorFlow </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> ‚Äçüéì ML Topics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> ‚Äçüéì ML Topics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Machine-Learning/ARIMA/ class=md-nav__link> <span class=md-ellipsis> ARIMA </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Activation%20functions/ class=md-nav__link> <span class=md-ellipsis> Activation functions </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Collaborative%20Filtering/ class=md-nav__link> <span class=md-ellipsis> Collaborative Filtering </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Confusion%20Matrix/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/DBSCAN/ class=md-nav__link> <span class=md-ellipsis> DBSCAN </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Decision%20Trees/ class=md-nav__link> <span class=md-ellipsis> Decision Trees </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Gradient%20Boosting/ class=md-nav__link> <span class=md-ellipsis> Gradient Boosting </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/K-means%20clustering/ class=md-nav__link> <span class=md-ellipsis> K-means clustering </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Linear%20Regression/ class=md-nav__link> <span class=md-ellipsis> Linear Regression </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Logistic%20Regression/ class=md-nav__link> <span class=md-ellipsis> Logistic Regression </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Loss%20Function%20MAE%2C%20RMSE/ class=md-nav__link> <span class=md-ellipsis> Loss Function MAE, RMSE </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Neural%20Networks/ class=md-nav__link> <span class=md-ellipsis> Neural Networks </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Normal%20Distribution/ class=md-nav__link> <span class=md-ellipsis> Normal Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Normalization%20Regularisation/ class=md-nav__link> <span class=md-ellipsis> Normalization Regularisation </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Overfitting%2C%20Underfitting/ class=md-nav__link> <span class=md-ellipsis> Overfitting, Underfitting </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/PCA/ class=md-nav__link> <span class=md-ellipsis> PCA </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Random%20Forest/ class=md-nav__link> <span class=md-ellipsis> Random Forest </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Support%20Vector%20Machines/ class=md-nav__link> <span class=md-ellipsis> Support Vector Machines </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Unbalanced%2C%20Skewed%20data/ class=md-nav__link> <span class=md-ellipsis> Unbalanced, Skewed data </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/kNN/ class=md-nav__link> <span class=md-ellipsis> kNN </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> üë®üèæ‚Äçüíª Online Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> üë®üèæ‚Äçüíª Online Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Online-Material/Online-Material-for-Learning/ class=md-nav__link> <span class=md-ellipsis> Online Study Material </span> </a> </li> <li class=md-nav__item> <a href=../../Online-Material/popular-resources/ class=md-nav__link> <span class=md-ellipsis> Popular Blogs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../Contribute/ class=md-nav__link> <span class=md-ellipsis> ü§ù Contribute </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#premium-interview-questions class=md-nav__link> <span class=md-ellipsis> Premium Interview Questions </span> </a> <nav class=md-nav aria-label="Premium Interview Questions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-is-bayes-theorem-explain-with-an-example-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bayes' Theorem? Explain with an Example - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-conditional-probability-vs-independence-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Conditional Probability vs Independence - Google, Meta Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#core-definitions class=md-nav__link> <span class=md-ellipsis> Core Definitions </span> </a> </li> <li class=md-nav__item> <a href=#conceptual-framework class=md-nav__link> <span class=md-ellipsis> Conceptual Framework </span> </a> </li> <li class=md-nav__item> <a href=#production-python-implementation class=md-nav__link> <span class=md-ellipsis> Production Python Implementation </span> </a> </li> <li class=md-nav__item> <a href=#comparison-tables class=md-nav__link> <span class=md-ellipsis> Comparison Tables </span> </a> <nav class=md-nav aria-label="Comparison Tables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#independence-vs-dependence-vs-mutual-exclusivity class=md-nav__link> <span class=md-ellipsis> Independence vs Dependence vs Mutual Exclusivity </span> </a> </li> <li class=md-nav__item> <a href=#real-company-applications class=md-nav__link> <span class=md-ellipsis> Real Company Applications </span> </a> </li> <li class=md-nav__item> <a href=#common-misconceptions class=md-nav__link> <span class=md-ellipsis> Common Misconceptions </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-law-of-total-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Law of Total Probability? - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#core-theorem class=md-nav__link> <span class=md-ellipsis> Core Theorem </span> </a> </li> <li class=md-nav__item> <a href=#conceptual-framework_1 class=md-nav__link> <span class=md-ellipsis> Conceptual Framework </span> </a> </li> <li class=md-nav__item> <a href=#production-python-implementation_1 class=md-nav__link> <span class=md-ellipsis> Production Python Implementation </span> </a> </li> <li class=md-nav__item> <a href=#comparison-tables_1 class=md-nav__link> <span class=md-ellipsis> Comparison Tables </span> </a> <nav class=md-nav aria-label="Comparison Tables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#law-of-total-probability-vs-related-concepts class=md-nav__link> <span class=md-ellipsis> Law of Total Probability vs Related Concepts </span> </a> </li> <li class=md-nav__item> <a href=#real-company-applications_1 class=md-nav__link> <span class=md-ellipsis> Real Company Applications </span> </a> </li> <li class=md-nav__item> <a href=#common-mistakes-vs-correct-approach class=md-nav__link> <span class=md-ellipsis> Common Mistakes vs Correct Approach </span> </a> </li> <li class=md-nav__item> <a href=#explain-expected-value-and-its-properties-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Expected Value and Its Properties - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#core-definitions_1 class=md-nav__link> <span class=md-ellipsis> Core Definitions </span> </a> </li> <li class=md-nav__item> <a href=#critical-properties-must-know class=md-nav__link> <span class=md-ellipsis> Critical Properties (Must Know) </span> </a> </li> <li class=md-nav__item> <a href=#production-python-implementation_2 class=md-nav__link> <span class=md-ellipsis> Production Python Implementation </span> </a> <nav class=md-nav aria-label="Production Python Implementation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-is-variance-how-is-it-related-to-standard-deviation-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Variance? How is it Related to Standard Deviation? - Google, Meta Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#core-definitions_2 class=md-nav__link> <span class=md-ellipsis> Core Definitions </span> </a> </li> <li class=md-nav__item> <a href=#variance-properties-framework class=md-nav__link> <span class=md-ellipsis> Variance Properties Framework </span> </a> <nav class=md-nav aria-label="Variance Properties Framework"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#explain-the-central-limit-theorem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Central Limit Theorem - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#formal-statement class=md-nav__link> <span class=md-ellipsis> Formal Statement </span> </a> </li> <li class=md-nav__item> <a href=#clt-workflow class=md-nav__link> <span class=md-ellipsis> CLT Workflow </span> </a> </li> <li class=md-nav__item> <a href=#production-python-implementation_3 class=md-nav__link> <span class=md-ellipsis> Production Python Implementation </span> </a> </li> <li class=md-nav__item> <a href=#comparison-tables_2 class=md-nav__link> <span class=md-ellipsis> Comparison Tables </span> </a> <nav class=md-nav aria-label="Comparison Tables"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#clt-requirements-and-edge-cases class=md-nav__link> <span class=md-ellipsis> CLT Requirements and Edge Cases </span> </a> </li> <li class=md-nav__item> <a href=#sample-size-guidelines-by-distribution-shape class=md-nav__link> <span class=md-ellipsis> Sample Size Guidelines by Distribution Shape </span> </a> </li> <li class=md-nav__item> <a href=#real-company-applications_2 class=md-nav__link> <span class=md-ellipsis> Real Company Applications </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-normal-distribution-state-its-properties-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Normal Distribution? State its Properties - Most Tech Companies Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#probability-density-function class=md-nav__link> <span class=md-ellipsis> Probability Density Function </span> </a> </li> <li class=md-nav__item> <a href=#key-properties class=md-nav__link> <span class=md-ellipsis> Key Properties </span> </a> <nav class=md-nav aria-label="Key Properties"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#explain-the-binomial-distribution-amazon-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Binomial Distribution - Amazon, Meta Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#probability-mass-function-pmf class=md-nav__link> <span class=md-ellipsis> Probability Mass Function (PMF) </span> </a> </li> <li class=md-nav__item> <a href=#conditions-bins class=md-nav__link> <span class=md-ellipsis> Conditions (BINS) </span> </a> </li> <li class=md-nav__item> <a href=#key-formulas class=md-nav__link> <span class=md-ellipsis> Key Formulas </span> </a> <nav class=md-nav aria-label="Key Formulas"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-is-the-poisson-distribution-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Poisson Distribution? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-exponential-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Exponential Distribution - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-geometric-distribution-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Geometric Distribution? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-birthday-problem-calculate-the-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Birthday Problem? Calculate the Probability - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-monty-hall-problem-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Monty Hall Problem - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-covariance-and-correlation-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Covariance and Correlation? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-law-of-large-numbers-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Law of Large Numbers - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-pdf-vs-pmf-vs-cdf-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is a PDF vs PMF vs CDF? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-confidence-interval-how-to-interpret-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Confidence Interval? How to Interpret It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-hypothesis-testing-null-alternative-p-value-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Hypothesis Testing: Null, Alternative, p-value - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-power-in-hypothesis-testing-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Power in Hypothesis Testing? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-permutations-vs-combinations-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Permutations vs Combinations - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-negative-binomial-distribution-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Negative Binomial Distribution? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-beta-distribution-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Beta Distribution? - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-gamma-distribution-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Gamma Distribution? - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-markov-chain-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Markov Chain? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-entropy-in-information-theory-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Entropy in Information Theory? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-are-joint-and-marginal-distributions-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What are Joint and Marginal Distributions? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-chi-squared-distribution-and-test-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Chi-Squared Distribution and Test? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-t-distribution-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the t-Distribution? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-uniform-distribution-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Uniform Distribution? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-sampling-with-vs-without-replacement-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Sampling With vs Without Replacement - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-hypergeometric-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Hypergeometric Distribution? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-f-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the F-Distribution? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#how-do-you-calculate-sample-size-for-ab-tests-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> How Do You Calculate Sample Size for A/B Tests? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-bayesian-vs-frequentist-probability-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bayesian vs Frequentist Probability? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-multiple-comparisons-problem-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Multiple Comparisons Problem? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-bootstrap-sampling-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Bootstrap Sampling? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#average-score-on-a-dice-role-of-at-most-3-times-jane-street-hudson-river-trading-citadel-interview-question class=md-nav__link> <span class=md-ellipsis> Average score on a dice role of at most 3 times - Jane Street, Hudson River Trading, Citadel Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-coupon-collector-problem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Coupon Collector Problem - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-simpsons-paradox-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Simpson's Paradox? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-are-quantiles-and-percentiles-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What Are Quantiles and Percentiles? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-difference-between-standard-deviation-and-standard-error-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Difference Between Standard Deviation and Standard Error? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-moment-generating-function-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is Moment Generating Function? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-waiting-time-paradox-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Waiting Time Paradox? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#how-do-you-estimate-probability-from-rare-events-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> How Do You Estimate Probability from Rare Events? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-type-i-and-type-ii-errors-with-examples-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Type I and Type II Errors with Examples - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-likelihood-ratio-test-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Likelihood Ratio Test? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-bias-of-an-estimator-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Bias of an Estimator - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-maximum-likelihood-estimation-mle-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Maximum Likelihood Estimation (MLE)? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-weak-vs-strong-law-of-large-numbers-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Weak vs Strong Law of Large Numbers - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-chebyshevs-inequality-when-to-use-it-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is Chebyshev's Inequality? When to Use It? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-jensens-inequality-give-examples-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is Jensen's Inequality? Give Examples - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-kullback-leibler-kl-divergence-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Kullback-Leibler (KL) Divergence - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-poisson-process-give-real-world-examples-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Poisson Process? Give Real-World Examples - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-memoryless-property-which-distributions-have-it-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Memoryless Property? Which Distributions Have It? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-difference-between-probability-and-odds-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Difference Between Probability and Odds - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-gamblers-fallacy-vs-hot-hand-fallacy-meta-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Gambler's Fallacy vs Hot Hand Fallacy? - Meta, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-martingale-give-an-example-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Martingale? Give an Example - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-walds-equation-walds-identity-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Wald's Equation (Wald's Identity) - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-rejection-sampling-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Rejection Sampling? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-importance-sampling-meta-google-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Importance Sampling - Meta, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-inverse-transform-method-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Inverse Transform Method? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-box-muller-transform-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> What is Box-Muller Transform? - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-alias-method-for-discrete-sampling-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Alias Method for Discrete Sampling - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-stratified-sampling-when-to-use-it-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is Stratified Sampling? When to Use It? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-coupon-collectors-variance-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Coupon Collector's Variance? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-chinese-restaurant-process-meta-google-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Chinese Restaurant Process - Meta, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-secretary-problem-optimal-stopping-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Secretary Problem (Optimal Stopping)? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-false-discovery-rate-fdr-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the False Discovery Rate (FDR)? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-bonferroni-correction-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Bonferroni Correction - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-two-child-problem-boy-girl-paradox-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Two-Child Problem (Boy-Girl Paradox)? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-st-petersburg-paradox-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the St. Petersburg Paradox - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-gamblers-ruin-problem-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Gambler's Ruin Problem? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-benfords-law-meta-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Benford's Law - Meta, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-hyperparameter-tuning-problem-in-bayesian-terms-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Hyperparameter Tuning Problem in Bayesian Terms? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-a-sufficient-statistic-give-examples-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is a Sufficient Statistic? Give Examples - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-rao-blackwell-theorem-google-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Rao-Blackwell Theorem - Google, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-simpsons-paradox-provide-examples-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is Simpson's Paradox? Provide Examples - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-delta-method-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Delta Method - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-likelihood-ratio-in-hypothesis-testing-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Likelihood Ratio in Hypothesis Testing? - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-bootstrap-method-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Bootstrap Method - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-curse-of-dimensionality-in-probability-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Curse of Dimensionality in Probability? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-pitman-koopman-darmois-theorem-google-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Pitman-Koopman-Darmois Theorem - Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-cramer-rao-lower-bound-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Cram√©r-Rao Lower Bound? - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-difference-between-joint-marginal-and-conditional-distributions-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Difference Between Joint, Marginal, and Conditional Distributions? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-expectation-maximization-em-algorithm-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Expectation-Maximization (EM) Algorithm - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-rejection-sampling-vs-importance-sampling-meta-google-interview-question class=md-nav__link> <span class=md-ellipsis> What is Rejection Sampling vs Importance Sampling? - Meta, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-poisson-distribution-and-its-applications-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Poisson Distribution and Its Applications - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-law-of-total-probability-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Law of Total Probability? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-geometric-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Geometric Distribution - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-power-analysis-in-hypothesis-testing-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is Power Analysis in Hypothesis Testing? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-negative-binomial-distribution-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Negative Binomial Distribution - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-exponential-distribution-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Exponential Distribution? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-variance-reduction-techniques-in-monte-carlo-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Explain Variance Reduction Techniques in Monte Carlo - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-chi-square-distribution-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> What is the Chi-Square Distribution? - Most Tech Companies Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#explain-the-multiple-comparisons-problem-most-tech-companies-interview-question class=md-nav__link> <span class=md-ellipsis> Explain the Multiple Comparisons Problem - Most Tech Companies Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#quick-reference-100-interview-questions class=md-nav__link> <span class=md-ellipsis> Quick Reference: 100+ Interview Questions </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-google-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Google interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-facebook-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Facebook interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-amazon-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Amazon interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-microsoft-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Microsoft interview </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/edit/master/docs/Interview-Questions/Probability.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/raw/master/docs/Interview-Questions/Probability.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=probability-interview-questions>Probability Interview Questions</h1> <!-- ![Total Questions](https://img.shields.io/badge/Total%20Questions-1-blue?style=flat&labelColor=black&color=blue)
![Unanswered Questions](https://img.shields.io/badge/Unanswered%20Questions-0-blue?style=flat&labelColor=black&color=yellow)
![Answered Questions](https://img.shields.io/badge/Answered%20Questions-1-blue?style=flat&labelColor=black&color=success) --> <p>This document provides a curated list of common probability interview questions frequently asked in technical interviews. It covers basic probability concepts, probability distributions, key theorems, and real-world applications. Use the practice links to explore detailed explanations and examples.</p> <hr> <h2 id=premium-interview-questions>Premium Interview Questions</h2> <h3 id=what-is-bayes-theorem-explain-with-an-example-google-amazon-interview-question>What is Bayes' Theorem? Explain with an Example - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Bayes</code>, <code>Conditional Probability</code>, <code>Inference</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Bayes' Theorem</strong> is a fundamental theorem in probability that describes how to update the probability of a hypothesis based on new evidence. It provides a mathematical framework for <strong>inverse probability</strong> ‚Äî computing the probability of a cause given an observed effect.</p> <p><strong>The Formula:</strong></p> <div class=arithmatex>\[P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}\]</div> <p>Or with the expanded denominator (Law of Total Probability):</p> <div class=arithmatex>\[P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B|A) \cdot P(A) + P(B|\neg A) \cdot P(\neg A)}\]</div> <p><strong>Components Explained:</strong></p> <table> <thead> <tr> <th>Term</th> <th>Name</th> <th>Meaning</th> <th>Intuition</th> </tr> </thead> <tbody> <tr> <td>P(A|B)</td> <td><strong>Posterior</strong></td> <td>Probability of A given B</td> <td>What we want to find (updated belief)</td> </tr> <tr> <td>P(B|A)</td> <td><strong>Likelihood</strong></td> <td>Probability of B given A</td> <td>How likely is the evidence if hypothesis is true</td> </tr> <tr> <td>P(A)</td> <td><strong>Prior</strong></td> <td>Initial probability of A</td> <td>Our belief before seeing evidence</td> </tr> <tr> <td>P(B)</td> <td><strong>Evidence/Marginal</strong></td> <td>Total probability of B</td> <td>Normalizing constant</td> </tr> </tbody> </table> <p><strong>Example 1: Medical Diagnosis (Classic)</strong></p> <ul> <li>Disease prevalence: P(Disease) = 1%</li> <li>Test sensitivity: P(Positive|Disease) = 99%</li> <li>Test specificity: P(Negative|No Disease) = 95%</li> </ul> <p><strong>Question: What's P(Disease|Positive)?</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Prior probabilities</span>
<span class=n>p_disease</span> <span class=o>=</span> <span class=mf>0.01</span>
<span class=n>p_no_disease</span> <span class=o>=</span> <span class=mf>0.99</span>

<span class=c1># Likelihood (test characteristics)</span>
<span class=n>p_pos_given_disease</span> <span class=o>=</span> <span class=mf>0.99</span>      <span class=c1># Sensitivity (True Positive Rate)</span>
<span class=n>p_pos_given_no_disease</span> <span class=o>=</span> <span class=mf>0.05</span>   <span class=c1># False Positive Rate (1 - Specificity)</span>

<span class=c1># Evidence: P(Positive) using Law of Total Probability</span>
<span class=n>p_positive</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_pos_given_disease</span> <span class=o>*</span> <span class=n>p_disease</span> <span class=o>+</span> 
              <span class=n>p_pos_given_no_disease</span> <span class=o>*</span> <span class=n>p_no_disease</span><span class=p>)</span>
<span class=c1># = 0.99 * 0.01 + 0.05 * 0.99 = 0.0099 + 0.0495 = 0.0594</span>

<span class=c1># Posterior: Apply Bayes&#39; Theorem</span>
<span class=n>p_disease_given_pos</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_pos_given_disease</span> <span class=o>*</span> <span class=n>p_disease</span><span class=p>)</span> <span class=o>/</span> <span class=n>p_positive</span>
<span class=c1># = 0.0099 / 0.0594 ‚âà 0.167 or 16.7%</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Disease|Positive) = </span><span class=si>{</span><span class=n>p_disease_given_pos</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># 16.7%</span>
</code></pre></div> <p><strong>üîë Key Insight (Base Rate Fallacy):</strong> Even with a 99% accurate test, there's only a 16.7% chance of actually having the disease! This counterintuitive result occurs because the disease is rare (1%), so false positives from the healthy population (99%) overwhelm the true positives.</p> <p><strong>Example 2: Spam Email Classification</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Prior: 30% of emails are spam</span>
<span class=n>p_spam</span> <span class=o>=</span> <span class=mf>0.30</span>
<span class=n>p_not_spam</span> <span class=o>=</span> <span class=mf>0.70</span>

<span class=c1># Likelihood: P(&quot;free&quot; appears | spam/not spam)</span>
<span class=n>p_free_given_spam</span> <span class=o>=</span> <span class=mf>0.80</span>       <span class=c1># 80% of spam contains &quot;free&quot;</span>
<span class=n>p_free_given_not_spam</span> <span class=o>=</span> <span class=mf>0.10</span>   <span class=c1># 10% of legitimate emails contain &quot;free&quot;</span>

<span class=c1># Evidence: P(&quot;free&quot; appears)</span>
<span class=n>p_free</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_free_given_spam</span> <span class=o>*</span> <span class=n>p_spam</span> <span class=o>+</span> 
          <span class=n>p_free_given_not_spam</span> <span class=o>*</span> <span class=n>p_not_spam</span><span class=p>)</span>
<span class=c1># = 0.80 * 0.30 + 0.10 * 0.70 = 0.24 + 0.07 = 0.31</span>

<span class=c1># Posterior: P(spam | &quot;free&quot; appears)</span>
<span class=n>p_spam_given_free</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_free_given_spam</span> <span class=o>*</span> <span class=n>p_spam</span><span class=p>)</span> <span class=o>/</span> <span class=n>p_free</span>
<span class=c1># = 0.24 / 0.31 ‚âà 0.774 or 77.4%</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Spam|&#39;free&#39;) = </span><span class=si>{</span><span class=n>p_spam_given_free</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># 77.4%</span>
</code></pre></div> <p><strong>Real-World Applications:</strong></p> <table> <thead> <tr> <th>Domain</th> <th>Application</th> </tr> </thead> <tbody> <tr> <td><strong>Medical</strong></td> <td>Disease diagnosis, drug efficacy</td> </tr> <tr> <td><strong>ML/AI</strong></td> <td>Naive Bayes classifier, Bayesian neural networks</td> </tr> <tr> <td><strong>Search</strong></td> <td>Spam filtering, recommendation systems</td> </tr> <tr> <td><strong>Finance</strong></td> <td>Risk assessment, fraud detection</td> </tr> <tr> <td><strong>Legal</strong></td> <td>DNA evidence interpretation</td> </tr> <tr> <td><strong>A/B Testing</strong></td> <td>Bayesian A/B testing</td> </tr> </tbody> </table> <p><strong>‚ö†Ô∏è Limitations and Challenges:</strong></p> <table> <thead> <tr> <th>Limitation</th> <th>Description</th> <th>Mitigation</th> </tr> </thead> <tbody> <tr> <td><strong>Prior Selection</strong></td> <td>Results are sensitive to prior choice; subjective priors can bias conclusions</td> <td>Use informative priors from domain expertise or non-informative priors</td> </tr> <tr> <td><strong>Computational Cost</strong></td> <td>Calculating posteriors can be intractable for complex models</td> <td>Use MCMC, Variational Inference, or conjugate priors</td> </tr> <tr> <td><strong>Independence Assumption</strong></td> <td>Naive Bayes assumes feature independence (often violated)</td> <td>Use more sophisticated models (Bayesian networks)</td> </tr> <tr> <td><strong>Base Rate Neglect</strong></td> <td>Humans often ignore priors, leading to wrong intuitions</td> <td>Always explicitly state and consider base rates</td> </tr> <tr> <td><strong>Data Requirements</strong></td> <td>Need reliable estimates of likelihoods and priors</td> <td>Collect sufficient data; use hierarchical models</td> </tr> <tr> <td><strong>Curse of Dimensionality</strong></td> <td>High-dimensional spaces make probability estimation difficult</td> <td>Dimensionality reduction, feature selection</td> </tr> </tbody> </table> <p><strong>Bayesian vs Frequentist Interpretation:</strong></p> <table> <thead> <tr> <th>Aspect</th> <th>Bayesian</th> <th>Frequentist</th> </tr> </thead> <tbody> <tr> <td><strong>Probability</strong></td> <td>Degree of belief</td> <td>Long-run frequency</td> </tr> <tr> <td><strong>Parameters</strong></td> <td>Random variables with distributions</td> <td>Fixed unknown constants</td> </tr> <tr> <td><strong>Inference</strong></td> <td>P(Œ∏|data) - posterior</td> <td>P(data|Œ∏) - likelihood</td> </tr> <tr> <td><strong>Prior info</strong></td> <td>Incorporated via prior</td> <td>Not formally used</td> </tr> </tbody> </table> <div class=highlight><pre><span></span><code><span class=c1># Complete Bayesian inference example</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>def</span><span class=w> </span><span class=nf>bayes_theorem</span><span class=p>(</span><span class=n>prior</span><span class=p>,</span> <span class=n>likelihood</span><span class=p>,</span> <span class=n>evidence</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Calculate posterior probability using Bayes&#39; theorem.</span>

<span class=sd>    Args:</span>
<span class=sd>        prior: P(H) - prior probability of hypothesis</span>
<span class=sd>        likelihood: P(E|H) - probability of evidence given hypothesis</span>
<span class=sd>        evidence: P(E) - total probability of evidence</span>

<span class=sd>    Returns:</span>
<span class=sd>        posterior: P(H|E) - updated probability after seeing evidence</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=p>(</span><span class=n>likelihood</span> <span class=o>*</span> <span class=n>prior</span><span class=p>)</span> <span class=o>/</span> <span class=n>evidence</span>

<span class=k>def</span><span class=w> </span><span class=nf>calculate_evidence</span><span class=p>(</span><span class=n>prior</span><span class=p>,</span> <span class=n>likelihood</span><span class=p>,</span> <span class=n>likelihood_complement</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Calculate P(E) using law of total probability.&quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=n>likelihood</span> <span class=o>*</span> <span class=n>prior</span> <span class=o>+</span> <span class=n>likelihood_complement</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>prior</span><span class=p>)</span>

<span class=c1># Example: Updated medical test with sequential testing</span>
<span class=n>prior</span> <span class=o>=</span> <span class=mf>0.01</span>  <span class=c1># Initial disease prevalence</span>

<span class=c1># First positive test</span>
<span class=n>sensitivity</span> <span class=o>=</span> <span class=mf>0.99</span>
<span class=n>false_positive_rate</span> <span class=o>=</span> <span class=mf>0.05</span>

<span class=n>evidence</span> <span class=o>=</span> <span class=n>calculate_evidence</span><span class=p>(</span><span class=n>prior</span><span class=p>,</span> <span class=n>sensitivity</span><span class=p>,</span> <span class=n>false_positive_rate</span><span class=p>)</span>
<span class=n>posterior_1</span> <span class=o>=</span> <span class=n>bayes_theorem</span><span class=p>(</span><span class=n>prior</span><span class=p>,</span> <span class=n>sensitivity</span><span class=p>,</span> <span class=n>evidence</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;After 1st positive test: </span><span class=si>{</span><span class=n>posterior_1</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># 16.7%</span>

<span class=c1># Second positive test (prior is now the previous posterior)</span>
<span class=n>evidence_2</span> <span class=o>=</span> <span class=n>calculate_evidence</span><span class=p>(</span><span class=n>posterior_1</span><span class=p>,</span> <span class=n>sensitivity</span><span class=p>,</span> <span class=n>false_positive_rate</span><span class=p>)</span>
<span class=n>posterior_2</span> <span class=o>=</span> <span class=n>bayes_theorem</span><span class=p>(</span><span class=n>posterior_1</span><span class=p>,</span> <span class=n>sensitivity</span><span class=p>,</span> <span class=n>evidence_2</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;After 2nd positive test: </span><span class=si>{</span><span class=n>posterior_2</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># 79.5%</span>

<span class=c1># Third positive test</span>
<span class=n>evidence_3</span> <span class=o>=</span> <span class=n>calculate_evidence</span><span class=p>(</span><span class=n>posterior_2</span><span class=p>,</span> <span class=n>sensitivity</span><span class=p>,</span> <span class=n>false_positive_rate</span><span class=p>)</span>
<span class=n>posterior_3</span> <span class=o>=</span> <span class=n>bayes_theorem</span><span class=p>(</span><span class=n>posterior_2</span><span class=p>,</span> <span class=n>sensitivity</span><span class=p>,</span> <span class=n>evidence_3</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;After 3rd positive test: </span><span class=si>{</span><span class=n>posterior_3</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># 98.7%</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Deep understanding of conditional probability, statistical reasoning, and practical applications.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Writes formula without hesitation: <em>P(A|B) = P(B|A) √ó P(A) / P(B)</em> and explains each term (posterior, likelihood, prior, evidence)</li> <li>Explains base rate fallacy: "Even with 99% accurate test, rare disease means most positives are false alarms because healthy population vastly outnumbers sick"</li> <li>Shows step-by-step calculation: Prior ‚Üí Likelihood ‚Üí Evidence (Law of Total Probability) ‚Üí Posterior</li> <li>Connects to real applications: spam filtering, medical diagnosis, recommendation systems, A/B testing, fraud detection</li> <li>Discusses limitations: prior sensitivity, computational cost, independence assumptions in Naive Bayes</li> </ul> <p><strong>Common follow-up questions:</strong></p> <ul> <li><em>"What happens with a second positive test?"</em> ‚Üí Use posterior (16.7%) as new prior ‚Üí ~79.5%</li> <li><em>"How would you choose a prior?"</em> ‚Üí Domain expertise, historical data, or uninformative priors (uniform, Jeffreys)</li> <li><em>"When Bayesian vs Frequentist?"</em> ‚Üí Bayesian for small samples, prior knowledge, sequential updates</li> <li><em>"Relationship to Naive Bayes?"</em> ‚Üí Applies Bayes' theorem assuming feature independence: P(class|features) ‚àù P(class) √ó ‚àèP(feature_i|class)</li> <li><em>"What are conjugate priors?"</em> ‚Üí Prior and posterior from same family (Beta-Binomial, Normal-Normal)</li> </ul> </div> <div class="admonition warning"> <p class=admonition-title>Common Mistakes to Avoid</p> <ul> <li>Confusing P(A|B) with P(B|A) ‚Äî the <strong>prosecutor's fallacy</strong></li> <li>Ignoring the base rate (prior probability)</li> <li>Assuming the posterior equals the likelihood</li> <li>Not normalizing (forgetting to divide by evidence)</li> </ul> </div> </details> <hr> <h3 id=explain-conditional-probability-vs-independence-google-meta-interview-question>Explain Conditional Probability vs Independence - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Conditional Probability</code>, <code>Independence</code>, <code>Fundamentals</code> | <strong>Asked by:</strong> Google, Meta, Amazon, Netflix</p> <details class=success> <summary>View Answer</summary> <p><strong>Conditional Probability</strong> and <strong>Independence</strong> are foundational concepts in probability that govern how events relate to each other. Understanding their distinction is critical for <strong>Bayesian inference</strong>, <strong>A/B testing</strong>, <strong>causal analysis</strong>, and <strong>machine learning feature selection</strong>.</p> <h2 id=core-definitions>Core Definitions</h2> <p><strong>Conditional Probability:</strong></p> <p>The probability of event A occurring given that event B has already occurred:</p> <div class=arithmatex>\[P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) &gt; 0\]</div> <p><strong>Independence:</strong></p> <p>Events A and B are independent if knowing one provides NO information about the other:</p> <div class=arithmatex>\[P(A|B) = P(A) \quad \text{or equivalently} \quad P(A \cap B) = P(A) \cdot P(B)\]</div> <h2 id=conceptual-framework>Conceptual Framework</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          CONDITIONAL PROBABILITY vs INDEPENDENCE              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  CONDITIONAL PROBABILITY                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ &quot;What&#39;s P(A) if we KNOW B occurred?&quot;                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Formula: P(A|B) = P(A‚à©B) / P(B)                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Example: P(Rain | Dark Clouds) = 0.8                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ          P(Rain alone) = 0.3                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ          ‚Üí Knowing clouds CHANGES probability         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  INDEPENDENCE TEST                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Does knowing B change P(A)?                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ IF P(A|B) = P(A) ‚Üí INDEPENDENT                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ IF P(A|B) ‚â† P(A) ‚Üí DEPENDENT                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Equivalent: P(A‚à©B) = P(A) √ó P(B) ‚úì Independent       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=production-python-implementation>Production Python Implementation</h2> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>Tuple</span><span class=p>,</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>List</span><span class=p>,</span> <span class=n>Optional</span>
<span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span>
<span class=kn>from</span><span class=w> </span><span class=nn>enum</span><span class=w> </span><span class=kn>import</span> <span class=n>Enum</span>


<span class=k>class</span><span class=w> </span><span class=nc>EventType</span><span class=p>(</span><span class=n>Enum</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Event relationship types.&quot;&quot;&quot;</span>
    <span class=n>INDEPENDENT</span> <span class=o>=</span> <span class=s2>&quot;independent&quot;</span>
    <span class=n>DEPENDENT</span> <span class=o>=</span> <span class=s2>&quot;dependent&quot;</span>
    <span class=n>MUTUALLY_EXCLUSIVE</span> <span class=o>=</span> <span class=s2>&quot;mutually_exclusive&quot;</span>


<span class=nd>@dataclass</span>
<span class=k>class</span><span class=w> </span><span class=nc>ProbabilityAnalysis</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Results from conditional probability analysis.&quot;&quot;&quot;</span>
    <span class=n>p_a</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>p_b</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>p_a_and_b</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>p_a_given_b</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>p_b_given_a</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>event_type</span><span class=p>:</span> <span class=n>EventType</span>
    <span class=n>independence_score</span><span class=p>:</span> <span class=nb>float</span>  <span class=c1># |P(A|B) - P(A)| / P(A)</span>
    <span class=n>details</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>any</span><span class=p>]</span>


<span class=k>class</span><span class=w> </span><span class=nc>ConditionalProbabilityAnalyzer</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Production-ready analyzer for conditional probability and independence.</span>

<span class=sd>    Used by Netflix for user behavior analysis, Google for ad targeting,</span>
<span class=sd>    and Meta for feed ranking independence tests.</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tolerance</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>1e-6</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Initialize analyzer.</span>

<span class=sd>        Args:</span>
<span class=sd>            tolerance: Numerical tolerance for independence test</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>tolerance</span> <span class=o>=</span> <span class=n>tolerance</span>

    <span class=k>def</span><span class=w> </span><span class=nf>analyze_events</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>data</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
        <span class=n>event_a</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>event_b</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>event_a_condition</span><span class=p>:</span> <span class=nb>any</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
        <span class=n>event_b_condition</span><span class=p>:</span> <span class=nb>any</span> <span class=o>=</span> <span class=kc>True</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>ProbabilityAnalysis</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Analyze conditional probability and independence from data.</span>

<span class=sd>        Args:</span>
<span class=sd>            data: DataFrame with event columns</span>
<span class=sd>            event_a: Column name for event A</span>
<span class=sd>            event_b: Column name for event B</span>
<span class=sd>            event_a_condition: Value/condition for event A occurring</span>
<span class=sd>            event_b_condition: Value/condition for event B occurring</span>

<span class=sd>        Returns:</span>
<span class=sd>            ProbabilityAnalysis with full statistical breakdown</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

        <span class=c1># Calculate marginal probabilities</span>
        <span class=n>a_occurs</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>event_a</span><span class=p>]</span> <span class=o>==</span> <span class=n>event_a_condition</span>
        <span class=n>b_occurs</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>event_b</span><span class=p>]</span> <span class=o>==</span> <span class=n>event_b_condition</span>
        <span class=n>both_occur</span> <span class=o>=</span> <span class=n>a_occurs</span> <span class=o>&amp;</span> <span class=n>b_occurs</span>

        <span class=n>p_a</span> <span class=o>=</span> <span class=n>a_occurs</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>/</span> <span class=n>n</span>
        <span class=n>p_b</span> <span class=o>=</span> <span class=n>b_occurs</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>/</span> <span class=n>n</span>
        <span class=n>p_a_and_b</span> <span class=o>=</span> <span class=n>both_occur</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>/</span> <span class=n>n</span>

        <span class=c1># Calculate conditional probabilities</span>
        <span class=n>p_a_given_b</span> <span class=o>=</span> <span class=n>p_a_and_b</span> <span class=o>/</span> <span class=n>p_b</span> <span class=k>if</span> <span class=n>p_b</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=k>else</span> <span class=mi>0</span>
        <span class=n>p_b_given_a</span> <span class=o>=</span> <span class=n>p_a_and_b</span> <span class=o>/</span> <span class=n>p_a</span> <span class=k>if</span> <span class=n>p_a</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=k>else</span> <span class=mi>0</span>

        <span class=c1># Determine event relationship</span>
        <span class=n>event_type</span><span class=p>,</span> <span class=n>independence_score</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_classify_events</span><span class=p>(</span>
            <span class=n>p_a</span><span class=p>,</span> <span class=n>p_b</span><span class=p>,</span> <span class=n>p_a_and_b</span><span class=p>,</span> <span class=n>p_a_given_b</span>
        <span class=p>)</span>

        <span class=n>details</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;n_samples&#39;</span><span class=p>:</span> <span class=n>n</span><span class=p>,</span>
            <span class=s1>&#39;n_a&#39;</span><span class=p>:</span> <span class=n>a_occurs</span><span class=o>.</span><span class=n>sum</span><span class=p>(),</span>
            <span class=s1>&#39;n_b&#39;</span><span class=p>:</span> <span class=n>b_occurs</span><span class=o>.</span><span class=n>sum</span><span class=p>(),</span>
            <span class=s1>&#39;n_both&#39;</span><span class=p>:</span> <span class=n>both_occur</span><span class=o>.</span><span class=n>sum</span><span class=p>(),</span>
            <span class=s1>&#39;expected_if_independent&#39;</span><span class=p>:</span> <span class=n>p_a</span> <span class=o>*</span> <span class=n>p_b</span> <span class=o>*</span> <span class=n>n</span><span class=p>,</span>
            <span class=s1>&#39;observed&#39;</span><span class=p>:</span> <span class=n>both_occur</span><span class=o>.</span><span class=n>sum</span><span class=p>(),</span>
            <span class=s1>&#39;deviation&#39;</span><span class=p>:</span> <span class=nb>abs</span><span class=p>(</span><span class=n>both_occur</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>-</span> <span class=n>p_a</span> <span class=o>*</span> <span class=n>p_b</span> <span class=o>*</span> <span class=n>n</span><span class=p>)</span>
        <span class=p>}</span>

        <span class=k>return</span> <span class=n>ProbabilityAnalysis</span><span class=p>(</span>
            <span class=n>p_a</span><span class=o>=</span><span class=n>p_a</span><span class=p>,</span>
            <span class=n>p_b</span><span class=o>=</span><span class=n>p_b</span><span class=p>,</span>
            <span class=n>p_a_and_b</span><span class=o>=</span><span class=n>p_a_and_b</span><span class=p>,</span>
            <span class=n>p_a_given_b</span><span class=o>=</span><span class=n>p_a_given_b</span><span class=p>,</span>
            <span class=n>p_b_given_a</span><span class=o>=</span><span class=n>p_b_given_a</span><span class=p>,</span>
            <span class=n>event_type</span><span class=o>=</span><span class=n>event_type</span><span class=p>,</span>
            <span class=n>independence_score</span><span class=o>=</span><span class=n>independence_score</span><span class=p>,</span>
            <span class=n>details</span><span class=o>=</span><span class=n>details</span>
        <span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_classify_events</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>p_a</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
        <span class=n>p_b</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
        <span class=n>p_a_and_b</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
        <span class=n>p_a_given_b</span><span class=p>:</span> <span class=nb>float</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>EventType</span><span class=p>,</span> <span class=nb>float</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Classify event relationship.&quot;&quot;&quot;</span>
        <span class=c1># Check mutual exclusivity</span>
        <span class=k>if</span> <span class=nb>abs</span><span class=p>(</span><span class=n>p_a_and_b</span><span class=p>)</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>tolerance</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>EventType</span><span class=o>.</span><span class=n>MUTUALLY_EXCLUSIVE</span><span class=p>,</span> <span class=mf>1.0</span>

        <span class=c1># Check independence: P(A‚à©B) ‚âà P(A) √ó P(B)</span>
        <span class=n>expected_if_independent</span> <span class=o>=</span> <span class=n>p_a</span> <span class=o>*</span> <span class=n>p_b</span>
        <span class=n>independence_deviation</span> <span class=o>=</span> <span class=nb>abs</span><span class=p>(</span><span class=n>p_a_and_b</span> <span class=o>-</span> <span class=n>expected_if_independent</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>independence_deviation</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>tolerance</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>EventType</span><span class=o>.</span><span class=n>INDEPENDENT</span><span class=p>,</span> <span class=mf>0.0</span>

        <span class=c1># Calculate independence score (normalized deviation)</span>
        <span class=n>independence_score</span> <span class=o>=</span> <span class=nb>abs</span><span class=p>(</span><span class=n>p_a_given_b</span> <span class=o>-</span> <span class=n>p_a</span><span class=p>)</span> <span class=o>/</span> <span class=n>p_a</span> <span class=k>if</span> <span class=n>p_a</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=k>else</span> <span class=mf>1.0</span>

        <span class=k>return</span> <span class=n>EventType</span><span class=o>.</span><span class=n>DEPENDENT</span><span class=p>,</span> <span class=n>independence_score</span>

    <span class=k>def</span><span class=w> </span><span class=nf>chi_square_independence_test</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>data</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>
        <span class=n>event_a</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>event_b</span><span class=p>:</span> <span class=nb>str</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Perform chi-square test for independence.</span>

<span class=sd>        Used by Google Analytics for feature correlation analysis.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chi2_contingency</span>

        <span class=c1># Create contingency table</span>
        <span class=n>contingency</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>crosstab</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=n>event_a</span><span class=p>],</span> <span class=n>data</span><span class=p>[</span><span class=n>event_b</span><span class=p>])</span>

        <span class=n>chi2</span><span class=p>,</span> <span class=n>p_value</span><span class=p>,</span> <span class=n>dof</span><span class=p>,</span> <span class=n>expected</span> <span class=o>=</span> <span class=n>chi2_contingency</span><span class=p>(</span><span class=n>contingency</span><span class=p>)</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;chi_square&#39;</span><span class=p>:</span> <span class=n>chi2</span><span class=p>,</span>
            <span class=s1>&#39;p_value&#39;</span><span class=p>:</span> <span class=n>p_value</span><span class=p>,</span>
            <span class=s1>&#39;degrees_of_freedom&#39;</span><span class=p>:</span> <span class=n>dof</span><span class=p>,</span>
            <span class=s1>&#39;is_independent&#39;</span><span class=p>:</span> <span class=n>p_value</span> <span class=o>&gt;</span> <span class=mf>0.05</span><span class=p>,</span>
            <span class=s1>&#39;effect_size_cramers_v&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>chi2</span> <span class=o>/</span> <span class=p>(</span><span class=n>contingency</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>*</span> <span class=p>(</span><span class=nb>min</span><span class=p>(</span><span class=n>contingency</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)))</span>
        <span class=p>}</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 1: NETFLIX - VIDEO STREAMING QUALITY vs USER RETENTION</span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 1: NETFLIX - Streaming Quality Impact on Retention&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=c1># Simulate Netflix user data (10,000 sessions)</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
<span class=n>n_users</span> <span class=o>=</span> <span class=mi>10000</span>

<span class=c1># High quality users have 85% retention, low quality 60% retention</span>
<span class=n>quality_high</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>],</span> <span class=n>n_users</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.4</span><span class=p>,</span> <span class=mf>0.6</span><span class=p>])</span>

<span class=n>retention</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>is_high_quality</span> <span class=ow>in</span> <span class=n>quality_high</span><span class=p>:</span>
    <span class=k>if</span> <span class=n>is_high_quality</span><span class=p>:</span>
        <span class=n>retention</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.85</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>]))</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>retention</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.60</span><span class=p>,</span> <span class=mf>0.40</span><span class=p>]))</span>

<span class=n>netflix_data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;high_quality&#39;</span><span class=p>:</span> <span class=n>quality_high</span><span class=p>,</span>
    <span class=s1>&#39;retained&#39;</span><span class=p>:</span> <span class=n>retention</span>
<span class=p>})</span>

<span class=n>analyzer</span> <span class=o>=</span> <span class=n>ConditionalProbabilityAnalyzer</span><span class=p>()</span>
<span class=n>result</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>analyze_events</span><span class=p>(</span>
    <span class=n>netflix_data</span><span class=p>,</span>
    <span class=n>event_a</span><span class=o>=</span><span class=s1>&#39;retained&#39;</span><span class=p>,</span>
    <span class=n>event_b</span><span class=o>=</span><span class=s1>&#39;high_quality&#39;</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>P(Retained) = </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>p_a</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(High Quality) = </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>p_b</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Retained ‚à© High Quality) = </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>p_a_and_b</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Retained | High Quality) = </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>p_a_given_b</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Retained | Low Quality) = </span><span class=si>{</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>p_a</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>result</span><span class=o>.</span><span class=n>p_a_and_b</span><span class=p>)</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=p>(</span><span class=mi>1</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>result</span><span class=o>.</span><span class=n>p_b</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Event Type: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>event_type</span><span class=o>.</span><span class=n>value</span><span class=o>.</span><span class=n>upper</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Independence Score: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>independence_score</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>üí° Insight: Knowing quality </span><span class=si>{</span><span class=s1>&#39;CHANGES&#39;</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>result</span><span class=o>.</span><span class=n>event_type</span><span class=w> </span><span class=o>==</span><span class=w> </span><span class=n>EventType</span><span class=o>.</span><span class=n>DEPENDENT</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s1>&#39;DOES NOT CHANGE&#39;</span><span class=si>}</span><span class=s2> retention probability&quot;</span><span class=p>)</span>

<span class=n>chi_result</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>chi_square_independence_test</span><span class=p>(</span><span class=n>netflix_data</span><span class=p>,</span> <span class=s1>&#39;retained&#39;</span><span class=p>,</span> <span class=s1>&#39;high_quality&#39;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Chi-square test: œá¬≤ = </span><span class=si>{</span><span class=n>chi_result</span><span class=p>[</span><span class=s1>&#39;chi_square&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, p = </span><span class=si>{</span><span class=n>chi_result</span><span class=p>[</span><span class=s1>&#39;p_value&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Statistical conclusion: Events are </span><span class=si>{</span><span class=s1>&#39;INDEPENDENT&#39;</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>chi_result</span><span class=p>[</span><span class=s1>&#39;is_independent&#39;</span><span class=p>]</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s1>&#39;DEPENDENT&#39;</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 2: GOOGLE ADS - Click-Through Rate Analysis  </span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 2: GOOGLE ADS - Ad Position vs CTR Independence&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=c1># Top positions get more clicks (DEPENDENT)</span>
<span class=n>ad_positions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=s1>&#39;top&#39;</span><span class=p>,</span> <span class=s1>&#39;side&#39;</span><span class=p>,</span> <span class=s1>&#39;bottom&#39;</span><span class=p>],</span> <span class=mi>5000</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>])</span>

<span class=n>clicks</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>pos</span> <span class=ow>in</span> <span class=n>ad_positions</span><span class=p>:</span>
    <span class=k>if</span> <span class=n>pos</span> <span class=o>==</span> <span class=s1>&#39;top&#39;</span><span class=p>:</span>
        <span class=n>clicks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.15</span><span class=p>,</span> <span class=mf>0.85</span><span class=p>]))</span>
    <span class=k>elif</span> <span class=n>pos</span> <span class=o>==</span> <span class=s1>&#39;side&#39;</span><span class=p>:</span>
        <span class=n>clicks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.95</span><span class=p>]))</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>clicks</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.02</span><span class=p>,</span> <span class=mf>0.98</span><span class=p>]))</span>

<span class=n>google_data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;position&#39;</span><span class=p>:</span> <span class=n>ad_positions</span><span class=p>,</span>
    <span class=s1>&#39;clicked&#39;</span><span class=p>:</span> <span class=n>clicks</span>
<span class=p>})</span>

<span class=c1># Analyze top position</span>
<span class=n>google_top</span> <span class=o>=</span> <span class=n>google_data</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
<span class=n>google_top</span><span class=p>[</span><span class=s1>&#39;is_top&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>google_top</span><span class=p>[</span><span class=s1>&#39;position&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;top&#39;</span>

<span class=n>result_google</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>analyze_events</span><span class=p>(</span><span class=n>google_top</span><span class=p>,</span> <span class=s1>&#39;clicked&#39;</span><span class=p>,</span> <span class=s1>&#39;is_top&#39;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>P(Click) = </span><span class=si>{</span><span class=n>result_google</span><span class=o>.</span><span class=n>p_a</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Top Position) = </span><span class=si>{</span><span class=n>result_google</span><span class=o>.</span><span class=n>p_b</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Click | Top Position) = </span><span class=si>{</span><span class=n>result_google</span><span class=o>.</span><span class=n>p_a_given_b</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Click | Not Top) = </span><span class=si>{</span><span class=p>(</span><span class=n>result_google</span><span class=o>.</span><span class=n>p_a</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>result_google</span><span class=o>.</span><span class=n>p_a_and_b</span><span class=p>)</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=p>(</span><span class=mi>1</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>result_google</span><span class=o>.</span><span class=n>p_b</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Lift from Top Position: </span><span class=si>{</span><span class=p>(</span><span class=n>result_google</span><span class=o>.</span><span class=n>p_a_given_b</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=n>result_google</span><span class=o>.</span><span class=n>p_a</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=mi>1</span><span class=p>)</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>100</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>%&quot;</span><span class=p>)</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 3: TRUE INDEPENDENCE - COIN FLIPS</span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 3: COIN FLIPS - True Independence Verification&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=c1># Two independent coin flips</span>
<span class=n>coin1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>],</span> <span class=mi>10000</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>])</span>
<span class=n>coin2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=kc>True</span><span class=p>,</span> <span class=kc>False</span><span class=p>],</span> <span class=mi>10000</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>])</span>

<span class=n>coin_data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;flip1_heads&#39;</span><span class=p>:</span> <span class=n>coin1</span><span class=p>,</span>
    <span class=s1>&#39;flip2_heads&#39;</span><span class=p>:</span> <span class=n>coin2</span>
<span class=p>})</span>

<span class=n>result_coin</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>analyze_events</span><span class=p>(</span><span class=n>coin_data</span><span class=p>,</span> <span class=s1>&#39;flip1_heads&#39;</span><span class=p>,</span> <span class=s1>&#39;flip2_heads&#39;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>P(Flip1 = Heads) = </span><span class=si>{</span><span class=n>result_coin</span><span class=o>.</span><span class=n>p_a</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Flip2 = Heads) = </span><span class=si>{</span><span class=n>result_coin</span><span class=o>.</span><span class=n>p_b</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Both Heads) = </span><span class=si>{</span><span class=n>result_coin</span><span class=o>.</span><span class=n>p_a_and_b</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected if independent: </span><span class=si>{</span><span class=n>result_coin</span><span class=o>.</span><span class=n>p_a</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>result_coin</span><span class=o>.</span><span class=n>p_b</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Event Type: </span><span class=si>{</span><span class=n>result_coin</span><span class=o>.</span><span class=n>event_type</span><span class=o>.</span><span class=n>value</span><span class=o>.</span><span class=n>upper</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Independence Score: </span><span class=si>{</span><span class=n>result_coin</span><span class=o>.</span><span class=n>independence_score</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2> (‚âà0 confirms independence)&quot;</span><span class=p>)</span>
</code></pre></div> <h2 id=comparison-tables>Comparison Tables</h2> <h3 id=independence-vs-dependence-vs-mutual-exclusivity>Independence vs Dependence vs Mutual Exclusivity</h3> <table> <thead> <tr> <th>Property</th> <th>Independent</th> <th>Dependent</th> <th>Mutually Exclusive</th> </tr> </thead> <tbody> <tr> <td><strong>Definition</strong></td> <td>P(A|B) = P(A)</td> <td>P(A|B) ‚â† P(A)</td> <td>P(A‚à©B) = 0</td> </tr> <tr> <td><strong>Joint Probability</strong></td> <td>P(A‚à©B) = P(A)¬∑P(B)</td> <td>P(A‚à©B) ‚â† P(A)¬∑P(B)</td> <td>P(A‚à©B) = 0</td> </tr> <tr> <td><strong>Information Flow</strong></td> <td>B tells nothing about A</td> <td>B changes probability of A</td> <td>B completely determines A (¬¨A)</td> </tr> <tr> <td><strong>Example</strong></td> <td>Coin flip 1, Coin flip 2</td> <td>Rain, Dark clouds</td> <td>Roll 6, Roll 5</td> </tr> <tr> <td><strong>Can Both Occur?</strong></td> <td>Yes</td> <td>Yes</td> <td><strong>No</strong></td> </tr> <tr> <td><strong>ML Feature Selection</strong></td> <td>Keep both (no redundancy)</td> <td>Check correlation</td> <td>Keep one only</td> </tr> </tbody> </table> <h3 id=real-company-applications>Real Company Applications</h3> <table> <thead> <tr> <th>Company</th> <th>Use Case</th> <th>Events</th> <th>Relationship</th> <th>Business Impact</th> </tr> </thead> <tbody> <tr> <td><strong>Netflix</strong></td> <td>Quality ‚Üí Retention</td> <td>High stream quality, User retained</td> <td><strong>Dependent</strong></td> <td>+25% retention with HD streaming</td> </tr> <tr> <td><strong>Google</strong></td> <td>Ad position ‚Üí CTR</td> <td>Top placement, Click</td> <td><strong>Dependent</strong></td> <td>3x higher CTR at top positions</td> </tr> <tr> <td><strong>Amazon</strong></td> <td>Prime ‚Üí Purchase frequency</td> <td>Prime member, Monthly purchase</td> <td><strong>Dependent</strong></td> <td>Prime users buy 4.2x more often</td> </tr> <tr> <td><strong>Meta</strong></td> <td>Friend connection ‚Üí Engagement</td> <td>User A friends with B, A likes B's posts</td> <td><strong>Dependent</strong></td> <td>12x higher engagement with friends</td> </tr> <tr> <td><strong>Uber</strong></td> <td>Surge pricing ‚Üí Driver acceptance</td> <td>Surge active, Ride accepted</td> <td><strong>Dependent</strong></td> <td>85% vs 65% acceptance</td> </tr> <tr> <td><strong>Spotify</strong></td> <td>Time of day ‚Üí Genre preference</td> <td>Morning time, Upbeat music</td> <td><strong>Dependent</strong></td> <td>2.1x classical in evening</td> </tr> </tbody> </table> <h3 id=common-misconceptions>Common Misconceptions</h3> <table> <thead> <tr> <th>Misconception</th> <th>Reality</th> <th>Example</th> </tr> </thead> <tbody> <tr> <td>Independent = Mutually Exclusive</td> <td><strong>FALSE</strong>: Opposite!</td> <td>If A, B mutually exclusive and P(A), P(B) &gt; 0, they're maximally dependent</td> </tr> <tr> <td>Correlation = Dependence</td> <td><strong>Partial</strong>: Linear dependence only</td> <td>Events can be dependent with 0 correlation (X, X¬≤)</td> </tr> <tr> <td>Zero covariance = Independence</td> <td><strong>FALSE</strong> for general case</td> <td>Only true for multivariate normal distributions</td> </tr> <tr> <td>P(A|B) = P(B|A)</td> <td><strong>FALSE</strong> unless P(A) = P(B)</td> <td>P(Rain|Clouds) ‚â† P(Clouds|Rain)</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they test:</strong></p> <ul> <li>Deep understanding of conditional probability formula and its derivation from joint probability</li> <li>Ability to distinguish three concepts: independence, dependence, mutual exclusivity</li> <li>Practical application to real-world scenarios (A/B testing, feature engineering, causal analysis)</li> <li>Recognition of the "independence ‚â† mutually exclusive" trap (trips up 60% of candidates)</li> </ul> <p><strong>Strong signals:</strong></p> <ul> <li><strong>Writes formula immediately</strong>: "P(A|B) = P(A‚à©B) / P(B), and for independence P(A|B) = P(A) which gives P(A‚à©B) = P(A)¬∑P(B)"</li> <li><strong>Tests independence in data</strong>: "At Netflix, we validated that streaming quality and retention are dependent using chi-square test with p-value &lt; 0.001"</li> <li><strong>Explains information flow</strong>: "Independence means knowing B provides ZERO information about A. Dependence means B changes the probability distribution of A"</li> <li><strong>Avoids the trap</strong>: "Mutually exclusive events with nonzero probabilities are maximally DEPENDENT, not independent‚Äîif I know A occurred, then P(B|A) = 0"</li> <li><strong>Real numbers</strong>: "Google found ad position and CTR are strongly dependent: P(Click|Top) = 0.15 vs P(Click|Side) = 0.05, a 3x lift"</li> </ul> <p><strong>Red flags:</strong></p> <ul> <li>Confuses independence with mutual exclusivity</li> <li>Cannot write P(A|B) formula from memory</li> <li>Thinks "no correlation" means "independent" in all cases</li> <li>Cannot calculate conditional probability from contingency table</li> <li>Doesn't test assumptions (assumes independence without verification)</li> </ul> <p><strong>Follow-up questions:</strong></p> <ul> <li><em>"How do you test independence in practice?"</em> ‚Üí Chi-square test, compare P(A|B) vs P(A), permutation test</li> <li><em>"Can mutually exclusive events be independent?"</em> ‚Üí No (unless one has probability 0)</li> <li><em>"Give example where Cov(X,Y)=0 but dependent"</em> ‚Üí X uniform on [-1,1], Y=X¬≤ (uncorrelated but perfectly dependent)</li> <li><em>"How does this relate to Naive Bayes?"</em> ‚Üí Assumes feature independence: P(features|class) = ‚àèP(feature_i|class)</li> <li><em>"What's conditional independence?"</em> ‚Üí P(A|B,C) = P(A|C) ‚Äî A and B independent given C</li> </ul> </div> <div class="admonition warning"> <p class=admonition-title>Common Pitfalls</p> <ol> <li><strong>Base rate neglect</strong>: Forgetting to weight by P(B) in denominator</li> <li><strong>Confusion with causation</strong>: Independence doesn't mean no causal link (could be confounded)</li> <li><strong>Sample size</strong>: Small samples may appear independent due to noise (always test statistically)</li> <li><strong>Direction confusion</strong>: P(A|B) ‚â† P(B|A) in general (Prosecutor's Fallacy)</li> </ol> </div> </details> <hr> <h3 id=what-is-the-law-of-total-probability-google-amazon-interview-question>What is the Law of Total Probability? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Total Probability</code>, <code>Partition</code>, <code>Bayes</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft, Uber</p> <details class=success> <summary>View Answer</summary> <p>The <strong>Law of Total Probability</strong> is a fundamental theorem that decomposes complex probabilities into manageable conditional pieces. It's the mathematical foundation for <strong>mixture models</strong>, <strong>hierarchical Bayesian inference</strong>, and <strong>marginalizing out nuisance variables</strong> in statistical modeling.</p> <h2 id=core-theorem>Core Theorem</h2> <p>If {B‚ÇÅ, B‚ÇÇ, ..., B‚Çô} form a <strong>partition</strong> of the sample space (mutually exclusive and exhaustive):</p> <div class=arithmatex>\[P(A) = \sum_{i=1}^{n} P(A|B_i) \cdot P(B_i)\]</div> <p><strong>Continuous version</strong> (for continuous partitioning variable):</p> <div class=arithmatex>\[P(A) = \int_{-\infty}^{\infty} P(A|B=b) \cdot f_B(b) \, db\]</div> <h2 id=conceptual-framework_1>Conceptual Framework</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         LAW OF TOTAL PROBABILITY WORKFLOW                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 1: Identify Complex Event A                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Event with unknown probability: P(A) = ?               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Example: P(Customer Churns)                            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  STEP 2: Find Partition {B‚ÇÅ, B‚ÇÇ, ..., B‚Çô}                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Requirements:                                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Mutually exclusive: B·µ¢ ‚à© B‚±º = ‚àÖ for i‚â†j           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Exhaustive: ‚à™B·µ¢ = Sample Space                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Example: {Premium, Standard, Free} user tiers         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  STEP 3: Calculate Conditional P(A|B·µ¢) and Prior P(B·µ¢)     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ P(Churn|Premium) = 0.05,  P(Premium) = 0.20          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ P(Churn|Standard) = 0.15, P(Standard) = 0.50         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ P(Churn|Free) = 0.30,     P(Free) = 0.30             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  STEP 4: Apply Formula (Weighted Average)                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ P(A) = Œ£ P(A|B·µ¢) √ó P(B·µ¢)                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ      = 0.05√ó0.20 + 0.15√ó0.50 + 0.30√ó0.30            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ      = 0.01 + 0.075 + 0.09 = 0.175 or 17.5%         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  BONUS: Bayes&#39; Theorem Inversion                            ‚îÇ
‚îÇ  P(B·µ¢|A) = P(A|B·µ¢) √ó P(B·µ¢) / P(A)                          ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=production-python-implementation_1>Production Python Implementation</h2> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>Tuple</span><span class=p>,</span> <span class=n>Callable</span><span class=p>,</span> <span class=n>Optional</span>
<span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>


<span class=nd>@dataclass</span>
<span class=k>class</span><span class=w> </span><span class=nc>PartitionElement</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Single element in a probability partition.&quot;&quot;&quot;</span>
    <span class=n>name</span><span class=p>:</span> <span class=nb>str</span>
    <span class=n>prior_prob</span><span class=p>:</span> <span class=nb>float</span>  <span class=c1># P(B·µ¢)</span>
    <span class=n>conditional_prob</span><span class=p>:</span> <span class=nb>float</span>  <span class=c1># P(A|B·µ¢)</span>

    <span class=nd>@property</span>
    <span class=k>def</span><span class=w> </span><span class=nf>contribution</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Contribution to total probability.&quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>prior_prob</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>conditional_prob</span>


<span class=nd>@dataclass</span>
<span class=k>class</span><span class=w> </span><span class=nc>TotalProbabilityResult</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Results from Law of Total Probability calculation.&quot;&quot;&quot;</span>
    <span class=n>total_probability</span><span class=p>:</span> <span class=nb>float</span>  <span class=c1># P(A)</span>
    <span class=n>partitions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>PartitionElement</span><span class=p>]</span>
    <span class=n>posterior_probs</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>]</span>  <span class=c1># P(B·µ¢|A) via Bayes</span>
    <span class=n>contributions</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>]</span>  <span class=c1># Each partition&#39;s contribution</span>
    <span class=n>dominant_partition</span><span class=p>:</span> <span class=nb>str</span>  <span class=c1># Which B·µ¢ contributes most</span>


<span class=k>class</span><span class=w> </span><span class=nc>TotalProbabilityCalculator</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Production calculator for Law of Total Probability.</span>

<span class=sd>    Used by:</span>
<span class=sd>    - Amazon: Customer lifetime value across segments</span>
<span class=sd>    - Google: Ad click-through rates across devices</span>
<span class=sd>    - Uber: Ride acceptance rates across driver tiers</span>
<span class=sd>    - Netflix: Content engagement across user cohorts</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>pass</span>

    <span class=k>def</span><span class=w> </span><span class=nf>calculate</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>partitions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>PartitionElement</span><span class=p>],</span>
        <span class=n>validate</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>TotalProbabilityResult</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Apply Law of Total Probability.</span>

<span class=sd>        Args:</span>
<span class=sd>            partitions: List of partition elements {B·µ¢, P(B·µ¢), P(A|B·µ¢)}</span>
<span class=sd>            validate: Check partition validity (exhaustive, mutually exclusive)</span>

<span class=sd>        Returns:</span>
<span class=sd>            TotalProbabilityResult with P(A) and Bayesian posteriors</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=n>validate</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_validate_partition</span><span class=p>(</span><span class=n>partitions</span><span class=p>)</span>

        <span class=c1># Calculate P(A) = Œ£ P(A|B·µ¢) √ó P(B·µ¢)</span>
        <span class=n>total_prob</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>contribution</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>partitions</span><span class=p>)</span>

        <span class=c1># Calculate contributions</span>
        <span class=n>contributions</span> <span class=o>=</span> <span class=p>{</span>
            <span class=n>p</span><span class=o>.</span><span class=n>name</span><span class=p>:</span> <span class=n>p</span><span class=o>.</span><span class=n>contribution</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>partitions</span>
        <span class=p>}</span>

        <span class=c1># Find dominant partition</span>
        <span class=n>dominant</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>partitions</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>p</span><span class=p>:</span> <span class=n>p</span><span class=o>.</span><span class=n>contribution</span><span class=p>)</span>

        <span class=c1># Calculate posteriors P(B·µ¢|A) via Bayes&#39; theorem</span>
        <span class=n>posteriors</span> <span class=o>=</span> <span class=p>{}</span>
        <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>partitions</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>total_prob</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
                <span class=n>posteriors</span><span class=p>[</span><span class=n>p</span><span class=o>.</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>contribution</span> <span class=o>/</span> <span class=n>total_prob</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>posteriors</span><span class=p>[</span><span class=n>p</span><span class=o>.</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=mf>0.0</span>

        <span class=k>return</span> <span class=n>TotalProbabilityResult</span><span class=p>(</span>
            <span class=n>total_probability</span><span class=o>=</span><span class=n>total_prob</span><span class=p>,</span>
            <span class=n>partitions</span><span class=o>=</span><span class=n>partitions</span><span class=p>,</span>
            <span class=n>posterior_probs</span><span class=o>=</span><span class=n>posteriors</span><span class=p>,</span>
            <span class=n>contributions</span><span class=o>=</span><span class=n>contributions</span><span class=p>,</span>
            <span class=n>dominant_partition</span><span class=o>=</span><span class=n>dominant</span><span class=o>.</span><span class=n>name</span>
        <span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_validate_partition</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>partitions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>PartitionElement</span><span class=p>]):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Validate partition properties.&quot;&quot;&quot;</span>
        <span class=n>total_prior</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>prior_prob</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>partitions</span><span class=p>)</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>total_prior</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=n>atol</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>):</span>
            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span>
                <span class=sa>f</span><span class=s2>&quot;Partition not exhaustive: Œ£ P(B·µ¢) = </span><span class=si>{</span><span class=n>total_prior</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2> ‚â† 1.0&quot;</span>
            <span class=p>)</span>

        <span class=c1># Check all probabilities in [0,1]</span>
        <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>partitions</span><span class=p>:</span>
            <span class=k>if</span> <span class=ow>not</span> <span class=p>(</span><span class=mi>0</span> <span class=o>&lt;=</span> <span class=n>p</span><span class=o>.</span><span class=n>prior_prob</span> <span class=o>&lt;=</span> <span class=mi>1</span> <span class=ow>and</span> <span class=mi>0</span> <span class=o>&lt;=</span> <span class=n>p</span><span class=o>.</span><span class=n>conditional_prob</span> <span class=o>&lt;=</span> <span class=mi>1</span><span class=p>):</span>
                <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Invalid probability for </span><span class=si>{</span><span class=n>p</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>sensitivity_analysis</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>base_partitions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>PartitionElement</span><span class=p>],</span>
        <span class=n>param_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>param_range</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Analyze sensitivity of P(A) to parameter changes.</span>

<span class=sd>        Used by data scientists to understand which partitions drive outcomes.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>results</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;param_values&#39;</span><span class=p>:</span> <span class=n>param_range</span><span class=p>,</span> <span class=s1>&#39;total_probs&#39;</span><span class=p>:</span> <span class=p>[]}</span>

        <span class=k>for</span> <span class=n>param_val</span> <span class=ow>in</span> <span class=n>param_range</span><span class=p>:</span>
            <span class=c1># Create modified partition (simplified: scale one conditional)</span>
            <span class=n>modified</span> <span class=o>=</span> <span class=n>base_partitions</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
            <span class=c1># Implementation depends on specific parameter</span>
            <span class=c1># This is a template</span>
            <span class=n>results</span><span class=p>[</span><span class=s1>&#39;total_probs&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>param_val</span><span class=p>)</span>  <span class=c1># Placeholder</span>

        <span class=k>return</span> <span class=n>results</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 1: UBER - RIDE ACCEPTANCE RATES ACROSS DRIVER TIERS</span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 1: UBER - Overall Ride Acceptance Rate&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=c1># Uber has 3 driver tiers with different acceptance rates</span>
<span class=n>uber_partitions</span> <span class=o>=</span> <span class=p>[</span>
    <span class=n>PartitionElement</span><span class=p>(</span>
        <span class=n>name</span><span class=o>=</span><span class=s2>&quot;Diamond (Top 10%)&quot;</span><span class=p>,</span>
        <span class=n>prior_prob</span><span class=o>=</span><span class=mf>0.10</span><span class=p>,</span>  <span class=c1># 10% of drivers</span>
        <span class=n>conditional_prob</span><span class=o>=</span><span class=mf>0.95</span>  <span class=c1># 95% acceptance rate</span>
    <span class=p>),</span>
    <span class=n>PartitionElement</span><span class=p>(</span>
        <span class=n>name</span><span class=o>=</span><span class=s2>&quot;Platinum (Next 30%)&quot;</span><span class=p>,</span>
        <span class=n>prior_prob</span><span class=o>=</span><span class=mf>0.30</span><span class=p>,</span>
        <span class=n>conditional_prob</span><span class=o>=</span><span class=mf>0.85</span>  <span class=c1># 85% acceptance rate</span>
    <span class=p>),</span>
    <span class=n>PartitionElement</span><span class=p>(</span>
        <span class=n>name</span><span class=o>=</span><span class=s2>&quot;Standard (60%)&quot;</span><span class=p>,</span>
        <span class=n>prior_prob</span><span class=o>=</span><span class=mf>0.60</span><span class=p>,</span>
        <span class=n>conditional_prob</span><span class=o>=</span><span class=mf>0.65</span>  <span class=c1># 65% acceptance rate</span>
    <span class=p>)</span>
<span class=p>]</span>

<span class=n>calc</span> <span class=o>=</span> <span class=n>TotalProbabilityCalculator</span><span class=p>()</span>
<span class=n>uber_result</span> <span class=o>=</span> <span class=n>calc</span><span class=o>.</span><span class=n>calculate</span><span class=p>(</span><span class=n>uber_partitions</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Overall acceptance rate: </span><span class=si>{</span><span class=n>uber_result</span><span class=o>.</span><span class=n>total_probability</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Contributions by tier:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>contrib</span> <span class=ow>in</span> <span class=n>uber_result</span><span class=o>.</span><span class=n>contributions</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=n>pct_of_total</span> <span class=o>=</span> <span class=n>contrib</span> <span class=o>/</span> <span class=n>uber_result</span><span class=o>.</span><span class=n>total_probability</span> <span class=o>*</span> <span class=mi>100</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>contrib</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=n>pct_of_total</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>% of total)&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Dominant tier: </span><span class=si>{</span><span class=n>uber_result</span><span class=o>.</span><span class=n>dominant_partition</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>If ride accepted, which tier? (Bayesian posterior):&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>post_prob</span> <span class=ow>in</span> <span class=n>uber_result</span><span class=o>.</span><span class=n>posterior_probs</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  P(</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2> | Accepted) = </span><span class=si>{</span><span class=n>post_prob</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>üí° Insight: Standard tier drivers (60%) contribute &quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   </span><span class=si>{</span><span class=n>uber_result</span><span class=o>.</span><span class=n>contributions</span><span class=p>[</span><span class=s1>&#39;Standard (60%)&#39;</span><span class=p>]</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=n>uber_result</span><span class=o>.</span><span class=n>total_probability</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2> of acceptances&quot;</span><span class=p>)</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 2: AMAZON - PRODUCT DEFECT RATE ACROSS SUPPLIERS</span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 2: AMAZON - Product Defect Rate Analysis&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=c1># Three suppliers with different defect rates</span>
<span class=n>amazon_partitions</span> <span class=o>=</span> <span class=p>[</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Supplier A (High Volume)&quot;</span><span class=p>,</span> <span class=mf>0.55</span><span class=p>,</span> <span class=mf>0.02</span><span class=p>),</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Supplier B (Medium Volume)&quot;</span><span class=p>,</span> <span class=mf>0.30</span><span class=p>,</span> <span class=mf>0.035</span><span class=p>),</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Supplier C (Low Volume)&quot;</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>,</span> <span class=mf>0.08</span><span class=p>)</span>
<span class=p>]</span>

<span class=n>amazon_result</span> <span class=o>=</span> <span class=n>calc</span><span class=o>.</span><span class=n>calculate</span><span class=p>(</span><span class=n>amazon_partitions</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Overall defect rate: </span><span class=si>{</span><span class=n>amazon_result</span><span class=o>.</span><span class=n>total_probability</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected defective units per 10,000: </span><span class=si>{</span><span class=n>amazon_result</span><span class=o>.</span><span class=n>total_probability</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>10000</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>If product is defective, which supplier?&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>post_prob</span> <span class=ow>in</span> <span class=n>amazon_result</span><span class=o>.</span><span class=n>posterior_probs</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>post_prob</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>üéØ Action: Focus QA on </span><span class=si>{</span><span class=n>amazon_result</span><span class=o>.</span><span class=n>dominant_partition</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 3: GOOGLE ADS - CLICK-THROUGH RATE ACROSS DEVICES</span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 3: GOOGLE ADS - Overall CTR Across Devices&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=n>google_partitions</span> <span class=o>=</span> <span class=p>[</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Desktop&quot;</span><span class=p>,</span> <span class=mf>0.35</span><span class=p>,</span> <span class=mf>0.08</span><span class=p>),</span>  <span class=c1># 35% traffic, 8% CTR</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Mobile&quot;</span><span class=p>,</span> <span class=mf>0.55</span><span class=p>,</span> <span class=mf>0.04</span><span class=p>),</span>   <span class=c1># 55% traffic, 4% CTR</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Tablet&quot;</span><span class=p>,</span> <span class=mf>0.10</span><span class=p>,</span> <span class=mf>0.06</span><span class=p>)</span>    <span class=c1># 10% traffic, 6% CTR</span>
<span class=p>]</span>

<span class=n>google_result</span> <span class=o>=</span> <span class=n>calc</span><span class=o>.</span><span class=n>calculate</span><span class=p>(</span><span class=n>google_partitions</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Overall CTR: </span><span class=si>{</span><span class=n>google_result</span><span class=o>.</span><span class=n>total_probability</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Revenue if $2 per click on 1M impressions: $</span><span class=si>{</span><span class=n>google_result</span><span class=o>.</span><span class=n>total_probability</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mf>1e6</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>2</span><span class=si>:</span><span class=s2>,.0f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Device mix optimization:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>google_partitions</span><span class=p>:</span>
    <span class=n>current_revenue</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>contribution</span> <span class=o>*</span> <span class=mf>1e6</span> <span class=o>*</span> <span class=mi>2</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>p</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>: $</span><span class=si>{</span><span class=n>current_revenue</span><span class=si>:</span><span class=s2>,.0f</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=n>p</span><span class=o>.</span><span class=n>prior_prob</span><span class=si>:</span><span class=s2>.0%</span><span class=si>}</span><span class=s2> traffic √ó </span><span class=si>{</span><span class=n>p</span><span class=o>.</span><span class=n>conditional_prob</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2> CTR)&quot;</span><span class=p>)</span>

<span class=c1># What if we increase mobile CTR by 1%?</span>
<span class=n>google_partitions_improved</span> <span class=o>=</span> <span class=p>[</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Desktop&quot;</span><span class=p>,</span> <span class=mf>0.35</span><span class=p>,</span> <span class=mf>0.08</span><span class=p>),</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Mobile&quot;</span><span class=p>,</span> <span class=mf>0.55</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>),</span>  <span class=c1># 4% ‚Üí 5%</span>
    <span class=n>PartitionElement</span><span class=p>(</span><span class=s2>&quot;Tablet&quot;</span><span class=p>,</span> <span class=mf>0.10</span><span class=p>,</span> <span class=mf>0.06</span><span class=p>)</span>
<span class=p>]</span>
<span class=n>google_result_improved</span> <span class=o>=</span> <span class=n>calc</span><span class=o>.</span><span class=n>calculate</span><span class=p>(</span><span class=n>google_partitions_improved</span><span class=p>)</span>

<span class=n>revenue_lift</span> <span class=o>=</span> <span class=p>(</span><span class=n>google_result_improved</span><span class=o>.</span><span class=n>total_probability</span> <span class=o>-</span> <span class=n>google_result</span><span class=o>.</span><span class=n>total_probability</span><span class=p>)</span> <span class=o>*</span> <span class=mf>1e6</span> <span class=o>*</span> <span class=mi>2</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>üöÄ If mobile CTR improves 4% ‚Üí 5%: +$</span><span class=si>{</span><span class=n>revenue_lift</span><span class=si>:</span><span class=s2>,.0f</span><span class=si>}</span><span class=s2> revenue&quot;</span><span class=p>)</span>
</code></pre></div> <h2 id=comparison-tables_1>Comparison Tables</h2> <h3 id=law-of-total-probability-vs-related-concepts>Law of Total Probability vs Related Concepts</h3> <table> <thead> <tr> <th>Concept</th> <th>Formula</th> <th>When to Use</th> <th>Partition Required?</th> </tr> </thead> <tbody> <tr> <td><strong>Law of Total Probability</strong></td> <td>P(A) = Œ£ P(A|B·µ¢)P(B·µ¢)</td> <td>Calculate marginal from conditionals</td> <td>Yes (exhaustive)</td> </tr> <tr> <td><strong>Bayes' Theorem</strong></td> <td>P(B·µ¢|A) = P(A|B·µ¢)P(B·µ¢)/P(A)</td> <td>Invert conditional direction</td> <td>No (but uses LOTP for P(A))</td> </tr> <tr> <td><strong>Chain Rule</strong></td> <td>P(A‚à©B) = P(A|B)P(B)</td> <td>Calculate joint probability</td> <td>No</td> </tr> <tr> <td><strong>Conditional Expectation</strong></td> <td>E[X] = Œ£ E[X|B·µ¢]P(B·µ¢)</td> <td>Calculate expected value</td> <td>Yes (exhaustive)</td> </tr> </tbody> </table> <h3 id=real-company-applications_1>Real Company Applications</h3> <table> <thead> <tr> <th>Company</th> <th>Problem</th> <th>Partition Variable</th> <th>Total Probability Calculated</th> <th>Business Impact</th> </tr> </thead> <tbody> <tr> <td><strong>Uber</strong></td> <td>Overall acceptance rate</td> <td>Driver tier (Diamond/Platinum/Standard)</td> <td>P(Ride Accepted) = 73.5%</td> <td>Identified Standard tier as improvement opportunity (+15% acceptance ‚Üí +$120M annual revenue)</td> </tr> <tr> <td><strong>Amazon</strong></td> <td>Product defect rate</td> <td>Supplier (A/B/C)</td> <td>P(Defective) = 3.28%</td> <td>Focused QA on Supplier C (contributes 36.6% of defects despite 15% volume)</td> </tr> <tr> <td><strong>Google Ads</strong></td> <td>Overall CTR</td> <td>Device type (Desktop/Mobile/Tablet)</td> <td>P(Click) = 5.48%</td> <td>1% mobile CTR improvement ‚Üí +$11M revenue on 1B impressions</td> </tr> <tr> <td><strong>Netflix</strong></td> <td>Content engagement</td> <td>User cohort (New/Casual/Binge)</td> <td>P(Finish Show) = 42.3%</td> <td>Personalized recommendations by cohort ‚Üí +18% completion</td> </tr> <tr> <td><strong>Stripe</strong></td> <td>Fraud detection</td> <td>Transaction type (Card/ACH/Wire)</td> <td>P(Fraud) = 1.85%</td> <td>Real-time fraud scoring reduced chargebacks by 23%</td> </tr> </tbody> </table> <h3 id=common-mistakes-vs-correct-approach>Common Mistakes vs Correct Approach</h3> <table> <thead> <tr> <th>Mistake</th> <th>Correct Approach</th> <th>Example</th> </tr> </thead> <tbody> <tr> <td>Using overlapping partitions</td> <td>Ensure B·µ¢ ‚à© B‚±º = ‚àÖ for all i‚â†j</td> <td>‚ùå {Age&lt;30, Age&gt;25} ‚Üí ‚úÖ {Age&lt;30, Age‚â•30}</td> </tr> <tr> <td>Partition doesn't sum to 1</td> <td>Verify Œ£ P(B·µ¢) = 1.0</td> <td>‚ùå P(A)=0.3, P(B)=0.5 ‚Üí ‚úÖ P(A)=0.3, P(B)=0.5, P(C)=0.2</td> </tr> <tr> <td>Forgetting continuous case</td> <td>Use integral for continuous partitions</td> <td>P(A) = ‚à´ P(A|X=x) f(x) dx</td> </tr> <tr> <td>Confusing P(A|B·µ¢) with P(B·µ¢|A)</td> <td>LOTP uses P(A|B·µ¢); Bayes gives P(B·µ¢|A)</td> <td>P(Click|Mobile) ‚â† P(Mobile|Click)</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they test:</strong></p> <ul> <li>Understanding of probability partitions (mutually exclusive, exhaustive)</li> <li>Ability to decompose complex probabilities into manageable pieces</li> <li>Connection to Bayes' theorem (LOTP computes denominator P(A))</li> <li>Application to real business problems (segmentation analysis, mixture models)</li> <li>Sensitivity analysis: which partition contributes most?</li> </ul> <p><strong>Strong signals:</strong></p> <ul> <li><strong>Writes formula immediately</strong>: "P(A) = Œ£ P(A|B·µ¢) √ó P(B·µ¢) where {B·µ¢} partition the space"</li> <li><strong>Validates partition</strong>: "First I verify Œ£ P(B·µ¢) = 1 and B·µ¢ ‚à© B‚±º = ‚àÖ for mutual exclusivity"</li> <li><strong>Real business context</strong>: "At Amazon, we use this to compute overall conversion rate across 5 customer segments‚ÄîPremium contributes 42% despite being 15% of users"</li> <li><strong>Connects to Bayes</strong>: "LOTP gives P(Defective)=3.2%, then Bayes inverts it: P(Supplier C | Defective) = 0.08√ó0.15 / 0.032 = 37.5%"</li> <li><strong>Sensitivity analysis</strong>: "Improving mobile CTR from 4% to 5% increases overall CTR by 0.55 percentage points, worth $11M on our impression volume"</li> </ul> <p><strong>Red flags:</strong></p> <ul> <li>Confuses LOTP with Bayes' theorem (they're related but distinct)</li> <li>Uses overlapping or incomplete partitions</li> <li>Can't explain when LOTP is useful (answer: marginalizing out variables)</li> <li>Forgets to weight by P(B·µ¢) ‚Äî just averages conditionals</li> <li>Doesn't validate partition sums to 1</li> </ul> <p><strong>Follow-up questions:</strong></p> <ul> <li><em>"How do you choose the partition?"</em> ‚Üí Based on available data and business segments</li> <li><em>"What if partition is continuous?"</em> ‚Üí Use integral: P(A) = ‚à´ P(A|X=x) f(x) dx</li> <li><em>"Connection to mixture models?"</em> ‚Üí Mixture density f(x) = Œ£ œÄ_k f_k(x) is LOTP for densities</li> <li><em>"How to find most important partition?"</em> ‚Üí Calculate contributions P(A|B·µ¢)P(B·µ¢), rank by magnitude</li> <li><em>"Relationship to conditional expectation?"</em> ‚Üí E[X] = Œ£ E[X|B·µ¢] P(B·µ¢) (same structure)</li> </ul> </div> <div class="admonition warning"> <p class=admonition-title>Common Pitfalls</p> <ol> <li><strong>Non-exhaustive partition</strong>: Missing categories (e.g., forgot "Other" category)</li> <li><strong>Overlap</strong>: Age groups [0-30], [25-50] ‚Üí double counts ages 25-30</li> <li><strong>Conditional direction</strong>: Using P(B·µ¢|A) instead of P(A|B·µ¢) in formula</li> <li><strong>Ignoring priors</strong>: Weighting all conditionals equally (forgetting √ó P(B·µ¢))</li> </ol> </div> </details> <hr> <h3 id=explain-expected-value-and-its-properties-google-amazon-interview-question>Explain Expected Value and Its Properties - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Expected Value</code>, <code>Mean</code>, <code>Random Variables</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Netflix, Uber</p> <details class=success> <summary>View Answer</summary> <p><strong>Expected Value</strong> (or <strong>expectation</strong>, denoted E[X]) is the long-run average value of a random variable across infinite repetitions. It's the cornerstone of <strong>decision theory</strong>, <strong>risk analysis</strong>, <strong>revenue modeling</strong>, and <strong>reinforcement learning</strong> (where agents maximize expected rewards).</p> <h2 id=core-definitions_1>Core Definitions</h2> <p><strong>Discrete Random Variable:</strong></p> <div class=arithmatex>\[E[X] = \sum_{x} x \cdot P(X=x)\]</div> <p><strong>Continuous Random Variable:</strong></p> <div class=arithmatex>\[E[X] = \int_{-\infty}^{\infty} x \cdot f(x) \, dx\]</div> <p><strong>Function of Random Variable:</strong></p> <div class=arithmatex>\[E[g(X)] = \sum_{x} g(x) \cdot P(X=x) \quad \text{or} \quad \int_{-\infty}^{\infty} g(x) \cdot f(x) \, dx\]</div> <h2 id=critical-properties-must-know>Critical Properties (Must Know)</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        EXPECTED VALUE PROPERTIES HIERARCHY                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  PROPERTY 1: LINEARITY (Most Important!)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ E[aX + bY + c] = aE[X] + bE[Y] + c                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚úÖ Works for ANY X, Y (even dependent!)                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚úÖ Extends to any linear combination                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚úÖ Foundation of portfolio theory, ML loss functions   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  PROPERTY 2: PRODUCT (Requires Independence)                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ E[XY] = E[X] ¬∑ E[Y]   IFF X ‚ä• Y                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚ö†Ô∏è  Only if X and Y are independent                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚ö†Ô∏è  Otherwise: E[XY] = E[X]E[Y] + Cov(X,Y)            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  PROPERTY 3: MONOTONICITY                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ If X ‚â§ Y, then E[X] ‚â§ E[Y]                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Preserves ordering                                     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  PROPERTY 4: LAW OF ITERATED EXPECTATIONS                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ E[X] = E[E[X|Y]]                                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ &quot;Expectation of conditional expectation = expectation&quot;‚îÇ ‚îÇ
‚îÇ  ‚îÇ Used in hierarchical models, Bayesian inference       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=production-python-implementation_2>Production Python Implementation</h2> <p>```python import numpy as np import pandas as pd from typing import Union, List, Callable, Tuple, Dict from dataclasses import dataclass from scipy import stats import matplotlib.pyplot as plt</p> <p>@dataclass class ExpectedValueResult: """Results from expected value calculation.""" expected_value: float variance: float std_dev: float median: float mode: Union[float, List[float]] distribution_type: str percentiles: Dict[int, float]</p> <p>class ExpectedValueCalculator: """ Production-grade expected value calculator.</p> <div class=codehilite><pre><span></span><code><span class=n>Used</span><span class=w> </span><span class=n>by</span><span class=o>:</span>
<span class=o>-</span><span class=w> </span><span class=n>Google</span><span class=o>:</span><span class=w> </span><span class=n>Ad</span><span class=w> </span><span class=n>revenue</span><span class=w> </span><span class=n>optimization</span><span class=w> </span><span class=p>(</span><span class=n>expected</span><span class=w> </span><span class=n>clicks</span><span class=w> </span><span class=err>√ó</span><span class=w> </span><span class=n>CPC</span><span class=p>)</span>
<span class=o>-</span><span class=w> </span><span class=n>Netflix</span><span class=o>:</span><span class=w> </span><span class=n>Content</span><span class=w> </span><span class=n>value</span><span class=w> </span><span class=n>estimation</span><span class=w> </span><span class=p>(</span><span class=n>expected</span><span class=w> </span><span class=n>watch</span><span class=w> </span><span class=n>time</span><span class=p>)</span>
<span class=o>-</span><span class=w> </span><span class=n>Uber</span><span class=o>:</span><span class=w> </span><span class=n>Trip</span><span class=w> </span><span class=n>revenue</span><span class=w> </span><span class=n>prediction</span><span class=w> </span><span class=p>(</span><span class=n>expected</span><span class=w> </span><span class=n>fare</span><span class=w> </span><span class=err>√ó</span><span class=w> </span><span class=n>acceptance</span><span class=p>)</span>
<span class=o>-</span><span class=w> </span><span class=n>DraftKings</span><span class=o>:</span><span class=w> </span><span class=n>Player</span><span class=w> </span><span class=n>value</span><span class=w> </span><span class=n>modeling</span><span class=w> </span><span class=p>(</span><span class=n>expected</span><span class=w> </span><span class=n>points</span><span class=p>)</span>
<span class=s>&quot;&quot;&quot;</span>

<span class=n>def</span><span class=w> </span><span class=n>__init__</span><span class=p>(</span><span class=nb>self</span><span class=p>)</span><span class=o>:</span>
<span class=w>    </span><span class=n>pass</span>

<span class=n>def</span><span class=w> </span><span class=n>discrete_expectation</span><span class=p>(</span>
<span class=w>    </span><span class=nb>self</span><span class=p>,</span>
<span class=w>    </span><span class=nl>values</span><span class=p>:</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>ndarray</span><span class=p>,</span>
<span class=w>    </span><span class=nl>probabilities</span><span class=p>:</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>ndarray</span><span class=p>,</span>
<span class=w>    </span><span class=nl>validate</span><span class=p>:</span><span class=w> </span><span class=kt>bool</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>True</span>
<span class=p>)</span><span class=w> </span><span class=o>-&gt;</span><span class=w> </span><span class=n>ExpectedValueResult</span><span class=o>:</span>
<span class=w>    </span><span class=s>&quot;&quot;&quot;</span>
<span class=w>    </span><span class=n>Calculate</span><span class=w> </span><span class=n>E</span><span class=p>[</span><span class=n>X</span><span class=p>]</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>discrete</span><span class=w> </span><span class=n>random</span><span class=w> </span><span class=n>variable</span><span class=p>.</span>

<span class=w>    </span><span class=nl>Args</span><span class=p>:</span>
<span class=w>        </span><span class=nl>values</span><span class=p>:</span><span class=w> </span><span class=n>Possible</span><span class=w> </span><span class=n>outcomes</span>
<span class=w>        </span><span class=nl>probabilities</span><span class=p>:</span><span class=w> </span><span class=n>P</span><span class=p>(</span><span class=n>X</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>value</span><span class=p>)</span>
<span class=w>        </span><span class=nl>validate</span><span class=p>:</span><span class=w> </span><span class=n>Check</span><span class=w> </span><span class=n>probabilities</span><span class=w> </span><span class=n>sum</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=mi>1</span>

<span class=w>    </span><span class=nl>Returns</span><span class=p>:</span>
<span class=w>        </span><span class=n>ExpectedValueResult</span><span class=w> </span><span class=n>with</span><span class=w> </span><span class=n>full</span><span class=w> </span><span class=n>statistics</span>
<span class=w>    </span><span class=s>&quot;&quot;&quot;</span>
<span class=w>    </span><span class=k>if</span><span class=w> </span><span class=n>validate</span><span class=o>:</span>
<span class=w>        </span><span class=k>if</span><span class=w> </span><span class=n>not</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>probabilities</span><span class=p>.</span><span class=n>sum</span><span class=p>(),</span><span class=w> </span><span class=mf>1.0</span><span class=p>,</span><span class=w> </span><span class=n>atol</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>)</span><span class=o>:</span>
<span class=w>            </span><span class=n>raise</span><span class=w> </span><span class=n>ValueError</span><span class=p>(</span><span class=n>f</span><span class=s>&quot;Probabilities sum to {probabilities.sum()}, not 1.0&quot;</span><span class=p>)</span>

<span class=w>    </span><span class=cp># Expected value: E[X] = Œ£ x¬∑P(X=x)</span>
<span class=w>    </span><span class=n>expected_value</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>sum</span><span class=p>(</span><span class=n>values</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>probabilities</span><span class=p>)</span>

<span class=w>    </span><span class=cp># Variance: E[X¬≤] - (E[X])¬≤</span>
<span class=w>    </span><span class=n>expected_x_squared</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>sum</span><span class=p>(</span><span class=n>values</span><span class=o>**</span><span class=mi>2</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>probabilities</span><span class=p>)</span>
<span class=w>    </span><span class=n>variance</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>expected_x_squared</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>expected_value</span><span class=o>**</span><span class=mi>2</span>
<span class=w>    </span><span class=n>std_dev</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>variance</span><span class=p>)</span>

<span class=w>    </span><span class=cp># Median (50th percentile)</span>
<span class=w>    </span><span class=n>cumulative</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>probabilities</span><span class=p>)</span>
<span class=w>    </span><span class=n>median_idx</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>cumulative</span><span class=w> </span><span class=o>&gt;=</span><span class=w> </span><span class=mf>0.5</span><span class=p>)</span>
<span class=w>    </span><span class=n>median</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>values</span><span class=p>[</span><span class=n>median_idx</span><span class=p>]</span>

<span class=w>    </span><span class=cp># Mode (most probable value)</span>
<span class=w>    </span><span class=n>mode_idx</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>probabilities</span><span class=p>)</span>
<span class=w>    </span><span class=n>mode</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>values</span><span class=p>[</span><span class=n>mode_idx</span><span class=p>]</span>

<span class=w>    </span><span class=cp># Percentiles</span>
<span class=w>    </span><span class=n>percentiles</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>{}</span><span class=err>\</span><span class=n>n</span><span class=w>            </span><span class=k>for</span><span class=w> </span><span class=n>p</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=p>[</span><span class=mi>25</span><span class=p>,</span><span class=w> </span><span class=mi>50</span><span class=p>,</span><span class=w> </span><span class=mi>75</span><span class=p>,</span><span class=w> </span><span class=mi>90</span><span class=p>,</span><span class=w> </span><span class=mi>95</span><span class=p>,</span><span class=w> </span><span class=mi>99</span><span class=p>]</span><span class=o>:</span><span class=err>\</span><span class=n>n</span><span class=w>                </span><span class=n>idx</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>np</span><span class=p>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>cumulative</span><span class=w> </span><span class=o>&gt;=</span><span class=w> </span><span class=n>p</span><span class=o>/</span><span class=mi>100</span><span class=p>)</span><span class=err>\</span><span class=n>n</span><span class=w>                </span><span class=n>percentiles</span><span class=p>[</span><span class=n>p</span><span class=p>]</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>values</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=err>\</span><span class=n>n</span><span class=w>            </span><span class=err>\</span><span class=n>n</span><span class=w>            </span><span class=k>return</span><span class=w> </span><span class=n>ExpectedValueResult</span><span class=p>(</span><span class=err>\</span><span class=n>n</span><span class=w>                </span><span class=n>expected_value</span><span class=o>=</span><span class=n>expected_value</span><span class=p>,</span><span class=err>\</span><span class=n>n</span><span class=w>                </span><span class=n>variance</span><span class=o>=</span><span class=n>variance</span><span class=p>,</span><span class=err>\</span><span class=n>n</span><span class=w>                </span><span class=n>std_dev</span><span class=o>=</span><span class=n>std_dev</span><span class=p>,</span><span class=err>\</span><span class=n>n</span><span class=w>                </span><span class=n>median</span><span class=o>=</span><span class=n>median</span><span class=p>,</span><span class=err>\</span><span class=n>n</span><span class=w>                </span><span class=n>mode</span><span class=o>=</span><span class=n>mode</span><span class=p>,</span><span class=err>\</span><span class=n>n</span><span class=w>                </span><span class=n>distribution_type</span><span class=o>=</span><span class=err>\</span><span class=s>&quot;discrete</span><span class=se>\&quot;</span><span class=s>,</span><span class=se>\n</span><span class=s>                percentiles=percentiles</span><span class=se>\n</span><span class=s>            )</span><span class=se>\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        def continuous_expectation(</span><span class=se>\n</span><span class=s>            self,</span><span class=se>\n</span><span class=s>            pdf_func: Callable[[float], float],</span><span class=se>\n</span><span class=s>            lower_bound: float = -10,</span><span class=se>\n</span><span class=s>            upper_bound: float = 10</span><span class=se>\n</span><span class=s>        ) -&gt; float:</span><span class=se>\n</span><span class=s>            </span><span class=se>\&quot;\&quot;\&quot;\n</span><span class=s>            Calculate E[X] for continuous random variable using numerical integration.</span><span class=se>\n</span><span class=s>            </span><span class=se>\n</span><span class=s>            Args:</span><span class=se>\n</span><span class=s>                pdf_func: Probability density function f(x)</span><span class=se>\n</span><span class=s>                lower_bound: Integration lower limit</span><span class=se>\n</span><span class=s>                upper_bound: Integration upper limit</span><span class=se>\n</span><span class=s>            </span><span class=se>\n</span><span class=s>            Returns:</span><span class=se>\n</span><span class=s>                Expected value</span><span class=se>\n</span><span class=s>            </span><span class=se>\&quot;\&quot;\&quot;\n</span><span class=s>            from scipy.integrate import quad</span><span class=se>\n</span><span class=s>            </span><span class=se>\n</span><span class=s>            def integrand(x):</span><span class=se>\n</span><span class=s>                return x * pdf_func(x)</span><span class=se>\n</span><span class=s>            </span><span class=se>\n</span><span class=s>            expected_value, _ = quad(integrand, lower_bound, upper_bound)</span><span class=se>\n</span><span class=s>            return expected_value</span><span class=se>\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        def linearity_demonstration(</span><span class=se>\n</span><span class=s>            self,</span><span class=se>\n</span><span class=s>            x_values: np.ndarray,</span><span class=se>\n</span><span class=s>            x_probs: np.ndarray,</span><span class=se>\n</span><span class=s>            y_values: np.ndarray,</span><span class=se>\n</span><span class=s>            y_probs: np.ndarray,</span><span class=se>\n</span><span class=s>            a: float,</span><span class=se>\n</span><span class=s>            b: float,</span><span class=se>\n</span><span class=s>            c: float</span><span class=se>\n</span><span class=s>        ) -&gt; Dict[str, float]:</span><span class=se>\n</span><span class=s>            </span><span class=se>\&quot;\&quot;\&quot;\n</span><span class=s>            Demonstrate E[aX + bY + c] = aE[X] + bE[Y] + c.</span><span class=se>\n</span><span class=s>            </span><span class=se>\n</span><span class=s>            This works EVEN IF X and Y are dependent!</span><span class=se>\n</span><span class=s>            </span><span class=se>\&quot;\&quot;\&quot;\n</span><span class=s>            e_x = np.sum(x_values * x_probs)</span><span class=se>\n</span><span class=s>            e_y = np.sum(y_values * y_probs)</span><span class=se>\n</span><span class=s>            </span><span class=se>\n</span><span class=s>            # Direct calculation: E[aX + bY + c]</span><span class=se>\n</span><span class=s>            expected_linear = a * e_x + b * e_y + c</span><span class=se>\n</span><span class=s>            </span><span class=se>\n</span><span class=s>            return {</span><span class=se>\n</span><span class=s>                &#39;E[X]&#39;: e_x,</span><span class=se>\n</span><span class=s>                &#39;E[Y]&#39;: e_y,</span><span class=se>\n</span><span class=s>                &#39;E[aX + bY + c]&#39;: expected_linear,</span><span class=se>\n</span><span class=s>                &#39;aE[X] + bE[Y] + c&#39;: a * e_x + b * e_y + c,</span><span class=se>\n</span><span class=s>                &#39;match&#39;: np.isclose(expected_linear, a * e_x + b * e_y + c)</span><span class=se>\n</span><span class=s>            }</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # ============================================================================</span><span class=se>\n</span><span class=s>    # EXAMPLE 1: UBER - EXPECTED TRIP REVENUE</span><span class=se>\n</span><span class=s>    # ============================================================================</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>=</span><span class=se>\&quot;</span><span class=s> * 70)</span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>EXAMPLE 1: UBER - Expected Trip Revenue Calculation</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>=</span><span class=se>\&quot;</span><span class=s> * 70)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Trip fare distribution based on distance</span><span class=se>\n</span><span class=s>    # Short (0-5 mi): $8-15, Medium (5-15 mi): $15-35, Long (15+ mi): $35-80</span><span class=se>\n</span><span class=s>    fare_values = np.array([10, 12, 18, 25, 30, 45, 60])</span><span class=se>\n</span><span class=s>    fare_probs = np.array([0.20, 0.15, 0.25, 0.20, 0.10, 0.07, 0.03])</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    calc = ExpectedValueCalculator()</span><span class=se>\n</span><span class=s>    result = calc.discrete_expectation(fare_values, fare_probs)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nExpected fare per trip: ${result.expected_value:.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>Standard deviation: ${result.std_dev:.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>Median fare: ${result.median:.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>Most common fare (mode): ${result.mode:.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nPercentiles:</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    for p, val in result.percentiles.items():</span><span class=se>\n</span><span class=s>        print(f</span><span class=se>\&quot;</span><span class=s>  {p}th percentile: ${val:.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Business calculation</span><span class=se>\n</span><span class=s>    trips_per_day = 1_000_000  # Uber processes 1M trips/day in major city</span><span class=se>\n</span><span class=s>    daily_revenue = result.expected_value * trips_per_day</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nüí∞ Expected daily revenue (1M trips): ${daily_revenue:,.0f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # What if we increase high-value trip probability by 5%?</span><span class=se>\n</span><span class=s>    fare_probs_optimized = np.array([0.15, 0.15, 0.25, 0.20, 0.10, 0.10, 0.05])</span><span class=se>\n</span><span class=s>    result_opt = calc.discrete_expectation(fare_values, fare_probs_optimized)</span><span class=se>\n</span><span class=s>    revenue_lift = (result_opt.expected_value - result.expected_value) * trips_per_day</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nüöÄ If we shift to longer trips: +${revenue_lift:,.0f}/day</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # ============================================================================</span><span class=se>\n</span><span class=s>    # EXAMPLE 2: DRAFTKINGS - PLAYER EXPECTED POINTS</span><span class=se>\n</span><span class=s>    # ============================================================================</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;\\</span><span class=s>n</span><span class=se>\&quot;</span><span class=s> + </span><span class=se>\&quot;</span><span class=s>=</span><span class=se>\&quot;</span><span class=s> * 70)</span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>EXAMPLE 2: DRAFTKINGS - NBA Player Expected Fantasy Points</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>=</span><span class=se>\&quot;</span><span class=s> * 70)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Player can score 0, 10, 20, 30, 40, 50+ points</span><span class=se>\n</span><span class=s>    points_values = np.array([0, 10, 20, 30, 40, 50])</span><span class=se>\n</span><span class=s>    points_probs = np.array([0.05, 0.20, 0.35, 0.25, 0.10, 0.05])</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    result_player = calc.discrete_expectation(points_values, points_probs)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nExpected points: {result_player.expected_value:.1f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>Risk (std dev): {result_player.std_dev:.1f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>75th percentile: {result_player.percentiles[75]:.0f} points</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # DraftKings pricing model: Cost = E[Points] √ó $200/point</span><span class=se>\n</span><span class=s>    cost_per_point = 200</span><span class=se>\n</span><span class=s>    player_salary = result_player.expected_value * cost_per_point</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nüíµ Fair salary: ${player_salary:,.0f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Value score: Expected points per $1000 of salary</span><span class=se>\n</span><span class=s>    value_score = result_player.expected_value / (player_salary / 1000)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>üìä Value score: {value_score:.2f} pts/$1000</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # ============================================================================</span><span class=se>\n</span><span class=s>    # EXAMPLE 3: NETFLIX - EXPECTED CONTENT WATCH TIME</span><span class=se>\n</span><span class=s>    # ============================================================================</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;\\</span><span class=s>n</span><span class=se>\&quot;</span><span class=s> + </span><span class=se>\&quot;</span><span class=s>=</span><span class=se>\&quot;</span><span class=s> * 70)</span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>EXAMPLE 3: NETFLIX - Expected Watch Time for New Show</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>=</span><span class=se>\&quot;</span><span class=s> * 70)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # User watch behavior: 0 episodes (bounce), 1-3 (sample), 4-8 (hooked), 9-10 (binge)</span><span class=se>\n</span><span class=s>    episodes_watched = np.array([0, 2, 5, 8, 10])</span><span class=se>\n</span><span class=s>    watch_probs = np.array([0.25, 0.30, 0.25, 0.15, 0.05])  # 25% bounce rate</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    result_watch = calc.discrete_expectation(episodes_watched, watch_probs)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nExpected episodes watched: {result_watch.expected_value:.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>Median: {result_watch.median:.0f} episodes</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Business metrics</span><span class=se>\n</span><span class=s>    avg_episode_length_min = 45</span><span class=se>\n</span><span class=s>    expected_watch_time_hours = result_watch.expected_value * avg_episode_length_min / 60</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>Expected watch time: {expected_watch_time_hours:.1f} hours</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Content value calculation</span><span class=se>\n</span><span class=s>    production_cost = 10_000_000  # $10M for 10 episodes</span><span class=se>\n</span><span class=s>    subscribers_viewing = 50_000_000  # 50M viewers</span><span class=se>\n</span><span class=s>    cost_per_viewer = production_cost / subscribers_viewing</span><span class=se>\n</span><span class=s>    value_per_hour = cost_per_viewer / expected_watch_time_hours</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nüì∫ Production cost: ${production_cost:,}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>Cost per viewer: ${cost_per_viewer:.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>Cost per viewer-hour: ${value_per_hour:.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # What if we reduce bounce rate from 25% to 20%?</span><span class=se>\n</span><span class=s>    watch_probs_improved = np.array([0.20, 0.30, 0.25, 0.18, 0.07])</span><span class=se>\n</span><span class=s>    result_watch_improved = calc.discrete_expectation(episodes_watched, watch_probs_improved)</span><span class=se>\n</span><span class=s>    watch_time_gain = (result_watch_improved.expected_value - result_watch.expected_value) * subscribers_viewing</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>n‚ú® Reducing bounce 25% ‚Üí 20%: +{watch_time_gain / 1e6:.1f}M total episodes watched</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # ============================================================================</span><span class=se>\n</span><span class=s>    # EXAMPLE 4: LINEARITY OF EXPECTATION (POWERFUL PROPERTY)</span><span class=se>\n</span><span class=s>    # ============================================================================</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;\\</span><span class=s>n</span><span class=se>\&quot;</span><span class=s> + </span><span class=se>\&quot;</span><span class=s>=</span><span class=se>\&quot;</span><span class=s> * 70)</span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>EXAMPLE 4: Linearity of Expectation - Portfolio Returns</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(</span><span class=se>\&quot;</span><span class=s>=</span><span class=se>\&quot;</span><span class=s> * 70)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Stock A returns</span><span class=se>\n</span><span class=s>    returns_a = np.array([-0.10, 0.00, 0.05, 0.15, 0.25])</span><span class=se>\n</span><span class=s>    probs_a = np.array([0.10, 0.20, 0.40, 0.20, 0.10])</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Stock B returns</span><span class=se>\n</span><span class=s>    returns_b = np.array([-0.05, 0.02, 0.08, 0.12, 0.20])</span><span class=se>\n</span><span class=s>    probs_b = np.array([0.15, 0.25, 0.30, 0.20, 0.10])</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    # Portfolio: 60% stock A, 40% stock B, with $10k initial investment</span><span class=se>\n</span><span class=s>    weight_a, weight_b = 0.6, 0.4</span><span class=se>\n</span><span class=s>    initial_investment = 10000</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    linearity_result = calc.linearity_demonstration(</span><span class=se>\n</span><span class=s>        returns_a, probs_a,</span><span class=se>\n</span><span class=s>        returns_b, probs_b,</span><span class=se>\n</span><span class=s>        a=weight_a, b=weight_b, c=0</span><span class=se>\n</span><span class=s>    )</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nE[Return_A] = {linearity_result[&#39;E[X]&#39;]:.2%}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>E[Return_B] = {linearity_result[&#39;E[Y]&#39;]:.2%}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nPortfolio: {weight_a:.0%} A + {weight_b:.0%} B</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>E[Portfolio Return] = {linearity_result[&#39;E[aX + bY + c]&#39;]:.2%}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    expected_profit = linearity_result[&#39;E[aX + bY + c]&#39;] * initial_investment</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>nExpected profit on ${initial_investment:,}: ${expected_profit:,.2f}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    </span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;\\</span><span class=s>n‚úÖ Linearity verified: {linearity_result[&#39;match&#39;]}</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    print(f</span><span class=se>\&quot;</span><span class=s>   (Works even if stock returns are correlated!)</span><span class=se>\&quot;</span><span class=s>)</span><span class=se>\n</span><span class=s>    ```</span><span class=se>\n\n</span><span class=s>    ## Comparison Tables</span><span class=se>\n\n</span><span class=s>    ### Expected Value vs Other Central Tendency Measures</span><span class=se>\n\n</span><span class=s>    | Measure | Formula | Interpretation | Robust to Outliers? | When to Use |</span><span class=se>\n</span><span class=s>    |---------|---------|----------------|---------------------|-------------|</span><span class=se>\n</span><span class=s>    | **Expected Value** | E[X] = Œ£ x¬∑P(x) | Long-run average | **No** | Decision-making, revenue forecasting |</span><span class=se>\n</span><span class=s>    | **Median** | 50th percentile | Middle value | **Yes** | Skewed distributions (income, house prices) |</span><span class=se>\n</span><span class=s>    | **Mode** | Most frequent value | Typical outcome | **Yes** | Categorical data, most likely scenario |</span><span class=se>\n</span><span class=s>    | **Geometric Mean** | (‚àè x_i)^(1/n) | Compound growth | **Partial** | Investment returns, growth rates |</span><span class=se>\n\n</span><span class=s>    ### Linearity vs Product Property</span><span class=se>\n\n</span><span class=s>    | Property | Formula | Independence Required? | Example | Power |</span><span class=se>\n</span><span class=s>    |----------|---------|----------------------|---------|-------|</span><span class=se>\n</span><span class=s>    | **Linearity** | E[aX + bY + c] = aE[X] + bE[Y] + c | **NO** ‚úÖ | Portfolio expected return = weighted average | Simplifies complex calculations |</span><span class=se>\n</span><span class=s>    | **Product** | E[XY] = E[X]¬∑E[Y] | **YES** ‚ö†Ô∏è | Expected revenue = E[customers] √ó E[spend per customer] | Only if independent |</span><span class=se>\n\n</span><span class=s>    ### Real Company Applications</span><span class=se>\n\n</span><span class=s>    | Company | Problem | Random Variable X | E[X] Used For | Business Impact |</span><span class=se>\n</span><span class=s>    |---------|---------|------------------|---------------|----------------|</span><span class=se>\n</span><span class=s>    | **Uber** | Trip revenue | Fare amount | E[Fare] = $22.50 | Revenue forecasting: $22.50 √ó 15M trips/day = $338M daily |</span><span class=se>\n</span><span class=s>    | **DraftKings** | Player pricing | Fantasy points | E[Points] = 28.5 ‚Üí Salary $5,700 | Fair pricing prevents arbitrage |</span><span class=se>\n</span><span class=s>    | **Netflix** | Content value | Episodes watched | E[Episodes] = 4.2 ‚Üí 3.15 hrs watch time | $10M show √∑ 50M viewers = $0.20/viewer |</span><span class=se>\n</span><span class=s>    | **Google Ads** | Campaign ROI | Click-through | E[Clicks] = 0.05 √ó 1M impressions = 50k clicks | Bid optimization: max bid = E[conversion value] |</span><span class=se>\n</span><span class=s>    | **Amazon** | Inventory planning | Daily demand | E[Units sold] = 1,250 ¬± 200 | Stock 1,450 units (E[X] + 1œÉ buffer) |</span><span class=se>\n\n</span><span class=s>    ### Common Misconceptions</span><span class=se>\n\n</span><span class=s>    | Misconception | Truth | Example |</span><span class=se>\n</span><span class=s>    |---------------|-------|----------|</span><span class=se>\n</span><span class=s>    | E[X] is the </span><span class=se>\&quot;</span><span class=s>most likely</span><span class=se>\&quot;</span><span class=s> value | **FALSE**: E[X] can be impossible outcome | E[Die roll] = 3.5, but die never shows 3.5 |</span><span class=se>\n</span><span class=s>    | E[1/X] = 1/E[X] | **FALSE**: Jensen&#39;s inequality | E[1/X] ‚â• 1/E[X] for positive X |</span><span class=se>\n</span><span class=s>    | E[X¬≤] = (E[X])¬≤ | **FALSE**: Missing variance term | E[X¬≤] = (E[X])¬≤ + Var(X) |</span><span class=se>\n</span><span class=s>    | Need independence for E[X+Y]=E[X]+E[Y] | **FALSE**: Linearity always works | Even correlated variables: E[X+X] = 2E[X] |</span><span class=se>\n\n</span><span class=s>    !!! tip </span><span class=se>\&quot;</span><span class=s>Interviewer&#39;s Insight</span><span class=se>\&quot;\n</span><span class=s>        **What they test:**</span><span class=se>\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        - Fundamental understanding: Can you explain E[X] as </span><span class=se>\&quot;</span><span class=s>probability-weighted average</span><span class=se>\&quot;</span><span class=s>?</span><span class=se>\n</span><span class=s>        - Linearity property: Do you know E[X+Y] = E[X] + E[Y] works WITHOUT independence?</span><span class=se>\n</span><span class=s>        - Practical application: Can you compute expected revenue, expected profit, expected return?</span><span class=se>\n</span><span class=s>        - Distinction from median/mode: When is E[X] not the </span><span class=se>\&quot;</span><span class=s>typical</span><span class=se>\&quot;</span><span class=s> value?</span><span class=se>\n</span><span class=s>        - Jensen&#39;s inequality: Understand E[g(X)] ‚â† g(E[X]) for nonlinear g</span><span class=se>\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        **Strong signals:**</span><span class=se>\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        - **Formula mastery**: </span><span class=se>\&quot;</span><span class=s>E[X] = Œ£ x¬∑P(x) for discrete, ‚à´ x¬∑f(x)dx for continuous</span><span class=se>\&quot;\n</span><span class=s>        - **Linearity emphasis**: </span><span class=se>\&quot;</span><span class=s>Linearity of expectation is EXTREMELY powerful‚Äîit works even when X and Y are dependent. At Uber, we use E[Revenue] = E[Trips] √ó E[Fare per trip] even though they&#39;re correlated</span><span class=se>\&quot;\n</span><span class=s>        - **Real calculation**: </span><span class=se>\&quot;</span><span class=s>Netflix&#39;s expected watch time: 25% bounce (0 eps) + 30% sample (2 eps) + 25% hooked (5 eps) + 15% binge (8 eps) + 5% complete (10 eps) = 0 + 0.6 + 1.25 + 1.2 + 0.5 = 3.55 episodes</span><span class=se>\&quot;\n</span><span class=s>        - **Business context**: </span><span class=se>\&quot;</span><span class=s>Expected value drives pricing: DraftKings prices players at $200 per expected fantasy point, so a 25-point expectation = $5,000 salary</span><span class=se>\&quot;\n</span><span class=s>        - **Distinguishes from median**: </span><span class=se>\&quot;</span><span class=s>For skewed distributions like income, median is more representative than mean. E[Income] is pulled up by billionaires</span><span class=se>\&quot;\n</span><span class=s>        - **Jensen&#39;s inequality**: </span><span class=se>\&quot;</span><span class=s>For convex function like x¬≤, E[X¬≤] ‚â• (E[X])¬≤. This is why Var(X) = E[X¬≤] - (E[X])¬≤ ‚â• 0</span><span class=se>\&quot;\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        **Red flags:**</span><span class=se>\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        - Confuses E[X] with </span><span class=se>\&quot;</span><span class=s>most likely value</span><span class=se>\&quot;</span><span class=s> (that&#39;s the mode)</span><span class=se>\n</span><span class=s>        - Thinks E[XY] = E[X]¬∑E[Y] always (needs independence)</span><span class=se>\n</span><span class=s>        - Can&#39;t calculate E[X] from a probability distribution by hand</span><span class=se>\n</span><span class=s>        - Doesn&#39;t recognize linearity as the KEY property</span><span class=se>\n</span><span class=s>        - Says </span><span class=se>\&quot;</span><span class=s>average</span><span class=se>\&quot;</span><span class=s> without clarifying arithmetic mean vs expected value</span><span class=se>\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        **Follow-up questions:**</span><span class=se>\n</span><span class=s>        </span><span class=se>\n</span><span class=s>        - *</span><span class=se>\&quot;</span><span class=s>How do you calculate E[X] if you only have data, not the distribution?</span><span class=se>\&quot;</span><span class=s>* ‚Üí Sample mean: xÃÑ = Œ£x_i/n</span><span class=se>\n</span><span class=s>        - *</span><span class=se>\&quot;</span><span class=s>When does E[XY] = E[X]¬∑E[Y]?</span><span class=se>\&quot;</span><span class=s>* ‚Üí When X ‚ä• Y (independent)</span><span class=se>\n</span><span class=s>        - *</span><span class=se>\&quot;</span><span class=s>What&#39;s E[X | Y]?</span><span class=se>\&quot;</span><span class=s>* ‚Üí Conditional expectation: E[X | Y=y] = Œ£ x¬∑P(X=x | Y=y)</span><span class=se>\n</span><span class=s>        - *</span><span class=se>\&quot;</span><span class=s>Explain Jensen&#39;s inequality</span><span class=se>\&quot;</span><span class=s>* ‚Üí For convex f: E[f(X)] ‚â• f(E[X])</span><span class=se>\n</span><span class=s>        - *</span><span class=se>\&quot;</span><span class=s>Expected value vs expected utility?</span><span class=se>\&quot;</span><span class=s>* ‚Üí Utility captures risk aversion: E[U(X)] vs E[X]</span><span class=se>\n\n</span><span class=s>    !!! warning </span><span class=se>\&quot;</span><span class=s>Common Pitfalls</span><span class=se>\&quot;\n</span><span class=s>        1. **Interpreting E[X] as attainable**: E[Die] = 3.5 is never rolled</span><span class=se>\n</span><span class=s>        2. **Forgetting to weight by probability**: E[X] ‚â† average of possible values</span><span class=se>\n</span><span class=s>        3. **Assuming product rule without independence**: E[XY] = E[X]E[Y] only if X ‚ä• Y</span><span class=se>\n</span><span class=s>        4. **Confusing E[X¬≤] with (E[X])¬≤**: Related by Var(X) = E[X¬≤] - (E[X])¬≤</span>
</code></pre></div> </details> <hr> <h3 id=what-is-variance-how-is-it-related-to-standard-deviation-google-meta-interview-question>What is Variance? How is it Related to Standard Deviation? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Variance</code>, <code>Standard Deviation</code>, <code>Spread</code>, <code>Risk</code> | <strong>Asked by:</strong> Google, Meta, Amazon, Netflix, JPMorgan</p> <details class=success> <summary>View Answer</summary> <p><strong>Variance</strong> and <strong>Standard Deviation</strong> quantify the <strong>spread</strong> or <strong>dispersion</strong> of a probability distribution. In business: variance = <strong>risk</strong>, and managing variance is critical for <strong>portfolio optimization</strong>, <strong>quality control</strong>, <strong>A/B test power analysis</strong>, and <strong>anomaly detection</strong>.</p> <h2 id=core-definitions_2>Core Definitions</h2> <p><strong>Variance (œÉ¬≤ or Var(X)):</strong></p> <div class=arithmatex>\[Var(X) = E[(X - \mu)^2] = E[X^2] - (E[X])^2\]</div> <p><strong>Standard Deviation (œÉ or SD(X)):</strong></p> <div class=arithmatex>\[\sigma = \sqrt{Var(X)}\]</div> <p><strong>Key Insight:</strong> Standard deviation has the SAME UNITS as X, while variance has squared units. This makes œÉ interpretable: "typical deviation from mean."</p> <h2 id=variance-properties-framework>Variance Properties Framework</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         VARIANCE PROPERTIES (CRITICAL FOR INTERVIEWS)         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  PROPERTY 1: Variance of Constant = 0                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Var(c) = 0                                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ No randomness ‚Üí no variance                           ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  PROPERTY 2: Scaling (QUADRATIC!)                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Var(aX) = a¬≤ ¬∑ Var(X)                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚ö†Ô∏è  SQUARES the constant (unlike expectation)          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Example: Var(2X) = 4¬∑Var(X), not 2¬∑Var(X)            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  PROPERTY 3: Translation Invariance                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Var(X + b) = Var(X)                                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Shifting all values doesn&#39;t change spread             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  PROPERTY 4: Sum of Independent Variables                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Var(X + Y) = Var(X) + Var(Y)   IFF X ‚ä• Y             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Variances ADD for independent variables               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚ö†Ô∏è  Requires independence (unlike expectation)         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  PROPERTY 5: Sum with Covariance (General Case)              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Var(X + Y) = Var(X) + Var(Y) + 2¬∑Cov(X,Y)            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Covariance term captures dependence                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Cov(X,Y) &gt; 0 ‚Üí more variance (positive correlation)   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Cov(X,Y) &lt; 0 ‚Üí less variance (hedging effect)         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p><strong>Example - Dice Variance:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Roll of fair die</span>
<span class=n>outcomes</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span>
<span class=n>probs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=o>/</span><span class=mi>6</span><span class=p>]</span> <span class=o>*</span> <span class=mi>6</span><span class=p>)</span>

<span class=c1># E[X] = 3.5</span>
<span class=n>E_X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>outcomes</span> <span class=o>*</span> <span class=n>probs</span><span class=p>)</span>

<span class=c1># E[X¬≤] = 1¬≤¬∑(1/6) + 2¬≤¬∑(1/6) + ... + 6¬≤¬∑(1/6) = 91/6 ‚âà 15.167</span>
<span class=n>E_X2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>outcomes</span><span class=o>**</span><span class=mi>2</span> <span class=o>*</span> <span class=n>probs</span><span class=p>)</span>

<span class=c1># Var(X) = E[X¬≤] - (E[X])¬≤  = 91/6 - (7/2)¬≤ = 91/6 - 49/4 ‚âà 2.917</span>
<span class=n>variance</span> <span class=o>=</span> <span class=n>E_X2</span> <span class=o>-</span> <span class=n>E_X</span><span class=o>**</span><span class=mi>2</span>
<span class=n>std_dev</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>variance</span><span class=p>)</span>  <span class=c1># œÉ ‚âà 1.708</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[X] = </span><span class=si>{</span><span class=n>E_X</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Var(X) = </span><span class=si>{</span><span class=n>variance</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;SD(X) = </span><span class=si>{</span><span class=n>std_dev</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Scaling demonstration: Var(2X) = 4¬∑Var(X)</span>
<span class=n>variance_2x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>outcomes</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=mi>6</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Var(2X) = </span><span class=si>{</span><span class=mi>4</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>variance</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>  (4 times larger!)&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Why Standard Deviation?</strong></p> <ul> <li><strong>Same units</strong> as original data (variance has squared units like "dollars¬≤")</li> <li><strong>Interpretable</strong>: For normal distributions, ~68% of data within ¬±1œÉ</li> <li><strong>Used in</strong> confidence intervals, z-scores, Sharpe ratios</li> <li><strong>Communication</strong>: Easier to explain "¬±$500" than "variance of 250,000 dollars¬≤"</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they test:</strong></p> <ul> <li>Formula mastery: Can you write Var(X) = E[X¬≤] - (E[X])¬≤ and derive it?</li> <li>Scaling property: Do you know Var(aX) = a¬≤¬∑Var(X) (quadratic, not linear)?</li> <li>Independence requirement: Var(X+Y) = Var(X)+Var(Y) only if X‚ä•Y</li> <li>Real-world interpretation: Variance = risk, lower variance = more predictable</li> <li>Coefficient of variation: œÉ/Œº for comparing variability across different scales</li> </ul> <p><strong>Strong signals:</strong></p> <ul> <li><strong>Formula with derivation</strong>: "Var(X) = E[(X-Œº)¬≤] expands to E[X¬≤-2ŒºX+Œº¬≤] = E[X¬≤]-2ŒºE[X]+Œº¬≤ = E[X¬≤]-(E[X])¬≤ by linearity"</li> <li><strong>Scaling intuition</strong>: "Var(2X) = 4¬∑Var(X) because variance measures squared deviations. Doubling all values quadruples spread"</li> <li><strong>Real business example</strong>: "At Amazon, Prime delivery has œÉ=0.6 days vs Standard œÉ=1.8 days. That's 67% variance reduction"</li> <li><strong>Covariance in sums</strong>: "For dependent variables: Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y). This is why diversification works in finance"</li> </ul> <p><strong>Red flags:</strong></p> <ul> <li>Confuses Var(aX) = a¬∑Var(X) (wrong, should be a¬≤)</li> <li>Thinks Var(X+Y) = Var(X)+Var(Y) always (needs independence)</li> <li>Can't explain why we use œÉ instead of œÉ¬≤ (units!)</li> <li>Doesn't know E[X¬≤] - (E[X])¬≤ formula</li> </ul> </div> </details> <hr> <h3 id=explain-the-central-limit-theorem-google-amazon-interview-question>Explain the Central Limit Theorem - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>CLT</code>, <code>Normal Distribution</code>, <code>Sampling</code>, <code>Inference</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft, Netflix</p> <details class=success> <summary>View Answer</summary> <p>The <strong>Central Limit Theorem (CLT)</strong> is arguably the most important theorem in statistics. It states that <strong>sample means become normally distributed</strong> as sample size increases, <strong>regardless of the population's original distribution</strong>. This is why we can use normal-based inference (z-tests, t-tests, confidence intervals) even when data isn't normal!</p> <h2 id=formal-statement>Formal Statement</h2> <p>Let X‚ÇÅ, X‚ÇÇ, ..., X‚Çô be i.i.d. random variables with E[X·µ¢] = Œº and Var(X·µ¢) = œÉ¬≤ &lt; ‚àû.</p> <p>Then the <strong>sample mean</strong> XÃÑ‚Çô = (X‚ÇÅ + ... + X‚Çô)/n converges in distribution to normal:</p> <div class=arithmatex>\[\bar{X}_n \xrightarrow{d} N\left(\mu, \frac{\sigma^2}{n}\right)\]</div> <p>Equivalently, the <strong>standardized</strong> sample mean:</p> <div class=arithmatex>\[Z_n = \frac{\bar{X}_n - \mu}{\sigma / \sqrt{n}} \xrightarrow{d} N(0, 1)\]</div> <h2 id=clt-workflow>CLT Workflow</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CENTRAL LIMIT THEOREM MAGIC EXPLAINED                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 1: Start with ANY Population Distribution              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Exponential, Uniform, Binomial, Even Bimodal!          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Only requirement: Finite variance œÉ¬≤                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Population: Œº (mean), œÉ¬≤ (variance)                   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  STEP 2: Draw Samples of Size n                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Take n observations: X‚ÇÅ, X‚ÇÇ, ..., X‚Çô                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Calculate sample mean: XÃÑ = (Œ£X·µ¢) / n                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Repeat many times ‚Üí get distribution of XÃÑ            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  STEP 3: Observe the Miracle! üéâ                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Distribution of XÃÑ becomes NORMAL as n increases!     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Mean: E[XÃÑ] = Œº (same as population)                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Variance: Var(XÃÑ) = œÉ¬≤/n (decreases with n)        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Std Dev (SE): SD(XÃÑ) = œÉ/‚àön (&quot;Standard Error&quot;)     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ For n‚â•30: XÃÑ ~ N(Œº, œÉ¬≤/n) approximately              ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ               ‚Üì                                              ‚îÇ
‚îÇ  PRACTICAL CONSEQUENCE                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Can use z-tests, t-tests, confidence intervals         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ WITHOUT assuming population is normal!                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ This is the foundation of A/B testing!                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=production-python-implementation_3>Production Python Implementation</h2> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>Callable</span><span class=p>,</span> <span class=n>List</span><span class=p>,</span> <span class=n>Tuple</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span>


<span class=nd>@dataclass</span>
<span class=k>class</span><span class=w> </span><span class=nc>CLTDemonstration</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Results from CLT simulation.&quot;&quot;&quot;</span>
    <span class=n>population_mean</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>population_std</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>sample_size</span><span class=p>:</span> <span class=nb>int</span>
    <span class=n>num_samples</span><span class=p>:</span> <span class=nb>int</span>
    <span class=n>sample_means</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span>
    <span class=n>theoretical_mean</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>theoretical_std_error</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>empirical_mean</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>empirical_std_error</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>normality_test_pvalue</span><span class=p>:</span> <span class=nb>float</span>


<span class=k>class</span><span class=w> </span><span class=nc>CentralLimitTheoremAnalyzer</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Demonstrate and apply Central Limit Theorem.</span>

<span class=sd>    Used by:</span>
<span class=sd>    - Google: A/B test sample size calculations</span>
<span class=sd>    - Netflix: Confidence intervals for engagement metrics</span>
<span class=sd>    - Amazon: Quality control (defect rate estimation)</span>
<span class=sd>    - Uber: Trip duration confidence intervals</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=nf>demonstrate_clt</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>population_dist</span><span class=p>:</span> <span class=n>Callable</span><span class=p>,</span>
        <span class=n>sample_size</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
        <span class=n>num_samples</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>10000</span><span class=p>,</span>
        <span class=n>population_mean</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>float</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
        <span class=n>population_std</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>float</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>CLTDemonstration</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Demonstrate CLT by simulation.</span>

<span class=sd>        Args:</span>
<span class=sd>            population_dist: Function that generates n samples from population</span>
<span class=sd>            sample_size: Size of each sample (n)</span>
<span class=sd>            num_samples: Number of sample means to generate</span>
<span class=sd>            population_mean: True population mean (if known)</span>
<span class=sd>            population_std: True population std dev (if known)</span>

<span class=sd>        Returns:</span>
<span class=sd>            CLTDemonstration with empirical and theoretical statistics</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=c1># Generate many sample means</span>
        <span class=n>sample_means</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
            <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>population_dist</span><span class=p>(</span><span class=n>sample_size</span><span class=p>))</span>
            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_samples</span><span class=p>)</span>
        <span class=p>])</span>

        <span class=c1># Empirical statistics from simulation</span>
        <span class=n>empirical_mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>sample_means</span><span class=p>)</span>
        <span class=n>empirical_std_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>sample_means</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

        <span class=c1># Theoretical statistics (if population params known)</span>
        <span class=k>if</span> <span class=n>population_mean</span> <span class=ow>is</span> <span class=kc>None</span> <span class=ow>or</span> <span class=n>population_std</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=c1># Estimate from large sample</span>
            <span class=n>large_sample</span> <span class=o>=</span> <span class=n>population_dist</span><span class=p>(</span><span class=mi>100000</span><span class=p>)</span>
            <span class=n>population_mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>large_sample</span><span class=p>)</span>
            <span class=n>population_std</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>large_sample</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

        <span class=n>theoretical_std_error</span> <span class=o>=</span> <span class=n>population_std</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>sample_size</span><span class=p>)</span>

        <span class=c1># Test normality (Shapiro-Wilk)</span>
        <span class=n>_</span><span class=p>,</span> <span class=n>normality_pvalue</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>shapiro</span><span class=p>(</span>
            <span class=n>sample_means</span><span class=p>[:</span><span class=mi>5000</span><span class=p>]</span>  <span class=c1># Shapiro-Wilk limit</span>
        <span class=p>)</span>

        <span class=k>return</span> <span class=n>CLTDemonstration</span><span class=p>(</span>
            <span class=n>population_mean</span><span class=o>=</span><span class=n>population_mean</span><span class=p>,</span>
            <span class=n>population_std</span><span class=o>=</span><span class=n>population_std</span><span class=p>,</span>
            <span class=n>sample_size</span><span class=o>=</span><span class=n>sample_size</span><span class=p>,</span>
            <span class=n>num_samples</span><span class=o>=</span><span class=n>num_samples</span><span class=p>,</span>
            <span class=n>sample_means</span><span class=o>=</span><span class=n>sample_means</span><span class=p>,</span>
            <span class=n>theoretical_mean</span><span class=o>=</span><span class=n>population_mean</span><span class=p>,</span>
            <span class=n>theoretical_std_error</span><span class=o>=</span><span class=n>theoretical_std_error</span><span class=p>,</span>
            <span class=n>empirical_mean</span><span class=o>=</span><span class=n>empirical_mean</span><span class=p>,</span>
            <span class=n>empirical_std_error</span><span class=o>=</span><span class=n>empirical_std_error</span><span class=p>,</span>
            <span class=n>normality_test_pvalue</span><span class=o>=</span><span class=n>normality_pvalue</span>
        <span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>minimum_sample_size</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>population_std</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
        <span class=n>margin_of_error</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
        <span class=n>confidence_level</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.95</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Calculate minimum sample size for desired precision.</span>

<span class=sd>        Based on CLT: n = (z*œÉ / E)¬≤</span>
<span class=sd>        where E = margin of error</span>

<span class=sd>        Used by data scientists for experiment design.</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>z_score</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>ppf</span><span class=p>((</span><span class=mi>1</span> <span class=o>+</span> <span class=n>confidence_level</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span><span class=p>)</span>
        <span class=n>n</span> <span class=o>=</span> <span class=p>(</span><span class=n>z_score</span> <span class=o>*</span> <span class=n>population_std</span> <span class=o>/</span> <span class=n>margin_of_error</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span>
        <span class=k>return</span> <span class=nb>int</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 1: EXPONENTIAL DISTRIBUTION ‚Üí NORMAL SAMPLE MEANS</span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 1: CLT with Exponential Distribution (Highly Skewed)&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=n>analyzer</span> <span class=o>=</span> <span class=n>CentralLimitTheoremAnalyzer</span><span class=p>()</span>

<span class=c1># Exponential(Œª=1): Mean=1, Var=1, Highly right-skewed</span>
<span class=n>exponential_dist</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>n</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>n</span><span class=p>)</span>

<span class=c1># Small sample size (n=5) - CLT weak</span>
<span class=n>result_n5</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>demonstrate_clt</span><span class=p>(</span>
    <span class=n>exponential_dist</span><span class=p>,</span>
    <span class=n>sample_size</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
    <span class=n>population_mean</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
    <span class=n>population_std</span><span class=o>=</span><span class=mf>1.0</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Sample size n=5:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Theoretical SE: </span><span class=si>{</span><span class=n>result_n5</span><span class=o>.</span><span class=n>theoretical_std_error</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Empirical SE: </span><span class=si>{</span><span class=n>result_n5</span><span class=o>.</span><span class=n>empirical_std_error</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Normality test p-value: </span><span class=si>{</span><span class=n>result_n5</span><span class=o>.</span><span class=n>normality_test_pvalue</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Normal? </span><span class=si>{</span><span class=n>result_n5</span><span class=o>.</span><span class=n>normality_test_pvalue</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=mf>0.05</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Medium sample size (n=30) - CLT kicks in!</span>
<span class=n>result_n30</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>demonstrate_clt</span><span class=p>(</span>
    <span class=n>exponential_dist</span><span class=p>,</span>
    <span class=n>sample_size</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span>
    <span class=n>population_mean</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
    <span class=n>population_std</span><span class=o>=</span><span class=mf>1.0</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Sample size n=30:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Theoretical SE: </span><span class=si>{</span><span class=n>result_n30</span><span class=o>.</span><span class=n>theoretical_std_error</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Empirical SE: </span><span class=si>{</span><span class=n>result_n30</span><span class=o>.</span><span class=n>empirical_std_error</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Normality test p-value: </span><span class=si>{</span><span class=n>result_n30</span><span class=o>.</span><span class=n>normality_test_pvalue</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Normal? </span><span class=si>{</span><span class=n>result_n30</span><span class=o>.</span><span class=n>normality_test_pvalue</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=mf>0.05</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Large sample size (n=100) - Strongly normal</span>
<span class=n>result_n100</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>demonstrate_clt</span><span class=p>(</span>
    <span class=n>exponential_dist</span><span class=p>,</span>
    <span class=n>sample_size</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
    <span class=n>population_mean</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
    <span class=n>population_std</span><span class=o>=</span><span class=mf>1.0</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Sample size n=100:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Theoretical SE: </span><span class=si>{</span><span class=n>result_n100</span><span class=o>.</span><span class=n>theoretical_std_error</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Empirical SE: </span><span class=si>{</span><span class=n>result_n100</span><span class=o>.</span><span class=n>empirical_std_error</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Normality test p-value: </span><span class=si>{</span><span class=n>result_n100</span><span class=o>.</span><span class=n>normality_test_pvalue</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Normal? </span><span class=si>{</span><span class=n>result_n100</span><span class=o>.</span><span class=n>normality_test_pvalue</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=mf>0.05</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>üéØ As n increases, SE decreases (‚àön): </span><span class=si>{</span><span class=mi>1</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>5</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ‚Üí </span><span class=si>{</span><span class=mi>1</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>30</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ‚Üí </span><span class=si>{</span><span class=mi>1</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>100</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 2: NETFLIX - CONFIDENCE INTERVAL FOR AVG WATCH TIME</span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 2: NETFLIX - Watch Time Confidence Interval (CLT)&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=c1># Sample of 500 users</span>
<span class=c1># Population: Unknown distribution (probably right-skewed)</span>
<span class=c1># But CLT lets us use normal inference!</span>

<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
<span class=n>watch_times</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>gamma</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>2.5</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>500</span><span class=p>)</span>  <span class=c1># Skewed data</span>

<span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>watch_times</span><span class=p>)</span>
<span class=n>sample_mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>watch_times</span><span class=p>)</span>
<span class=n>sample_std</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>watch_times</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=c1># Standard error (by CLT)</span>
<span class=n>se</span> <span class=o>=</span> <span class=n>sample_std</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>

<span class=c1># 95% confidence interval</span>
<span class=n>z_95</span> <span class=o>=</span> <span class=mf>1.96</span>
<span class=n>ci_95</span> <span class=o>=</span> <span class=p>(</span><span class=n>sample_mean</span> <span class=o>-</span> <span class=n>z_95</span> <span class=o>*</span> <span class=n>se</span><span class=p>,</span> <span class=n>sample_mean</span> <span class=o>+</span> <span class=n>z_95</span> <span class=o>*</span> <span class=n>se</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Sample size: </span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s2> users&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Sample mean: </span><span class=si>{</span><span class=n>sample_mean</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> hours&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Sample std dev: </span><span class=si>{</span><span class=n>sample_std</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> hours&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Standard error: </span><span class=si>{</span><span class=n>se</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> hours&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>95% CI: (</span><span class=si>{</span><span class=n>ci_95</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci_95</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>) hours&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>üé¨ We&#39;re 95% confident true mean watch time is in [</span><span class=si>{</span><span class=n>ci_95</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci_95</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>]&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   (Thanks to CLT, even though data is skewed!)&quot;</span><span class=p>)</span>


<span class=c1># ============================================================================</span>
<span class=c1># EXAMPLE 3: GOOGLE - A/B TEST SAMPLE SIZE CALCULATION</span>
<span class=c1># ============================================================================</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;EXAMPLE 3: GOOGLE - Sample Size for A/B Test (CLT-based)&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span> <span class=o>*</span> <span class=mi>70</span><span class=p>)</span>

<span class=c1># Google wants to detect 2% CTR improvement</span>
<span class=c1># Control CTR: 5% (œÉ ‚âà ‚àö(0.05 √ó 0.95) ‚âà 0.218 for binary outcome)</span>

<span class=n>baseline_ctr</span> <span class=o>=</span> <span class=mf>0.05</span>
<span class=n>population_std</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>baseline_ctr</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>baseline_ctr</span><span class=p>))</span>

<span class=c1># Want margin of error = 0.005 (0.5%) at 95% confidence</span>
<span class=n>margin_of_error</span> <span class=o>=</span> <span class=mf>0.005</span>

<span class=n>n_required</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>minimum_sample_size</span><span class=p>(</span>
    <span class=n>population_std</span><span class=o>=</span><span class=n>population_std</span><span class=p>,</span>
    <span class=n>margin_of_error</span><span class=o>=</span><span class=n>margin_of_error</span><span class=p>,</span>
    <span class=n>confidence_level</span><span class=o>=</span><span class=mf>0.95</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Baseline CTR: </span><span class=si>{</span><span class=n>baseline_ctr</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Population std: </span><span class=si>{</span><span class=n>population_std</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Desired margin of error: </span><span class=si>{</span><span class=n>margin_of_error</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Required sample size per variant: </span><span class=si>{</span><span class=n>n_required</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total experiment size: </span><span class=si>{</span><span class=mi>2</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>n_required</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># At 1M daily users, how long to run?</span>
<span class=n>daily_users</span> <span class=o>=</span> <span class=mi>1_000_000</span>
<span class=n>users_per_variant</span> <span class=o>=</span> <span class=n>daily_users</span> <span class=o>/</span> <span class=mi>2</span>
<span class=n>days_needed</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>n_required</span> <span class=o>/</span> <span class=n>users_per_variant</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>üìä With </span><span class=si>{</span><span class=n>daily_users</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2> daily users (50/50 split):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   Need to run experiment for </span><span class=si>{</span><span class=nb>int</span><span class=p>(</span><span class=n>days_needed</span><span class=p>)</span><span class=si>}</span><span class=s2> days&quot;</span><span class=p>)</span>
</code></pre></div> <h2 id=comparison-tables_2>Comparison Tables</h2> <h3 id=clt-requirements-and-edge-cases>CLT Requirements and Edge Cases</h3> <table> <thead> <tr> <th>Condition</th> <th>Requirement</th> <th>What If Violated?</th> <th>Example</th> </tr> </thead> <tbody> <tr> <td><strong>Independence</strong></td> <td>X‚ÇÅ, X‚ÇÇ, ..., X‚Çô i.i.d.</td> <td>CLT may not hold</td> <td>Time series with autocorrelation</td> </tr> <tr> <td><strong>Finite Variance</strong></td> <td>œÉ¬≤ &lt; ‚àû</td> <td>CLT fails</td> <td>Cauchy distribution (heavy tails)</td> </tr> <tr> <td><strong>Sample Size</strong></td> <td>n "large enough" (‚â•30)</td> <td>CLT approximation poor</td> <td>n=5 with skewed data</td> </tr> <tr> <td><strong>Identical Distribution</strong></td> <td>All from same population</td> <td>Need more complex theory</td> <td>Mixed populations</td> </tr> </tbody> </table> <h3 id=sample-size-guidelines-by-distribution-shape>Sample Size Guidelines by Distribution Shape</h3> <table> <thead> <tr> <th>Population Distribution</th> <th>Minimum n for CLT</th> <th>Rationale</th> </tr> </thead> <tbody> <tr> <td><strong>Normal</strong></td> <td>n ‚â• 1 (already normal!)</td> <td>Sample mean exactly normal</td> </tr> <tr> <td><strong>Symmetric (uniform, etc)</strong></td> <td>n ‚â• 5-10</td> <td>Fast convergence</td> </tr> <tr> <td><strong>Moderate Skew (exponential)</strong></td> <td>n ‚â• 30</td> <td>Classic "rule of 30"</td> </tr> <tr> <td><strong>High Skew (Pareto, log-normal)</strong></td> <td>n ‚â• 100+</td> <td>Slow convergence</td> </tr> <tr> <td><strong>Heavy Tails (t-dist)</strong></td> <td>n ‚â• 50</td> <td>Depends on tail parameter</td> </tr> </tbody> </table> <h3 id=real-company-applications_2>Real Company Applications</h3> <table> <thead> <tr> <th>Company</th> <th>Application</th> <th>Population Distribution</th> <th>Sample Size</th> <th>CLT Enables</th> </tr> </thead> <tbody> <tr> <td><strong>Google</strong></td> <td>A/B test CTR</td> <td>Bernoulli (binary clicks)</td> <td>10,000 per variant</td> <td>95% CI: [3.2%, 3.8%] for control</td> </tr> <tr> <td><strong>Netflix</strong></td> <td>Avg watch time</td> <td>Right-skewed (gamma-like)</td> <td>500 users</td> <td>CI without assuming normality</td> </tr> <tr> <td><strong>Amazon</strong></td> <td>Order value</td> <td>Heavy right tail (large orders)</td> <td>1,000 customers/day</td> <td>Daily revenue forecasting</td> </tr> <tr> <td><strong>Uber</strong></td> <td>Trip duration</td> <td>Bimodal (short vs long trips)</td> <td>50 trips ‚Üí normal means</td> <td>Pricing optimization</td> </tr> <tr> <td><strong>Stripe</strong></td> <td>Transaction amounts</td> <td>Highly skewed (few large)</td> <td>200 transactions</td> <td>Fraud detection thresholds</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they test:</strong></p> <ul> <li>Core understanding: Can you explain WHY sample means become normal?</li> <li>Conditions: Independence, finite variance, large enough n</li> <li>Standard error: SE = œÉ/‚àön (not œÉ/n)</li> <li>Practical application: Confidence intervals, hypothesis testing, sample size calculations</li> <li>Limitations: Doesn't apply to individual observations, only sample means</li> </ul> <p><strong>Strong signals:</strong></p> <ul> <li><strong>Statement with precision</strong>: "CLT says the SAMPLING DISTRIBUTION of the sample mean approaches N(Œº, œÉ¬≤/n) as n‚Üí‚àû, regardless of population distribution‚Äîassuming i.i.d. and finite variance"</li> <li><strong>Standard error mastery</strong>: "SE = œÉ/‚àön means precision improves with ‚àön, not n. To halve SE, need 4x sample size. This is why A/B tests at Google need 10k+ users per variant"</li> <li><strong>Real application</strong>: "At Netflix, even though watch times are right-skewed (many short views, few bingers), with n=500 we can use CLT to build 95% CI: [4.8, 5.4] hours. The skewness doesn't matter for the MEAN's distribution"</li> <li><strong>n‚â•30 nuance</strong>: "n‚â•30 is a rule of thumb. For symmetric distributions like uniform, n=10 works. For highly skewed like exponential, might need n=50+. I'd check with QQ-plot or bootstrap"</li> <li><strong>Individual vs mean</strong>: "CLT applies to XÃÑ, not individual X·µ¢. Individual observations DON'T become normal. Common mistake!"</li> </ul> <p><strong>Red flags:</strong></p> <ul> <li>Says "data becomes normal" (wrong: sample MEANS become normal)</li> <li>Thinks CLT requires normal population (opposite: it's powerful because it doesn't!)</li> <li>Can't explain standard error = œÉ/‚àön</li> <li>Doesn't know conditions (independence, finite variance)</li> <li>Confuses n‚â•30 as hard rule (it's context-dependent)</li> </ul> <p><strong>Follow-up questions:</strong></p> <ul> <li><em>"What if population variance is infinite?"</em> ‚Üí CLT fails (Cauchy distribution example)</li> <li><em>"Does CLT apply to medians?"</em> ‚Üí No, different limit theorem (quantile asymptotics)</li> <li><em>"What if observations are dependent?"</em> ‚Üí Need time series CLT or assume weak dependence</li> <li><em>"How to check if n is large enough?"</em> ‚Üí QQ-plot, normality tests, bootstrap simulation</li> <li><em>"What's finite sample correction?"</em> ‚Üí t-distribution when œÉ unknown and n small</li> </ul> </div> <div class="admonition warning"> <p class=admonition-title>Common Pitfalls</p> <ol> <li><strong>Individual vs mean</strong>: CLT applies to XÃÑ, not individual X·µ¢ values</li> <li><strong>Magic n=30</strong>: Not always sufficient for skewed data</li> <li><strong>SE formula</strong>: It's œÉ/‚àön, not œÉ/n</li> <li><strong>Assuming normality</strong>: CLT tells us when we CAN assume normality (for means), not when data IS normal</li> </ol> </div> </details> <hr> <h3 id=what-is-the-normal-distribution-state-its-properties-most-tech-companies-interview-question>What is the Normal Distribution? State its Properties - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Normal</code>, <code>Gaussian</code>, <code>Continuous Distribution</code>, <code>CLT</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft, Netflix</p> <details class=success> <summary>View Answer</summary> <p>The <strong>Normal (Gaussian) Distribution</strong> is the most important probability distribution in statistics. Its ubiquity comes from the <strong>Central Limit Theorem</strong>: sums and averages of many random variables converge to normal, making it the default for modeling aggregate phenomena like <strong>test scores</strong>, <strong>measurement errors</strong>, <strong>stock returns</strong>, and <strong>biological traits</strong>.</p> <h2 id=probability-density-function>Probability Density Function</h2> <div class=arithmatex>\[f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right), \quad -\infty &lt; x &lt; \infty\]</div> <p><strong>Notation:</strong> X ~ N(Œº, œÉ¬≤) where: - Œº = mean (location parameter) - œÉ¬≤ = variance (scale parameter) - œÉ = standard deviation</p> <h2 id=key-properties>Key Properties</h2> <p>| Property | Value | Significance |\n |----------|-------|---------------|\n | <strong>Mean</strong> | Œº | Center of distribution |\n | <strong>Median</strong> | Œº | Same as mean (symmetric) |\n | <strong>Mode</strong> | Œº | Peak at mean |\n | <strong>Variance</strong> | œÉ¬≤ | Spread measure |\n | <strong>Skewness</strong> | 0 | Perfectly symmetric |\n | <strong>Kurtosis</strong> | 3 | Moderate tails (mesokurtic) |\n | <strong>Support</strong> | (-‚àû, ‚àû) | All real numbers possible |\n | <strong>Entropy</strong> | ¬Ω log(2œÄeœÉ¬≤) | Maximum among all distributions with given variance |\n\n ## Empirical Rule (68-95-99.7)\n\n <code>\n ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n ‚îÇ NORMAL DISTRIBUTION INTERVALS ‚îÇ\n ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n ‚îÇ ‚îÇ\n ‚îÇ ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 68.27% of data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îÇ\n ‚îÇ Œº-œÉ Œº+œÉ ‚îÇ\n ‚îÇ ‚îÇ\n ‚îÇ ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 95.45% of data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îÇ\n ‚îÇ Œº-2œÉ Œº+2œÉ ‚îÇ\n ‚îÇ ‚îÇ\n ‚îÇ ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 99.73% of data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚îÇ\n ‚îÇŒº-3œÉ Œº+3œÉ ‚îÇ\n ‚îÇ ‚îÇ\n ‚îÇ \ud83d\udcc8 Bell Curve: ‚îÇ\n ‚îÇ ‚ï±‚îÄ‚ï≤ ‚îÇ\n ‚îÇ ‚ï± ‚ï≤ ‚îÇ\n ‚îÇ ‚ï± ‚ï≤ ‚îÇ\n ‚îÇ ‚ï± ‚ï≤ ‚îÇ\n ‚îÇ _‚ï±‚îÄ ‚îÄ‚ï≤_ ‚îÇ\n ‚îÇ __‚ï±‚îÄ ‚îÄ‚ï≤__ ‚îÇ\n ‚îÇ ___‚ï±‚îÄ ‚îÄ‚ï≤___ ‚îÇ\n ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ\n ‚îÇ -3œÉ -2œÉ -œÉ Œº +œÉ +2œÉ +3œÉ ‚îÇ\n ‚îÇ ‚îÇ\n ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</code>\n\n ## Standard Normal Distribution\n\n <strong>Z-score transformation</strong> standardizes any normal to N(0,1):\n \n <span class=arithmatex>\(<span class=arithmatex>\(Z = \\frac{X - \\mu}{\\sigma} \\sim N(0, 1)\)</span>\)</span>\n \n <strong>Properties of Z:</strong>\n - Mean = 0\n - Variance = 1\n - Used for: probability lookups, comparing across scales\n\n ## Production Python Implementation\n\n <code>python\n import numpy as np\n import pandas as pd\n from scipy import stats\n from typing import Tuple, List\n from dataclasses import dataclass\n \n \n @dataclass\n class NormalAnalysisResult:\n \"\"\"Results from normal distribution analysis.\"\"\"\n mean: float\n std_dev: float\n percentiles: dict\n probabilities: dict\n z_scores: dict\n \n \n class NormalDistributionAnalyzer:\n \"\"\"\n Production analyzer for normal distribution.\n \n Used by:\n - Google: Latency SLA monitoring (99th percentile)\n - Netflix: Video quality scores (QoE distribution)\n - SAT/ACT: Test score standardization\n - Finance: VaR (Value at Risk) calculations\n \"\"\"\n \n def __init__(self, mu: float, sigma: float):\n \"\"\"Initialize with distribution parameters.\"\"\"\n self.mu = mu\n self.sigma = sigma\n self.dist = stats.norm(loc=mu, scale=sigma)\n \n def probability(self, lower: float = -np.inf, upper: float = np.inf) -&gt; float:\n \"\"\"Calculate P(lower &lt; X &lt; upper).\"\"\"\n return self.dist.cdf(upper) - self.dist.cdf(lower)\n \n def percentile(self, p: float) -&gt; float:\n \"\"\"Find value at percentile p (0-1).\"\"\"\n return self.dist.ppf(p)\n \n def z_score(self, x: float) -&gt; float:\n \"\"\"Standardize value to z-score.\"\"\"\n return (x - self.mu) / self.sigma\n \n def empirical_rule_check(self, data: np.ndarray) -&gt; dict:\n \"\"\"Verify empirical rule on actual data.\"\"\"\n within_1sigma = np.sum((data &gt;= self.mu - self.sigma) &amp; \n (data &lt;= self.mu + self.sigma)) / len(data)\n within_2sigma = np.sum((data &gt;= self.mu - 2*self.sigma) &amp; \n (data &lt;= self.mu + 2*self.sigma)) / len(data)\n within_3sigma = np.sum((data &gt;= self.mu - 3*self.sigma) &amp; \n (data &lt;= self.mu + 3*self.sigma)) / len(data)\n \n return {\n '1_sigma': {'empirical': within_1sigma, 'theoretical': 0.6827},\n '2_sigma': {'empirical': within_2sigma, 'theoretical': 0.9545},\n '3_sigma': {'empirical': within_3sigma, 'theoretical': 0.9973}\n }\n \n \n # ============================================================================\n # EXAMPLE 1: SAT SCORES - PERCENTILE ANALYSIS\n # ============================================================================\n \n print(\"=\" * 70)\n print(\"EXAMPLE 1: SAT SCORES - Normal Distribution Analysis\")\n print(\"=\" * 70)\n \n # SAT Math: Œº=528, œÉ=117 (approximate 2023 data)\n sat_math = NormalDistributionAnalyzer(mu=528, sigma=117)\n \n print(f\"\\nSAT Math Distribution: N({sat_math.mu}, {sat_math.sigma}\u00b2)\")\n \n # Key percentiles\n percentiles = [25, 50, 75, 90, 95, 99]\n print(f\"\\nPercentiles:\")\n for p in percentiles:\n score = sat_math.percentile(p/100)\n print(f\" {p}th: {score:.0f}\")\n \n # Probability calculations\n print(f\"\\nProbabilities:\")\n print(f\" P(Score &gt; 700): {sat_math.probability(700, np.inf):.2%}\")\n print(f\" P(Score &gt; 750): {sat_math.probability(750, np.inf):.2%}\")\n print(f\" P(400 &lt; Score &lt; 600): {sat_math.probability(400, 600):.2%}\")\n \n # Z-scores for key values\n print(f\"\\nZ-scores:\")\n for score in [400, 528, 600, 700, 800]:\n z = sat_math.z_score(score)\n print(f\" Score {score}: z = {z:.2f}\")\n \n \n # ============================================================================\n # EXAMPLE 2: GOOGLE - API LATENCY MONITORING\n # ============================================================================\n \n print(\"\\n\" + \"=\" * 70)\n print(\"EXAMPLE 2: GOOGLE - API Latency SLA Monitoring\")\n print(\"=\" * 70)\n \n # API latency: Œº=45ms, œÉ=12ms (approximately normal by CLT)\n latency = NormalDistributionAnalyzer(mu=45, sigma=12)\n \n print(f\"\\nAPI Latency: N({latency.mu}ms, {latency.sigma}ms)\")\n \n # SLA: 95% of requests &lt; 65ms\n sla_threshold = 65\n p_within_sla = latency.probability(-np.inf, sla_threshold)\n \n print(f\"\\nSLA Analysis:\")\n print(f\" Threshold: {sla_threshold}ms\")\n print(f\" P(Latency &lt; {sla_threshold}ms): {p_within_sla:.2%}\")\n print(f\" SLA Met? {p_within_sla &gt;= 0.95}\")\n \n # What latency is 99th percentile? (for alerting)\n p99 = latency.percentile(0.99)\n print(f\"\\n P99 latency: {p99:.1f}ms\")\n print(f\" \ud83d\udea8 Alert if latency &gt; {p99:.0f}ms (top 1%)\")\n \n # Expected violations per 1M requests\n total_requests = 1_000_000\n violations = total_requests * (1 - p_within_sla)\n print(f\"\\n Expected SLA violations per 1M requests: {violations:,.0f}\")\n \n \n # ============================================================================\n # EXAMPLE 3: FINANCE - VALUE AT RISK (VaR)\n # ============================================================================\n \n print(\"\\n\" + \"=\" * 70)\n print(\"EXAMPLE 3: FINANCE - Portfolio Value at Risk (VaR)\")\n print(\"=\" * 70)\n \n # Daily portfolio returns: Œº=0.05%, œÉ=1.2%\n returns = NormalDistributionAnalyzer(mu=0.0005, sigma=0.012)\n \n portfolio_value = 10_000_000 # $10M\n \n print(f\"\\nPortfolio: ${portfolio_value:,}\")\n print(f\"Daily returns: N({returns.mu:.2%}, {returns.sigma:.2%})\")\n \n # VaR at 95% confidence: \"Maximum loss with 95% probability\"\n var_95 = returns.percentile(0.05) # 5th percentile (left tail)\n dollar_var_95 = portfolio_value * var_95\n \n print(f\"\\nValue at Risk (VaR):\")\n print(f\" 95% VaR (returns): {var_95:.2%}\")\n print(f\" 95% VaR (dollars): ${abs(dollar_var_95):,.0f}\")\n print(f\" Interpretation: 95% confident we won't lose more than ${abs(dollar_var_95):,.0f} tomorrow\")\n \n # 99% VaR (more conservative)\n var_99 = returns.percentile(0.01)\n dollar_var_99 = portfolio_value * var_99\n print(f\"\\n 99% VaR (returns): {var_99:.2%}\")\n print(f\" 99% VaR (dollars): ${abs(dollar_var_99):,.0f}\")\n \n \n # ============================================================================\n # EXAMPLE 4: EMPIRICAL RULE VERIFICATION\n # ============================================================================\n \n print(\"\\n\" + \"=\" * 70)\n print(\"EXAMPLE 4: Empirical Rule (68-95-99.7) Verification\")\n print(\"=\" * 70)\n \n # Generate sample data\n np.random.seed(42)\n sample_data = np.random.normal(loc=100, scale=15, size=100000)\n \n analyzer = NormalDistributionAnalyzer(mu=100, sigma=15)\n rule_check = analyzer.empirical_rule_check(sample_data)\n \n print(f\"\\nSample: N(100, 15\u00b2), n=100,000\")\n print(f\"\\nEmpirical Rule Verification:\")\n for interval, values in rule_check.items():\n emp = values['empirical']\n theo = values['theoretical']\n diff = abs(emp - theo)\n print(f\" \u00b1{interval.replace('_', ' ')}: {emp:.2%} (theoretical: {theo:.2%}, diff: {diff:.2%})\")\n</code>\n\n ## Comparison Tables\n\n ### Normal vs Other Distributions\n\n | Property | Normal | Uniform | Exponential | t-Distribution |\n |----------|--------|---------|-------------|----------------|\n | <strong>Symmetry</strong> | Symmetric | Symmetric | Right-skewed | Symmetric |\n | <strong>Tails</strong> | Moderate | None (bounded) | Heavy right tail | Heavy both tails |\n | <strong>Parameters</strong> | Œº, œÉ | a, b (bounds) | Œª (rate) | ŒΩ (df) |\n | <strong>Support</strong> | (-‚àû, ‚àû) | [a, b] | [0, ‚àû) | (-‚àû, ‚àû) |\n | <strong>Sum Property</strong> | Sum is normal | Sum not uniform | Sum is gamma | Sum not t |\n | <strong>CLT Result</strong> | Appears naturally | From uniform samples | From exponential samples | Approaches normal as df‚Üë |\n\n ### Real Company Applications\n\n | Company | Application | Mean (Œº) | Std Dev (œÉ) | Business Decision |\n |---------|-------------|----------|-------------|-------------------|\n | <strong>Google</strong> | API latency | 45ms | 12ms | P99 SLA = Œº + 2.33œÉ = 73ms |\n | <strong>Netflix</strong> | Video quality score | 4.&#8534; | 0.6 | P(QoE &gt; 4.5) = 31% ‚Üí improve encoding |\n | <strong>SAT/ACT</strong> | Test scores | 528 | 117 | 700+ score = top 7% (z=1.47) |\n | <strong>JPMorgan</strong> | Daily returns | 0.05% | 1.2% | 99% VaR = -2.75% ‚Üí risk limit |\n | <strong>Amazon</strong> | Delivery time (Prime) | 2 days | 0.5 days | 99% within 3.2 days |\n\n ### Z-Score Interpretation\n\n | Z-Score | Percentile | Interpretation | Example (IQ: Œº=100, œÉ=15) |\n |---------|------------|----------------|---------------------------|\n | <strong>-3.0</strong> | 0.13% | Extremely low | IQ = 55 |\n | <strong>-2.0</strong> | 2.28% | Very low | IQ = 70 |\n | <strong>-1.0</strong> | 15.87% | Below average | IQ = 85 |\n | <strong>0.0</strong> | 50% | Average | IQ = 100 |\n | <strong>+1.0</strong> | 84.13% | Above average | IQ = 115 |\n | <strong>+2.0</strong> | 97.72% | Very high | IQ = 130 |\n | <strong>+3.0</strong> | 99.87% | Extremely high | IQ = 145 |\n\n !!! tip \"Interviewer's Insight\"\n <strong>What they test:</strong>\n \n - Empirical rule: Can you state 68-95-99.7 rule and use it?\n - Z-score: Can you standardize values and interpret z-scores?\n - Sum property: Do you know sum of independent normals is normal?\n - CLT connection: Why is normal distribution so ubiquitous?\n - Practical applications: Percentiles, SLAs, confidence intervals\n \n <strong>Strong signals:</strong>\n \n - <strong>PDF formula</strong>: \"f(x) = (1/œÉ‚àö(2œÄ)) exp(-(x-Œº)¬≤/(2œÉ¬≤)) ‚Äî I recognize the exponential with squared term in numerator\"\n - <strong>Empirical rule precision</strong>: \"68.27% within ¬±1œÉ, 95.45% within ¬±2œÉ, 99.73% within ¬±3œÉ. At Google, we use P99 = Œº + 2.33œÉ for SLAs\"\n - <strong>Z-score transformation</strong>: \"z = (x-Œº)/œÉ standardizes to N(0,1). This lets us compare across different scales\u2014SAT score 700 (z=1.47) equals IQ 122 in terms of percentile\"\n - <strong>Sum property</strong>: \"If X~N(Œº‚ÇÅ,œÉ‚ÇÅ¬≤) and Y~N(Œº‚ÇÇ,œÉ‚ÇÇ¬≤) independent, then X+Y~N(Œº‚ÇÅ+Œº‚ÇÇ, œÉ‚ÇÅ¬≤+œÉ‚ÇÇ¬≤). Means add, variances add\"\n - <strong>Real calculation</strong>: \"For API latency N(45ms, 12ms), P99 = 45 + 2.33√ó12 = 73ms. We alert if sustained latency exceeds this\"\n \n <strong>Red flags:</strong>\n \n - Confuses œÉ with œÉ¬≤ in notation N(Œº, œÉ¬≤)\n - Can't calculate z-score or interpret it\n - Doesn't know empirical rule percentages\n - Thinks normal is only distribution (ignores heavy tails, skewness in real data)\n - Says \"average\" without specifying mean (could be median, mode)\n \n <strong>Follow-up questions:</strong>\n \n - <em>\"How do you test if data is normal?\"</em> ‚Üí QQ-plot, Shapiro-Wilk test, check skewness/kurtosis\n - <em>\"What if data has heavy tails?\"</em> ‚Üí Use t-distribution or robust methods\n - <em>\"Why (2œÄ)^(-&frac12;) in PDF?\"</em> ‚Üí Normalization constant so ‚à´f(x)dx = 1\n - <em>\"What's the relationship to CLT?\"</em> ‚Üí CLT explains why normal appears so often (sums converge to normal)\n - <em>\"How to generate normal random variables?\"</em> ‚Üí Box-Muller transform, inverse CDF method\n\n !!! warning \"Common Pitfalls\"\n 1. <strong>Notation confusion</strong>: N(Œº, œÉ¬≤) uses variance, not std dev (some texts use œÉ)\n 2. <strong>Empirical rule misapplication</strong>: Only applies to normal, not skewed data\n 3. <strong>Z-score direction</strong>: z=2 means 2œÉ ABOVE mean (positive), not below\n 4. <strong>Assuming normality</strong>: Real data often has outliers/skew‚Äîalways check!</p> </details> <hr> <h3 id=explain-the-binomial-distribution-amazon-meta-interview-question>Explain the Binomial Distribution - Amazon, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Binomial</code>, <code>Discrete</code>, <code>Bernoulli Trials</code>, <code>PMF</code> | <strong>Asked by:</strong> Amazon, Meta, Google, Microsoft</p> <details class=success> <summary>View Answer</summary> <p>The <strong>Binomial Distribution</strong> models the <strong>number of successes in n fixed, independent trials</strong>, each with the same success probability p. It's the fundamental discrete distribution for <strong>binary outcome experiments</strong>: coin flips, A/B tests, quality control, medical trials.</p> <h2 id=probability-mass-function-pmf>Probability Mass Function (PMF)</h2> <div class=arithmatex>\[P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}, \quad k = 0, 1, 2, ..., n\]</div> <p>Where: - <span class=arithmatex>\(\binom{n}{k} = \frac{n!}{k!(n-k)!}\)</span> = number of ways to choose k successes from n trials - <span class=arithmatex>\(p^k\)</span> = probability of k successes - <span class=arithmatex>\((1-p)^{n-k}\)</span> = probability of (n-k) failures</p> <h2 id=conditions-bins>Conditions (BINS)</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         BINOMIAL DISTRIBUTION CONDITIONS (BINS)            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                            ‚îÇ
‚îÇ  B - Binary outcomes:    Each trial has 2 outcomes        ‚îÇ
‚îÇ                           (Success/Failure, Yes/No)        ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  I - Independent trials: Outcome of one trial doesn&#39;t     ‚îÇ
‚îÇ                           affect others                    ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  N - Number fixed:       n trials determined in advance   ‚îÇ
‚îÇ                           (not stopping after X successes) ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  S - Same probability:   p constant across all trials     ‚îÇ
‚îÇ                           (homogeneous)                    ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  \ud83d\udcca Distribution Shape:                                    ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ   p=0.1 (skewed right)     p=0.5 (symmetric)              ‚îÇ
‚îÇ   ‚ñà                        ‚ñà‚ñà‚ñà‚ñà                            ‚îÇ
‚îÇ   ‚ñà‚ñà                      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           ‚îÇ
‚îÇ   ‚ñà‚ñà‚ñà                    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          ‚îÇ
‚îÇ   ‚ñà‚ñà‚ñà‚ñà                  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                  ‚îÇ
‚îÇ   0 1 2 3 4 5...        0  1  2  3  4  5                  ‚îÇ
‚îÇ                                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=key-formulas>Key Formulas</h2> <p>| Statistic | Formula | Intuition |\n |-----------|---------|------------|\n | <strong>Mean</strong> | E[X] = np | Average successes = trials √ó success rate |\n | <strong>Variance</strong> | Var(X) = np(1-p) | Maximum when p=0.5 (most uncertain) |\n | <strong>Std Dev</strong> | œÉ = ‚àö[np(1-p)] | Spread of successes |\n | <strong>Mode</strong> | ‚åä(n+1)p‚åã | Most likely number of successes |\n | <strong>P(X=0)</strong> | (1-p)‚Åø | All failures |\n | <strong>P(X=n)</strong> | p‚Åø | All successes |\n\n <strong>Variance interpretation:</strong> Maximum at p=0.5 (coin flip), minimum at p‚Üí0 or p‚Üí1 (deterministic)\n\n ## Production Python Implementation\n\n <code>python\n import numpy as np\n import pandas as pd\n from scipy.stats import binom\n from scipy.special import comb\n from typing import List, Tuple\n from dataclasses import dataclass\n \n \n @dataclass\n class BinomialAnalysisResult:\n \"\"\"Results from binomial distribution analysis.\"\"\"\n n: int\n p: float\n mean: float\n variance: float\n std_dev: float\n probabilities: dict\n \n \n class BinomialAnalyzer:\n \"\"\"\n Production analyzer for binomial distribution.\n \n Used by:\n - Amazon: Defect rate analysis in warehouse operations\n - Meta: A/B test significance (conversions out of n visitors)\n - Google: Click-through rate experiments\n - Pharmaceutical: Clinical trial success modeling\n \"\"\"\n \n def __init__(self, n: int, p: float):\n \"\"\"Initialize with n trials and success probability p.\"\"\"\n self.n = n\n self.p = p\n self.dist = binom(n=n, p=p)\n self.mean = n * p\n self.variance = n * p * (1 - p)\n self.std_dev = np.sqrt(self.variance)\n \n def pmf(self, k: int) -&gt; float:\n \"\"\"P(X = k): Probability of exactly k successes.\"\"\"\n return self.dist.pmf(k)\n \n def cdf(self, k: int) -&gt; float:\n \"\"\"P(X ‚â§ k): Probability of at most k successes.\"\"\"\n return self.dist.cdf(k)\n \n def survival(self, k: int) -&gt; float:\n \"\"\"P(X &gt; k): Probability of more than k successes.\"\"\"\n return 1 - self.dist.cdf(k)\n \n def probability_range(self, k_min: int, k_max: int) -&gt; float:\n \"\"\"P(k_min ‚â§ X ‚â§ k_max).\"\"\"\n return self.dist.cdf(k_max) - self.dist.cdf(k_min - 1)\n \n def confidence_interval(self, confidence: float = 0.95) -&gt; Tuple[int, int]:\n \"\"\"Find (lower, upper) bounds containing confidence% of probability.\"\"\"\n alpha = (1 - confidence) / 2\n lower = self.dist.ppf(alpha)\n upper = self.dist.ppf(1 - alpha)\n return (int(np.floor(lower)), int(np.ceil(upper)))\n \n def normal_approximation_valid(self) -&gt; bool:\n \"\"\"Check if normal approximation conditions met.\"\"\"\n return (self.n * self.p &gt;= 5) and (self.n * (1 - self.p) &gt;= 5)\n \n \n # ============================================================================\n # EXAMPLE 1: AMAZON WAREHOUSE - QUALITY CONTROL\n # ============================================================================\n \n print(\"=\" * 70)\n print(\"EXAMPLE 1: AMAZON WAREHOUSE - Defect Rate Quality Control\")\n print(\"=\" * 70)\n \n # Amazon inspects batch of 100 items, historical defect rate = 3%\n amazon_qc = BinomialAnalyzer(n=100, p=0.03)\n \n print(f\"\\nBatch Size: {amazon_qc.n}\")\n print(f\"Defect Rate: {amazon_qc.p:.1%}\")\n print(f\"Expected defects: {amazon_qc.mean:.2f} \u00b1 {amazon_qc.std_dev:.2f}\")\n \n # Key questions\n print(f\"\\nProbability Analysis:\")\n print(f\" P(X = 0) [no defects]: {amazon_qc.pmf(0):.2%}\")\n print(f\" P(X = 3) [exactly 3]: {amazon_qc.pmf(3):.2%}\")\n print(f\" P(X ‚â§ 2) [acceptable]: {amazon_qc.cdf(2):.2%}\")\n print(f\" P(X &gt; 5) [reject batch]: {amazon_qc.survival(5):.2%}\")\n \n # Decision rule: Reject if &gt; 5 defects\n reject_prob = amazon_qc.survival(5)\n print(f\"\\nBatch Rejection:\")\n print(f\" Rule: Reject if more than 5 defects\")\n print(f\" P(Reject | true p=0.03): {reject_prob:.2%}\")\n print(f\" \ud83d\udea8 False positive rate: {reject_prob:.2%}\")\n \n # 95% confidence interval\n lower, upper = amazon_qc.confidence_interval(0.95)\n print(f\"\\n 95% CI for defects: [{lower}, {upper}]\")\n print(f\" Interpretation: 95% of batches will have {lower}-{upper} defects\")\n \n \n # ============================================================================\n # EXAMPLE 2: META A/B TEST - CONVERSION RATE\n # ============================================================================\n \n print(\"\\n\" + \"=\" * 70)\n print(\"EXAMPLE 2: META A/B TEST - Button Conversion Rate\")\n print(\"=\" * 70)\n \n # Control group: n=1000 visitors, p=0.12 (12% baseline conversion)\n control = BinomialAnalyzer(n=1000, p=0.12)\n \n # Treatment group: hypothesized p=0.15 (15% after button change)\n treatment = BinomialAnalyzer(n=1000, p=0.15)\n \n print(f\"\\nControl Group: n={control.n}, p={control.p:.1%}\")\n print(f\" Expected conversions: {control.mean:.1f} \u00b1 {control.std_dev:.2f}\")\n print(f\" 95% CI: {control.confidence_interval(0.95)}\")\n \n print(f\"\\nTreatment Group: n={treatment.n}, p={treatment.p:.1%}\")\n print(f\" Expected conversions: {treatment.mean:.1f} \u00b1 {treatment.std_dev:.2f}\")\n print(f\" 95% CI: {treatment.confidence_interval(0.95)}\")\n \n # Power analysis: Can we detect difference?\n # P(Treatment shows &gt; 140 conversions | p=0.15)\n threshold = 140\n power = treatment.survival(threshold - 1)\n type_2_error = 1 - power\n \n print(f\"\\nPower Analysis (threshold = {threshold} conversions):\")\n print(f\" P(Detect improvement | true p=0.15): {power:.2%}\")\n print(f\" Type II error (Œ≤): {type_2_error:.2%}\")\n print(f\" Statistical power: {power:.2%}\")\n \n # Interpretation\n if power &gt;= 0.80:\n print(f\" ‚úÖ Sufficient power (‚â•80%) to detect 3% lift\")\n else:\n print(f\" \u26a0\ufe0f Insufficient power (&lt;80%), need larger sample\")\n \n \n # ============================================================================\n # EXAMPLE 3: GOOGLE ADS - CLICK-THROUGH RATE\n # ============================================================================\n \n print(\"\\n\" + \"=\" * 70)\n print(\"EXAMPLE 3: GOOGLE ADS - Click-Through Rate (CTR) Analysis\")\n print(\"=\" * 70)\n \n # Ad shown to 500 users, expected CTR = 8%\n google_ads = BinomialAnalyzer(n=500, p=0.08)\n \n print(f\"\\nAd Campaign:\")\n print(f\" Impressions: {google_ads.n:,}\")\n print(f\" Expected CTR: {google_ads.p:.1%}\")\n print(f\" Expected clicks: {google_ads.mean:.1f} \u00b1 {google_ads.std_dev:.2f}\")\n \n # Revenue: $2 per click\n revenue_per_click = 2.0\n expected_revenue = google_ads.mean * revenue_per_click\n revenue_std = google_ads.std_dev * revenue_per_click\n \n print(f\"\\nRevenue Analysis ($2/click):\")\n print(f\" Expected revenue: ${expected_revenue:.2f} \u00b1 ${revenue_std:.2f}\")\n \n # Percentiles for budgeting\n clicks_p10 = google_ads.dist.ppf(0.10)\n clicks_p50 = google_ads.dist.ppf(0.50)\n clicks_p90 = google_ads.dist.ppf(0.90)\n \n print(f\"\\n Revenue Percentiles:\")\n print(f\" P10: {clicks_p10:.0f} clicks ‚Üí ${clicks_p10 * revenue_per_click:.2f}\")\n print(f\" P50: {clicks_p50:.0f} clicks ‚Üí ${clicks_p50 * revenue_per_click:.2f}\")\n print(f\" P90: {clicks_p90:.0f} clicks ‚Üí ${clicks_p90 * revenue_per_click:.2f}\")\n \n # Normal approximation check\n print(f\"\\nNormal Approximation:\")\n if google_ads.normal_approximation_valid():\n print(f\" ‚úÖ Valid (np={google_ads.n*google_ads.p:.1f} ‚â• 5, n(1-p)={google_ads.n*(1-google_ads.p):.1f} ‚â• 5)\")\n print(f\" Can use X ~ N({google_ads.mean:.1f}, {google_ads.variance:.2f})\")\n else:\n print(f\" \u274c Invalid, use exact binomial\")\n \n \n # ============================================================================\n # EXAMPLE 4: PHARMACEUTICAL TRIAL - FDA APPROVAL\n # ============================================================================\n \n print(\"\\n\" + \"=\" * 70)\n print(\"EXAMPLE 4: PHARMACEUTICAL TRIAL - Drug Efficacy\")\n print(\"=\" * 70)\n \n # Trial: 50 patients, drug success rate = 70%\n clinical = BinomialAnalyzer(n=50, p=0.70)\n \n print(f\"\\nClinical Trial:\")\n print(f\" Patients: {clinical.n}\")\n print(f\" Success rate: {clinical.p:.0%}\")\n print(f\" Expected successes: {clinical.mean:.1f} \u00b1 {clinical.std_dev:.2f}\")\n \n # FDA approval: Need at least 32 successes (64%)\n approval_threshold = 32\n p_approval = clinical.survival(approval_threshold - 1)\n \n print(f\"\\nFDA Approval Analysis:\")\n print(f\" Threshold: ‚â•{approval_threshold} successes ({approval_threshold/clinical.n:.0%})\")\n print(f\" P(Approval | true p=0.70): {p_approval:.2%}\")\n print(f\" P(Rejection | true p=0.70): {1 - p_approval:.2%} (Type II error)\")\n \n # Distribution of outcomes\n print(f\"\\nOutcome Distribution:\")\n for k in [30, 32, 35, 38, 40]:\n prob = clinical.pmf(k)\n print(f\" P(X = {k}): {prob:.3%}\")\n</code>\n\n ## Comparison Tables\n\n ### Binomial vs Related Distributions\n\n | Distribution | Formula | Use Case | Relationship to Binomial |\n |--------------|---------|----------|---------------------------|\n | <strong>Bernoulli</strong> | p^k (1-p)^(1-k), k‚àà{0,1} | Single trial | Binomial(1, p) |\n | <strong>Binomial</strong> | C(n,k) p^k (1-p)^(n-k) | n fixed trials | Sum of n Bernoullis |\n | <strong>Geometric</strong> | (1-p)^(k-1) p | Trials until first success | Unbounded trials |\n | <strong>Negative Binomial</strong> | C(k-1,r-1) p^r (1-p)^(k-r) | Trials until r successes | Generalized geometric |\n | <strong>Poisson</strong> | (Œª^k/k!) e^(-Œª) | Rare events (n‚Üí‚àû, p‚Üí0, np=Œª) | Limit of binomial |\n\n ### Real Company Applications\n\n | Company | Application | n | p | Business Decision |\n |---------|-------------|---|---|-------------------|\n | <strong>Amazon</strong> | Warehouse defect rate | 100 items | 0.03 | Reject batch if &gt;5 defects (0.6% FP rate) |\n | <strong>Meta</strong> | A/B test conversions | 1000 visitors | 0.12 | Need 80% power to detect 3% lift |\n | <strong>Google</strong> | Ad click-through rate | 500 impressions | 0.08 | Expected 40 clicks ‚Üí $80 revenue |\n | <strong>Pfizer</strong> | Drug efficacy trial | 50 patients | 0.70 | P(FDA approval ‚â•32 successes) = 93% |\n | <strong>Netflix</strong> | Thumbnail A/B test | 10000 views | 0.45 | 95% CI: [4430, 4570] clicks |\n\n ### Normal Approximation Guidelines\n\n | Condition | Rule | Example | Valid? |\n |-----------|------|---------|--------|\n | <strong>np ‚â• 5</strong> | Enough expected successes | n=100, p=0.03 ‚Üí np=3 | \u274c No |\n | <strong>n(1-p) ‚â• 5</strong> | Enough expected failures | n=100, p=0.98 ‚Üí n(1-p)=2 | \u274c No |\n | <strong>Both</strong> | Safe to use N(np, np(1-p)) | n=500, p=0.08 ‚Üí np=40, n(1-p)=460 | ‚úÖ Yes |\n | <strong>Continuity correction</strong> | Add ¬±0.5 for discrete‚Üícontinuous | P(X‚â§10) ‚âà P(Z‚â§10.5) | Improves accuracy |\n\n !!! tip \"Interviewer's Insight\"\n <strong>What they test:</strong>\n \n - <strong>BINS conditions</strong>: Can you verify binomial applies?\n - <strong>PMF formula</strong>: Understand C(n,k) √ó p^k √ó (1-p)^(n-k)?\n - <strong>Mean/variance</strong>: Derive or know E[X]=np, Var(X)=np(1-p)?\n - <strong>Complement rule</strong>: P(X‚â•k) = 1 - P(X‚â§k-1) for efficiency?\n - <strong>Normal approximation</strong>: When np and n(1-p) both ‚â• 5?\n \n <strong>Strong signals:</strong>\n \n - <strong>Conditions check</strong>: \"Binomial requires BINS: Binary outcomes, Independent trials, Number fixed, Same probability. Here n=100, p=0.03, all met\"\n - <strong>Intuitive mean</strong>: \"E[X] = np makes sense: 100 trials √ó 3% rate = 3 expected defects\"\n - <strong>Variance interpretation</strong>: \"Var(X) = np(1-p) = 2.91. Maximum variance is at p=0.5, so low p=0.03 gives low variance\"\n - <strong>Complement efficiency</strong>: \"P(X&gt;5) = 1 - P(X‚â§5) avoids summing pmf(6)+pmf(7)+...+pmf(100)\"\n - <strong>Normal approx</strong>: \"np=3 &lt; 5, so can't use normal. Must use exact binomial or Poisson approximation\"\n - <strong>Business context</strong>: \"At Amazon, we reject batches with &gt;5 defects. With p=0.03, false positive rate is only 0.6%‚Äîlow Type I error\"\n \n <strong>Red flags:</strong>\n \n - Forgets independence assumption (e.g., sampling without replacement from small population)\n - Uses normal approximation when np&lt;5 or n(1-p)&lt;5\n - Confuses P(X=k) with P(X‚â•k) or P(X&gt;k)\n - Doesn't use complement for \"at least\" questions\n - Can't explain why variance is np(1-p), not np\n \n <strong>Follow-up questions:</strong>\n \n - <em>\"What if we sample without replacement?\"</em> ‚Üí Use hypergeometric, not binomial (trials no longer independent)\n - <em>\"Derive E[X] = np\"</em> ‚Üí X = X‚ÇÅ+...+X‚Çô where X·µ¢~Bernoulli(p), so E[X] = Œ£ E[X·µ¢] = Œ£ p = np\n - <em>\"Why is variance maximized at p=0.5?\"</em> ‚Üí Var(X)=np(1-p) is quadratic in p, max at p=0.5\n - <em>\"When does binomial ‚Üí Poisson?\"</em> ‚Üí n‚Üí‚àû, p‚Üí0, np=Œª constant. Useful for rare events\n - <em>\"What's the mode of Binomial(n,p)?\"</em> ‚Üí ‚åä(n+1)p‚åã or sometimes two modes\n\n !!! warning \"Common Pitfalls\"\n 1. <strong>Sampling without replacement</strong>: Binomial requires independence. For small populations, use hypergeometric\n 2. <strong>Forgetting (1-p)^(n-k) term</strong>: PMF needs probability of failures too!\n 3. <strong>P(X‚â•k) vs P(X&gt;k)</strong>: Off-by-one error‚ÄîP(X&gt;k) = 1 - P(X‚â§k), not 1 - P(X‚â§k-1)\n 4. <strong>Normal approximation abuse</strong>: Don't use when np&lt;5 or n(1-p)&lt;5‚Äîsubstantial error</p> </details> <hr> <h3 id=what-is-the-poisson-distribution-when-to-use-it-google-amazon-interview-question>What is the Poisson Distribution? When to Use It? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Poisson</code>, <code>Discrete</code>, <code>Rare Events</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Poisson Distribution:</strong></p> <p>Models count of events in fixed interval (time, space):</p> <div class=arithmatex>\[P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}\]</div> <p><strong>Parameters:</strong></p> <ul> <li>Œª = rate (expected count per interval)</li> <li>k = actual count (0, 1, 2, ...)</li> </ul> <p><strong>Special Property:</strong></p> <p>E[X] = Var(X) = Œª</p> <p><strong>When to Use:</strong></p> <ol> <li>Events occur independently</li> <li>Rate is constant</li> <li>Events are "rare" (compared to opportunities)</li> </ol> <p><strong>Examples:</strong> - Website visits per minute - Typos per page - Goals in a soccer game - Radioactive decays per second</p> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>poisson</span>

<span class=c1># 4 customers per hour on average</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mi>4</span>

<span class=c1># P(exactly 6 customers)?</span>
<span class=n>p_6</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>  <span class=c1># ‚âà 0.104</span>

<span class=c1># P(at most 2 customers)?</span>
<span class=n>p_le_2</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>  <span class=c1># ‚âà 0.238</span>

<span class=c1># P(more than 5)?</span>
<span class=n>p_gt_5</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>poisson</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>  <span class=c1># ‚âà 0.215</span>
</code></pre></div> <p><strong>Poisson as Binomial Limit:</strong></p> <p>When n ‚Üí ‚àû, p ‚Üí 0, np = Œª: Binomial(n, p) ‚Üí Poisson(Œª)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Count data modeling.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>States E[X] = Var(X) = Œª</li> <li>Gives real-world examples</li> <li>Knows Poisson-Binomial relationship</li> <li>Uses for rate-based problems</li> </ul> </div> </details> <hr> <h3 id=explain-the-exponential-distribution-google-amazon-interview-question>Explain the Exponential Distribution - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Exponential</code>, <code>Continuous</code>, <code>Waiting Time</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Exponential Distribution:</strong></p> <p>Models time between Poisson events (waiting time):</p> <div class=arithmatex>\[f(x) = \lambda e^{-\lambda x}, \quad x \geq 0\]</div> <p><strong>Parameters:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>1/Œª</td> </tr> <tr> <td>Variance</td> <td>1/Œª¬≤</td> </tr> <tr> <td>Median</td> <td>ln(2)/Œª</td> </tr> </tbody> </table> <p><strong>Memoryless Property:</strong></p> <div class=arithmatex>\[P(X &gt; s + t | X &gt; s) = P(X &gt; t)\]</div> <p>"Past doesn't affect future" - unique to exponential!</p> <p><strong>Example:</strong></p> <p>Bus arrives every 10 minutes on average (Œª = 0.1/min):</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>expon</span>

<span class=c1># Œª = 0.1, scale = 1/Œª = 10</span>
<span class=n>wait_time</span> <span class=o>=</span> <span class=n>expon</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>

<span class=c1># P(wait &lt; 5 minutes)?</span>
<span class=n>p_lt_5</span> <span class=o>=</span> <span class=n>wait_time</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>5</span><span class=p>)</span>  <span class=c1># ‚âà 0.393</span>

<span class=c1># P(wait &gt; 15 minutes)?</span>
<span class=n>p_gt_15</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>wait_time</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>15</span><span class=p>)</span>  <span class=c1># ‚âà 0.223</span>

<span class=c1># Mean wait time</span>
<span class=n>mean_wait</span> <span class=o>=</span> <span class=n>wait_time</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># 10 minutes</span>
</code></pre></div> <p><strong>Relationship with Poisson:</strong></p> <ul> <li>If counts per time ~ Poisson(Œª)</li> <li>Then time between events ~ Exponential(Œª)</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Continuous distribution for waiting.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows memoryless property and its implications</li> <li>Connects to Poisson process</li> <li>Can calculate probabilities</li> <li>Gives practical examples</li> </ul> </div> </details> <hr> <h3 id=what-is-the-geometric-distribution-amazon-microsoft-interview-question>What is the Geometric Distribution? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Geometric</code>, <code>Discrete</code>, <code>First Success</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Geometric Distribution:</strong></p> <p>Number of trials until first success:</p> <div class=arithmatex>\[P(X = k) = (1-p)^{k-1} p, \quad k = 1, 2, 3, ...\]</div> <p><strong>Formulas:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>1/p</td> </tr> <tr> <td>Variance</td> <td>(1-p)/p¬≤</td> </tr> <tr> <td>Mode</td> <td>1</td> </tr> </tbody> </table> <p><strong>Memoryless (like Exponential):</strong></p> <p>P(X &gt; m + n | X &gt; m) = P(X &gt; n)</p> <p><strong>Example - Interview Success:</strong></p> <p>30% chance of passing each interview:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>geom</span>

<span class=n>p</span> <span class=o>=</span> <span class=mf>0.3</span>

<span class=c1># P(pass on exactly 3rd interview)?</span>
<span class=n>p_3rd</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=c1># = (0.7)^2 * 0.3 = 0.147</span>

<span class=c1># Expected interviews until first pass?</span>
<span class=n>expected</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=mf>0.3</span>  <span class=c1># ‚âà 3.33 interviews</span>

<span class=c1># P(need more than 5 interviews)?</span>
<span class=n>p_gt_5</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>geom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=c1># = (0.7)^5 ‚âà 0.168</span>
</code></pre></div> <p><strong>Alternative Definition:</strong></p> <p>Some texts define as failures before first success (k = 0, 1, 2, ...)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> First success modeling.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows two common definitions</li> <li>Calculates E[X] = 1/p intuitively</li> <li>Connects to negative binomial</li> <li>Uses memoryless property</li> </ul> </div> </details> <hr> <h3 id=what-is-the-birthday-problem-calculate-the-probability-google-amazon-interview-question>What is the Birthday Problem? Calculate the Probability - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Birthday Problem</code>, <code>Combinatorics</code>, <code>Probability Puzzle</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Birthday Problem:</strong></p> <p>What's the probability that in a group of n people, at least 2 share a birthday?</p> <p><strong>Approach - Complement:</strong></p> <p>P(at least 2 share) = 1 - P(all different birthdays)</p> <div class=arithmatex>\[P(\text{all different}) = \frac{365}{365} \cdot \frac{364}{365} \cdot \frac{363}{365} \cdot ... \cdot \frac{365-n+1}{365}\]</div> <p><strong>Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>birthday_probability</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;P(at least 2 share birthday in group of n)&quot;&quot;&quot;</span>
    <span class=n>p_all_different</span> <span class=o>=</span> <span class=mf>1.0</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
        <span class=n>p_all_different</span> <span class=o>*=</span> <span class=p>(</span><span class=mi>365</span> <span class=o>-</span> <span class=n>i</span><span class=p>)</span> <span class=o>/</span> <span class=mi>365</span>
    <span class=k>return</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>p_all_different</span>

<span class=c1># Results:</span>
<span class=c1># n=23: 50.7% (famous result!)</span>
<span class=c1># n=50: 97.0%</span>
<span class=c1># n=70: 99.9%</span>

<span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>70</span><span class=p>]:</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;n=</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>birthday_probability</span><span class=p>(</span><span class=n>n</span><span class=p>)</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Why So Counter-Intuitive?</strong></p> <ul> <li>We think: 23 people, 365 days ‚Üí small chance</li> <li>Reality: C(23,2) = 253 pairs to compare!</li> </ul> <p><strong>Generalized Version:</strong></p> <p>P(collision in hash table) follows same logic - birthday attack in cryptography.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Complement probability, combinatorics.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Uses complement approach</li> <li>Knows n=23 gives ~50%</li> <li>Can generalize to other collision problems</li> <li>Explains why intuition fails</li> </ul> </div> </details> <hr> <h3 id=explain-the-monty-hall-problem-google-meta-interview-question>Explain the Monty Hall Problem - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Monty Hall</code>, <code>Conditional Probability</code>, <code>Puzzle</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>The Setup:</strong></p> <ul> <li>3 doors: 1 car, 2 goats</li> <li>You pick a door (say Door 1)</li> <li>Host (who knows what's behind each) opens another door showing a goat</li> <li>Should you switch?</li> </ul> <p><strong>Answer: YES - Switch gives &#8532; chance!</strong></p> <p><strong>Intuition:</strong></p> <div class=highlight><pre><span></span><code>Initial pick: P(Car) = 1/3
Other doors:  P(Car) = 2/3

After host reveals goat:
- Your door still has P = 1/3
- Remaining door gets all 2/3
</code></pre></div> <p><strong>Simulation Proof:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>random</span>

<span class=k>def</span><span class=w> </span><span class=nf>monty_hall</span><span class=p>(</span><span class=n>switch</span><span class=p>,</span> <span class=n>n_simulations</span><span class=o>=</span><span class=mi>100000</span><span class=p>):</span>
    <span class=n>wins</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_simulations</span><span class=p>):</span>
        <span class=n>car</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
        <span class=n>choice</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>

        <span class=c1># Host opens a goat door (not your choice, not car)</span>
        <span class=n>goat_doors</span> <span class=o>=</span> <span class=p>[</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span> <span class=k>if</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>choice</span> <span class=ow>and</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>car</span><span class=p>]</span>
        <span class=n>host_opens</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>goat_doors</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>switch</span><span class=p>:</span>
            <span class=c1># Switch to remaining door</span>
            <span class=n>choice</span> <span class=o>=</span> <span class=p>[</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span> <span class=k>if</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>choice</span> <span class=ow>and</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>host_opens</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>

        <span class=k>if</span> <span class=n>choice</span> <span class=o>==</span> <span class=n>car</span><span class=p>:</span>
            <span class=n>wins</span> <span class=o>+=</span> <span class=mi>1</span>

    <span class=k>return</span> <span class=n>wins</span> <span class=o>/</span> <span class=n>n_simulations</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Stay:   </span><span class=si>{</span><span class=n>monty_hall</span><span class=p>(</span><span class=n>switch</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>   <span class=c1># ~33.3%</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Switch: </span><span class=si>{</span><span class=n>monty_hall</span><span class=p>(</span><span class=n>switch</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>    <span class=c1># ~66.7%</span>
</code></pre></div> <p><strong>Key Insight:</strong></p> <p>Host's action is not random - he MUST reveal a goat. This transfers information.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Conditional probability reasoning.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Gives correct answer (switch = &#8532;)</li> <li>Explains WHY (host's constraint)</li> <li>Can simulate or prove mathematically</li> <li>Addresses common misconceptions</li> </ul> </div> </details> <hr> <h3 id=what-is-covariance-and-correlation-google-meta-interview-question>What is Covariance and Correlation? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Covariance</code>, <code>Correlation</code>, <code>Dependency</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Covariance:</strong></p> <p>Measures joint variability of two variables:</p> <div class=arithmatex>\[Cov(X, Y) = E[(X - \mu_X)(Y - \mu_Y)] = E[XY] - E[X]E[Y]\]</div> <p><strong>Correlation (Pearson):</strong></p> <p>Standardized covariance, range [-1, 1]:</p> <div class=arithmatex>\[\rho_{XY} = \frac{Cov(X, Y)}{\sigma_X \sigma_Y}\]</div> <p><strong>Interpretation:</strong></p> <table> <thead> <tr> <th>Value</th> <th>Meaning</th> </tr> </thead> <tbody> <tr> <td>œÅ = 1</td> <td>Perfect positive linear</td> </tr> <tr> <td>œÅ = 0</td> <td>No linear relationship</td> </tr> <tr> <td>œÅ = -1</td> <td>Perfect negative linear</td> </tr> </tbody> </table> <p><strong>Important Properties:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Covariance</span>
<span class=n>Cov</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span> <span class=o>=</span> <span class=n>Var</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
<span class=n>Cov</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span> <span class=o>=</span> <span class=n>Cov</span><span class=p>(</span><span class=n>Y</span><span class=p>,</span> <span class=n>X</span><span class=p>)</span>  <span class=c1># Symmetric</span>
<span class=n>Cov</span><span class=p>(</span><span class=n>aX</span> <span class=o>+</span> <span class=n>b</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span> <span class=o>=</span> <span class=n>a¬∑Cov</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span>

<span class=c1># Correlation</span>
<span class=n>Corr</span><span class=p>(</span><span class=n>aX</span> <span class=o>+</span> <span class=n>b</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span> <span class=o>=</span> <span class=n>sign</span><span class=p>(</span><span class=n>a</span><span class=p>)</span> <span class=err>¬∑</span> <span class=n>Corr</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)</span>  <span class=c1># Unaffected by linear transform</span>
</code></pre></div> <p><strong>Python Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
<span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>

<span class=n>cov_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cov</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
<span class=n>cov_xy</span> <span class=o>=</span> <span class=n>cov_matrix</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>  <span class=c1># Covariance</span>

<span class=n>corr_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>corrcoef</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
<span class=n>corr_xy</span> <span class=o>=</span> <span class=n>corr_matrix</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>  <span class=c1># Correlation</span>
</code></pre></div> <p><strong>Warning:</strong></p> <p>Correlation ‚â† Causation Correlation = 0 does NOT mean independence!</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding relationship measures.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows correlation is dimensionless</li> <li>States correlation measures LINEAR relationship only</li> <li>Knows correlation = 0 ‚â† independence</li> <li>Can distinguish correlation from causation</li> </ul> </div> </details> <hr> <h3 id=explain-the-law-of-large-numbers-google-amazon-interview-question>Explain the Law of Large Numbers - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>LLN</code>, <code>Convergence</code>, <code>Sampling</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Law of Large Numbers:</strong></p> <p>Sample mean converges to population mean as sample size ‚Üí ‚àû:</p> <div class=arithmatex>\[\bar{X}_n \xrightarrow{p} \mu \quad \text{as} \quad n \to \infty\]</div> <p><strong>Two Forms:</strong></p> <table> <thead> <tr> <th>Weak LLN</th> <th>Strong LLN</th> </tr> </thead> <tbody> <tr> <td>Convergence in probability</td> <td>Almost sure convergence</td> </tr> <tr> <td>P(|XÃÑ‚Çô - Œº| &gt; Œµ) ‚Üí 0</td> <td>P(XÃÑ‚Çô ‚Üí Œº) = 1</td> </tr> </tbody> </table> <p><strong>Intuition:</strong></p> <p>More samples ‚Üí better estimate of true mean</p> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Fair coin: P(Heads) = 0.5</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=n>flips</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mi>10000</span><span class=p>)</span>
<span class=n>running_mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>flips</span><span class=p>)</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10001</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>running_mean</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;True Mean&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Flips&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Running Mean&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Law of Large Numbers: Coin Flips&#39;</span><span class=p>)</span>
</code></pre></div> <p><strong>Key Distinction from CLT:</strong></p> <table> <thead> <tr> <th>LLN</th> <th>CLT</th> </tr> </thead> <tbody> <tr> <td>Sample mean ‚Üí population mean</td> <td>Sample mean distribution ‚Üí Normal</td> </tr> <tr> <td>About convergence to a value</td> <td>About shape of distribution</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Asymptotic behavior understanding.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Distinguishes LLN from CLT</li> <li>Knows weak vs strong forms</li> <li>Explains practical implications</li> <li>Shows convergence concept</li> </ul> </div> </details> <hr> <h3 id=what-is-a-pdf-vs-pmf-vs-cdf-most-tech-companies-interview-question>What is a PDF vs PMF vs CDF? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>PDF</code>, <code>PMF</code>, <code>CDF</code>, <code>Distributions</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Probability Mass Function (PMF):</strong></p> <p>For discrete random variables:</p> <div class=arithmatex>\[P(X = x) = p(x)\]</div> <p>Properties: - p(x) ‚â• 0 - Œ£p(x) = 1</p> <p><strong>Probability Density Function (PDF):</strong></p> <p>For continuous random variables:</p> <div class=arithmatex>\[P(a &lt; X &lt; b) = \int_a^b f(x) dx\]</div> <p>Properties: - f(x) ‚â• 0 - ‚à´f(x)dx = 1 - P(X = a) = 0 for any exact value!</p> <p><strong>Cumulative Distribution Function (CDF):</strong></p> <p>For both discrete and continuous:</p> <div class=arithmatex>\[F(x) = P(X \leq x)\]</div> <p>Properties: - F(-‚àû) = 0, F(+‚àû) = 1 - Monotonically non-decreasing - F'(x) = f(x) for continuous</p> <p><strong>Visual Comparison:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Discrete: Binomial PMF and CDF</span>
<span class=n>x_discrete</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>11</span><span class=p>)</span>
<span class=n>pmf</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>binom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>x_discrete</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
<span class=n>cdf_discrete</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>binom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>x_discrete</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>

<span class=c1># Continuous: Normal PDF and CDF</span>
<span class=n>x_continuous</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=n>pdf</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_continuous</span><span class=p>)</span>
<span class=n>cdf_continuous</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>x_continuous</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Distribution fundamentals.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows PDF ‚â† probability (can exceed 1)</li> <li>Uses CDF for probability calculations</li> <li>Knows F'(x) = f(x) relationship</li> <li>Distinguishes discrete from continuous</li> </ul> </div> </details> <hr> <h3 id=what-is-a-confidence-interval-how-to-interpret-it-google-amazon-interview-question>What is a Confidence Interval? How to Interpret It? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Confidence Interval</code>, <code>Inference</code>, <code>Uncertainty</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Confidence Interval:</strong></p> <p>Range that likely contains true population parameter:</p> <div class=arithmatex>\[CI = \text{estimate} \pm \text{margin of error}\]</div> <p><strong>For Mean (known œÉ):</strong></p> <div class=arithmatex>\[CI = \bar{x} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}\]</div> <p><strong>For Mean (unknown œÉ):</strong></p> <div class=arithmatex>\[CI = \bar{x} \pm t_{\alpha/2, n-1} \cdot \frac{s}{\sqrt{n}}\]</div> <p><strong>Common z-values:</strong></p> <table> <thead> <tr> <th>Confidence</th> <th>z-value</th> </tr> </thead> <tbody> <tr> <td>90%</td> <td>1.645</td> </tr> <tr> <td>95%</td> <td>1.96</td> </tr> <tr> <td>99%</td> <td>2.576</td> </tr> </tbody> </table> <p><strong>Correct Interpretation:</strong></p> <p>‚úÖ "95% of such intervals contain the true mean" ‚ùå "95% probability the true mean is in this interval"</p> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>]</span>

<span class=c1># 95% CI for mean</span>
<span class=n>mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
<span class=n>se</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>sem</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  <span class=c1># Standard error</span>
<span class=n>ci</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>t</span><span class=o>.</span><span class=n>interval</span><span class=p>(</span><span class=mf>0.95</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>loc</span><span class=o>=</span><span class=n>mean</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>se</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: (</span><span class=si>{</span><span class=n>ci</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Width Factors:</strong></p> <ul> <li>Higher confidence ‚Üí wider CI</li> <li>Larger n ‚Üí narrower CI</li> <li>More variability ‚Üí wider CI</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Statistical inference understanding.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Correct frequentist interpretation</li> <li>Knows t vs z distribution choice</li> <li>Understands factors affecting width</li> <li>Can calculate by hand</li> </ul> </div> </details> <hr> <h3 id=explain-hypothesis-testing-null-alternative-p-value-google-amazon-interview-question>Explain Hypothesis Testing: Null, Alternative, p-value - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Hypothesis Testing</code>, <code>p-value</code>, <code>Significance</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Hypothesis Testing Framework:</strong></p> <table> <thead> <tr> <th>Component</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>H‚ÇÄ (Null)</td> <td>Default assumption (no effect)</td> </tr> <tr> <td>H‚ÇÅ (Alternative)</td> <td>What we want to prove</td> </tr> <tr> <td>Œ± (Significance)</td> <td>False positive threshold (usually 0.05)</td> </tr> <tr> <td>p-value</td> <td>P(data | H‚ÇÄ true)</td> </tr> </tbody> </table> <p><strong>Decision Rule:</strong></p> <ul> <li>If p-value ‚â§ Œ±: Reject H‚ÇÄ</li> <li>If p-value &gt; Œ±: Fail to reject H‚ÇÄ</li> </ul> <p><strong>Types of Errors:</strong></p> <table> <thead> <tr> <th>Error</th> <th>Description</th> <th>Name</th> </tr> </thead> <tbody> <tr> <td>Type I</td> <td>Reject H‚ÇÄ when true</td> <td>False Positive</td> </tr> <tr> <td>Type II</td> <td>Accept H‚ÇÄ when false</td> <td>False Negative</td> </tr> </tbody> </table> <p><strong>Example - A/B Test:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># Control: 100 conversions out of 1000</span>
<span class=c1># Treatment: 120 conversions out of 1000</span>

<span class=n>control_conv</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>control_n</span> <span class=o>=</span> <span class=mi>1000</span>
<span class=n>treatment_conv</span> <span class=o>=</span> <span class=mi>120</span>
<span class=n>treatment_n</span> <span class=o>=</span> <span class=mi>1000</span>

<span class=c1># H‚ÇÄ: p1 = p2 (no difference)</span>
<span class=c1># H‚ÇÅ: p1 ‚â† p2 (difference exists)</span>

<span class=c1># Two-proportion z-test</span>
<span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.proportion</span><span class=w> </span><span class=kn>import</span> <span class=n>proportions_ztest</span>

<span class=n>stat</span><span class=p>,</span> <span class=n>pvalue</span> <span class=o>=</span> <span class=n>proportions_ztest</span><span class=p>(</span>
    <span class=p>[</span><span class=n>control_conv</span><span class=p>,</span> <span class=n>treatment_conv</span><span class=p>],</span>
    <span class=p>[</span><span class=n>control_n</span><span class=p>,</span> <span class=n>treatment_n</span><span class=p>]</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>pvalue</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># If p &lt; 0.05, reject H‚ÇÄ ‚Üí significant difference</span>
</code></pre></div> <p><strong>p-value Misconceptions:</strong></p> <p>‚ùå p-value = P(H‚ÇÄ is true) ‚úÖ p-value = P(observing this data or more extreme | H‚ÇÄ true)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Core statistical testing knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Correct p-value interpretation</li> <li>Knows Type I vs Type II errors</li> <li>Understands "fail to reject" vs "accept"</li> <li>Can set up hypotheses correctly</li> </ul> </div> </details> <hr> <h3 id=what-is-power-in-hypothesis-testing-google-meta-interview-question>What is Power in Hypothesis Testing? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Power</code>, <code>Type II Error</code>, <code>Sample Size</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Power:</strong></p> <p>Probability of correctly rejecting H‚ÇÄ when it's false:</p> <div class=arithmatex>\[\text{Power} = 1 - \beta = P(\text{Reject } H_0 | H_0 \text{ is false})\]</div> <p><strong>Factors Affecting Power:</strong></p> <table> <thead> <tr> <th>Factor</th> <th>Effect on Power</th> </tr> </thead> <tbody> <tr> <td>Effect size ‚Üë</td> <td>Power ‚Üë</td> </tr> <tr> <td>Sample size ‚Üë</td> <td>Power ‚Üë</td> </tr> <tr> <td>Œ± ‚Üë</td> <td>Power ‚Üë</td> </tr> <tr> <td>Variance ‚Üì</td> <td>Power ‚Üë</td> </tr> </tbody> </table> <p><strong>Typical Target: Power = 0.80</strong></p> <p><strong>Power Analysis - Sample Size Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.power</span><span class=w> </span><span class=kn>import</span> <span class=n>TTestIndPower</span>

<span class=c1># Parameters</span>
<span class=n>effect_size</span> <span class=o>=</span> <span class=mf>0.5</span>  <span class=c1># Cohen&#39;s d (medium effect)</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>
<span class=n>power</span> <span class=o>=</span> <span class=mf>0.80</span>

<span class=c1># Calculate required sample size</span>
<span class=n>analysis</span> <span class=o>=</span> <span class=n>TTestIndPower</span><span class=p>()</span>
<span class=n>n</span> <span class=o>=</span> <span class=n>analysis</span><span class=o>.</span><span class=n>solve_power</span><span class=p>(</span>
    <span class=n>effect_size</span><span class=o>=</span><span class=n>effect_size</span><span class=p>,</span>
    <span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>,</span>
    <span class=n>power</span><span class=o>=</span><span class=n>power</span><span class=p>,</span>
    <span class=n>ratio</span><span class=o>=</span><span class=mi>1</span>  <span class=c1># Equal group sizes</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Required n per group: </span><span class=si>{</span><span class=n>n</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># ~64 per group for medium effect</span>
</code></pre></div> <p><strong>Effect Size (Cohen's d):</strong></p> <div class=arithmatex>\[d = \frac{\mu_1 - \mu_2}{\sigma}\]</div> <table> <thead> <tr> <th>d</th> <th>Interpretation</th> </tr> </thead> <tbody> <tr> <td>0.2</td> <td>Small</td> </tr> <tr> <td>0.5</td> <td>Medium</td> </tr> <tr> <td>0.8</td> <td>Large</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Experimental design knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows power = 1 - Œ≤</li> <li>Can perform power analysis</li> <li>Understands sample size trade-offs</li> <li>Uses effect size appropriately</li> </ul> </div> </details> <hr> <h3 id=explain-permutations-vs-combinations-most-tech-companies-interview-question>Explain Permutations vs Combinations - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Combinatorics</code>, <code>Counting</code>, <code>Fundamentals</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Permutations (Order Matters):</strong></p> <div class=arithmatex>\[P(n, r) = \frac{n!}{(n-r)!}\]</div> <p><strong>Combinations (Order Doesn't Matter):</strong></p> <div class=arithmatex>\[C(n, r) = \binom{n}{r} = \frac{n!}{r!(n-r)!}\]</div> <p><strong>Key Relationship:</strong></p> <div class=arithmatex>\[P(n, r) = C(n, r) \cdot r!\]</div> <p><strong>Examples:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>math</span><span class=w> </span><span class=kn>import</span> <span class=n>factorial</span><span class=p>,</span> <span class=n>comb</span><span class=p>,</span> <span class=n>perm</span>

<span class=c1># 5 people, select 3 for positions (President, VP, Secretary)</span>
<span class=c1># Order matters ‚Üí Permutation</span>
<span class=n>positions</span> <span class=o>=</span> <span class=n>perm</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># = 5 √ó 4 √ó 3 = 60</span>

<span class=c1># 5 people, select 3 for a committee</span>
<span class=c1># Order doesn&#39;t matter ‚Üí Combination</span>
<span class=n>committee</span> <span class=o>=</span> <span class=n>comb</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># = 10</span>

<span class=c1># Relationship</span>
<span class=k>assert</span> <span class=n>perm</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span> <span class=o>==</span> <span class=n>comb</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span> <span class=o>*</span> <span class=n>factorial</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
<span class=c1># 60 = 10 √ó 6</span>
</code></pre></div> <p><strong>With Repetition:</strong></p> <table> <thead> <tr> <th>Type</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Permutation with repetition</td> <td>n ≥</td> </tr> <tr> <td>Combination with repetition</td> <td>C(n+r-1, r)</td> </tr> </tbody> </table> <div class=highlight><pre><span></span><code><span class=c1># 4-digit PIN (0-9): 10^4 = 10000</span>
<span class=c1># Choose 3 scoops from 5 flavors (repeats OK): C(5+3-1, 3) = C(7,3) = 35</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Basic counting principles.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Immediate recognition of order relevance</li> <li>Knows formulas without derivation</li> <li>Distinguishes with vs without replacement</li> <li>Gives intuitive examples</li> </ul> </div> </details> <hr> <h3 id=what-is-the-negative-binomial-distribution-amazon-microsoft-interview-question>What is the Negative Binomial Distribution? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Negative Binomial</code>, <code>Discrete</code>, <code>Failures</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Negative Binomial Distribution:</strong></p> <p>Number of trials until rth success:</p> <div class=arithmatex>\[P(X = k) = \binom{k-1}{r-1} p^r (1-p)^{k-r}\]</div> <p><strong>Alternative: Number of failures before rth success (Y = X - r)</strong></p> <p><strong>Parameters:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>r/p</td> </tr> <tr> <td>Variance</td> <td>r(1-p)/p¬≤</td> </tr> </tbody> </table> <p><strong>Special Case:</strong></p> <p>When r = 1: Negative Binomial ‚Üí Geometric</p> <p><strong>Example - Quality Control:</strong></p> <p>Need 3 good widgets. P(good) = 0.8. Expected total inspections?</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>nbinom</span>

<span class=n>r</span><span class=p>,</span> <span class=n>p</span> <span class=o>=</span> <span class=mi>3</span><span class=p>,</span> <span class=mf>0.8</span>

<span class=c1># Expected trials until 3 successes</span>
<span class=n>expected_trials</span> <span class=o>=</span> <span class=n>r</span> <span class=o>/</span> <span class=n>p</span>  <span class=c1># = 3 / 0.8 = 3.75</span>

<span class=c1># P(need exactly 5 trials)?</span>
<span class=c1># 5 trials, 3 successes, 2 failures</span>
<span class=n>p_5</span> <span class=o>=</span> <span class=n>nbinom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>  <span class=c1># k = failures</span>
<span class=c1># = C(4,2) * 0.8^3 * 0.2^2 = 0.0512</span>

<span class=c1># P(need at most 4 trials)?</span>
<span class=n>p_le_4</span> <span class=o>=</span> <span class=n>nbinom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.8</span><span class=p>)</span>  <span class=c1># ‚â§1 failure</span>
</code></pre></div> <p><strong>Applications:</strong></p> <ul> <li>Number of sales calls until quota</li> <li>Waiting for multiple events</li> <li>Overdispersed count data</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Generalized geometric distribution.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows relationship to geometric</li> <li>Handles both parameterizations</li> <li>Calculates mean = r/p</li> <li>Gives practical applications</li> </ul> </div> </details> <hr> <h3 id=what-is-the-beta-distribution-amazon-google-interview-question>What is the Beta Distribution? - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Beta</code>, <code>Continuous</code>, <code>Bayesian</code> | <strong>Asked by:</strong> Amazon, Google, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Beta Distribution:</strong></p> <p>Models probabilities (values in [0, 1]):</p> <div class=arithmatex>\[f(x; \alpha, \beta) = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha, \beta)}\]</div> <p><strong>Parameters:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>Œ± / (Œ± + Œ≤)</td> </tr> <tr> <td>Mode</td> <td>(Œ±-1) / (Œ±+Œ≤-2) for Œ±,Œ≤ &gt; 1</td> </tr> <tr> <td>Variance</td> <td>Œ±Œ≤ / [(Œ±+Œ≤)¬≤(Œ±+Œ≤+1)]</td> </tr> </tbody> </table> <p><strong>Special Cases:</strong></p> <table> <thead> <tr> <th>Œ±</th> <th>Œ≤</th> <th>Shape</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>1</td> <td>Uniform</td> </tr> <tr> <td>0.5</td> <td>0.5</td> <td>U-shaped</td> </tr> <tr> <td>2</td> <td>5</td> <td>Left-skewed</td> </tr> <tr> <td>5</td> <td>2</td> <td>Right-skewed</td> </tr> </tbody> </table> <p><strong>Bayesian Application:</strong></p> <p>Prior for probability p, with binomial likelihood:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>beta</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Prior: Beta(2, 2) - slight preference for 0.5</span>
<span class=c1># Observed: 7 successes, 3 failures</span>
<span class=c1># Posterior: Beta(2+7, 2+3) = Beta(9, 5)</span>

<span class=n>prior_alpha</span><span class=p>,</span> <span class=n>prior_beta</span> <span class=o>=</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span>
<span class=n>successes</span><span class=p>,</span> <span class=n>failures</span> <span class=o>=</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>3</span>

<span class=n>post_alpha</span> <span class=o>=</span> <span class=n>prior_alpha</span> <span class=o>+</span> <span class=n>successes</span>
<span class=n>post_beta</span> <span class=o>=</span> <span class=n>prior_beta</span> <span class=o>+</span> <span class=n>failures</span>

<span class=n>posterior</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=n>post_alpha</span><span class=p>,</span> <span class=n>post_beta</span><span class=p>)</span>

<span class=n>mean</span> <span class=o>=</span> <span class=n>posterior</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># 9/14 ‚âà 0.643</span>
<span class=n>ci</span> <span class=o>=</span> <span class=n>posterior</span><span class=o>.</span><span class=n>interval</span><span class=p>(</span><span class=mf>0.95</span><span class=p>)</span>  <span class=c1># 95% credible interval</span>
</code></pre></div> <p><strong>Why Use Beta?</strong></p> <ul> <li>Conjugate prior for binomial</li> <li>Posterior is also Beta</li> <li>Flexible shape for [0,1] data</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Bayesian statistics foundation.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows it models probabilities</li> <li>Uses as prior in Bayesian inference</li> <li>Understands conjugacy</li> <li>Can update with observed data</li> </ul> </div> </details> <hr> <h3 id=what-is-the-gamma-distribution-amazon-google-interview-question>What is the Gamma Distribution? - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Gamma</code>, <code>Continuous</code>, <code>Waiting</code> | <strong>Asked by:</strong> Amazon, Google, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Gamma Distribution:</strong></p> <p>Generalized exponential - time until kth event:</p> <div class=arithmatex>\[f(x; k, \theta) = \frac{x^{k-1}e^{-x/\theta}}{\theta^k \Gamma(k)}\]</div> <p><strong>Parameters:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>kŒ∏</td> </tr> <tr> <td>Variance</td> <td>kŒ∏¬≤</td> </tr> <tr> <td>Mode</td> <td>(k-1)Œ∏ for k ‚â• 1</td> </tr> </tbody> </table> <p><strong>Special Cases:</strong></p> <table> <thead> <tr> <th>Distribution</th> <th>Gamma Parameters</th> </tr> </thead> <tbody> <tr> <td>Exponential</td> <td>k = 1</td> </tr> <tr> <td>Chi-squared</td> <td>k = ŒΩ/2, Œ∏ = 2</td> </tr> <tr> <td>Erlang</td> <td>k ‚àà integers</td> </tr> </tbody> </table> <p><strong>Application:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>gamma</span>

<span class=c1># Phone calls: avg 3 per hour (Œª=3)</span>
<span class=c1># Time until 5th call?</span>

<span class=n>k</span> <span class=o>=</span> <span class=mi>5</span>  <span class=c1># 5th event</span>
<span class=n>theta</span> <span class=o>=</span> <span class=mi>1</span><span class=o>/</span><span class=mi>3</span>  <span class=c1># Scale = 1/rate</span>

<span class=n>waiting</span> <span class=o>=</span> <span class=n>gamma</span><span class=p>(</span><span class=n>a</span><span class=o>=</span><span class=n>k</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>theta</span><span class=p>)</span>

<span class=c1># Expected wait</span>
<span class=n>expected</span> <span class=o>=</span> <span class=n>waiting</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># = 5 * (1/3) = 1.67 hours</span>

<span class=c1># P(wait &gt; 2 hours)?</span>
<span class=n>p_gt_2</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>waiting</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</code></pre></div> <p><strong>Relationship to Poisson:</strong></p> <ul> <li>Poisson: count in fixed time</li> <li>Gamma: time until kth count</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced distribution knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows exponential is Gamma(1, Œ∏)</li> <li>Connects to Poisson process</li> <li>Uses for waiting time problems</li> <li>Knows chi-squared is special gamma</li> </ul> </div> </details> <hr> <h3 id=what-is-a-markov-chain-google-amazon-interview-question>What is a Markov Chain? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Markov Chain</code>, <code>Stochastic Process</code>, <code>Probability</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Markov Chain:</strong></p> <p>Stochastic process with memoryless property:</p> <div class=arithmatex>\[P(X_{n+1} = j | X_n = i, X_{n-1}, ..., X_0) = P(X_{n+1} = j | X_n = i)\]</div> <p>"Future depends only on present, not past"</p> <p><strong>Components:</strong></p> <ul> <li>States: Finite or infinite set</li> <li>Transition probabilities: P(i ‚Üí j)</li> <li>Transition matrix: P where P·µ¢‚±º = P(i ‚Üí j)</li> </ul> <p><strong>Example - Weather:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># States: Sunny (0), Rainy (1)</span>
<span class=c1># P[i,j] = probability of going from i to j</span>
<span class=n>P</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>],</span>  <span class=c1># Sunny ‚Üí Sunny=0.8, Rainy=0.2</span>
    <span class=p>[</span><span class=mf>0.4</span><span class=p>,</span> <span class=mf>0.6</span><span class=p>]</span>   <span class=c1># Rainy ‚Üí Sunny=0.4, Rainy=0.6</span>
<span class=p>])</span>

<span class=c1># After n steps from initial state</span>
<span class=k>def</span><span class=w> </span><span class=nf>state_after_n_steps</span><span class=p>(</span><span class=n>P</span><span class=p>,</span> <span class=n>initial</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>matrix_power</span><span class=p>(</span><span class=n>P</span><span class=p>,</span> <span class=n>n</span><span class=p>)[</span><span class=n>initial</span><span class=p>]</span>

<span class=c1># Stationary distribution (œÄ = œÄP)</span>
<span class=n>eigenvalues</span><span class=p>,</span> <span class=n>eigenvectors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>eig</span><span class=p>(</span><span class=n>P</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
<span class=n>stationary</span> <span class=o>=</span> <span class=n>eigenvectors</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>real</span>
<span class=n>stationary</span> <span class=o>=</span> <span class=n>stationary</span> <span class=o>/</span> <span class=n>stationary</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
<span class=c1># [0.667, 0.333] - long-run: 66.7% sunny</span>
</code></pre></div> <p><strong>Key Properties:</strong></p> <ul> <li>Irreducible: Can reach any state from any other</li> <li>Aperiodic: No fixed cycles</li> <li>Ergodic: Irreducible + aperiodic ‚Üí unique stationary dist</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Stochastic modeling knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>States memoryless property clearly</li> <li>Can write transition matrix</li> <li>Knows stationary distribution concept</li> <li>Gives PageRank as application</li> </ul> </div> </details> <hr> <h3 id=what-is-entropy-in-information-theory-google-meta-interview-question>What is Entropy in Information Theory? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Entropy</code>, <code>Information Theory</code>, <code>Uncertainty</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Shannon Entropy:</strong></p> <p>Measures uncertainty/information content:</p> <div class=arithmatex>\[H(X) = -\sum_x P(x) \log_2 P(x)\]</div> <p><strong>Properties:</strong></p> <table> <thead> <tr> <th>Distribution</th> <th>Entropy</th> </tr> </thead> <tbody> <tr> <td>Uniform</td> <td>Maximum (log‚ÇÇn for n outcomes)</td> </tr> <tr> <td>Deterministic</td> <td>0 (no uncertainty)</td> </tr> <tr> <td>Binary (p=0.5)</td> <td>1 bit</td> </tr> </tbody> </table> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>def</span><span class=w> </span><span class=nf>entropy</span><span class=p>(</span><span class=n>probs</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Calculate Shannon entropy in bits&quot;&quot;&quot;</span>
    <span class=n>probs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span>
    <span class=n>probs</span> <span class=o>=</span> <span class=n>probs</span><span class=p>[</span><span class=n>probs</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>]</span>  <span class=c1># Avoid log(0)</span>
    <span class=k>return</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>probs</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log2</span><span class=p>(</span><span class=n>probs</span><span class=p>))</span>

<span class=c1># Fair coin: maximum entropy</span>
<span class=n>fair_coin</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>([</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>])</span>  <span class=c1># 1.0 bit</span>

<span class=c1># Biased coin</span>
<span class=n>biased</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>([</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>])</span>  <span class=c1># 0.47 bits</span>

<span class=c1># Fair die</span>
<span class=n>fair_die</span> <span class=o>=</span> <span class=n>entropy</span><span class=p>([</span><span class=mi>1</span><span class=o>/</span><span class=mi>6</span><span class=p>]</span> <span class=o>*</span> <span class=mi>6</span><span class=p>)</span>  <span class=c1># 2.58 bits</span>
</code></pre></div> <p><strong>Cross-Entropy (ML Loss):</strong></p> <div class=arithmatex>\[H(p, q) = -\sum_x p(x) \log q(x)\]</div> <p><strong>KL Divergence:</strong></p> <div class=arithmatex>\[D_{KL}(p||q) = H(p, q) - H(p)\]</div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Information theory fundamentals.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows entropy measures uncertainty</li> <li>Uses log‚ÇÇ for bits, ln for nats</li> <li>Connects to ML cross-entropy loss</li> <li>Understands maximum entropy principle</li> </ul> </div> </details> <hr> <h3 id=what-are-joint-and-marginal-distributions-google-amazon-interview-question>What are Joint and Marginal Distributions? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Joint Distribution</code>, <code>Marginal</code>, <code>Multivariate</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Joint Distribution:</strong></p> <p>Probability distribution over multiple variables:</p> <div class=arithmatex>\[P(X=x, Y=y) = P(X=x \cap Y=y)\]</div> <p><strong>Marginal Distribution:</strong></p> <p>Distribution of single variable from joint:</p> <div class=arithmatex>\[P(X=x) = \sum_y P(X=x, Y=y)\]</div> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Joint PMF of X and Y</span>
<span class=n>joint</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>],</span>  <span class=c1># X=0</span>
    <span class=p>[</span><span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>],</span>  <span class=c1># X=1</span>
    <span class=p>[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>]</span> <span class=c1># X=2</span>
<span class=p>])</span>
<span class=c1># Columns: Y=0, Y=1, Y=2</span>

<span class=c1># Marginal of X (sum over Y)</span>
<span class=n>marginal_x</span> <span class=o>=</span> <span class=n>joint</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [0.4, 0.5, 0.1]</span>

<span class=c1># Marginal of Y (sum over X)</span>
<span class=n>marginal_y</span> <span class=o>=</span> <span class=n>joint</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># [0.3, 0.45, 0.25]</span>

<span class=c1># Conditional P(Y|X=1)</span>
<span class=n>conditional_y_given_x1</span> <span class=o>=</span> <span class=n>joint</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>/</span> <span class=n>marginal_x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
<span class=c1># [0.4, 0.4, 0.2]</span>
</code></pre></div> <p><strong>Independence Check:</strong></p> <p>X and Y independent iff: P(X=x, Y=y) = P(X=x) ¬∑ P(Y=y) for all x, y</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Multivariate probability.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows marginalization = summing out</li> <li>Can derive conditional from joint</li> <li>Checks independence via product rule</li> <li>Extends to continuous case</li> </ul> </div> </details> <hr> <h3 id=what-is-the-chi-squared-distribution-and-test-amazon-microsoft-interview-question>What is the Chi-Squared Distribution and Test? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Chi-Squared</code>, <code>Hypothesis Testing</code>, <code>Categorical</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Chi-Squared Distribution:</strong></p> <p>Sum of squared standard normals:</p> <div class=arithmatex>\[\chi^2_k = Z_1^2 + Z_2^2 + ... + Z_k^2\]</div> <p>where Z·µ¢ ~ N(0,1) and k = degrees of freedom</p> <p><strong>Chi-Squared Test for Independence:</strong></p> <p>Tests if two categorical variables are independent:</p> <div class=arithmatex>\[\chi^2 = \sum \frac{(O - E)^2}{E}\]</div> <ul> <li>O = observed frequency</li> <li>E = expected frequency (under independence)</li> </ul> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chi2_contingency</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Observed: Gender vs Product Preference</span>
<span class=n>observed</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=mi>30</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span>  <span class=c1># Male: A, B, C</span>
    <span class=p>[</span><span class=mi>20</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>   <span class=c1># Female: A, B, C</span>
<span class=p>])</span>

<span class=n>chi2</span><span class=p>,</span> <span class=n>p_value</span><span class=p>,</span> <span class=n>dof</span><span class=p>,</span> <span class=n>expected</span> <span class=o>=</span> <span class=n>chi2_contingency</span><span class=p>(</span><span class=n>observed</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Chi-squared: </span><span class=si>{</span><span class=n>chi2</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Degrees of freedom: </span><span class=si>{</span><span class=n>dof</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># If p &lt; 0.05: Reject H‚ÇÄ ‚Üí Variables are dependent</span>
</code></pre></div> <p><strong>Chi-Squared Goodness of Fit:</strong></p> <p>Tests if data follows expected distribution:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chisquare</span>

<span class=n>observed</span> <span class=o>=</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>32</span><span class=p>]</span>  <span class=c1># Dice rolls</span>
<span class=n>expected</span> <span class=o>=</span> <span class=p>[</span><span class=mi>25</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>25</span><span class=p>]</span>   <span class=c1># Fair die</span>

<span class=n>stat</span><span class=p>,</span> <span class=n>p</span> <span class=o>=</span> <span class=n>chisquare</span><span class=p>(</span><span class=n>observed</span><span class=p>,</span> <span class=n>expected</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Categorical data analysis.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows œá¬≤ tests independence/goodness-of-fit</li> <li>Calculates expected under null</li> <li>Uses at least 5 per cell rule</li> <li>Interprets p-value correctly</li> </ul> </div> </details> <hr> <h3 id=what-is-the-t-distribution-when-to-use-it-google-amazon-interview-question>What is the t-Distribution? When to Use It? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>t-Distribution</code>, <code>Small Samples</code>, <code>Inference</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>t-Distribution:</strong></p> <p>For inference when œÉ is unknown (uses sample s):</p> <div class=arithmatex>\[t = \frac{\bar{X} - \mu}{s / \sqrt{n}}\]</div> <p><strong>Properties:</strong></p> <table> <thead> <tr> <th>Property</th> <th>Value</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>0 (for ŒΩ &gt; 1)</td> </tr> <tr> <td>Variance</td> <td>ŒΩ/(ŒΩ-2) for ŒΩ &gt; 2</td> </tr> <tr> <td>Shape</td> <td>Bell-shaped, heavier tails than Normal</td> </tr> <tr> <td>DOF ‚Üí ‚àû</td> <td>Converges to N(0,1)</td> </tr> </tbody> </table> <p><strong>When to Use:</strong></p> <table> <thead> <tr> <th>Use t</th> <th>Use z</th> </tr> </thead> <tbody> <tr> <td>œÉ unknown</td> <td>œÉ known</td> </tr> <tr> <td>Small n (&lt; 30)</td> <td>Large n (n ‚â• 30)</td> </tr> <tr> <td>Population ~normal</td> <td>CLT applies</td> </tr> </tbody> </table> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># t-test: is population mean = 100?</span>
<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>102</span><span class=p>,</span> <span class=mi>98</span><span class=p>,</span> <span class=mi>105</span><span class=p>,</span> <span class=mi>99</span><span class=p>,</span> <span class=mi>103</span><span class=p>,</span> <span class=mi>101</span><span class=p>,</span> <span class=mi>97</span><span class=p>,</span> <span class=mi>104</span><span class=p>]</span>

<span class=c1># One-sample t-test</span>
<span class=n>t_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>ttest_1samp</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>

<span class=c1># Critical value for 95% CI (df = n-1)</span>
<span class=n>t_crit</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>t</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.975</span><span class=p>,</span> <span class=n>df</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>

<span class=c1># Two-sample t-test</span>
<span class=n>group1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>]</span>
<span class=n>group2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>]</span>
<span class=n>t_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>ttest_ind</span><span class=p>(</span><span class=n>group1</span><span class=p>,</span> <span class=n>group2</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Small sample inference.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows to use t when œÉ unknown</li> <li>States heavier tails than normal</li> <li>Uses correct degrees of freedom</li> <li>Knows t ‚Üí z as n ‚Üí ‚àû</li> </ul> </div> </details> <hr> <h3 id=what-is-the-uniform-distribution-most-tech-companies-interview-question>What is the Uniform Distribution? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Uniform</code>, <code>Continuous</code>, <code>Random</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Continuous Uniform Distribution:</strong></p> <p>Equal probability over interval [a, b]:</p> <div class=arithmatex>\[f(x) = \frac{1}{b-a}, \quad a \leq x \leq b\]</div> <p><strong>Properties:</strong></p> <table> <thead> <tr> <th>Statistic</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Mean</td> <td>(a + b) / 2</td> </tr> <tr> <td>Variance</td> <td>(b - a)¬≤ / 12</td> </tr> <tr> <td>CDF</td> <td>(x - a) / (b - a)</td> </tr> </tbody> </table> <p><strong>Discrete Uniform:</strong></p> <div class=arithmatex>\[P(X = k) = \frac{1}{n}\]</div> <p>for k in {1, 2, ..., n}</p> <p><strong>Python:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>uniform</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Uniform[0, 1]</span>
<span class=n>U</span> <span class=o>=</span> <span class=n>uniform</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=c1># Generate random samples</span>
<span class=n>samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>

<span class=c1># Uniform[2, 8]</span>
<span class=n>U</span> <span class=o>=</span> <span class=n>uniform</span><span class=p>(</span><span class=n>loc</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>6</span><span class=p>)</span>  <span class=c1># loc=a, scale=b-a</span>
<span class=n>U</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># 5.0</span>
<span class=n>U</span><span class=o>.</span><span class=n>var</span><span class=p>()</span>   <span class=c1># 3.0</span>
</code></pre></div> <p><strong>Inverse Transform Sampling:</strong></p> <p>If U ~ Uniform(0,1), then F‚Åª¬π(U) has distribution F:</p> <div class=highlight><pre><span></span><code><span class=c1># Generate exponential from uniform</span>
<span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>exponential_samples</span> <span class=o>=</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>u</span><span class=p>)</span>  <span class=c1># Inverse CDF of Exp(1)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Basic distribution knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows mean = (a+b)/2</li> <li>Uses for random number generation</li> <li>Knows inverse transform method</li> <li>Distinguishes continuous vs discrete</li> </ul> </div> </details> <hr> <h3 id=explain-sampling-with-vs-without-replacement-most-tech-companies-interview-question>Explain Sampling With vs Without Replacement - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Sampling</code>, <code>Replacement</code>, <code>Combinatorics</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>With Replacement:</strong></p> <ul> <li>Each item can be selected multiple times</li> <li>Trials are independent</li> <li>Probabilities remain constant</li> </ul> <p><strong>Without Replacement:</strong></p> <ul> <li>Each item selected at most once</li> <li>Trials are dependent</li> <li>Probabilities change after each selection</li> </ul> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>population</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>]</span>

<span class=c1># With replacement - same item can appear multiple times</span>
<span class=n>with_rep</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>population</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>replace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=c1># Possible: [3, 3, 1]</span>

<span class=c1># Without replacement - unique items only</span>
<span class=n>without_rep</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>population</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>replace</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=c1># Possible: [4, 1, 3] but never [3, 3, 1]</span>
</code></pre></div> <p><strong>Probability Differences:</strong></p> <p>Drawing 2 red cards from deck:</p> <div class=highlight><pre><span></span><code><span class=c1># With replacement</span>
<span class=n>p_with</span> <span class=o>=</span> <span class=p>(</span><span class=mi>26</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>26</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>=</span> <span class=mf>0.25</span>

<span class=c1># Without replacement  </span>
<span class=n>p_without</span> <span class=o>=</span> <span class=p>(</span><span class=mi>26</span><span class=o>/</span><span class=mi>52</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>25</span><span class=o>/</span><span class=mi>51</span><span class=p>)</span> <span class=err>‚âà</span> <span class=mf>0.245</span>
</code></pre></div> <p><strong>When Each is Used:</strong></p> <table> <thead> <tr> <th>With Replacement</th> <th>Without Replacement</th> </tr> </thead> <tbody> <tr> <td>Bootstrap sampling</td> <td>Survey sampling</td> </tr> <tr> <td>Dice rolling</td> <td>Lottery</td> </tr> <tr> <td>Monte Carlo</td> <td>Card dealing</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Sampling concepts.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows independence implications</li> <li>Can calculate both scenarios</li> <li>Mentions hypergeometric for without</li> <li>Knows bootstrap uses with replacement</li> </ul> </div> </details> <hr> <h3 id=what-is-the-hypergeometric-distribution-google-amazon-interview-question>What is the Hypergeometric Distribution? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Hypergeometric</code>, <code>Sampling</code>, <code>Without Replacement</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Hypergeometric Distribution:</strong></p> <p>Successes in n draws without replacement:</p> <div class=arithmatex>\[P(X = k) = \frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}}\]</div> <ul> <li>N = population size</li> <li>K = successes in population</li> <li>n = sample size</li> <li>k = successes in sample</li> </ul> <p><strong>Example - Quality Control:</strong></p> <p>Lot of 100 items, 10 defective. Sample 15 without replacement.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>hypergeom</span>

<span class=n>N</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>n</span> <span class=o>=</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>15</span>

<span class=c1># P(exactly 2 defective)?</span>
<span class=n>p_2</span> <span class=o>=</span> <span class=n>hypergeom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>M</span><span class=o>=</span><span class=n>N</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=n>K</span><span class=p>,</span> <span class=n>N</span><span class=o>=</span><span class=n>n</span><span class=p>)</span>

<span class=c1># Expected defectives</span>
<span class=n>expected</span> <span class=o>=</span> <span class=n>n</span> <span class=o>*</span> <span class=n>K</span> <span class=o>/</span> <span class=n>N</span>  <span class=c1># = 15 * 10/100 = 1.5</span>

<span class=c1># P(at least 1 defective)?</span>
<span class=n>p_at_least_1</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>hypergeom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>M</span><span class=o>=</span><span class=n>N</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=n>K</span><span class=p>,</span> <span class=n>N</span><span class=o>=</span><span class=n>n</span><span class=p>)</span>
</code></pre></div> <p><strong>Comparison with Binomial:</strong></p> <table> <thead> <tr> <th>Hypergeometric</th> <th>Binomial</th> </tr> </thead> <tbody> <tr> <td>Without replacement</td> <td>With replacement</td> </tr> <tr> <td>p changes</td> <td>p constant</td> </tr> <tr> <td>Var &lt; np(1-p)</td> <td>Var = np(1-p)</td> </tr> </tbody> </table> <p><strong>For large N, hypergeometric ‚âà binomial</strong></p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Finite population sampling.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows formula intuitively</li> <li>Compares to binomial</li> <li>Uses for quality control problems</li> <li>Knows approximation for large N</li> </ul> </div> </details> <hr> <h3 id=what-is-the-f-distribution-google-amazon-interview-question>What is the F-Distribution? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>F-Distribution</code>, <code>ANOVA</code>, <code>Variance Comparison</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>F-Distribution:</strong></p> <p>Ratio of two chi-squared distributions:</p> <div class=arithmatex>\[F = \frac{\chi^2_1 / d_1}{\chi^2_2 / d_2}\]</div> <p><strong>Use Cases:</strong></p> <ol> <li>ANOVA (compare group means)</li> <li>Comparing variances</li> <li>Regression overall significance</li> </ol> <p><strong>F-Test for Variance:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Compare variances of two samples</span>
<span class=n>sample1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>]</span>
<span class=n>sample2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>19</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>35</span><span class=p>]</span>

<span class=n>var1</span><span class=p>,</span> <span class=n>var2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>sample1</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>sample2</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>f_stat</span> <span class=o>=</span> <span class=n>var1</span> <span class=o>/</span> <span class=n>var2</span>
<span class=n>df1</span><span class=p>,</span> <span class=n>df2</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>sample1</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>sample2</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span>

<span class=n>p_value</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=nb>min</span><span class=p>(</span>
    <span class=n>stats</span><span class=o>.</span><span class=n>f</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>f_stat</span><span class=p>,</span> <span class=n>df1</span><span class=p>,</span> <span class=n>df2</span><span class=p>),</span>
    <span class=mi>1</span> <span class=o>-</span> <span class=n>stats</span><span class=o>.</span><span class=n>f</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>f_stat</span><span class=p>,</span> <span class=n>df1</span><span class=p>,</span> <span class=n>df2</span><span class=p>)</span>
<span class=p>)</span>
</code></pre></div> <p><strong>One-Way ANOVA:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>f_oneway</span>

<span class=n>group1</span> <span class=o>=</span> <span class=p>[</span><span class=mi>85</span><span class=p>,</span> <span class=mi>90</span><span class=p>,</span> <span class=mi>88</span><span class=p>,</span> <span class=mi>92</span><span class=p>,</span> <span class=mi>87</span><span class=p>]</span>
<span class=n>group2</span> <span class=o>=</span> <span class=p>[</span><span class=mi>78</span><span class=p>,</span> <span class=mi>82</span><span class=p>,</span> <span class=mi>80</span><span class=p>,</span> <span class=mi>79</span><span class=p>,</span> <span class=mi>81</span><span class=p>]</span>
<span class=n>group3</span> <span class=o>=</span> <span class=p>[</span><span class=mi>91</span><span class=p>,</span> <span class=mi>95</span><span class=p>,</span> <span class=mi>89</span><span class=p>,</span> <span class=mi>94</span><span class=p>,</span> <span class=mi>92</span><span class=p>]</span>

<span class=n>f_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>f_oneway</span><span class=p>(</span><span class=n>group1</span><span class=p>,</span> <span class=n>group2</span><span class=p>,</span> <span class=n>group3</span><span class=p>)</span>
<span class=c1># If p &lt; 0.05: At least one group mean differs</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced statistical tests.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows F = ratio of variances</li> <li>Uses for ANOVA and regression</li> <li>Understands two df parameters</li> <li>Can interpret F-stat and p-value</li> </ul> </div> </details> <hr> <h3 id=how-do-you-calculate-sample-size-for-ab-tests-google-meta-interview-question>How Do You Calculate Sample Size for A/B Tests? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>A/B Testing</code>, <code>Sample Size</code>, <code>Power</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Sample Size Formula (Two Proportions):</strong></p> <div class=arithmatex>\[n = \frac{2(z_{\alpha/2} + z_{\beta})^2 \bar{p}(1-\bar{p})}{\delta^2}\]</div> <p>where: - Œ¥ = minimum detectable effect - pÃÑ = average proportion - Œ± = significance level (usually 0.05) - 1-Œ≤ = power (usually 0.80)</p> <p><strong>Python Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.power</span><span class=w> </span><span class=kn>import</span> <span class=n>NormalIndPower</span>
<span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.proportion</span><span class=w> </span><span class=kn>import</span> <span class=n>proportion_effectsize</span>

<span class=c1># Current conversion: 10%</span>
<span class=c1># Want to detect: 2% absolute lift (to 12%)</span>
<span class=n>p1</span><span class=p>,</span> <span class=n>p2</span> <span class=o>=</span> <span class=mf>0.10</span><span class=p>,</span> <span class=mf>0.12</span>

<span class=c1># Effect size</span>
<span class=n>effect_size</span> <span class=o>=</span> <span class=n>proportion_effectsize</span><span class=p>(</span><span class=n>p1</span><span class=p>,</span> <span class=n>p2</span><span class=p>)</span>

<span class=c1># Power analysis</span>
<span class=n>power_analysis</span> <span class=o>=</span> <span class=n>NormalIndPower</span><span class=p>()</span>
<span class=n>n_per_group</span> <span class=o>=</span> <span class=n>power_analysis</span><span class=o>.</span><span class=n>solve_power</span><span class=p>(</span>
    <span class=n>effect_size</span><span class=o>=</span><span class=n>effect_size</span><span class=p>,</span>
    <span class=n>alpha</span><span class=o>=</span><span class=mf>0.05</span><span class=p>,</span>
    <span class=n>power</span><span class=o>=</span><span class=mf>0.80</span><span class=p>,</span>
    <span class=n>ratio</span><span class=o>=</span><span class=mi>1</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Required per group: </span><span class=si>{</span><span class=n>n_per_group</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># ~3,600 per group for 2% lift detection</span>
</code></pre></div> <p><strong>Rule of Thumb:</strong></p> <p>For 80% power, 5% significance: - 1% absolute lift: ~15,000 per group - 2% absolute lift: ~3,800 per group - 5% absolute lift: ~600 per group</p> <p><strong>Factors:</strong></p> <table> <thead> <tr> <th>Factor</th> <th>Effect on n</th> </tr> </thead> <tbody> <tr> <td>Smaller effect ‚Üí</td> <td>Larger n</td> </tr> <tr> <td>Higher power ‚Üí</td> <td>Larger n</td> </tr> <tr> <td>Lower Œ± ‚Üí</td> <td>Larger n</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Experimental design skills.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows key inputs (effect, power, Œ±)</li> <li>Uses standard library for calculation</li> <li>Understands trade-offs</li> <li>Gives practical rule of thumb</li> </ul> </div> </details> <hr> <h3 id=what-is-bayesian-vs-frequentist-probability-google-amazon-interview-question>What is Bayesian vs Frequentist Probability? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Bayesian</code>, <code>Frequentist</code>, <code>Philosophy</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Frequentist:</strong></p> <ul> <li>Probability = long-run frequency</li> <li>Parameters are fixed (unknown constants)</li> <li>Inference via sampling distribution</li> <li>Uses p-values and confidence intervals</li> </ul> <p><strong>Bayesian:</strong></p> <ul> <li>Probability = degree of belief</li> <li>Parameters have distributions</li> <li>Inference via Bayes' theorem</li> <li>Uses posterior and credible intervals</li> </ul> <p><strong>Comparison:</strong></p> <table> <thead> <tr> <th>Aspect</th> <th>Frequentist</th> <th>Bayesian</th> </tr> </thead> <tbody> <tr> <td>Probability</td> <td>Long-run frequency</td> <td>Belief/uncertainty</td> </tr> <tr> <td>Parameters</td> <td>Fixed</td> <td>Random</td> </tr> <tr> <td>Prior info</td> <td>Not used</td> <td>Used explicitly</td> </tr> <tr> <td>Intervals</td> <td>95% CI: "95% of intervals contain true value"</td> <td>95% credible: "95% probability parameter in interval"</td> </tr> </tbody> </table> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Frequentist: p-value</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>ttest_1samp</span>
<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>52</span><span class=p>,</span> <span class=mi>48</span><span class=p>,</span> <span class=mi>55</span><span class=p>,</span> <span class=mi>49</span><span class=p>,</span> <span class=mi>51</span><span class=p>]</span>
<span class=n>t_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>ttest_1samp</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>

<span class=c1># Bayesian: posterior</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pymc</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pm</span>
<span class=k>with</span> <span class=n>pm</span><span class=o>.</span><span class=n>Model</span><span class=p>():</span>
    <span class=n>mu</span> <span class=o>=</span> <span class=n>pm</span><span class=o>.</span><span class=n>Normal</span><span class=p>(</span><span class=s1>&#39;mu&#39;</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>sigma</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>  <span class=c1># Prior</span>
    <span class=n>obs</span> <span class=o>=</span> <span class=n>pm</span><span class=o>.</span><span class=n>Normal</span><span class=p>(</span><span class=s1>&#39;obs&#39;</span><span class=p>,</span> <span class=n>mu</span><span class=o>=</span><span class=n>mu</span><span class=p>,</span> <span class=n>sigma</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>observed</span><span class=o>=</span><span class=n>data</span><span class=p>)</span>
    <span class=n>trace</span> <span class=o>=</span> <span class=n>pm</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=mi>1000</span><span class=p>)</span>
<span class=c1># 95% credible interval from posterior</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Statistical philosophy understanding.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Explains both paradigms fairly</li> <li>Knows interval interpretation difference</li> <li>Mentions when each is preferred</li> <li>Doesn't dogmatically favor one</li> </ul> </div> </details> <hr> <h3 id=what-is-the-multiple-comparisons-problem-google-meta-interview-question>What is the Multiple Comparisons Problem? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Multiple Testing</code>, <code>FWER</code>, <code>FDR</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>The Problem:</strong></p> <p>With many tests at Œ±=0.05, false positives accumulate:</p> <p>P(at least 1 false positive) = 1 - (1-Œ±)‚Åø</p> <ul> <li>20 tests: 64% chance of false positive</li> <li>100 tests: 99.4% chance!</li> </ul> <p><strong>Solutions:</strong></p> <p><strong>1. Bonferroni Correction (FWER):</strong></p> <p>Use Œ±/n for each test:</p> <div class=highlight><pre><span></span><code><span class=n>n_tests</span> <span class=o>=</span> <span class=mi>20</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>
<span class=n>bonferroni_alpha</span> <span class=o>=</span> <span class=n>alpha</span> <span class=o>/</span> <span class=n>n_tests</span>  <span class=c1># 0.0025</span>
</code></pre></div> <p>Conservative but controls family-wise error rate.</p> <p><strong>2. Benjamini-Hochberg (FDR):</strong></p> <p>Controls false discovery rate:</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>false_discovery_control</span>

<span class=n>p_values</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.001</span><span class=p>,</span> <span class=mf>0.008</span><span class=p>,</span> <span class=mf>0.012</span><span class=p>,</span> <span class=mf>0.045</span><span class=p>,</span> <span class=mf>0.060</span><span class=p>,</span> <span class=mf>0.120</span><span class=p>]</span>

<span class=c1># Adjust p-values</span>
<span class=n>adjusted</span> <span class=o>=</span> <span class=n>false_discovery_control</span><span class=p>(</span><span class=n>p_values</span><span class=p>,</span> <span class=n>method</span><span class=o>=</span><span class=s1>&#39;bh&#39;</span><span class=p>)</span>

<span class=c1># Or manually:</span>
<span class=n>sorted_p</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>
<span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>p</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>sorted_p</span><span class=p>):</span>
    <span class=n>threshold</span> <span class=o>=</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span> <span class=o>*</span> <span class=n>alpha</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p=</span><span class=si>{</span><span class=n>p</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, threshold=</span><span class=si>{</span><span class=n>threshold</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>When to Use:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td>No correction</td> <td>Single pre-specified test</td> </tr> <tr> <td>Bonferroni</td> <td>Few tests, must avoid any FP</td> </tr> <tr> <td>BH</td> <td>Many tests, some FP acceptable</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Rigorous testing knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Explains why it's a problem</li> <li>Knows Bonferroni is conservative</li> <li>Uses FDR for exploratory analysis</li> <li>Applies to A/B testing scenarios</li> </ul> </div> </details> <hr> <h3 id=what-is-bootstrap-sampling-google-amazon-interview-question>What is Bootstrap Sampling? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Bootstrap</code>, <code>Resampling</code>, <code>Non-parametric</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Bootstrap:</strong></p> <p>Resampling with replacement to estimate sampling distribution.</p> <p><strong>Process:</strong></p> <ol> <li>Draw n samples with replacement from data</li> <li>Calculate statistic of interest</li> <li>Repeat B times (e.g., 10,000)</li> <li>Use distribution of statistics for inference</li> </ol> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>25</span><span class=p>]</span>
<span class=n>n_bootstrap</span> <span class=o>=</span> <span class=mi>10000</span>

<span class=c1># Bootstrap confidence interval for mean</span>
<span class=n>bootstrap_means</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_bootstrap</span><span class=p>):</span>
    <span class=n>sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>),</span> <span class=n>replace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=n>bootstrap_means</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>sample</span><span class=p>))</span>

<span class=c1># 95% CI (percentile method)</span>
<span class=n>ci_lower</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>bootstrap_means</span><span class=p>,</span> <span class=mf>2.5</span><span class=p>)</span>
<span class=n>ci_upper</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>bootstrap_means</span><span class=p>,</span> <span class=mf>97.5</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: (</span><span class=si>{</span><span class=n>ci_lower</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci_upper</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Use Cases:</strong></p> <ul> <li>Confidence intervals for any statistic</li> <li>Estimating standard errors</li> <li>When distribution unknown</li> <li>Complex statistics (median, ratios)</li> </ul> <p><strong>Types:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>Percentile</td> <td>Use quantiles directly</td> </tr> <tr> <td>Basic</td> <td>Reflect around estimate</td> </tr> <tr> <td>BCa</td> <td>Bias-corrected accelerated</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Modern statistical methods.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows to resample WITH replacement</li> <li>Uses for non-standard statistics</li> <li>Knows different CI methods</li> <li>Mentions computational cost</li> </ul> </div> </details> <hr> <h3 id=average-score-on-a-dice-role-of-at-most-3-times-jane-street-hudson-river-trading-citadel-interview-question>Average score on a dice role of at most 3 times - Jane Street, Hudson River Trading, Citadel Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Probability</code>, <code>Expected Value</code>, <code>Game Theory</code> | <strong>Asked by:</strong> Jane Street, Hudson River Trading, Citadel</p> <details class=success> <summary>View Answer</summary> <p>Consider a fair 6-sided dice. Your aim is to get the highest score you can, in at-most 3 roles.</p> <p>A score is defined as the number that appears on the face of the dice facing up after the role. You can role at most 3 times but every time you role it is up to you to decide whether you want to role again.</p> <p>The last score will be counted as your final score.</p> <ul> <li>Find the average score if you rolled the dice only once?</li> <li>Find the average score that you can get with at most 3 roles?</li> <li>If the dice is fair, why is the average score for at most 3 roles and 1 role not the same?</li> </ul> </details> <details class=info> <summary>Hint 1</summary> <p>Find what is the expected score on single role</p> <p>And for cases when scores of single role &lt; <code>expected score on single role</code> is when you will go for next role</p> <p>Eg: if expected score of single role comes out to be 4.5, you will only role next turn for 1,2,3,4 and not for 5,6</p> </details> <details class=success> <summary>Answer</summary> <p>If you role a fair dice once you can get:</p> <table> <thead> <tr> <th style="text-align: center;">Score</th> <th style="text-align: center;">Probability</th> </tr> </thead> <tbody> <tr> <td style="text-align: center;">1</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">2</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">3</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">4</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">5</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">6</td> <td style="text-align: center;">&#8537;</td> </tr> </tbody> </table> <p>So your average score with one role is: </p> <p><code>sum of(score * scores's probability)</code> = (1+2+3+4+5+6)*(&#8537;) = (21/6) = 3.5</p> <p><strong>The average score if you rolled the dice only once is 3.5</strong></p> <p>For at most 3 roles, let's try back-tracking. Let's say just did your second role and you have to decide whether to do your 3<sup>rd</sup> role!</p> <p>We just found out if we role dice once on average we can expect score of 3.5. So we will only role the 3<sup>rd</sup> time if score on 2<sup>nd</sup> role is less than 3.5 i.e (1,2 or 3)</p> <p>Possibilities</p> <table> <thead> <tr> <th style="text-align: center;">2<sup>nd</sup> role score</th> <th style="text-align: center;">Probability</th> <th style="text-align: center;">3<sup>rd</sup> role score</th> <th style="text-align: center;">Probability</th> </tr> </thead> <tbody> <tr> <td style="text-align: center;">1</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">3.5</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">2</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">3.5</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">3</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">3.5</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">4</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">We won't role</td> </tr> <tr> <td style="text-align: center;">5</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">3<sup>rd</sup> time if we</td> </tr> <tr> <td style="text-align: center;">6</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">get score &gt;3 on 2<sup>nd</sup></td> </tr> </tbody> </table> <p>So if we had 2 roles, average score would be:</p> <div class=highlight><pre><span></span><code>[We role again if current score is less than 3.4]
(3.5)*(1/6) + (3.5)*(1/6) + (3.5)*(1/6) 
+
(4)*(1/6) + (5)*(1/6) + (6)*(1/6) [Decide not to role again]
=
1.75 + 2.5 = 4.25
</code></pre></div> <p>The average score if you rolled the dice twice is 4.25</p> <p>So now if we look from the perspective of first role. We will only role again if our score is less than 4.25 i.e 1,2,3 or 4</p> <p>Possibilities</p> <table> <thead> <tr> <th style="text-align: center;">1<sup>st</sup> role score</th> <th style="text-align: center;">Probability</th> <th style="text-align: center;">2<sup>nd</sup> role score (Exp)</th> <th style="text-align: center;">Probability/Note</th> </tr> </thead> <tbody> <tr> <td style="text-align: center;">1</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">4.25</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">2</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">4.25</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">3</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">4.25</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">4</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">4.25</td> <td style="text-align: center;">&#8537;</td> </tr> <tr> <td style="text-align: center;">5</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">We won't role again if we</td> </tr> <tr> <td style="text-align: center;">6</td> <td style="text-align: center;">&#8537;</td> <td style="text-align: center;">NA</td> <td style="text-align: center;">get score &gt;4.25 on 1<sup>st</sup></td> </tr> </tbody> </table> <p>So if we had 3 roles, average score would be:</p> <p><div class=highlight><pre><span></span><code>[We role again if current score is less than 4.25]
(4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) + (4.25)*(1/6) 
+
(5)*(1/6) + (6)*(1/6) [[Decide not to role again]
=
17/6 + 11/6 = 4.66
</code></pre></div> <strong>The average score if you rolled the dice only once is 4.66</strong></p> <p>The average score for at most 3 roles and 1 role is not the same because although the dice is fair the event of rolling the dice is no longer <strong>independent</strong>. The scores would have been the same if we rolled the dice 2<sup>nd</sup> and 3<sup>rd</sup> time without considering what we got in the last roll i.e. if the event of rolling the dice was independent.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Optimal stopping and backward induction.</p> </div> </details> <h3 id=explain-the-coupon-collector-problem-google-amazon-interview-question>Explain the Coupon Collector Problem - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Coupon Collector</code>, <code>Expected Value</code>, <code>Puzzle</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Problem:</strong></p> <p>How many items to collect before getting all n types? (Each type equally likely)</p> <p><strong>Expected Value:</strong></p> <div class=arithmatex>\[E[T] = n \cdot H_n = n \cdot \sum_{i=1}^{n} \frac{1}{i}\]</div> <p>where H‚Çô is the nth harmonic number.</p> <p><strong>Intuition:</strong></p> <p>After collecting k types, expected trials until new type = n/(n-k)</p> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>def</span><span class=w> </span><span class=nf>expected_trials</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Expected trials to collect all n types&quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=n>n</span> <span class=o>*</span> <span class=nb>sum</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span>

<span class=c1># 6 types (like Pokemon cards)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[trials]: </span><span class=si>{</span><span class=n>expected_trials</span><span class=p>(</span><span class=mi>6</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># ~14.7</span>

<span class=c1># Simulation</span>
<span class=k>def</span><span class=w> </span><span class=nf>simulate_coupon_collector</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>simulations</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>trials</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>simulations</span><span class=p>):</span>
        <span class=n>collected</span> <span class=o>=</span> <span class=nb>set</span><span class=p>()</span>
        <span class=n>count</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>collected</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>:</span>
            <span class=n>collected</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>
            <span class=n>count</span> <span class=o>+=</span> <span class=mi>1</span>
        <span class=n>trials</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>count</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>trials</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Simulated: </span><span class=si>{</span><span class=n>simulate_coupon_collector</span><span class=p>(</span><span class=mi>6</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Applications:</strong></p> <ul> <li>A/B testing (all user segments)</li> <li>Load testing (all code paths)</li> <li>Collecting rare items</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Probability puzzle solving.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Uses linearity of expectation</li> <li>Knows harmonic series result</li> <li>Can simulate to verify</li> <li>Applies to real scenarios</li> </ul> </div> </details> <hr> <h3 id=what-is-simpsons-paradox-google-meta-interview-question>What is Simpson's Paradox? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Simpson's Paradox</code>, <code>Confounding</code>, <code>Causality</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Simpson's Paradox:</strong></p> <p>Trend appears in subgroups but reverses when combined.</p> <p><strong>Classic Example - UC Berkeley Admissions:</strong></p> <table> <thead> <tr> <th></th> <th>Men Apply</th> <th>Men Admit</th> <th>Women Apply</th> <th>Women Admit</th> </tr> </thead> <tbody> <tr> <td>Overall</td> <td>8,442</td> <td>44%</td> <td>4,321</td> <td>35%</td> </tr> </tbody> </table> <p>Looks like discrimination against women!</p> <p>But by department:</p> <table> <thead> <tr> <th>Dept</th> <th>Men Apply</th> <th>Men %</th> <th>Women Apply</th> <th>Women %</th> </tr> </thead> <tbody> <tr> <td>A</td> <td>825</td> <td>62%</td> <td>108</td> <td>82%</td> </tr> <tr> <td>B</td> <td>560</td> <td>63%</td> <td>25</td> <td>68%</td> </tr> <tr> <td>C</td> <td>325</td> <td>37%</td> <td>593</td> <td>34%</td> </tr> </tbody> </table> <p>Women had HIGHER rates in each department!</p> <p><strong>Cause:</strong></p> <p>Women applied more to competitive departments.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>

<span class=c1># Weighted vs unweighted</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;dept&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;A&#39;</span><span class=p>,</span> <span class=s1>&#39;A&#39;</span><span class=p>,</span> <span class=s1>&#39;B&#39;</span><span class=p>,</span> <span class=s1>&#39;B&#39;</span><span class=p>],</span>
    <span class=s1>&#39;gender&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;M&#39;</span><span class=p>,</span> <span class=s1>&#39;F&#39;</span><span class=p>,</span> <span class=s1>&#39;M&#39;</span><span class=p>,</span> <span class=s1>&#39;F&#39;</span><span class=p>],</span>
    <span class=s1>&#39;applications&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>825</span><span class=p>,</span> <span class=mi>108</span><span class=p>,</span> <span class=mi>560</span><span class=p>,</span> <span class=mi>25</span><span class=p>],</span>
    <span class=s1>&#39;rate&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mf>0.62</span><span class=p>,</span> <span class=mf>0.82</span><span class=p>,</span> <span class=mf>0.63</span><span class=p>,</span> <span class=mf>0.68</span><span class=p>]</span>
<span class=p>})</span>

<span class=c1># Department is a confounding variable</span>
</code></pre></div> <p><strong>Lesson:</strong></p> <p>Always consider lurking/confounding variables before drawing conclusions.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Critical thinking about data.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Gives clear example</li> <li>Identifies confounding variable</li> <li>Knows when to aggregate vs stratify</li> <li>Relates to A/B testing concerns</li> </ul> </div> </details> <hr> <h3 id=what-are-quantiles-and-percentiles-most-tech-companies-interview-question>What Are Quantiles and Percentiles? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Quantiles</code>, <code>Percentiles</code>, <code>Descriptive</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Definitions:</strong></p> <ul> <li>Quantile: Values dividing distribution into intervals</li> <li>Percentile: Quantile expressed as percentage</li> <li>P-th percentile: Value below which P% of data falls</li> </ul> <p><strong>Common Quantiles:</strong></p> <table> <thead> <tr> <th>Name</th> <th>Divides Into</th> </tr> </thead> <tbody> <tr> <td>Median (Q2)</td> <td>2 equal parts</td> </tr> <tr> <td>Quartiles (Q1, Q2, Q3)</td> <td>4 equal parts</td> </tr> <tr> <td>Deciles</td> <td>10 equal parts</td> </tr> <tr> <td>Percentiles</td> <td>100 equal parts</td> </tr> </tbody> </table> <p><strong>Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>40</span><span class=p>]</span>

<span class=c1># Percentiles</span>
<span class=n>p25</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>25</span><span class=p>)</span>  <span class=c1># Q1</span>
<span class=n>p50</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>  <span class=c1># Median</span>
<span class=n>p75</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>75</span><span class=p>)</span>  <span class=c1># Q3</span>
<span class=n>p90</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=mi>90</span><span class=p>)</span>  <span class=c1># 90th percentile</span>

<span class=c1># IQR (Interquartile Range)</span>
<span class=n>iqr</span> <span class=o>=</span> <span class=n>p75</span> <span class=o>-</span> <span class=n>p25</span>
</code></pre></div> <p><strong>Uses:</strong></p> <ul> <li>Latency: "p99 response time &lt; 100ms"</li> <li>Salaries: "In top 10% earners"</li> <li>Outlier detection: Beyond 1.5*IQR</li> </ul> <p><strong>Z-score to Percentile:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>norm</span>

<span class=c1># Z = 1.645 ‚Üí 95th percentile</span>
<span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mf>1.645</span><span class=p>)</span>  <span class=c1># ‚âà 0.95</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Basic statistical literacy.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows p50 = median</li> <li>Uses for SLA metrics</li> <li>Can convert z-scores to percentiles</li> <li>Understands IQR for robustness</li> </ul> </div> </details> <hr> <h3 id=what-is-the-difference-between-standard-deviation-and-standard-error-google-amazon-interview-question>What is the Difference Between Standard Deviation and Standard Error? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Standard Deviation</code>, <code>Standard Error</code>, <code>Sampling</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Standard Deviation (SD):</strong></p> <p>Measures spread of individual observations:</p> <div class=arithmatex>\[SD = \sqrt{\frac{\sum(x_i - \bar{x})^2}{n-1}}\]</div> <p><strong>Standard Error (SE):</strong></p> <p>Measures uncertainty in sample mean:</p> <div class=arithmatex>\[SE = \frac{SD}{\sqrt{n}}\]</div> <p><strong>Key Difference:</strong></p> <table> <thead> <tr> <th>SD</th> <th>SE</th> </tr> </thead> <tbody> <tr> <td>Describes data spread</td> <td>Describes estimate precision</td> </tr> <tr> <td>Doesn't depend on n (conceptually)</td> <td>Decreases with larger n</td> </tr> <tr> <td>Used for z-scores</td> <td>Used for confidence intervals</td> </tr> </tbody> </table> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>sem</span>

<span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>]</span>

<span class=n>sd</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># Sample SD</span>
<span class=n>se</span> <span class=o>=</span> <span class=n>sem</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  <span class=c1># Standard error of mean</span>
<span class=c1># or se = sd / np.sqrt(len(data))</span>

<span class=n>mean</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=c1># 95% CI using SE</span>
<span class=n>ci</span> <span class=o>=</span> <span class=p>(</span><span class=n>mean</span> <span class=o>-</span> <span class=mf>1.96</span><span class=o>*</span><span class=n>se</span><span class=p>,</span> <span class=n>mean</span> <span class=o>+</span> <span class=mf>1.96</span><span class=o>*</span><span class=n>se</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;SD: </span><span class=si>{</span><span class=n>sd</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>   <span class=c1># ~2.21</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;SE: </span><span class=si>{</span><span class=n>se</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>   <span class=c1># ~0.70</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: </span><span class=si>{</span><span class=n>ci</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Intuition:</strong></p> <ul> <li>SD: "Typical distance of point from mean"</li> <li>SE: "Typical error in our estimate of the mean"</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Sampling variability understanding.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Clearly distinguishes the two concepts</li> <li>Knows SE = SD/‚àön</li> <li>Uses SE for confidence intervals</li> <li>Knows SE decreases with n</li> </ul> </div> </details> <hr> <h3 id=what-is-moment-generating-function-amazon-microsoft-interview-question>What is Moment Generating Function? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>MGF</code>, <code>Moments</code>, <code>Advanced</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Moment Generating Function (MGF):</strong></p> <div class=arithmatex>\[M_X(t) = E[e^{tX}] = \sum_x e^{tx} P(X=x)\]</div> <p><strong>Why "Moment Generating"?</strong></p> <p>nth moment = nth derivative at t=0:</p> <div class=arithmatex>\[E[X^n] = M_X^{(n)}(0)\]</div> <p><strong>Properties:</strong></p> <ol> <li>Uniquely determines distribution</li> <li>Sum of independent RVs: MGF = product of MGFs</li> <li>Linear transform: M_{aX+b}(t) = e^{bt} M_X(at)</li> </ol> <p><strong>Examples:</strong></p> <table> <thead> <tr> <th>Distribution</th> <th>MGF</th> </tr> </thead> <tbody> <tr> <td>Normal(Œº,œÉ¬≤)</td> <td>exp(Œºt + œÉ¬≤t¬≤/2)</td> </tr> <tr> <td>Exponential(Œª)</td> <td>Œª/(Œª-t) for t &lt; Œª</td> </tr> <tr> <td>Poisson(Œª)</td> <td>exp(Œª(e·µó-1))</td> </tr> <tr> <td>Binomial(n,p)</td> <td>(1-p+pe·µó)‚Åø</td> </tr> </tbody> </table> <p><strong>Deriving Moments:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># For Exponential(Œª=2): M(t) = 2/(2-t)</span>
<span class=c1># E[X] = M&#39;(0) = 2/(2-0)¬≤ = 1/2</span>
<span class=c1># E[X¬≤] = M&#39;&#39;(0) = 4/(2-0)¬≥ = 1/2</span>
<span class=c1># Var(X) = E[X¬≤] - (E[X])¬≤ = 1/2 - 1/4 = 1/4</span>
</code></pre></div> <p><strong>Application:</strong></p> <p>Proving CLT: MGF of sum ‚Üí MGF of normal</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced probability theory.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows moment derivation via derivatives</li> <li>Uses for proving sum distributions</li> <li>Knows MGF uniquely identifies distribution</li> <li>Can derive simple moments</li> </ul> </div> </details> <hr> <h3 id=what-is-the-waiting-time-paradox-google-amazon-interview-question>What is the Waiting Time Paradox? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Waiting Time</code>, <code>Inspection Paradox</code>, <code>Counter-intuitive</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>The Paradox:</strong></p> <p>Average wait for a bus can exceed half the average interval!</p> <p><strong>Explanation:</strong></p> <p>You're more likely to arrive during a LONG interval than a short one.</p> <p><strong>Mathematical:</strong></p> <p>For Poisson arrivals (rate Œª): - Average interval: 1/Œª - Expected wait: 1/Œª (same as full interval!)</p> <p>Due to memoryless property.</p> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Buses every 10 minutes on average (Poisson)</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mf>0.1</span>  <span class=c1># per minute</span>

<span class=c1># Simulate arrivals</span>
<span class=n>n_buses</span> <span class=o>=</span> <span class=mi>10000</span>
<span class=n>intervals</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>,</span> <span class=n>n_buses</span><span class=p>)</span>

<span class=c1># Arrive at random time within each interval</span>
<span class=n>random_fraction</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n_buses</span><span class=p>)</span>
<span class=n>wait_times</span> <span class=o>=</span> <span class=n>intervals</span> <span class=o>*</span> <span class=n>random_fraction</span>

<span class=n>avg_wait</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>wait_times</span><span class=p>)</span>
<span class=n>avg_interval</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>intervals</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Avg interval: </span><span class=si>{</span><span class=n>avg_interval</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> min&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Avg wait: </span><span class=si>{</span><span class=n>avg_wait</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> min&quot;</span><span class=p>)</span>
<span class=c1># Both approximately 10 minutes!</span>
</code></pre></div> <p><strong>Real-World:</strong></p> <p>If buses are scheduled (not Poisson), wait ‚âà interval/2. But with variability, wait increases due to "length-biased sampling."</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Counter-intuitive probability.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Explains length-biased sampling</li> <li>Connects to memoryless property</li> <li>Can simulate to demonstrate</li> <li>Knows scheduled vs random arrivals differ</li> </ul> </div> </details> <hr> <h3 id=how-do-you-estimate-probability-from-rare-events-google-amazon-interview-question>How Do You Estimate Probability from Rare Events? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Rare Events</code>, <code>Estimation</code>, <code>Confidence</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>The Challenge:</strong></p> <p>0 events in n trials. Is probability really 0?</p> <p><strong>Rule of Three:</strong></p> <p>If 0 events in n trials, 95% confident p &lt; 3/n</p> <div class=highlight><pre><span></span><code><span class=n>n</span> <span class=o>=</span> <span class=mi>1000</span>  <span class=c1># trials</span>
<span class=n>events</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># observed</span>

<span class=c1># 95% upper bound</span>
<span class=n>upper_bound</span> <span class=o>=</span> <span class=mi>3</span> <span class=o>/</span> <span class=n>n</span>  <span class=c1># 0.003 or 0.3%</span>
</code></pre></div> <p><strong>Bayesian Approach:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>beta</span>

<span class=c1># Prior: Beta(1, 1) = Uniform</span>
<span class=c1># Posterior: Beta(1 + k, 1 + n - k)</span>

<span class=n>n</span><span class=p>,</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>1000</span><span class=p>,</span> <span class=mi>0</span>
<span class=n>posterior</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>k</span><span class=p>,</span> <span class=mi>1</span> <span class=o>+</span> <span class=n>n</span> <span class=o>-</span> <span class=n>k</span><span class=p>)</span>

<span class=c1># 95% credible interval</span>
<span class=n>ci</span> <span class=o>=</span> <span class=n>posterior</span><span class=o>.</span><span class=n>interval</span><span class=p>(</span><span class=mf>0.95</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: (</span><span class=si>{</span><span class=n>ci</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s2>.5f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.5f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
<span class=c1># (0.0, 0.003)</span>

<span class=c1># With 3 events in 1000:</span>
<span class=n>posterior</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span> <span class=o>+</span> <span class=mi>1000</span> <span class=o>-</span> <span class=mi>3</span><span class=p>)</span>
<span class=n>mean_estimate</span> <span class=o>=</span> <span class=n>posterior</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>  <span class=c1># ‚âà 0.004</span>
</code></pre></div> <p><strong>Methods Comparison:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Estimate</th> <th>CI</th> </tr> </thead> <tbody> <tr> <td>MLE (k/n)</td> <td>0</td> <td>Undefined</td> </tr> <tr> <td>Rule of 3</td> <td>-</td> <td>(0, 0.003)</td> </tr> <tr> <td>Bayesian</td> <td>0.001</td> <td>(0, 0.003)</td> </tr> <tr> <td>Wilson</td> <td>0.0002</td> <td>(0, 0.002)</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Practical estimation skills.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows Rule of Three for quick bounds</li> <li>Uses Bayesian for proper intervals</li> <li>Doesn't report 0 as point estimate</li> <li>Mentions sample size requirements</li> </ul> </div> </details> <hr> <h3 id=explain-type-i-and-type-ii-errors-with-examples-google-amazon-interview-question>Explain Type I and Type II Errors with Examples - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Hypothesis Testing</code>, <code>Error Types</code>, <code>Statistics</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Type I Error (False Positive):</strong></p> <p>Rejecting true null hypothesis. Denoted Œ± (significance level).</p> <p><strong>Type II Error (False Negative):</strong></p> <p>Failing to reject false null hypothesis. Denoted Œ≤.</p> <p><strong>Power = 1 - Œ≤:</strong> Probability of correctly rejecting false null.</p> <p><strong>Medical Test Example:</strong></p> <table> <thead> <tr> <th>Test Result</th> <th>Truth: No Disease</th> <th>Truth: Disease</th> </tr> </thead> <tbody> <tr> <td>Negative</td> <td>‚úÖ Correct</td> <td>‚ùå Type II Error (Œ≤)</td> </tr> <tr> <td>Positive</td> <td>‚ùå Type I Error (Œ±)</td> <td>‚úÖ Correct (Power)</td> </tr> </tbody> </table> <p><strong>Criminal Trial Analogy:</strong></p> <div class=highlight><pre><span></span><code>H‚ÇÄ: Defendant is innocent
H‚ÇÅ: Defendant is guilty

Type I Error: Convict innocent person (Œ±)
Type II Error: Acquit guilty person (Œ≤)

Legal system prefers Type II over Type I
‚Üí Set Œ± = 0.05 (strict threshold)
</code></pre></div> <p><strong>Trade-off:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># Two distributions: H0 and H1</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>h0_dist</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># Null</span>
<span class=n>h1_dist</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># Alternative</span>

<span class=c1># Critical value for Œ± = 0.05</span>
<span class=n>critical</span> <span class=o>=</span> <span class=n>h0_dist</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.95</span><span class=p>)</span>  <span class=c1># 1.645</span>

<span class=c1># Œ±: Area under H0 beyond critical</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>h0_dist</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>critical</span><span class=p>)</span>  <span class=c1># 0.05</span>

<span class=c1># Œ≤: Area under H1 below critical</span>
<span class=n>beta</span> <span class=o>=</span> <span class=n>h1_dist</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>critical</span><span class=p>)</span>  <span class=c1># 0.09</span>

<span class=n>power</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>beta</span>  <span class=c1># 0.91</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Œ± (Type I): </span><span class=si>{</span><span class=n>alpha</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Œ≤ (Type II): </span><span class=si>{</span><span class=n>beta</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Power: </span><span class=si>{</span><span class=n>power</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>How to Reduce Errors:</strong></p> <table> <thead> <tr> <th>Action</th> <th>Effect on Œ±</th> <th>Effect on Œ≤</th> </tr> </thead> <tbody> <tr> <td>Increase sample size</td> <td>Same</td> <td>Decreases ‚Üì</td> </tr> <tr> <td>Decrease Œ± threshold</td> <td>Decreases ‚Üì</td> <td>Increases ‚Üë</td> </tr> <tr> <td>Increase Œ± threshold</td> <td>Increases ‚Üë</td> <td>Decreases ‚Üì</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding hypothesis test trade-offs.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Uses clear real-world analogy</li> <li>Explains Œ±-Œ≤ trade-off</li> <li>Knows power = 1 - Œ≤</li> <li>Mentions sample size as solution</li> </ul> </div> </details> <hr> <h3 id=what-is-the-likelihood-ratio-test-google-meta-interview-question>What is the Likelihood Ratio Test? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Hypothesis Testing</code>, <code>Likelihood</code>, <code>Statistical Tests</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Likelihood Ratio Test (LRT):</strong></p> <p>Compares fit of two nested models:</p> <div class=arithmatex>\[\Lambda = \frac{L(\theta_0 | data)}{L(\hat{\theta} | data)}\]</div> <p>Or equivalently:</p> <div class=arithmatex>\[-2\log(\Lambda) = 2[\log L(\hat{\theta}) - \log L(\theta_0)]\]</div> <p>Follows œá¬≤ distribution with df = difference in parameters.</p> <p><strong>Example - Coin Fairness:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Data: 60 heads in 100 flips</span>
<span class=n>heads</span> <span class=o>=</span> <span class=mi>60</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>100</span>

<span class=c1># H0: p = 0.5 (fair coin)</span>
<span class=n>p0</span> <span class=o>=</span> <span class=mf>0.5</span>
<span class=n>L0</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>binom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>heads</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>p0</span><span class=p>)</span>

<span class=c1># H1: p = MLE = 60/100</span>
<span class=n>p_hat</span> <span class=o>=</span> <span class=n>heads</span> <span class=o>/</span> <span class=n>n</span>
<span class=n>L1</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>binom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>heads</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>p_hat</span><span class=p>)</span>

<span class=c1># Likelihood ratio</span>
<span class=n>lambda_stat</span> <span class=o>=</span> <span class=n>L0</span> <span class=o>/</span> <span class=n>L1</span>

<span class=c1># Test statistic (asymptotically œá¬≤ with df=1)</span>
<span class=n>test_stat</span> <span class=o>=</span> <span class=o>-</span><span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>lambda_stat</span><span class=p>)</span>

<span class=c1># p-value</span>
<span class=n>p_value</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>stats</span><span class=o>.</span><span class=n>chi2</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>test_stat</span><span class=p>,</span> <span class=n>df</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test statistic: </span><span class=si>{</span><span class=n>test_stat</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=k>if</span> <span class=n>p_value</span> <span class=o>&lt;</span> <span class=mf>0.05</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Reject H0: Coin is biased&quot;</span><span class=p>)</span>
<span class=k>else</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Fail to reject H0: Coin appears fair&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Why LRT is Powerful:</strong></p> <ul> <li>Optimal under certain conditions (Neyman-Pearson lemma)</li> <li>Works for complex hypotheses</li> <li>Asymptotically œá¬≤ distributed</li> </ul> <p><strong>Common Applications:</strong></p> <ul> <li>Model selection (compare nested models)</li> <li>Goodness of fit tests</li> <li>Testing parameter significance in regression</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced statistical testing knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows -2 log(Œõ) ~ œá¬≤</li> <li>Can apply to real problem</li> <li>Mentions nested models requirement</li> <li>Links to model selection</li> </ul> </div> </details> <hr> <h3 id=explain-the-bias-of-an-estimator-amazon-microsoft-interview-question>Explain the Bias of an Estimator - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Estimation</code>, <code>Bias</code>, <code>Statistics</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Bias of Estimator:</strong></p> <div class=arithmatex>\[Bias(\hat{\theta}) = E[\hat{\theta}] - \theta\]</div> <p><strong>Unbiased:</strong> <span class=arithmatex>\(E[\hat{\theta}] = \theta\)</span></p> <p><strong>Example - Sample Variance:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Population variance: divide by n</span>
<span class=n>population</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>10000</span><span class=p>)</span>
<span class=n>pop_var</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>population</span><span class=p>)</span>  <span class=c1># True variance</span>

<span class=c1># Sample variance (biased): divide by n</span>
<span class=n>sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>population</span><span class=p>,</span> <span class=mi>30</span><span class=p>)</span>
<span class=n>biased_var</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>((</span><span class=n>sample</span> <span class=o>-</span> <span class=n>sample</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>  <span class=c1># √∑n</span>

<span class=c1># Sample variance (unbiased): divide by n-1</span>
<span class=n>unbiased_var</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>sample</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># √∑(n-1)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Population variance: </span><span class=si>{</span><span class=n>pop_var</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Biased estimator: </span><span class=si>{</span><span class=n>biased_var</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Unbiased estimator: </span><span class=si>{</span><span class=n>unbiased_var</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Repeat 10000 times</span>
<span class=n>biased_estimates</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>unbiased_estimates</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>s</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>population</span><span class=p>,</span> <span class=mi>30</span><span class=p>)</span>
    <span class=n>biased_estimates</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>((</span><span class=n>s</span> <span class=o>-</span> <span class=n>s</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>
    <span class=n>unbiased_estimates</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Biased mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>biased_estimates</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Unbiased mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>unbiased_estimates</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Why Divide by n-1?</strong></p> <p>Using sample mean (not true mean) introduces bias: - Sample points closer to sample mean than true mean - Need Bessel's correction: n/(n-1) factor</p> <p><strong>Bias-Variance Tradeoff:</strong></p> <div class=arithmatex>\[MSE = Bias^2 + Variance\]</div> <p>Sometimes biased estimators have lower MSE!</p> <p><strong>Example:</strong></p> <table> <thead> <tr> <th>Estimator</th> <th>Bias</th> <th>Variance</th> <th>MSE</th> </tr> </thead> <tbody> <tr> <td>Sample mean</td> <td>0</td> <td>œÉ¬≤/n</td> <td>œÉ¬≤/n</td> </tr> <tr> <td>Median (normal)</td> <td>0</td> <td>œÄœÉ¬≤/(2n)</td> <td>œÄœÉ¬≤/(2n)</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Deep understanding of estimation.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows formula E[Œ∏ÃÇ] - Œ∏</li> <li>Explains Bessel's correction</li> <li>Mentions bias-variance tradeoff</li> <li>Knows unbiased ‚â† always better</li> </ul> </div> </details> <hr> <h3 id=what-is-the-maximum-likelihood-estimation-mle-google-amazon-interview-question>What is the Maximum Likelihood Estimation (MLE)? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>MLE</code>, <code>Parameter Estimation</code>, <code>Statistics</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Maximum Likelihood Estimation:</strong></p> <p>Find parameter Œ∏ that maximizes probability of observed data:</p> <div class=arithmatex>\[\hat{\theta}_{MLE} = \arg\max_\theta L(\theta | data)\]</div> <p>Often maximize log-likelihood:</p> <div class=arithmatex>\[\hat{\theta}_{MLE} = \arg\max_\theta \log L(\theta | data)\]</div> <p><strong>Example - Coin Flip:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.optimize</span><span class=w> </span><span class=kn>import</span> <span class=n>minimize_scalar</span>

<span class=c1># Data: 7 heads in 10 flips</span>
<span class=n>heads</span> <span class=o>=</span> <span class=mi>7</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>10</span>

<span class=c1># Likelihood function</span>
<span class=k>def</span><span class=w> </span><span class=nf>neg_log_likelihood</span><span class=p>(</span><span class=n>p</span><span class=p>):</span>
    <span class=c1># Negative because we minimize</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>binom</span>
    <span class=k>return</span> <span class=o>-</span><span class=n>binom</span><span class=o>.</span><span class=n>logpmf</span><span class=p>(</span><span class=n>heads</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>

<span class=c1># Find MLE</span>
<span class=n>result</span> <span class=o>=</span> <span class=n>minimize_scalar</span><span class=p>(</span><span class=n>neg_log_likelihood</span><span class=p>,</span> <span class=n>bounds</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>method</span><span class=o>=</span><span class=s1>&#39;bounded&#39;</span><span class=p>)</span>
<span class=n>p_mle</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>x</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;MLE estimate: p = </span><span class=si>{</span><span class=n>p_mle</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Expected: 7/10 = 0.7</span>

<span class=c1># Analytical solution</span>
<span class=n>p_analytical</span> <span class=o>=</span> <span class=n>heads</span> <span class=o>/</span> <span class=n>n</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Analytical: p = </span><span class=si>{</span><span class=n>p_analytical</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Example - Normal Distribution:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Data</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>2.1</span><span class=p>,</span> <span class=mf>1.9</span><span class=p>,</span> <span class=mf>2.3</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=mf>1.8</span><span class=p>,</span> <span class=mf>2.2</span><span class=p>])</span>

<span class=c1># MLE for normal: Œº = mean, œÉ¬≤ = variance (biased)</span>
<span class=n>mu_mle</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
<span class=n>sigma_mle</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Note: biased MLE</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;MLE Œº: </span><span class=si>{</span><span class=n>mu_mle</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;MLE œÉ: </span><span class=si>{</span><span class=n>sigma_mle</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Properties of MLE:</strong></p> <table> <thead> <tr> <th>Property</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>Consistent</td> <td>‚ÜíŒ∏ as n‚Üí‚àû</td> </tr> <tr> <td>Asymptotically normal</td> <td>‚àön(Œ∏ÃÇ-Œ∏) ~ N(0, I‚Åª¬π)</td> </tr> <tr> <td>Invariant</td> <td>If Œ∏ÃÇ is MLE, g(Œ∏ÃÇ) is MLE of g(Œ∏)</td> </tr> <tr> <td>May be biased</td> <td>In finite samples</td> </tr> </tbody> </table> <p><strong>When to Use:</strong></p> <ul> <li>Have parametric model</li> <li>Want point estimate</li> <li>Large sample size</li> <li>No strong prior belief (use MLE over Bayesian)</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Fundamental parameter estimation.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Maximizes likelihood of data</li> <li>Takes log for computational ease</li> <li>Knows properties (consistency, asymptotic normality)</li> <li>Can derive analytically for simple cases</li> </ul> </div> </details> <hr> <h3 id=explain-the-weak-vs-strong-law-of-large-numbers-google-meta-interview-question>Explain the Weak vs Strong Law of Large Numbers - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Law of Large Numbers</code>, <code>Convergence</code>, <code>Theory</code> | <strong>Asked by:</strong> Google, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Weak Law of Large Numbers (WLLN):</strong></p> <p>Convergence in probability:</p> <div class=arithmatex>\[\frac{1}{n}\sum_{i=1}^n X_i \xrightarrow{P} \mu \quad \text{as } n \to \infty\]</div> <p>For any Œµ &gt; 0:</p> <div class=arithmatex>\[P\left(\left|\frac{1}{n}\sum_{i=1}^n X_i - \mu\right| &gt; \epsilon\right) \to 0\]</div> <p><strong>Strong Law of Large Numbers (SLLN):</strong></p> <p>Almost sure convergence:</p> <div class=arithmatex>\[P\left(\lim_{n\to\infty} \frac{1}{n}\sum_{i=1}^n X_i = \mu\right) = 1\]</div> <p><strong>Key Difference:</strong></p> <table> <thead> <tr> <th>Type</th> <th>Convergence</th> <th>Meaning</th> </tr> </thead> <tbody> <tr> <td>WLLN</td> <td>In probability</td> <td>For large n, probably close to Œº</td> </tr> <tr> <td>SLLN</td> <td>Almost surely</td> <td>Path converges to Œº with prob 1</td> </tr> </tbody> </table> <p><strong>Visualization:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># 100 paths of cumulative averages</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>10000</span>
<span class=n>num_paths</span> <span class=o>=</span> <span class=mi>100</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_paths</span><span class=p>):</span>
    <span class=c1># Fair coin flips (Bernoulli(0.5))</span>
    <span class=n>flips</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
    <span class=n>cumsum</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>flips</span><span class=p>)</span>
    <span class=n>cum_avg</span> <span class=o>=</span> <span class=n>cumsum</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>cum_avg</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Œº = 0.5&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of flips&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Cumulative average&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Strong Law: All paths converge&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Intuition:</strong></p> <ul> <li><strong>WLLN:</strong> At n=1000, most samples close to Œº</li> <li><strong>SLLN:</strong> Each individual sequence eventually stays near Œº forever</li> </ul> <p><strong>Requirements:</strong></p> <p>Both need: - Independent observations - Identically distributed - Finite mean Œº</p> <p>WLLN only needs finite variance; SLLN is stronger result.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Theoretical understanding of convergence.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Distinguishes convergence types</li> <li>"SLLN is stronger than WLLN"</li> <li>Mentions independence requirement</li> <li>Can explain with simulation</li> </ul> </div> </details> <hr> <h3 id=what-is-chebyshevs-inequality-when-to-use-it-amazon-microsoft-interview-question>What is Chebyshev's Inequality? When to Use It? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Concentration Inequality</code>, <code>Probability Bounds</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Chebyshev's Inequality:</strong></p> <p>For any random variable X with finite mean Œº and variance œÉ¬≤:</p> <div class=arithmatex>\[P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}\]</div> <p>Or equivalently:</p> <div class=arithmatex>\[P(|X - \mu| &lt; k\sigma) \geq 1 - \frac{1}{k^2}\]</div> <p><strong>Key Insight:</strong> Works for ANY distribution!</p> <p><strong>Examples:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># At least 75% of data within 2 std devs</span>
<span class=n>k</span> <span class=o>=</span> <span class=mi>2</span>
<span class=n>prob_within</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=mi>1</span><span class=o>/</span><span class=n>k</span><span class=o>**</span><span class=mi>2</span>  <span class=c1># 1 - 1/4 = 0.75 or 75%</span>

<span class=c1># At least 88.9% within 3 std devs</span>
<span class=n>k</span> <span class=o>=</span> <span class=mi>3</span>
<span class=n>prob_within</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=mi>1</span><span class=o>/</span><span class=n>k</span><span class=o>**</span><span class=mi>2</span>  <span class=c1># 1 - 1/9 ‚âà 0.889</span>

<span class=c1># Compare to normal (68-95-99.7):</span>
<span class=c1># Normal: 95% within 2œÉ</span>
<span class=c1># Chebyshev: ‚â•75% within 2œÉ (works for ANY distribution!)</span>
</code></pre></div> <p><strong>When to Use:</strong></p> <ol> <li><strong>Unknown distribution:</strong> Only know mean and variance</li> <li><strong>Conservative bounds:</strong> Guaranteed bound for any distribution</li> <li><strong>Worst-case analysis:</strong> Planning for extreme scenarios</li> </ol> <p><strong>Application - Sample Size:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># How many samples for XÃÑ within 0.1 of Œº with 95% confidence?</span>

<span class=c1># Want: P(|XÃÑ - Œº| &lt; 0.1) ‚â• 0.95</span>
<span class=c1># Chebyshev: P(|XÃÑ - Œº| &lt; kœÉ/‚àön) ‚â• 1 - 1/k¬≤</span>

<span class=c1># Set: kœÉ/‚àön = 0.1 and 1 - 1/k¬≤ = 0.95</span>
<span class=c1># ‚Üí k¬≤ = 20, so k = 4.47</span>
<span class=c1># If œÉ = 1: n = (k*œÉ/0.1)¬≤ = (4.47)¬≤/0.01 ‚âà 2000</span>

<span class=n>sigma</span> <span class=o>=</span> <span class=mf>1.0</span>
<span class=n>epsilon</span> <span class=o>=</span> <span class=mf>0.1</span>
<span class=n>confidence</span> <span class=o>=</span> <span class=mf>0.95</span>

<span class=n>k</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>confidence</span><span class=p>)</span>
<span class=n>n</span> <span class=o>=</span> <span class=p>(</span><span class=n>k</span> <span class=o>*</span> <span class=n>sigma</span> <span class=o>/</span> <span class=n>epsilon</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Required sample size: </span><span class=si>{</span><span class=nb>int</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>n</span><span class=p>))</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Comparison:</strong></p> <table> <thead> <tr> <th>k</th> <th>Chebyshev Bound</th> <th>Normal (if applicable)</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>‚â• 0%</td> <td>68%</td> </tr> <tr> <td>2</td> <td>‚â• 75%</td> <td>95%</td> </tr> <tr> <td>3</td> <td>‚â• 88.9%</td> <td>99.7%</td> </tr> </tbody> </table> <p>Chebyshev is conservative but universally applicable!</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding of probability bounds.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Works for ANY distribution"</li> <li>Can apply to sample means</li> <li>Knows it's conservative</li> <li>Uses for worst-case analysis</li> </ul> </div> </details> <hr> <h3 id=what-is-jensens-inequality-give-examples-google-meta-interview-question>What is Jensen's Inequality? Give Examples - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Convexity</code>, <code>Inequalities</code>, <code>Theory</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Jensen's Inequality:</strong></p> <p>For convex function f:</p> <div class=arithmatex>\[f(E[X]) \leq E[f(X)]\]</div> <p>For concave function f:</p> <div class=arithmatex>\[f(E[X]) \geq E[f(X)]\]</div> <p><strong>Intuition:</strong> Average of function ‚â• function of average (if convex)</p> <p><strong>Example 1 - Variance:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># E[X¬≤] ‚â• (E[X])¬≤</span>
<span class=c1># Because f(x) = x¬≤ is convex</span>

<span class=c1># This gives us: Var(X) = E[X¬≤] - (E[X])¬≤ ‚â• 0</span>
</code></pre></div> <p><strong>Example 2 - Log:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># f(x) = log(x) is concave</span>
<span class=c1># So: log(E[X]) ‚â• E[log(X)]</span>

<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>

<span class=n>left</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>  <span class=c1># log(3) ‚âà 1.099</span>
<span class=n>right</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>  <span class=c1># mean of [0, 0.69, 1.10, 1.39, 1.61] ‚âà 0.958</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;log(E[X]) = </span><span class=si>{</span><span class=n>left</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[log(X)] = </span><span class=si>{</span><span class=n>right</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Inequality holds: </span><span class=si>{</span><span class=n>left</span><span class=w> </span><span class=o>&gt;=</span><span class=w> </span><span class=n>right</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># True</span>
</code></pre></div> <p><strong>Example 3 - Machine Learning (Cross-Entropy):</strong></p> <div class=highlight><pre><span></span><code><span class=c1># KL divergence is always ‚â• 0</span>
<span class=c1># Proof uses Jensen on f(x) = -log(x):</span>

<span class=c1># KL(P||Q) = Œ£ P(x) log(P(x)/Q(x))</span>
<span class=c1>#          = -Œ£ P(x) log(Q(x)/P(x))</span>
<span class=c1>#          ‚â• -log(Œ£ P(x) ¬∑ Q(x)/P(x))  [Jensen]</span>
<span class=c1>#          = -log(Œ£ Q(x))</span>
<span class=c1>#          = -log(1) = 0</span>
</code></pre></div> <p><strong>Applications in Data Science:</strong></p> <ol> <li><strong>Prove variance ‚â• 0</strong></li> <li><strong>Derive information inequalities</strong></li> <li><strong>Optimization (EM algorithm)</strong></li> <li><strong>Risk analysis</strong> (concave utility functions)</li> </ol> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced mathematical maturity.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows convex vs concave</li> <li>Can prove Var(X) ‚â• 0</li> <li>Mentions ML applications</li> <li>Draws visual representation</li> </ul> </div> </details> <hr> <h3 id=explain-the-kullback-leibler-kl-divergence-google-meta-interview-question>Explain the Kullback-Leibler (KL) Divergence - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Information Theory</code>, <code>Divergence</code>, <code>ML</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>KL Divergence:</strong></p> <p>Measures "distance" from distribution Q to P:</p> <div class=arithmatex>\[D_{KL}(P||Q) = \sum_x P(x) \log\frac{P(x)}{Q(x)}\]</div> <p>Or for continuous:</p> <div class=arithmatex>\[D_{KL}(P||Q) = \int p(x) \log\frac{p(x)}{q(x)} dx\]</div> <p><strong>Properties:</strong></p> <table> <thead> <tr> <th>Property</th> <th>Value</th> </tr> </thead> <tbody> <tr> <td>Non-negative</td> <td>D_KL ‚â• 0</td> </tr> <tr> <td>Zero iff P=Q</td> <td>D_KL = 0 ‚ü∫ P=Q</td> </tr> <tr> <td>NOT symmetric</td> <td>D_KL(P‚ÄñQ) ‚â† D_KL(Q‚ÄñP)</td> </tr> <tr> <td>NOT a metric</td> <td>Doesn't satisfy triangle inequality</td> </tr> </tbody> </table> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.special</span><span class=w> </span><span class=kn>import</span> <span class=n>rel_entr</span>

<span class=c1># Two distributions</span>
<span class=n>P</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.7</span><span class=p>])</span>
<span class=n>Q</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.4</span><span class=p>])</span>

<span class=c1># KL divergence P || Q</span>
<span class=n>kl_pq</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>rel_entr</span><span class=p>(</span><span class=n>P</span><span class=p>,</span> <span class=n>Q</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;KL(P||Q) = </span><span class=si>{</span><span class=n>kl_pq</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># 0.2393</span>

<span class=c1># KL divergence Q || P  </span>
<span class=n>kl_qp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>rel_entr</span><span class=p>(</span><span class=n>Q</span><span class=p>,</span> <span class=n>P</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;KL(Q||P) = </span><span class=si>{</span><span class=n>kl_qp</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># 0.2582</span>

<span class=c1># Not symmetric!</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Symmetric? </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>kl_pq</span><span class=p>,</span><span class=w> </span><span class=n>kl_qp</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># False</span>
</code></pre></div> <p><strong>Interpretation:</strong></p> <ul> <li><strong>Information gain:</strong> Extra bits needed if using Q instead of P</li> <li><strong>Relative entropy:</strong> How much P diverges from Q</li> <li><strong>Surprise:</strong> Expected surprise if Q is true but we assume P</li> </ul> <p><strong>ML Applications:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># 1. Variational Autoencoders (VAE)</span>
<span class=c1># Minimize KL between learned Q(z|x) and prior P(z)</span>

<span class=c1># 2. Knowledge Distillation</span>
<span class=c1># Match student Q to teacher P</span>

<span class=c1># 3. Policy Gradient (RL)</span>
<span class=c1># KL constraint on policy updates</span>

<span class=c1># 4. Model Selection</span>
<span class=c1># AIC/BIC based on KL divergence</span>
</code></pre></div> <p><strong>Cross-Entropy Connection:</strong></p> <div class=arithmatex>\[D_{KL}(P||Q) = H(P, Q) - H(P)\]</div> <p>Where H(P,Q) is cross-entropy. Minimizing cross-entropy = minimizing KL divergence!</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Information theory for ML.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows D_KL ‚â• 0 (Jensen)</li> <li>NOT symmetric or metric</li> <li>Links to cross-entropy</li> <li>Mentions VAE/RL applications</li> </ul> </div> </details> <hr> <h3 id=what-is-the-poisson-process-give-real-world-examples-google-amazon-interview-question>What is the Poisson Process? Give Real-World Examples - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Stochastic Processes</code>, <code>Poisson</code>, <code>Applications</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Poisson Process:</strong></p> <p>Models random events occurring continuously over time with:</p> <ol> <li>Events occur independently</li> <li>Constant average rate Œª (events per time unit)</li> <li>Two events don't occur at exactly same time</li> </ol> <p><strong>Key Results:</strong></p> <table> <thead> <tr> <th>Quantity</th> <th>Distribution</th> </tr> </thead> <tbody> <tr> <td>N(t) = # events in [0,t]</td> <td>Poisson(Œªt)</td> </tr> <tr> <td>T = time until first event</td> <td>Exponential(Œª)</td> </tr> <tr> <td>T_n = time until nth event</td> <td>Gamma(n, Œª)</td> </tr> <tr> <td>S = time between events</td> <td>Exponential(Œª)</td> </tr> </tbody> </table> <p><strong>Example - Customer Arrivals:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>poisson</span><span class=p>,</span> <span class=n>expon</span>

<span class=c1># Œª = 5 customers per hour</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>t_max</span> <span class=o>=</span> <span class=mi>2</span>  <span class=c1># 2 hours</span>

<span class=c1># Simulate Poisson process</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=c1># Method 1: Generate inter-arrival times</span>
<span class=n>arrivals</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>t</span> <span class=o>=</span> <span class=mi>0</span>
<span class=k>while</span> <span class=n>t</span> <span class=o>&lt;</span> <span class=n>t_max</span><span class=p>:</span>
    <span class=c1># Time to next customer ~ Exp(Œª)</span>
    <span class=n>dt</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>)</span>
    <span class=n>t</span> <span class=o>+=</span> <span class=n>dt</span>
    <span class=k>if</span> <span class=n>t</span> <span class=o>&lt;</span> <span class=n>t_max</span><span class=p>:</span>
        <span class=n>arrivals</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>t</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total arrivals in </span><span class=si>{</span><span class=n>t_max</span><span class=si>}</span><span class=s2> hours: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>arrivals</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected: Œªt = </span><span class=si>{</span><span class=n>lambda_rate</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>t_max</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>eventplot</span><span class=p>(</span><span class=n>arrivals</span><span class=p>,</span> <span class=n>lineoffsets</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>linelengths</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlim</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>t_max</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Time (hours)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Poisson Process (Œª=</span><span class=si>{</span><span class=n>lambda_rate</span><span class=si>}</span><span class=s1>/hour)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>([])</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Real-World Applications:</strong></p> <ol> <li><strong>Customer Service:</strong></li> <li>Call center arrivals</li> <li> <p>Queue management</p> </li> <li> <p><strong>Infrastructure:</strong></p> </li> <li>Equipment failures</li> <li> <p>Server requests</p> </li> <li> <p><strong>Natural Phenomena:</strong></p> </li> <li>Radioactive decay</li> <li> <p>Earthquake occurrences</p> </li> <li> <p><strong>Web Analytics:</strong></p> </li> <li>Page views</li> <li>Ad clicks</li> </ol> <p><strong>Interview Questions:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Q: Server gets 10 requests/minute. </span>
<span class=c1># What&#39;s P(‚â•15 requests in next minute)?</span>

<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>poisson</span>

<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mi>10</span>
<span class=n>k</span> <span class=o>=</span> <span class=mi>15</span>

<span class=c1># P(X ‚â• 15) = 1 - P(X ‚â§ 14)</span>
<span class=n>p</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>poisson</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>14</span><span class=p>,</span> <span class=n>lambda_rate</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(X ‚â• 15) = </span><span class=si>{</span><span class=n>p</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># 0.0487</span>

<span class=c1># Q: Average time between requests?</span>
<span class=n>avg_time</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>lambda_rate</span>  <span class=c1># 0.1 minutes = 6 seconds</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Applied probability modeling.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>States 3 key properties</li> <li>Links to exponential distribution</li> <li>Gives relevant examples</li> <li>Can calculate probabilities</li> </ul> </div> </details> <hr> <h3 id=what-is-a-memoryless-property-which-distributions-have-it-amazon-microsoft-interview-question>What is a Memoryless Property? Which Distributions Have It? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Probability Properties</code>, <code>Exponential</code>, <code>Geometric</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Memoryless Property:</strong></p> <p>For random variable X:</p> <div class=arithmatex>\[P(X &gt; s + t | X &gt; s) = P(X &gt; t)\]</div> <p>"Given you've waited s time, probability of waiting additional t is same as waiting t from start."</p> <p><strong>Only Two Distributions:</strong></p> <ol> <li><strong>Exponential</strong> (continuous)</li> <li><strong>Geometric</strong> (discrete)</li> </ol> <p><strong>Exponential Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>expon</span>

<span class=c1># Waiting time for bus: Œª = 1/10 (avg 10 min)</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mf>0.1</span>

<span class=n>s</span><span class=p>,</span> <span class=n>t</span> <span class=o>=</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>5</span>  <span class=c1># Already waited 5 min, what&#39;s P(wait 5+ more)?</span>

<span class=c1># Direct calculation</span>
<span class=n>p_conditional</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=n>s</span> <span class=o>+</span> <span class=n>t</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>)</span> <span class=o>/</span> <span class=n>expon</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>)</span>

<span class=c1># Memoryless: should equal P(X &gt; 5)</span>
<span class=n>p_unconditional</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=n>t</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(X &gt; 10 | X &gt; 5) = </span><span class=si>{</span><span class=n>p_conditional</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(X &gt; 5) = </span><span class=si>{</span><span class=n>p_unconditional</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Memoryless? </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>p_conditional</span><span class=p>,</span><span class=w> </span><span class=n>p_unconditional</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># True: both ‚âà 0.6065</span>
</code></pre></div> <p><strong>Geometric Example:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Rolling die until 6 appears</span>
<span class=c1># Already rolled 3 times without 6</span>
<span class=c1># What&#39;s P(need 5+ more rolls)?</span>

<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>geom</span>

<span class=n>p</span> <span class=o>=</span> <span class=mi>1</span><span class=o>/</span><span class=mi>6</span>  <span class=c1># P(6 on single roll)</span>

<span class=n>s</span><span class=p>,</span> <span class=n>t</span> <span class=o>=</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span>

<span class=c1># P(X &gt; 8 | X &gt; 3) = P(X &gt; 5)</span>
<span class=n>p_conditional</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=n>s</span> <span class=o>+</span> <span class=n>t</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span> <span class=o>/</span> <span class=n>geom</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=n>s</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
<span class=n>p_unconditional</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=n>t</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Conditional: </span><span class=si>{</span><span class=n>p_conditional</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Unconditional: </span><span class=si>{</span><span class=n>p_unconditional</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Both ‚âà 0.4019</span>
</code></pre></div> <p><strong>Why Important?</strong></p> <table> <thead> <tr> <th>Context</th> <th>Implication</th> </tr> </thead> <tbody> <tr> <td>Queues</td> <td>Waiting time doesn't depend on time already waited</td> </tr> <tr> <td>Reliability</td> <td>Equipment failure rate constant over time</td> </tr> <tr> <td>Modeling</td> <td>Simplifies calculations dramatically</td> </tr> </tbody> </table> <p><strong>Counter-Example (NOT memoryless):</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Normal distribution is NOT memoryless</span>
<span class=c1># If X ~ N(100, 15), knowing X &gt; 90 changes distribution</span>

<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>norm</span>

<span class=c1># This will NOT be equal:</span>
<span class=n>p1</span> <span class=o>=</span> <span class=n>norm</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=mi>110</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>15</span><span class=p>)</span> <span class=o>/</span> <span class=n>norm</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=mi>90</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>15</span><span class=p>)</span>
<span class=n>p2</span> <span class=o>=</span> <span class=n>norm</span><span class=o>.</span><span class=n>sf</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>15</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Normal memoryless? </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>p1</span><span class=p>,</span><span class=w> </span><span class=n>p2</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># False</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Deep distribution knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Only exponential and geometric"</li> <li>Explains with waiting time</li> <li>Can prove mathematically</li> <li>Knows why it matters (simplification)</li> </ul> </div> </details> <hr> <h3 id=explain-the-difference-between-probability-and-odds-most-tech-companies-interview-question>Explain the Difference Between Probability and Odds - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Fundamentals</code>, <code>Odds</code>, <code>Probability</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Probability:</strong></p> <div class=arithmatex>\[P(A) = \frac{\text{# favorable outcomes}}{\text{# total outcomes}}\]</div> <p>Range: [0, 1]</p> <p><strong>Odds:</strong></p> <div class=arithmatex>\[\text{Odds}(A) = \frac{P(A)}{1 - P(A)} = \frac{P(A)}{P(A^c)}\]</div> <p>Range: [0, ‚àû)</p> <p><strong>Conversion:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Probability ‚Üí Odds</span>
<span class=n>p</span> <span class=o>=</span> <span class=mf>0.75</span>
<span class=n>odds</span> <span class=o>=</span> <span class=n>p</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p</span><span class=p>)</span>  <span class=c1># 0.75/0.25 = 3</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Probability </span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s2> = Odds </span><span class=si>{</span><span class=n>odds</span><span class=si>}</span><span class=s2>:1&quot;</span><span class=p>)</span>

<span class=c1># Odds ‚Üí Probability</span>
<span class=n>odds</span> <span class=o>=</span> <span class=mi>3</span>
<span class=n>p</span> <span class=o>=</span> <span class=n>odds</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>odds</span><span class=p>)</span>  <span class=c1># 3/4 = 0.75</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Odds </span><span class=si>{</span><span class=n>odds</span><span class=si>}</span><span class=s2>:1 = Probability </span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Examples:</strong></p> <table> <thead> <tr> <th>Scenario</th> <th>Probability</th> <th>Odds</th> <th>Odds Notation</th> </tr> </thead> <tbody> <tr> <td>Coin flip (heads)</td> <td>0.5</td> <td>1</td> <td>1:1 or "even"</td> </tr> <tr> <td>Roll 6 on die</td> <td>&#8537; ‚âà 0.167</td> <td>&#8533; = 0.2</td> <td>1:5 or "5 to 1 against"</td> </tr> <tr> <td>Disease prevalence 1%</td> <td>0.01</td> <td>0.0101</td> <td>1:99</td> </tr> <tr> <td>Rain 80%</td> <td>0.8</td> <td>4</td> <td>4:1</td> </tr> </tbody> </table> <p><strong>Why Odds in Logistic Regression:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Logistic regression models log-odds:</span>
<span class=c1># log(p/(1-p)) = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ...</span>

<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Example</span>
<span class=n>beta_0</span> <span class=o>=</span> <span class=o>-</span><span class=mi>2</span>
<span class=n>beta_1</span> <span class=o>=</span> <span class=mf>0.5</span>
<span class=n>x</span> <span class=o>=</span> <span class=mi>6</span>

<span class=c1># Log-odds</span>
<span class=n>log_odds</span> <span class=o>=</span> <span class=n>beta_0</span> <span class=o>+</span> <span class=n>beta_1</span> <span class=o>*</span> <span class=n>x</span>  <span class=c1># -2 + 0.5*6 = 1</span>

<span class=c1># Convert to probability</span>
<span class=n>odds</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>log_odds</span><span class=p>)</span>  <span class=c1># e^1 ‚âà 2.718</span>
<span class=n>p</span> <span class=o>=</span> <span class=n>odds</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>odds</span><span class=p>)</span>     <span class=c1># 2.718/3.718 ‚âà 0.731</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Log-odds: </span><span class=si>{</span><span class=n>log_odds</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Odds: </span><span class=si>{</span><span class=n>odds</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Probability: </span><span class=si>{</span><span class=n>p</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Betting Example:</strong></p> <ul> <li><strong>Odds 5:1 against</strong> means bet $1 to win $5</li> <li>Implies probability = 1/(5+1) = &#8537; ‚âà 0.167</li> <li><strong>Odds 1:2 for</strong> means bet $2 to win $1</li> <li>Implies probability = 2/(1+2) = &#8532; ‚âà 0.667</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Basic probability literacy.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Clear formula for both</li> <li>Can convert between them</li> <li>Mentions logistic regression connection</li> <li>Explains betting context</li> </ul> </div> </details> <hr> <h3 id=what-is-the-gamblers-fallacy-vs-hot-hand-fallacy-meta-google-interview-question>What is the Gambler's Fallacy vs Hot Hand Fallacy? - Meta, Google Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Cognitive Bias</code>, <code>Independence</code>, <code>Misconceptions</code> | <strong>Asked by:</strong> Meta, Google, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Gambler's Fallacy:</strong></p> <p>Believing that past independent events affect future probabilities.</p> <p>"Red came up 5 times, black is 'due' now!"</p> <p><strong>Hot Hand Fallacy:</strong></p> <p>Believing that success/failure streaks will continue.</p> <p>"I made 5 baskets in a row, I'm on fire!"</p> <p><strong>Why They're Wrong:</strong></p> <p>For <strong>independent</strong> events, each trial has same probability.</p> <div class=highlight><pre><span></span><code><span class=c1># Coin flips</span>
<span class=c1># After 5 heads: P(6th is heads) = 0.5</span>
<span class=c1># NOT higher (hot hand) or lower (gambler&#39;s fallacy)</span>

<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Simulation</span>
<span class=n>flips</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>100000</span><span class=p>)</span>

<span class=c1># Find all positions after 5 consecutive heads</span>
<span class=n>streak_positions</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>flips</span><span class=p>)):</span>
    <span class=k>if</span> <span class=nb>all</span><span class=p>(</span><span class=n>flips</span><span class=p>[</span><span class=n>i</span><span class=o>-</span><span class=mi>5</span><span class=p>:</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=mi>1</span><span class=p>):</span>  <span class=c1># 5 heads</span>
        <span class=n>streak_positions</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>

<span class=c1># What happens next?</span>
<span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>streak_positions</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
    <span class=n>next_flips</span> <span class=o>=</span> <span class=n>flips</span><span class=p>[</span><span class=n>streak_positions</span><span class=p>]</span>
    <span class=n>prob_heads</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>next_flips</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(heads after 5 heads) = </span><span class=si>{</span><span class=n>prob_heads</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=c1># ‚âà 0.5, not different!</span>
</code></pre></div> <p><strong>Examples:</strong></p> <table> <thead> <tr> <th>Scenario</th> <th>Fallacy</th> <th>Reality</th> </tr> </thead> <tbody> <tr> <td>Roulette: 10 reds in a row</td> <td>"Black is due!"</td> <td>Still 18/37 ‚âà 0.486</td> </tr> <tr> <td>Lottery: Same numbers twice</td> <td>"Won't repeat!"</td> <td>Same 1/millions chance</td> </tr> <tr> <td>Basketball: 5 made shots</td> <td>"On fire, keep shooting!"</td> <td>Might be, if skill varies</td> </tr> </tbody> </table> <p><strong>When Hot Hand is REAL:</strong></p> <ul> <li><strong>Not independent:</strong> Basketball (confidence, defense adjustment)</li> <li><strong>Changing conditions:</strong> Weather in sports, market trends</li> <li><strong>Adaptive systems:</strong> Video games (difficulty adjustment)</li> </ul> <p><strong>In Data Science:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># A/B test: first 100 users show lift</span>
<span class=c1># Gambler&#39;s fallacy: &quot;Next 100 will reverse&quot;</span>
<span class=c1># Reality: If real effect, will persist</span>

<span class=c1># Stock trading: 5 winning trades</span>
<span class=c1># Hot hand: &quot;I&#39;m skilled, bet bigger&quot;</span>
<span class=c1># Reality: Check if strategy or luck</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding independence vs dependence.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Distinguishes both fallacies clearly</li> <li>"For independent events..."</li> <li>Knows when hot hand IS real</li> <li>Gives data science examples</li> </ul> </div> </details> <hr> <h3 id=what-is-a-martingale-give-an-example-google-meta-interview-question>What is a Martingale? Give an Example - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Stochastic Processes</code>, <code>Martingale</code>, <code>Finance</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Martingale:</strong></p> <p>Sequence of random variables {X‚ÇÄ, X‚ÇÅ, X‚ÇÇ, ...} where:</p> <div class=arithmatex>\[E[X_{n+1} | X_0, ..., X_n] = X_n\]</div> <p><strong>Intuition:</strong> Expected future value = current value (given history)</p> <p>"Fair game" - no expected gain or loss.</p> <p><strong>Example 1 - Fair Coin Toss:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Start with $100, bet $1 per flip</span>
<span class=c1># Win $1 if heads, lose $1 if tails</span>

<span class=n>n_flips</span> <span class=o>=</span> <span class=mi>1000</span>
<span class=n>n_paths</span> <span class=o>=</span> <span class=mi>10</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_paths</span><span class=p>):</span>
    <span class=n>wealth</span> <span class=o>=</span> <span class=p>[</span><span class=mi>100</span><span class=p>]</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_flips</span><span class=p>):</span>
        <span class=n>flip</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
        <span class=n>wealth</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>wealth</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>+</span> <span class=n>flip</span><span class=p>)</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>wealth</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Starting value&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Flip number&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Wealth&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Martingale: Fair Coin Betting&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># E[wealth_n | wealth_0, ..., wealth_{n-1}] = wealth_{n-1}</span>
</code></pre></div> <p><strong>Example 2 - Random Walk:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># S_n = X_1 + X_2 + ... + X_n</span>
<span class=c1># where X_i are independent with E[X_i] = 0</span>

<span class=c1># This is a martingale:</span>
<span class=c1># E[S_{n+1} | S_n] = S_n + E[X_{n+1}] = S_n + 0 = S_n</span>
</code></pre></div> <p><strong>Properties:</strong></p> <ol> <li><strong>Optional Stopping Theorem:</strong></li> <li>E[X_œÑ] = E[X_0] for stopping time œÑ (under conditions)</li> <li> <p>"Can't beat the house with any strategy"</p> </li> <li> <p><strong>Martingale Convergence:</strong></p> </li> <li>Bounded martingales converge</li> </ol> <p><strong>Not a Martingale:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Unfair coin: P(heads) = 0.6</span>
<span class=c1># Bet $1, win $1 if heads, lose $1 if tails</span>

<span class=c1># E[W_{n+1} | W_n] = W_n + 0.6*1 + 0.4*(-1)</span>
<span class=c1>#                   = W_n + 0.2 ‚â† W_n</span>

<span class=c1># This is a SUB-martingale (expected increase)</span>
</code></pre></div> <p><strong>Applications:</strong></p> <table> <thead> <tr> <th>Field</th> <th>Example</th> </tr> </thead> <tbody> <tr> <td>Finance</td> <td>Stock prices (efficient market hypothesis)</td> </tr> <tr> <td>Gambling</td> <td>Betting strategies analysis</td> </tr> <tr> <td>Statistics</td> <td>Sequential analysis</td> </tr> <tr> <td>Machine Learning</td> <td>Stochastic gradient descent analysis</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced probability/finance knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>E[X_{n+1}|history] = X_n</li> <li>"Fair game" intuition</li> <li>Mentions random walk</li> <li>Optional stopping theorem</li> </ul> </div> </details> <hr> <h3 id=explain-the-walds-equation-walds-identity-amazon-microsoft-interview-question>Explain the Wald's Equation (Wald's Identity) - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Random Sums</code>, <code>Theory</code>, <code>Expectations</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Wald's Equation:</strong></p> <p>If X‚ÇÅ, X‚ÇÇ, ... are i.i.d. with E[X·µ¢] = Œº, and N is a stopping time with E[N] &lt; ‚àû:</p> <div class=arithmatex>\[E\left[\sum_{i=1}^N X_i\right] = E[N] \cdot E[X]\]</div> <p><strong>Intuition:</strong> Expected sum = (expected # terms) √ó (expected value per term)</p> <p><strong>Key Requirement:</strong> N must be a stopping time (decision to stop at n only uses X‚ÇÅ,...,X‚Çô)</p> <p><strong>Example 1 - Gambling:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Play until you win (or 100 games)</span>
<span class=c1># Each game: win $5 with p=0.3, lose $2 with p=0.7</span>

<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=n>p_win</span> <span class=o>=</span> <span class=mf>0.3</span>
<span class=n>win_amount</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>lose_amount</span> <span class=o>=</span> <span class=o>-</span><span class=mi>2</span>

<span class=c1># E[X] per game</span>
<span class=n>E_X</span> <span class=o>=</span> <span class=n>p_win</span> <span class=o>*</span> <span class=n>win_amount</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_win</span><span class=p>)</span> <span class=o>*</span> <span class=n>lose_amount</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[X per game] = $</span><span class=si>{</span><span class=n>E_X</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># $0.10</span>

<span class=c1># Play until first win (N ~ Geometric)</span>
<span class=n>E_N</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>p_win</span>  <span class=c1># 3.33 games</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[N games] = </span><span class=si>{</span><span class=n>E_N</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Total expected winnings (Wald&#39;s)</span>
<span class=n>E_total</span> <span class=o>=</span> <span class=n>E_N</span> <span class=o>*</span> <span class=n>E_X</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[Total] = $</span><span class=si>{</span><span class=n>E_total</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># $0.33</span>

<span class=c1># Verify with simulation</span>
<span class=n>simulations</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=n>n</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>while</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>()</span> <span class=o>&gt;</span> <span class=n>p_win</span> <span class=ow>and</span> <span class=n>n</span> <span class=o>&lt;</span> <span class=mi>100</span><span class=p>:</span>
        <span class=n>total</span> <span class=o>+=</span> <span class=n>lose_amount</span>
        <span class=n>n</span> <span class=o>+=</span> <span class=mi>1</span>
    <span class=n>total</span> <span class=o>+=</span> <span class=n>win_amount</span>  <span class=c1># Final win</span>
    <span class=n>simulations</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>total</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Simulated E[Total] = $</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>simulations</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Example 2 - Quality Control:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Inspect items until 3rd defect</span>
<span class=c1># Each inspection costs $10</span>
<span class=c1># P(defective) = 0.05</span>

<span class=n>p_defect</span> <span class=o>=</span> <span class=mf>0.05</span>
<span class=n>cost_per_inspection</span> <span class=o>=</span> <span class=mi>10</span>
<span class=n>target_defects</span> <span class=o>=</span> <span class=mi>3</span>

<span class=c1># N ~ Negative Binomial</span>
<span class=c1># E[N] = target_defects / p_defect</span>
<span class=n>E_N</span> <span class=o>=</span> <span class=n>target_defects</span> <span class=o>/</span> <span class=n>p_defect</span>  <span class=c1># 60 inspections</span>

<span class=c1># E[Cost] = E[N] √ó cost</span>
<span class=n>E_cost</span> <span class=o>=</span> <span class=n>E_N</span> <span class=o>*</span> <span class=n>cost_per_inspection</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected cost: $</span><span class=si>{</span><span class=n>E_cost</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>  <span class=c1># $600</span>
</code></pre></div> <p><strong>Why Important:</strong></p> <ul> <li>Extends linearity of expectation to random # terms</li> <li>Applies to many real scenarios (queues, sequential sampling)</li> <li>Foundation for renewal theory</li> </ul> <p><strong>Violations (when Wald's fails):</strong></p> <ul> <li>N is not a stopping time</li> <li>X's are not i.i.d.</li> <li>E[N] is infinite</li> <li>N depends on future X's</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced expectation theory.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>E[sum] = E[N]¬∑E[X]</li> <li>"N must be stopping time"</li> <li>Applies to sequential problems</li> <li>Can calculate for geometric/negative binomial</li> </ul> </div> </details> <hr> <h3 id=what-is-rejection-sampling-google-amazon-interview-question>What is Rejection Sampling? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Monte Carlo</code>, <code>Sampling</code>, <code>Simulation</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Rejection Sampling:</strong></p> <p>Method to sample from difficult distribution f(x) using easy distribution g(x):</p> <ol> <li>Find M where f(x) ‚â§ M¬∑g(x) for all x</li> <li>Sample x ~ g(x)</li> <li>Sample u ~ Uniform(0, 1)</li> <li>Accept x if u ‚â§ f(x)/(M¬∑g(x)), otherwise reject and repeat</li> </ol> <p><strong>Example - Beta Distribution:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>beta</span><span class=p>,</span> <span class=n>uniform</span>

<span class=c1># Target: Beta(2, 5)</span>
<span class=n>target</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span>

<span class=c1># Proposal: Uniform(0, 1)</span>
<span class=n>proposal</span> <span class=o>=</span> <span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

<span class=c1># Find M: max of f(x)/g(x)</span>
<span class=n>x_grid</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>f_vals</span> <span class=o>=</span> <span class=n>target</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_grid</span><span class=p>)</span>
<span class=n>g_vals</span> <span class=o>=</span> <span class=n>proposal</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_grid</span><span class=p>)</span>  <span class=c1># All 1&#39;s</span>
<span class=n>M</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>f_vals</span> <span class=o>/</span> <span class=n>g_vals</span><span class=p>)</span>

<span class=c1># Rejection sampling</span>
<span class=n>samples</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>attempts</span> <span class=o>=</span> <span class=mi>0</span>

<span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>samples</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mi>1000</span><span class=p>:</span>
    <span class=c1># Sample from proposal</span>
    <span class=n>x</span> <span class=o>=</span> <span class=n>proposal</span><span class=o>.</span><span class=n>rvs</span><span class=p>()</span>
    <span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>()</span>

    <span class=c1># Accept/reject</span>
    <span class=k>if</span> <span class=n>u</span> <span class=o>&lt;=</span> <span class=n>target</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>M</span> <span class=o>*</span> <span class=n>proposal</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)):</span>
        <span class=n>samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
    <span class=n>attempts</span> <span class=o>+=</span> <span class=mi>1</span>

<span class=n>acceptance_rate</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>samples</span><span class=p>)</span> <span class=o>/</span> <span class=n>attempts</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Acceptance rate: </span><span class=si>{</span><span class=n>acceptance_rate</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>samples</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Samples&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_grid</span><span class=p>,</span> <span class=n>target</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_grid</span><span class=p>),</span> <span class=s1>&#39;r-&#39;</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Target Beta(2,5)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Example - Sampling from Complex Distribution:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Target: f(x) = c¬∑x¬≤¬∑exp(-x) for x &gt; 0</span>
<span class=c1># Use exponential proposal: g(x) = Œª¬∑exp(-Œªx)</span>

<span class=k>def</span><span class=w> </span><span class=nf>target_unnormalized</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>x</span><span class=o>**</span><span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>x</span><span class=p>)</span>

<span class=c1># Proposal: Exponential(Œª=1)</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mf>1.0</span>

<span class=c1># Find M</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.optimize</span><span class=w> </span><span class=kn>import</span> <span class=n>minimize_scalar</span>
<span class=n>result</span> <span class=o>=</span> <span class=n>minimize_scalar</span><span class=p>(</span>
    <span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=o>-</span><span class=n>target_unnormalized</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>lambda_rate</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>lambda_rate</span> <span class=o>*</span> <span class=n>x</span><span class=p>)),</span>
    <span class=n>bounds</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>),</span>
    <span class=n>method</span><span class=o>=</span><span class=s1>&#39;bounded&#39;</span>
<span class=p>)</span>
<span class=n>M</span> <span class=o>=</span> <span class=o>-</span><span class=n>result</span><span class=o>.</span><span class=n>fun</span>

<span class=c1># Sample</span>
<span class=n>samples</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>)</span>
    <span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>()</span>

    <span class=n>g_x</span> <span class=o>=</span> <span class=n>lambda_rate</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>lambda_rate</span> <span class=o>*</span> <span class=n>x</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>u</span> <span class=o>&lt;=</span> <span class=n>target_unnormalized</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>M</span> <span class=o>*</span> <span class=n>g_x</span><span class=p>):</span>
        <span class=n>samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>samples</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Samples from x¬≤¬∑exp(-x)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Efficiency:</strong></p> <ul> <li>Acceptance rate = 1/M</li> <li>Want M as small as possible</li> <li>Choose g(x) similar to f(x)</li> </ul> <p><strong>When to Use:</strong></p> <ul> <li>f(x) known up to normalizing constant</li> <li>Can't sample from f(x) directly</li> <li>Low-dimensional (high-d needs MCMC)</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Sampling method knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Explains accept/reject mechanism</li> <li>Knows acceptance rate = 1/M</li> <li>Mentions need for good proposal</li> <li>Can implement from scratch</li> </ul> </div> </details> <hr> <h3 id=explain-importance-sampling-meta-google-interview-question>Explain Importance Sampling - Meta, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Monte Carlo</code>, <code>Variance Reduction</code>, <code>Sampling</code> | <strong>Asked by:</strong> Meta, Google, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Importance Sampling:</strong></p> <p>Estimate E_f[h(X)] by sampling from different distribution g(x):</p> <div class=arithmatex>\[E_f[h(X)] = \int h(x) f(x) dx = \int h(x) \frac{f(x)}{g(x)} g(x) dx = E_g\left[h(X) \frac{f(X)}{g(X)}\right]\]</div> <p><strong>Algorithm:</strong></p> <ol> <li>Sample X‚ÇÅ,...,X‚Çô ~ g(x)</li> <li>Compute weights: w·µ¢ = f(X·µ¢)/g(X·µ¢)</li> <li>Estimate: <span class=arithmatex>\(\hat{\theta} = \frac{1}{n}\sum_{i=1}^n h(X_i) w_i\)</span></li> </ol> <p><strong>Example - Rare Event Probability:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>norm</span>

<span class=c1># Estimate P(X &gt; 5) where X ~ N(0,1)</span>
<span class=c1># This is rare: P(X &gt; 5) ‚âà 2.87√ó10‚Åª‚Å∑</span>

<span class=c1># Method 1: Direct sampling (poor)</span>
<span class=n>samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000000</span><span class=p>)</span>
<span class=n>estimate_direct</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>samples</span> <span class=o>&gt;</span> <span class=mi>5</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Direct: </span><span class=si>{</span><span class=n>estimate_direct</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Often gives 0!</span>

<span class=c1># Method 2: Importance sampling</span>
<span class=c1># Use g(x) = N(5, 1) to focus on rare region</span>

<span class=n>n</span> <span class=o>=</span> <span class=mi>10000</span>
<span class=n>samples_g</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

<span class=c1># Indicator function</span>
<span class=n>h</span> <span class=o>=</span> <span class=p>(</span><span class=n>samples_g</span> <span class=o>&gt;</span> <span class=mi>5</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>float</span><span class=p>)</span>

<span class=c1># Importance weights: f(x)/g(x)</span>
<span class=n>f_vals</span> <span class=o>=</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>samples_g</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>g_vals</span> <span class=o>=</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>samples_g</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>weights</span> <span class=o>=</span> <span class=n>f_vals</span> <span class=o>/</span> <span class=n>g_vals</span>

<span class=n>estimate_importance</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>h</span> <span class=o>*</span> <span class=n>weights</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Importance sampling: </span><span class=si>{</span><span class=n>estimate_importance</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># True value</span>
<span class=n>true_value</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True value: </span><span class=si>{</span><span class=n>true_value</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Variance Comparison:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Run multiple trials</span>
<span class=n>n_trials</span> <span class=o>=</span> <span class=mi>1000</span>
<span class=n>direct_estimates</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>importance_estimates</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_trials</span><span class=p>):</span>
    <span class=c1># Direct</span>
    <span class=n>samp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10000</span><span class=p>)</span>
    <span class=n>direct_estimates</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>samp</span> <span class=o>&gt;</span> <span class=mi>5</span><span class=p>))</span>

    <span class=c1># Importance</span>
    <span class=n>samp_g</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10000</span><span class=p>)</span>
    <span class=n>h</span> <span class=o>=</span> <span class=p>(</span><span class=n>samp_g</span> <span class=o>&gt;</span> <span class=mi>5</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>float</span><span class=p>)</span>
    <span class=n>w</span> <span class=o>=</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>samp_g</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>samp_g</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
    <span class=n>importance_estimates</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>h</span> <span class=o>*</span> <span class=n>w</span><span class=p>))</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Direct variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>direct_estimates</span><span class=p>)</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Importance variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>importance_estimates</span><span class=p>)</span><span class=si>:</span><span class=s2>.2e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Importance sampling has much lower variance!</span>
</code></pre></div> <p><strong>Choosing Good g(x):</strong></p> <table> <thead> <tr> <th>Criterion</th> <th>Guideline</th> </tr> </thead> <tbody> <tr> <td>Coverage</td> <td>g(x) &gt; 0 wherever f(x)¬∑h(x) &gt; 0</td> </tr> <tr> <td>Similarity</td> <td>g(x) similar shape to f(x)¬∑h(x)</td> </tr> <tr> <td>Heavy tails</td> <td>g(x) should have heavier tails than f(x)</td> </tr> </tbody> </table> <p><strong>Applications:</strong></p> <ul> <li>Rare event estimation (finance, reliability)</li> <li>Bayesian computation</li> <li>Reinforcement learning (off-policy evaluation)</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced Monte Carlo knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Formula with f(x)/g(x) ratio</li> <li>"Reduce variance for rare events"</li> <li>Knows good g needs heavy tails</li> <li>Can implement and compare variance</li> </ul> </div> </details> <hr> <h3 id=what-is-the-inverse-transform-method-google-amazon-interview-question>What is the Inverse Transform Method? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Random Generation</code>, <code>CDF</code>, <code>Simulation</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Inverse Transform Method:</strong></p> <p>Generate samples from distribution F(x) using:</p> <ol> <li>Generate U ~ Uniform(0,1)</li> <li>Return X = F‚Åª¬π(U)</li> </ol> <p><strong>Why it works:</strong> P(X ‚â§ x) = P(F‚Åª¬π(U) ‚â§ x) = P(U ‚â§ F(x)) = F(x) ‚úì</p> <p><strong>Example - Exponential Distribution:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Generate Exp(Œª=0.5) samples</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mf>0.5</span>

<span class=c1># Method 1: Using inverse CDF</span>
<span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10000</span><span class=p>)</span>

<span class=c1># CDF: F(x) = 1 - e^(-Œªx)</span>
<span class=c1># Inverse: F^(-1)(u) = -log(1-u)/Œª</span>
<span class=n>x</span> <span class=o>=</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>u</span><span class=p>)</span> <span class=o>/</span> <span class=n>lambda_rate</span>

<span class=c1># Method 2: Built-in (for comparison)</span>
<span class=n>x_builtin</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>,</span> <span class=mi>10000</span><span class=p>)</span>

<span class=c1># Compare</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Inverse transform&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>x_builtin</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Built-in&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Generated samples&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>expon</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=n>x</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>x</span><span class=p>)),</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Generated&#39;</span><span class=p>)</span>
<span class=n>x_theory</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_theory</span><span class=p>,</span> <span class=n>expon</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>x_theory</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>),</span> 
         <span class=s1>&#39;r--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Theoretical&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;CDF comparison&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Example - Custom Distribution:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Generate from triangular distribution on [0,1]</span>
<span class=c1># PDF: f(x) = 2x for x in [0,1]</span>
<span class=c1># CDF: F(x) = x¬≤</span>
<span class=c1># Inverse: F^(-1)(u) = ‚àöu</span>

<span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>10000</span><span class=p>)</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>u</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Generated&#39;</span><span class=p>)</span>
<span class=n>x_theory</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_theory</span><span class=p>,</span> <span class=mi>2</span><span class=o>*</span><span class=n>x_theory</span><span class=p>,</span> <span class=s1>&#39;r-&#39;</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;True PDF: 2x&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Triangular Distribution&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Example - Discrete Distribution:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Roll a weighted die</span>
<span class=c1># P(1)=0.1, P(2)=0.2, P(3)=0.3, P(4)=0.25, P(5)=0.1, P(6)=0.05</span>

<span class=n>probs</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.25</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>]</span>
<span class=n>cdf</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span>  <span class=c1># [0.1, 0.3, 0.6, 0.85, 0.95, 1.0]</span>

<span class=k>def</span><span class=w> </span><span class=nf>weighted_die</span><span class=p>():</span>
    <span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>()</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>c</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>cdf</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>u</span> <span class=o>&lt;=</span> <span class=n>c</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span>

<span class=c1># Generate 10000 rolls</span>
<span class=n>rolls</span> <span class=o>=</span> <span class=p>[</span><span class=n>weighted_die</span><span class=p>()</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>)]</span>

<span class=c1># Verify</span>
<span class=kn>from</span><span class=w> </span><span class=nn>collections</span><span class=w> </span><span class=kn>import</span> <span class=n>Counter</span>
<span class=n>counts</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>rolls</span><span class=p>)</span>
<span class=k>for</span> <span class=n>face</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>7</span><span class=p>):</span>
    <span class=n>observed</span> <span class=o>=</span> <span class=n>counts</span><span class=p>[</span><span class=n>face</span><span class=p>]</span> <span class=o>/</span> <span class=mi>10000</span>
    <span class=n>expected</span> <span class=o>=</span> <span class=n>probs</span><span class=p>[</span><span class=n>face</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Face </span><span class=si>{</span><span class=n>face</span><span class=si>}</span><span class=s2>: Observed=</span><span class=si>{</span><span class=n>observed</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, Expected=</span><span class=si>{</span><span class=n>expected</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>When to Use:</strong></p> <table> <thead> <tr> <th>Pros</th> <th>Cons</th> </tr> </thead> <tbody> <tr> <td>Exact samples (not approximate)</td> <td>Need closed-form F‚Åª¬π(u)</td> </tr> <tr> <td>Fast if F‚Åª¬π is simple</td> <td>Doesn't work for complex F</td> </tr> <tr> <td>No tuning needed</td> <td>Need to derive inverse</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Random generation fundamentals.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>X = F‚Åª¬π(U) formula</li> <li>Can prove why it works</li> <li>Implements for exponential</li> <li>Knows when it's practical</li> </ul> </div> </details> <hr> <h3 id=what-is-box-muller-transform-amazon-microsoft-interview-question>What is Box-Muller Transform? - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Normal Generation</code>, <code>Transformation</code>, <code>Simulation</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Box-Muller Transform:</strong></p> <p>Generate two independent N(0,1) from two independent U(0,1):</p> <div class=arithmatex>\[Z_0 = \sqrt{-2\ln(U_1)} \cos(2\pi U_2)$$ $$Z_1 = \sqrt{-2\ln(U_1)} \sin(2\pi U_2)\]</div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=k>def</span><span class=w> </span><span class=nf>box_muller</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Generate n pairs of independent N(0,1) samples&quot;&quot;&quot;</span>
    <span class=c1># Generate uniform samples</span>
    <span class=n>u1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
    <span class=n>u2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

    <span class=c1># Box-Muller transform</span>
    <span class=n>r</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>u1</span><span class=p>))</span>
    <span class=n>theta</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>pi</span> <span class=o>*</span> <span class=n>u2</span>

    <span class=n>z0</span> <span class=o>=</span> <span class=n>r</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>theta</span><span class=p>)</span>
    <span class=n>z1</span> <span class=o>=</span> <span class=n>r</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>theta</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>z0</span><span class=p>,</span> <span class=n>z1</span>

<span class=c1># Generate samples</span>
<span class=n>z0</span><span class=p>,</span> <span class=n>z1</span> <span class=o>=</span> <span class=n>box_muller</span><span class=p>(</span><span class=mi>10000</span><span class=p>)</span>

<span class=c1># Verify normality</span>
<span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>

<span class=c1># Histogram Z0</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>z0</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>),</span> <span class=s1>&#39;r-&#39;</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Z0 Distribution&#39;</span><span class=p>)</span>

<span class=c1># Histogram Z1</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>z1</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>),</span> <span class=s1>&#39;r-&#39;</span><span class=p>,</span> <span class=n>lw</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Z1 Distribution&#39;</span><span class=p>)</span>

<span class=c1># Q-Q plot</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=n>stats</span><span class=o>.</span><span class=n>probplot</span><span class=p>(</span><span class=n>z0</span><span class=p>,</span> <span class=n>dist</span><span class=o>=</span><span class=s2>&quot;norm&quot;</span><span class=p>,</span> <span class=n>plot</span><span class=o>=</span><span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Q-Q Plot Z0&#39;</span><span class=p>)</span>

<span class=c1># 2D scatter (independence check)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>z0</span><span class=p>,</span> <span class=n>z1</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Z0&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Z1&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Independence check&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;equal&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Verify mean and variance</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Z0: mean=</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>z0</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, std=</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>z0</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Z1: mean=</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>z1</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, std=</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>z1</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Correlation: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>corrcoef</span><span class=p>(</span><span class=n>z0</span><span class=p>,</span><span class=w> </span><span class=n>z1</span><span class=p>)[</span><span class=mi>0</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Why It Works:</strong></p> <p>Uses polar coordinates (R, Œò) in 2D: - R¬≤ = X¬≤ + Y¬≤ ~ Exponential(&frac12;) for X,Y ~ N(0,1) - R¬≤ = -2ln(U) gives correct distribution - Œò ~ Uniform(0, 2œÄ) from U‚ÇÇ</p> <p><strong>Polar Form (more efficient):</strong></p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>box_muller_polar</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Marsaglia polar method - faster&quot;&quot;&quot;</span>
    <span class=n>z0</span><span class=p>,</span> <span class=n>z1</span> <span class=o>=</span> <span class=p>[],</span> <span class=p>[]</span>

    <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>z0</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>:</span>
        <span class=c1># Generate in unit circle</span>
        <span class=n>u1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
        <span class=n>u2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
        <span class=n>s</span> <span class=o>=</span> <span class=n>u1</span><span class=o>**</span><span class=mi>2</span> <span class=o>+</span> <span class=n>u2</span><span class=o>**</span><span class=mi>2</span>

        <span class=c1># Reject if outside circle</span>
        <span class=k>if</span> <span class=n>s</span> <span class=o>&gt;=</span> <span class=mi>1</span> <span class=ow>or</span> <span class=n>s</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=k>continue</span>

        <span class=c1># Transform</span>
        <span class=n>factor</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=n>s</span><span class=p>)</span>
        <span class=n>z0</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>u1</span> <span class=o>*</span> <span class=n>factor</span><span class=p>)</span>
        <span class=n>z1</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>u2</span> <span class=o>*</span> <span class=n>factor</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>z0</span><span class=p>[:</span><span class=n>n</span><span class=p>]),</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>z1</span><span class=p>[:</span><span class=n>n</span><span class=p>])</span>

<span class=c1># Compare efficiency</span>
<span class=kn>import</span><span class=w> </span><span class=nn>time</span>

<span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
<span class=n>z0</span><span class=p>,</span> <span class=n>z1</span> <span class=o>=</span> <span class=n>box_muller</span><span class=p>(</span><span class=mi>100000</span><span class=p>)</span>
<span class=n>time_basic</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>

<span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
<span class=n>z0</span><span class=p>,</span> <span class=n>z1</span> <span class=o>=</span> <span class=n>box_muller_polar</span><span class=p>(</span><span class=mi>100000</span><span class=p>)</span>
<span class=n>time_polar</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Basic: </span><span class=si>{</span><span class=n>time_basic</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Polar: </span><span class=si>{</span><span class=n>time_polar</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Applications:</strong></p> <ul> <li>Monte Carlo simulations</li> <li>Generate multivariate normal (with Cholesky)</li> <li>Random initialization in ML</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Practical random generation.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Formulas with ‚àö(-2ln) and 2œÄ</li> <li>"Generates TWO independent normals"</li> <li>Mentions polar form as optimization</li> <li>Knows why: polar coordinates</li> </ul> </div> </details> <hr> <h3 id=explain-the-alias-method-for-discrete-sampling-google-meta-interview-question>Explain the Alias Method for Discrete Sampling - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Discrete Sampling</code>, <code>Algorithms</code>, <code>Efficiency</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Alias Method:</strong></p> <p>Sample from discrete distribution in O(1) time after O(n) preprocessing.</p> <p><strong>Problem:</strong> Sample from {x‚ÇÅ,...,x‚Çô} with probabilities {p‚ÇÅ,...,p‚Çô}</p> <p><strong>Idea:</strong> Split each probability into two "aliases" to create uniform structure.</p> <p><strong>Algorithm:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>class</span><span class=w> </span><span class=nc>AliasMethod</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>probs</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Setup alias method for discrete distribution</span>
<span class=sd>        probs: array of probabilities (must sum to 1)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>n</span> <span class=o>=</span> <span class=n>n</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>prob</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>alias</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>int</span><span class=p>)</span>

        <span class=c1># Scale probabilities</span>
        <span class=n>scaled</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span> <span class=o>*</span> <span class=n>n</span>

        <span class=c1># Separate into small and large</span>
        <span class=n>small</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=n>large</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>p</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>scaled</span><span class=p>):</span>
            <span class=k>if</span> <span class=n>p</span> <span class=o>&lt;</span> <span class=mi>1</span><span class=p>:</span>
                <span class=n>small</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>large</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>

        <span class=c1># Build tables</span>
        <span class=k>while</span> <span class=n>small</span> <span class=ow>and</span> <span class=n>large</span><span class=p>:</span>
            <span class=n>s</span> <span class=o>=</span> <span class=n>small</span><span class=o>.</span><span class=n>pop</span><span class=p>()</span>
            <span class=n>l</span> <span class=o>=</span> <span class=n>large</span><span class=o>.</span><span class=n>pop</span><span class=p>()</span>

            <span class=bp>self</span><span class=o>.</span><span class=n>prob</span><span class=p>[</span><span class=n>s</span><span class=p>]</span> <span class=o>=</span> <span class=n>scaled</span><span class=p>[</span><span class=n>s</span><span class=p>]</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>alias</span><span class=p>[</span><span class=n>s</span><span class=p>]</span> <span class=o>=</span> <span class=n>l</span>

            <span class=c1># Update large probability</span>
            <span class=n>scaled</span><span class=p>[</span><span class=n>l</span><span class=p>]</span> <span class=o>=</span> <span class=n>scaled</span><span class=p>[</span><span class=n>l</span><span class=p>]</span> <span class=o>-</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>scaled</span><span class=p>[</span><span class=n>s</span><span class=p>])</span>

            <span class=k>if</span> <span class=n>scaled</span><span class=p>[</span><span class=n>l</span><span class=p>]</span> <span class=o>&lt;</span> <span class=mi>1</span><span class=p>:</span>
                <span class=n>small</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>l</span><span class=p>)</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>large</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>l</span><span class=p>)</span>

        <span class=c1># Remaining probabilities</span>
        <span class=k>while</span> <span class=n>large</span><span class=p>:</span>
            <span class=n>l</span> <span class=o>=</span> <span class=n>large</span><span class=o>.</span><span class=n>pop</span><span class=p>()</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>prob</span><span class=p>[</span><span class=n>l</span><span class=p>]</span> <span class=o>=</span> <span class=mf>1.0</span>

        <span class=k>while</span> <span class=n>small</span><span class=p>:</span>
            <span class=n>s</span> <span class=o>=</span> <span class=n>small</span><span class=o>.</span><span class=n>pop</span><span class=p>()</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>prob</span><span class=p>[</span><span class=n>s</span><span class=p>]</span> <span class=o>=</span> <span class=mf>1.0</span>

    <span class=k>def</span><span class=w> </span><span class=nf>sample</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Generate single sample in O(1)&quot;&quot;&quot;</span>
        <span class=c1># Pick random bin</span>
        <span class=n>i</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n</span><span class=p>)</span>

        <span class=c1># Flip biased coin</span>
        <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>()</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>prob</span><span class=p>[</span><span class=n>i</span><span class=p>]:</span>
            <span class=k>return</span> <span class=n>i</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>alias</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>

<span class=c1># Example: Weighted die</span>
<span class=n>probs</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.25</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>]</span>
<span class=n>sampler</span> <span class=o>=</span> <span class=n>AliasMethod</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span>

<span class=c1># Generate samples</span>
<span class=n>samples</span> <span class=o>=</span> <span class=p>[</span><span class=n>sampler</span><span class=o>.</span><span class=n>sample</span><span class=p>()</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>100000</span><span class=p>)]</span>

<span class=c1># Verify</span>
<span class=kn>from</span><span class=w> </span><span class=nn>collections</span><span class=w> </span><span class=kn>import</span> <span class=n>Counter</span>
<span class=n>counts</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>samples</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Face | Observed | Expected&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>6</span><span class=p>):</span>
    <span class=n>obs</span> <span class=o>=</span> <span class=n>counts</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>/</span> <span class=mi>100000</span>
    <span class=n>exp</span> <span class=o>=</span> <span class=n>probs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>:</span><span class=s2>4d</span><span class=si>}</span><span class=s2> | </span><span class=si>{</span><span class=n>obs</span><span class=si>:</span><span class=s2>8.3f</span><span class=si>}</span><span class=s2> | </span><span class=si>{</span><span class=n>exp</span><span class=si>:</span><span class=s2>8.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Complexity:</strong></p> <table> <thead> <tr> <th>Operation</th> <th>Time</th> </tr> </thead> <tbody> <tr> <td>Setup</td> <td>O(n)</td> </tr> <tr> <td>Single sample</td> <td>O(1)</td> </tr> <tr> <td>k samples</td> <td>O(k)</td> </tr> </tbody> </table> <p><strong>Comparison:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>time</span>

<span class=c1># Method 1: Linear search (naive)</span>
<span class=k>def</span><span class=w> </span><span class=nf>naive_sample</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>cdf</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span>
    <span class=n>samples</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>k</span><span class=p>):</span>
        <span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>()</span>
        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>c</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>cdf</span><span class=p>):</span>
            <span class=k>if</span> <span class=n>u</span> <span class=o>&lt;=</span> <span class=n>c</span><span class=p>:</span>
                <span class=n>samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
                <span class=k>break</span>
    <span class=k>return</span> <span class=n>samples</span>

<span class=c1># Method 2: Alias method</span>
<span class=k>def</span><span class=w> </span><span class=nf>alias_sample</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>sampler</span> <span class=o>=</span> <span class=n>AliasMethod</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span>
    <span class=k>return</span> <span class=p>[</span><span class=n>sampler</span><span class=o>.</span><span class=n>sample</span><span class=p>()</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>k</span><span class=p>)]</span>

<span class=n>probs</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.25</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>]</span>
<span class=n>k</span> <span class=o>=</span> <span class=mi>100000</span>

<span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
<span class=n>s1</span> <span class=o>=</span> <span class=n>naive_sample</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span>
<span class=n>time_naive</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>

<span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
<span class=n>s2</span> <span class=o>=</span> <span class=n>alias_sample</span><span class=p>(</span><span class=n>probs</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span>
<span class=n>time_alias</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Naive:  </span><span class=si>{</span><span class=n>time_naive</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>s (O(nk))&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Alias:  </span><span class=si>{</span><span class=n>time_alias</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>s (O(n+k))&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Speedup: </span><span class=si>{</span><span class=n>time_naive</span><span class=o>/</span><span class=n>time_alias</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>x&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>When to Use:</strong></p> <ul> <li>Need many samples from same distribution</li> <li>Distribution doesn't change</li> <li>Want guaranteed O(1) per sample</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced algorithms knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"O(1) sampling after O(n) setup"</li> <li>Explains alias table concept</li> <li>Can implement from scratch</li> <li>Knows use case: many samples</li> </ul> </div> </details> <hr> <h3 id=what-is-stratified-sampling-when-to-use-it-google-amazon-interview-question>What is Stratified Sampling? When to Use It? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Sampling Methods</code>, <code>Variance Reduction</code>, <code>Survey</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Stratified Sampling:</strong></p> <p>Divide population into homogeneous subgroups (strata), then sample from each stratum.</p> <div class=arithmatex>\[\bar{X}_{st} = \sum_{h=1}^H W_h \bar{X}_h\]</div> <p>Where: - H = number of strata - W_h = proportion of population in stratum h - <span class=arithmatex>\(\bar{X}_h\)</span> = sample mean from stratum h</p> <p><strong>Variance:</strong></p> <div class=arithmatex>\[Var(\bar{X}_{st}) = \sum_{h=1}^H W_h^2 \frac{\sigma_h^2}{n_h}\]</div> <p><strong>Always better than simple random sampling when strata differ!</strong></p> <p><strong>Example - A/B Test by Country:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>

<span class=c1># Population: users from 3 countries with different conversion rates</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=n>population</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;country&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;US&#39;</span><span class=p>]</span><span class=o>*</span><span class=mi>5000</span> <span class=o>+</span> <span class=p>[</span><span class=s1>&#39;UK&#39;</span><span class=p>]</span><span class=o>*</span><span class=mi>3000</span> <span class=o>+</span> <span class=p>[</span><span class=s1>&#39;CA&#39;</span><span class=p>]</span><span class=o>*</span><span class=mi>2000</span><span class=p>,</span>
    <span class=s1>&#39;converted&#39;</span><span class=p>:</span> <span class=p>(</span>
        <span class=nb>list</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.10</span><span class=p>,</span> <span class=mi>5000</span><span class=p>))</span> <span class=o>+</span>  <span class=c1># US: 10%</span>
        <span class=nb>list</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.15</span><span class=p>,</span> <span class=mi>3000</span><span class=p>))</span> <span class=o>+</span>  <span class=c1># UK: 15%</span>
        <span class=nb>list</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.08</span><span class=p>,</span> <span class=mi>2000</span><span class=p>))</span>    <span class=c1># CA: 8%</span>
    <span class=p>)</span>
<span class=p>})</span>

<span class=c1># True overall conversion</span>
<span class=n>true_rate</span> <span class=o>=</span> <span class=n>population</span><span class=p>[</span><span class=s1>&#39;converted&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True conversion: </span><span class=si>{</span><span class=n>true_rate</span><span class=si>:</span><span class=s2>.3%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Method 1: Simple random sampling</span>
<span class=n>n_trials</span> <span class=o>=</span> <span class=mi>1000</span>
<span class=n>srs_estimates</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_trials</span><span class=p>):</span>
    <span class=n>sample</span> <span class=o>=</span> <span class=n>population</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
    <span class=n>srs_estimates</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>sample</span><span class=p>[</span><span class=s1>&#39;converted&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>

<span class=c1># Method 2: Stratified sampling</span>
<span class=n>stratified_estimates</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_trials</span><span class=p>):</span>
    <span class=n>samples</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=c1># Sample proportionally from each stratum</span>
    <span class=n>samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>population</span><span class=p>[</span><span class=n>population</span><span class=p>[</span><span class=s1>&#39;country&#39;</span><span class=p>]</span><span class=o>==</span><span class=s1>&#39;US&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>150</span><span class=p>))</span>  <span class=c1># 50%</span>
    <span class=n>samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>population</span><span class=p>[</span><span class=n>population</span><span class=p>[</span><span class=s1>&#39;country&#39;</span><span class=p>]</span><span class=o>==</span><span class=s1>&#39;UK&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>90</span><span class=p>))</span>   <span class=c1># 30%</span>
    <span class=n>samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>population</span><span class=p>[</span><span class=n>population</span><span class=p>[</span><span class=s1>&#39;country&#39;</span><span class=p>]</span><span class=o>==</span><span class=s1>&#39;CA&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=n>n</span><span class=o>=</span><span class=mi>60</span><span class=p>))</span>   <span class=c1># 20%</span>

    <span class=n>sample</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>concat</span><span class=p>(</span><span class=n>samples</span><span class=p>)</span>
    <span class=n>stratified_estimates</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>sample</span><span class=p>[</span><span class=s1>&#39;converted&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>

<span class=c1># Compare</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Simple Random Sampling:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>srs_estimates</span><span class=p>)</span><span class=si>:</span><span class=s2>.3%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Std:  </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>srs_estimates</span><span class=p>)</span><span class=si>:</span><span class=s2>.3%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Stratified Sampling:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>stratified_estimates</span><span class=p>)</span><span class=si>:</span><span class=s2>.3%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Std:  </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>stratified_estimates</span><span class=p>)</span><span class=si>:</span><span class=s2>.3%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=n>variance_reduction</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>stratified_estimates</span><span class=p>)</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>srs_estimates</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Variance reduction: </span><span class=si>{</span><span class=n>variance_reduction</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Optimal Allocation (Neyman):</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Allocate samples proportional to œÉ_h * N_h</span>

<span class=k>def</span><span class=w> </span><span class=nf>optimal_allocation</span><span class=p>(</span><span class=n>strata_sizes</span><span class=p>,</span> <span class=n>strata_stds</span><span class=p>,</span> <span class=n>total_n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Neyman optimal allocation</span>
<span class=sd>    Returns samples per stratum</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>products</span> <span class=o>=</span> <span class=p>[</span><span class=n>n</span> <span class=o>*</span> <span class=n>s</span> <span class=k>for</span> <span class=n>n</span><span class=p>,</span> <span class=n>s</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>strata_sizes</span><span class=p>,</span> <span class=n>strata_stds</span><span class=p>)]</span>
    <span class=n>total_product</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>products</span><span class=p>)</span>

    <span class=k>return</span> <span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=n>total_n</span> <span class=o>*</span> <span class=n>p</span> <span class=o>/</span> <span class=n>total_product</span><span class=p>)</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>products</span><span class=p>]</span>

<span class=c1># Example</span>
<span class=n>N</span> <span class=o>=</span> <span class=p>[</span><span class=mi>5000</span><span class=p>,</span> <span class=mi>3000</span><span class=p>,</span> <span class=mi>2000</span><span class=p>]</span>  <span class=c1># Stratum sizes</span>
<span class=n>sigma</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.36</span><span class=p>,</span> <span class=mf>0.27</span><span class=p>]</span>  <span class=c1># Stratum std devs</span>
<span class=n>total_n</span> <span class=o>=</span> <span class=mi>300</span>

<span class=c1># Proportional allocation</span>
<span class=n>prop_alloc</span> <span class=o>=</span> <span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=mi>300</span> <span class=o>*</span> <span class=n>n</span><span class=o>/</span><span class=nb>sum</span><span class=p>(</span><span class=n>N</span><span class=p>))</span> <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>N</span><span class=p>]</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Proportional: </span><span class=si>{</span><span class=n>prop_alloc</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Optimal allocation</span>
<span class=n>opt_alloc</span> <span class=o>=</span> <span class=n>optimal_allocation</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=n>total_n</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Optimal: </span><span class=si>{</span><span class=n>opt_alloc</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>When to Use:</strong></p> <table> <thead> <tr> <th>Use Case</th> <th>Benefit</th> </tr> </thead> <tbody> <tr> <td>Heterogeneous population</td> <td>Reduce variance</td> </tr> <tr> <td>Subgroup analysis</td> <td>Ensure representation</td> </tr> <tr> <td>Rare subgroups</td> <td>Oversample minorities</td> </tr> <tr> <td>Known stratification</td> <td>Leverage prior knowledge</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Practical sampling knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Divide into homogeneous strata"</li> <li>Lower variance than SRS</li> <li>Mentions Neyman allocation</li> <li>Real examples (A/B tests, surveys)</li> </ul> </div> </details> <hr> <h3 id=what-is-the-coupon-collectors-variance-google-meta-interview-question>What is the Coupon Collector's Variance? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Coupon Collector</code>, <code>Variance</code>, <code>Theory</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Coupon Collector Problem:</strong></p> <p>How many draws (with replacement) to collect all n distinct coupons?</p> <p><strong>Expected Value:</strong></p> <div class=arithmatex>\[E[T] = n \sum_{i=1}^n \frac{1}{i} = n \cdot H_n \approx n \ln(n)\]</div> <p>Where H_n is harmonic number.</p> <p><strong>Variance:</strong></p> <div class=arithmatex>\[Var(T) = n^2 \sum_{i=1}^n \frac{1}{i^2} - n \sum_{i=1}^n \frac{1}{i}\]</div> <div class=arithmatex>\[Var(T) \approx n^2 \left(\frac{\pi^2}{6} - (\ln n)^2\right)\]</div> <p>For large n: <span class=arithmatex>\(Var(T) \approx n^2 \frac{\pi^2}{6}\)</span></p> <p><strong>Simulation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=k>def</span><span class=w> </span><span class=nf>coupon_collector</span><span class=p>(</span><span class=n>n_coupons</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Simulate single coupon collecting run&quot;&quot;&quot;</span>
    <span class=n>collected</span> <span class=o>=</span> <span class=nb>set</span><span class=p>()</span>
    <span class=n>draws</span> <span class=o>=</span> <span class=mi>0</span>

    <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>collected</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>n_coupons</span><span class=p>:</span>
        <span class=n>coupon</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_coupons</span><span class=p>)</span>
        <span class=n>collected</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>coupon</span><span class=p>)</span>
        <span class=n>draws</span> <span class=o>+=</span> <span class=mi>1</span>

    <span class=k>return</span> <span class=n>draws</span>

<span class=c1># Simulate for different n</span>
<span class=n>n_values</span> <span class=o>=</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>]</span>

<span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>n_values</span><span class=p>:</span>
    <span class=c1># Run simulations</span>
    <span class=n>trials</span> <span class=o>=</span> <span class=p>[</span><span class=n>coupon_collector</span><span class=p>(</span><span class=n>n</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>)]</span>

    <span class=c1># Theoretical</span>
    <span class=n>harmonic</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>i</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span>
    <span class=n>E_T_theory</span> <span class=o>=</span> <span class=n>n</span> <span class=o>*</span> <span class=n>harmonic</span>

    <span class=n>var_theory</span> <span class=o>=</span> <span class=n>n</span><span class=o>**</span><span class=mi>2</span> <span class=o>*</span> <span class=nb>sum</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=n>i</span><span class=o>**</span><span class=mi>2</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span> <span class=o>-</span> <span class=n>E_T_theory</span><span class=o>**</span><span class=mi>2</span>

    <span class=c1># Empirical</span>
    <span class=n>E_T_sim</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>trials</span><span class=p>)</span>
    <span class=n>var_sim</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>trials</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;n=</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  E[T]: Theory=</span><span class=si>{</span><span class=n>E_T_theory</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>, Sim=</span><span class=si>{</span><span class=n>E_T_sim</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Var(T): Theory=</span><span class=si>{</span><span class=n>var_theory</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>, Sim=</span><span class=si>{</span><span class=n>var_sim</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>()</span>

<span class=c1># Visualize distribution for n=50</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>50</span>
<span class=n>trials</span> <span class=o>=</span> <span class=p>[</span><span class=n>coupon_collector</span><span class=p>(</span><span class=n>n</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>)]</span>

<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>trials</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>trials</span><span class=p>),</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> 
            <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Mean=</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>trials</span><span class=p>)</span><span class=si>:</span><span class=s1>.0f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of draws&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Coupon Collector Distribution (n=</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Decomposition:</strong></p> <p>Let T_i = draws to get ith new coupon (given i-1 collected)</p> <div class=highlight><pre><span></span><code><span class=c1># T_i ~ Geometric(p_i) where p_i = (n-i+1)/n</span>

<span class=n>n</span> <span class=o>=</span> <span class=mi>50</span>

<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>6</span><span class=p>):</span>
    <span class=n>p_i</span> <span class=o>=</span> <span class=p>(</span><span class=n>n</span> <span class=o>-</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span>
    <span class=n>E_Ti</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>p_i</span>
    <span class=n>Var_Ti</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_i</span><span class=p>)</span> <span class=o>/</span> <span class=n>p_i</span><span class=o>**</span><span class=mi>2</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Coupon </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  p=</span><span class=si>{</span><span class=n>p_i</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, E[T_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>]=</span><span class=si>{</span><span class=n>E_Ti</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, Var(T_</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>)=</span><span class=si>{</span><span class=n>Var_Ti</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Applications:</strong></p> <ol> <li><strong>Hash collisions:</strong> How many items until collision?</li> <li><strong>Testing:</strong> How many tests to cover all branches?</li> <li><strong>Matching problems:</strong> Collecting pairs/sets</li> </ol> <p><strong>Follow-up Questions:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Q1: Expected draws to collect m &lt; n coupons?</span>
<span class=k>def</span><span class=w> </span><span class=nf>expected_m_coupons</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>m</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>n</span> <span class=o>*</span> <span class=nb>sum</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=p>(</span><span class=n>n</span><span class=o>-</span><span class=n>i</span><span class=p>)</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>m</span><span class=p>))</span>

<span class=c1># Q2: Probability of collecting all in k draws?</span>
<span class=c1># Use inclusion-exclusion principle (complex!)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Deep combinatorics + probability.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>E[T] = n¬∑H_n formula</li> <li>Knows variance exists and scales as n¬≤</li> <li>Decomposes into geometric RVs</li> <li>Mentions applications</li> </ul> </div> </details> <hr> <h3 id=explain-the-chinese-restaurant-process-meta-google-interview-question>Explain the Chinese Restaurant Process - Meta, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Stochastic Process</code>, <code>Clustering</code>, <code>Bayesian</code> | <strong>Asked by:</strong> Meta, Google, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Chinese Restaurant Process (CRP):</strong></p> <p>Stochastic process for clustering with unbounded number of clusters.</p> <p><strong>Setup:</strong> - Restaurant with infinite tables - Customers enter one by one - Each customer: - Sits at occupied table k with prob ‚àù n_k (# customers at table k) - Sits at new table with prob ‚àù Œ± (concentration parameter)</p> <p><strong>Probability:</strong></p> <div class=arithmatex>\[P(\text{table } k) = \begin{cases} \frac{n_k}{n-1+\alpha} &amp; \text{if table } k \text{ occupied} \\ \frac{\alpha}{n-1+\alpha} &amp; \text{if new table} \end{cases}\]</div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>collections</span><span class=w> </span><span class=kn>import</span> <span class=n>Counter</span>

<span class=k>def</span><span class=w> </span><span class=nf>chinese_restaurant_process</span><span class=p>(</span><span class=n>n_customers</span><span class=p>,</span> <span class=n>alpha</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Simulate CRP</span>
<span class=sd>    Returns: list of table assignments</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>tables</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span>  <span class=c1># First customer at table 0</span>

    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n_customers</span><span class=p>):</span>
        <span class=c1># Count customers at each table</span>
        <span class=n>counts</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>tables</span><span class=p>)</span>

        <span class=c1># Probabilities</span>
        <span class=n>probs</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=n>table_ids</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>for</span> <span class=n>table</span><span class=p>,</span> <span class=n>count</span> <span class=ow>in</span> <span class=n>counts</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=n>probs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>count</span><span class=p>)</span>
            <span class=n>table_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>table</span><span class=p>)</span>

        <span class=c1># New table probability</span>
        <span class=n>probs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>alpha</span><span class=p>)</span>
        <span class=n>table_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=nb>max</span><span class=p>(</span><span class=n>table_ids</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>

        <span class=c1># Normalize</span>
        <span class=n>probs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>probs</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=n>alpha</span><span class=p>)</span>

        <span class=c1># Sample</span>
        <span class=n>chosen</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>probs</span><span class=p>),</span> <span class=n>p</span><span class=o>=</span><span class=n>probs</span><span class=p>)</span>
        <span class=n>tables</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>table_ids</span><span class=p>[</span><span class=n>chosen</span><span class=p>])</span>

    <span class=k>return</span> <span class=n>tables</span>

<span class=c1># Simulate</span>
<span class=n>n_customers</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mf>2.0</span>

<span class=n>assignments</span> <span class=o>=</span> <span class=n>chinese_restaurant_process</span><span class=p>(</span><span class=n>n_customers</span><span class=p>,</span> <span class=n>alpha</span><span class=p>)</span>

<span class=c1># Visualize</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>assignments</span><span class=p>,</span> <span class=s1>&#39;o-&#39;</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Customer&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Table&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;CRP: Œ±=</span><span class=si>{</span><span class=n>alpha</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=n>table_sizes</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>assignments</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>table_sizes</span><span class=o>.</span><span class=n>keys</span><span class=p>(),</span> <span class=n>table_sizes</span><span class=o>.</span><span class=n>values</span><span class=p>())</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Table ID&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Number of customers&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Table sizes (Total tables: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>table_sizes</span><span class=p>)</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Effect of Œ±:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Compare different Œ± values</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>alphas</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>5.0</span><span class=p>,</span> <span class=mf>10.0</span><span class=p>]</span>

<span class=k>for</span> <span class=n>alpha</span> <span class=ow>in</span> <span class=n>alphas</span><span class=p>:</span>
    <span class=n>trials</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>):</span>
        <span class=n>tables</span> <span class=o>=</span> <span class=n>chinese_restaurant_process</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>alpha</span><span class=p>)</span>
        <span class=n>n_tables</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>tables</span><span class=p>))</span>
        <span class=n>trials</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>n_tables</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Œ±=</span><span class=si>{</span><span class=n>alpha</span><span class=si>:</span><span class=s2>4.1f</span><span class=si>}</span><span class=s2>: E[# tables] = </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>trials</span><span class=p>)</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> ¬± </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>trials</span><span class=p>)</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Œ± small ‚Üí few large tables (low diversity)</span>
<span class=c1># Œ± large ‚Üí many small tables (high diversity)</span>
</code></pre></div> <p><strong>Expected Number of Tables:</strong></p> <div class=arithmatex>\[E[K_n] \approx \alpha \log\left(\frac{n}{\alpha} + 1\right)\]</div> <p>For large n: <span class=arithmatex>\(E[K_n] \approx \alpha \log n\)</span></p> <p><strong>Applications:</strong></p> <ol> <li><strong>Topic modeling:</strong> Dirichlet process mixture models</li> <li><strong>Clustering:</strong> Nonparametric Bayesian clustering</li> <li><strong>Natural language:</strong> Word clustering</li> <li><strong>Genetics:</strong> Species sampling problems</li> </ol> <p><strong>Connection to Dirichlet Process:</strong></p> <p>CRP is the "exchangeable" partition distribution induced by a Dirichlet Process.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced ML/statistics knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Rich get richer" intuition</li> <li>Knows Œ± controls # clusters</li> <li>Can simulate from scratch</li> <li>Mentions DP mixture models</li> </ul> </div> </details> <hr> <h3 id=what-is-the-secretary-problem-optimal-stopping-google-amazon-interview-question>What is the Secretary Problem (Optimal Stopping)? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Optimal Stopping</code>, <code>Decision Theory</code>, <code>Probability</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Secretary Problem:</strong></p> <p>Interview n candidates sequentially, must accept/reject immediately. Goal: maximize probability of selecting the best candidate.</p> <p><strong>Optimal Strategy:</strong></p> <ol> <li>Reject first n/e ‚âà 0.368n candidates (observation phase)</li> <li>Then accept first candidate better than all observed</li> </ol> <p><strong>Success Probability:</strong> ‚âà 1/e ‚âà 0.368 (37%)</p> <p><strong>Proof Intuition:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>def</span><span class=w> </span><span class=nf>secretary_problem</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>r</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Simulate secretary problem</span>
<span class=sd>    n: number of candidates</span>
<span class=sd>    r: number to observe before selecting</span>
<span class=sd>    Returns: True if best candidate selected</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># Random permutation (1 = best)</span>
    <span class=n>candidates</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>permutation</span><span class=p>(</span><span class=n>n</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span>

    <span class=c1># Observe first r</span>
    <span class=n>best_observed</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>candidates</span><span class=p>[:</span><span class=n>r</span><span class=p>])</span>

    <span class=c1># Select first better than best_observed</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>r</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
        <span class=k>if</span> <span class=n>candidates</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>&gt;</span> <span class=n>best_observed</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>candidates</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>==</span> <span class=n>n</span>  <span class=c1># n is the best</span>

    <span class=k>return</span> <span class=kc>False</span>  <span class=c1># No one selected</span>

<span class=c1># Find optimal r for different n</span>
<span class=n>n_values</span> <span class=o>=</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>1000</span><span class=p>]</span>

<span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>n_values</span><span class=p>:</span>
    <span class=n>best_r</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=n>best_prob</span> <span class=o>=</span> <span class=mi>0</span>

    <span class=c1># Try different r values</span>
    <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
        <span class=c1># Simulate</span>
        <span class=n>trials</span> <span class=o>=</span> <span class=p>[</span><span class=n>secretary_problem</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>r</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>)]</span>
        <span class=n>prob</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>trials</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>prob</span> <span class=o>&gt;</span> <span class=n>best_prob</span><span class=p>:</span>
            <span class=n>best_prob</span> <span class=o>=</span> <span class=n>prob</span>
            <span class=n>best_r</span> <span class=o>=</span> <span class=n>r</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;n=</span><span class=si>{</span><span class=n>n</span><span class=si>:</span><span class=s2>4d</span><span class=si>}</span><span class=s2>: Optimal r=</span><span class=si>{</span><span class=n>best_r</span><span class=si>:</span><span class=s2>3d</span><span class=si>}</span><span class=s2> (r/n=</span><span class=si>{</span><span class=n>best_r</span><span class=o>/</span><span class=n>n</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>), P(success)=</span><span class=si>{</span><span class=n>best_prob</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># All approach r/n ‚âà 1/e ‚âà 0.368</span>
</code></pre></div> <p><strong>Visualize for n=100:</strong></p> <div class=highlight><pre><span></span><code><span class=n>n</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>r_values</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
<span class=n>success_probs</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>r_values</span><span class=p>:</span>
    <span class=n>trials</span> <span class=o>=</span> <span class=p>[</span><span class=n>secretary_problem</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>r</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5000</span><span class=p>)]</span>
    <span class=n>success_probs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>trials</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>r_values</span><span class=p>)</span><span class=o>/</span><span class=n>n</span><span class=p>,</span> <span class=n>success_probs</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>e</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;1/e ‚âà 0.368&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>e</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;r&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;r/n (fraction observed)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;P(selecting best)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Secretary Problem Optimal Strategy&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Variants:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># 1. Want top k candidates (not just best)</span>
<span class=c1># Strategy: observe n/k candidates, select next better</span>

<span class=c1># 2. Know value distribution</span>
<span class=c1># Use threshold strategy with known distribution</span>

<span class=c1># 3. Maximize expected rank</span>
<span class=c1># Different strategy, different cutoff</span>

<span class=c1># 4. Multiple positions</span>
<span class=c1># Generalized secretary problem</span>
</code></pre></div> <p><strong>Real-World Applications:</strong></p> <table> <thead> <tr> <th>Domain</th> <th>Application</th> </tr> </thead> <tbody> <tr> <td>Hiring</td> <td>When to stop interviewing</td> </tr> <tr> <td>Dating</td> <td>When to propose</td> </tr> <tr> <td>Real estate</td> <td>When to make offer</td> </tr> <tr> <td>Trading</td> <td>When to sell asset</td> </tr> <tr> <td>Parking</td> <td>When to take spot</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Decision theory under uncertainty.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Observe n/e, then select"</li> <li>Success probability 1/e</li> <li>Can simulate strategy</li> <li>Mentions real applications</li> </ul> </div> </details> <hr> <h3 id=what-is-the-false-discovery-rate-fdr-google-meta-interview-question>What is the False Discovery Rate (FDR)? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Multiple Testing</code>, <code>FDR</code>, <code>Statistics</code> | <strong>Asked by:</strong> Google, Meta, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>False Discovery Rate:</strong></p> <p>Among all rejected (declared significant) null hypotheses, what proportion are false rejections?</p> <div class=arithmatex>\[FDR = E\left[\frac{V}{R}\right] = E\left[\frac{\text{# false positives}}{\text{# rejections}}\right]\]</div> <p>Where V = false discoveries, R = total rejections.</p> <p><strong>Contrast with FWER:</strong></p> <table> <thead> <tr> <th>Metric</th> <th>Definition</th> <th>Control</th> </tr> </thead> <tbody> <tr> <td>FWER</td> <td>P(‚â•1 false positive)</td> <td>Bonferroni: Œ±/m</td> </tr> <tr> <td>FDR</td> <td>E[false positives / rejections]</td> <td>BH: less stringent</td> </tr> </tbody> </table> <p><strong>Benjamini-Hochberg Procedure:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=k>def</span><span class=w> </span><span class=nf>benjamini_hochberg</span><span class=p>(</span><span class=n>p_values</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.05</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    BH procedure for FDR control</span>
<span class=sd>    Returns: boolean array of rejections</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>m</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>

    <span class=c1># Sort p-values with indices</span>
    <span class=n>sorted_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>
    <span class=n>sorted_p</span> <span class=o>=</span> <span class=n>p_values</span><span class=p>[</span><span class=n>sorted_indices</span><span class=p>]</span>

    <span class=c1># BH threshold: p_i ‚â§ (i/m)¬∑Œ±</span>
    <span class=n>thresholds</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>m</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>m</span> <span class=o>*</span> <span class=n>alpha</span>

    <span class=c1># Find largest i where p_i ‚â§ threshold</span>
    <span class=n>comparisons</span> <span class=o>=</span> <span class=n>sorted_p</span> <span class=o>&lt;=</span> <span class=n>thresholds</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=n>np</span><span class=o>.</span><span class=n>any</span><span class=p>(</span><span class=n>comparisons</span><span class=p>):</span>
        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>bool</span><span class=p>)</span>

    <span class=n>k</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>comparisons</span><span class=p>)[</span><span class=mi>0</span><span class=p>])</span>

    <span class=c1># Reject all hypotheses up to k</span>
    <span class=n>reject</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>bool</span><span class=p>)</span>
    <span class=n>reject</span><span class=p>[</span><span class=n>sorted_indices</span><span class=p>[:</span><span class=n>k</span><span class=o>+</span><span class=mi>1</span><span class=p>]]</span> <span class=o>=</span> <span class=kc>True</span>

    <span class=k>return</span> <span class=n>reject</span>

<span class=c1># Example: 100 hypotheses</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=c1># 90 true nulls (p ~ Uniform)</span>
<span class=c1># 10 false nulls (p ~ small values)</span>
<span class=n>p_true_null</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>90</span><span class=p>)</span>
<span class=n>p_false_null</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>beta</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>  <span class=c1># Skewed to small values</span>

<span class=n>p_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>p_true_null</span><span class=p>,</span> <span class=n>p_false_null</span><span class=p>])</span>
<span class=n>truth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=kc>False</span><span class=p>]</span><span class=o>*</span><span class=mi>90</span> <span class=o>+</span> <span class=p>[</span><span class=kc>True</span><span class=p>]</span><span class=o>*</span><span class=mi>10</span><span class=p>)</span>  <span class=c1># True = alternative is true</span>

<span class=c1># Method 1: Bonferroni (control FWER)</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>
<span class=n>bonf_reject</span> <span class=o>=</span> <span class=n>p_values</span> <span class=o>&lt;</span> <span class=n>alpha</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>

<span class=c1># Method 2: BH (control FDR)</span>
<span class=n>bh_reject</span> <span class=o>=</span> <span class=n>benjamini_hochberg</span><span class=p>(</span><span class=n>p_values</span><span class=p>,</span> <span class=n>alpha</span><span class=p>)</span>

<span class=c1># Evaluate</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Bonferroni:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Rejections: </span><span class=si>{</span><span class=n>bonf_reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  True positives: </span><span class=si>{</span><span class=p>(</span><span class=n>bonf_reject</span><span class=w> </span><span class=o>&amp;</span><span class=w> </span><span class=n>truth</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  False positives: </span><span class=si>{</span><span class=p>(</span><span class=n>bonf_reject</span><span class=w> </span><span class=o>&amp;</span><span class=w> </span><span class=o>~</span><span class=n>truth</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Benjamini-Hochberg:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Rejections: </span><span class=si>{</span><span class=n>bh_reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  True positives: </span><span class=si>{</span><span class=p>(</span><span class=n>bh_reject</span><span class=w> </span><span class=o>&amp;</span><span class=w> </span><span class=n>truth</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  False positives: </span><span class=si>{</span><span class=p>(</span><span class=n>bh_reject</span><span class=w> </span><span class=o>&amp;</span><span class=w> </span><span class=o>~</span><span class=n>truth</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=k>if</span> <span class=n>bh_reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
    <span class=n>fdr</span> <span class=o>=</span> <span class=p>(</span><span class=n>bh_reject</span> <span class=o>&amp;</span> <span class=o>~</span><span class=n>truth</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>/</span> <span class=n>bh_reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Empirical FDR: </span><span class=si>{</span><span class=n>fdr</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Visualization:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Plot sorted p-values with BH threshold</span>
<span class=n>sorted_p</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sort</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>
<span class=n>bh_line</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span> <span class=o>*</span> <span class=n>alpha</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>sorted_p</span><span class=p>,</span> <span class=s1>&#39;bo&#39;</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Sorted p-values&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>bh_line</span><span class=p>,</span> <span class=s1>&#39;r-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;BH line: (i/m)¬∑</span><span class=si>{</span><span class=n>alpha</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Rank&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;p-value&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Benjamini-Hochberg Procedure&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>When to Use FDR:</strong></p> <ul> <li><strong>Genomics:</strong> Test thousands of genes</li> <li><strong>A/B testing:</strong> Multiple variants</li> <li><strong>Feature selection:</strong> Many candidate features</li> <li><strong>Exploratory analysis:</strong> Generate hypotheses</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Multiple testing awareness.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Distinguishes FDR from FWER</li> <li>"Less conservative than Bonferroni"</li> <li>Knows BH procedure</li> <li>Mentions genomics/big data</li> </ul> </div> </details> <hr> <h3 id=explain-the-bonferroni-correction-most-tech-companies-interview-question>Explain the Bonferroni Correction - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Multiple Testing</code>, <code>FWER</code>, <code>Correction</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Bonferroni Correction:</strong></p> <p>When performing m hypothesis tests, control family-wise error rate (FWER) by testing each at level:</p> <div class=arithmatex>\[\alpha_{Bonf} = \frac{\alpha}{m}\]</div> <p><strong>Guarantees:</strong> P(at least one false positive) ‚â§ Œ±</p> <p><strong>Proof:</strong></p> <p>By union bound: <span class=arithmatex>\(<span class=arithmatex>\(P(\cup_{i=1}^m \{reject H_i | H_i true\}) \leq \sum_{i=1}^m P(reject H_i | H_i true) = m \cdot \frac{\alpha}{m} = \alpha\)</span>\)</span></p> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># Test 20 features for correlation with outcome</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=n>n</span> <span class=o>=</span> <span class=mi>100</span>  <span class=c1># samples</span>
<span class=n>m</span> <span class=o>=</span> <span class=mi>20</span>   <span class=c1># features</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>

<span class=c1># Generate data: all features independent of outcome</span>
<span class=n>features</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>m</span><span class=p>)</span>
<span class=n>outcome</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>

<span class=c1># Test each feature</span>
<span class=n>p_values</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>m</span><span class=p>):</span>
    <span class=n>corr</span><span class=p>,</span> <span class=n>p</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>pearsonr</span><span class=p>(</span><span class=n>features</span><span class=p>[:,</span> <span class=n>i</span><span class=p>],</span> <span class=n>outcome</span><span class=p>)</span>
    <span class=n>p_values</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>p</span><span class=p>)</span>

<span class=n>p_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>

<span class=c1># No correction</span>
<span class=n>naive_reject</span> <span class=o>=</span> <span class=n>p_values</span> <span class=o>&lt;</span> <span class=n>alpha</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;No correction: </span><span class=si>{</span><span class=n>naive_reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2> rejections&quot;</span><span class=p>)</span>

<span class=c1># Bonferroni correction</span>
<span class=n>bonf_reject</span> <span class=o>=</span> <span class=n>p_values</span> <span class=o>&lt;</span> <span class=n>alpha</span> <span class=o>/</span> <span class=n>m</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Bonferroni: </span><span class=si>{</span><span class=n>bonf_reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2> rejections&quot;</span><span class=p>)</span>

<span class=c1># All features are actually null, so any rejection is false positive</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>False positives (no correction): </span><span class=si>{</span><span class=n>naive_reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;False positives (Bonferroni): </span><span class=si>{</span><span class=n>bonf_reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Simulation - FWER Control:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Verify FWER control over many trials</span>
<span class=n>n_trials</span> <span class=o>=</span> <span class=mi>10000</span>
<span class=n>fwer_naive</span> <span class=o>=</span> <span class=mi>0</span>
<span class=n>fwer_bonf</span> <span class=o>=</span> <span class=mi>0</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_trials</span><span class=p>):</span>
    <span class=c1># Generate null data</span>
    <span class=n>features</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>m</span><span class=p>)</span>
    <span class=n>outcome</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>

    <span class=c1># Test</span>
    <span class=n>p_values</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>m</span><span class=p>):</span>
        <span class=n>_</span><span class=p>,</span> <span class=n>p</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>pearsonr</span><span class=p>(</span><span class=n>features</span><span class=p>[:,</span> <span class=n>i</span><span class=p>],</span> <span class=n>outcome</span><span class=p>)</span>
        <span class=n>p_values</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>p</span><span class=p>)</span>
    <span class=n>p_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>

    <span class=c1># Check if any false positive</span>
    <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>any</span><span class=p>(</span><span class=n>p_values</span> <span class=o>&lt;</span> <span class=n>alpha</span><span class=p>):</span>
        <span class=n>fwer_naive</span> <span class=o>+=</span> <span class=mi>1</span>
    <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>any</span><span class=p>(</span><span class=n>p_values</span> <span class=o>&lt;</span> <span class=n>alpha</span><span class=o>/</span><span class=n>m</span><span class=p>):</span>
        <span class=n>fwer_bonf</span> <span class=o>+=</span> <span class=mi>1</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Empirical FWER (no correction): </span><span class=si>{</span><span class=n>fwer_naive</span><span class=o>/</span><span class=n>n_trials</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Empirical FWER (Bonferroni): </span><span class=si>{</span><span class=n>fwer_bonf</span><span class=o>/</span><span class=n>n_trials</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Target FWER: </span><span class=si>{</span><span class=n>alpha</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Bonferroni successfully controls FWER ‚â§ 0.05</span>
</code></pre></div> <p><strong>Limitations:</strong></p> <table> <thead> <tr> <th>Issue</th> <th>Impact</th> </tr> </thead> <tbody> <tr> <td>Too conservative</td> <td>Low power for large m</td> </tr> <tr> <td>Assumes independence</td> <td>Actually works for any dependence!</td> </tr> <tr> <td>Loses power</td> <td>May miss true effects</td> </tr> </tbody> </table> <p><strong>When to Use:</strong></p> <ul> <li>Small number of tests (m &lt; 20)</li> <li>Need strong FWER control</li> <li>Tests are critical (avoid any false positive)</li> </ul> <p><strong>Alternatives:</strong></p> <ul> <li><strong>≈†id√°k correction:</strong> <span class=arithmatex>\(1-(1-\alpha)^{1/m}\)</span> (assumes independence)</li> <li><strong>Holm-Bonferroni:</strong> More powerful, still controls FWER</li> <li><strong>FDR methods:</strong> BH for exploratory analysis</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Multiple testing basics.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Formula Œ±/m</li> <li>"Controls FWER"</li> <li>Knows it's conservative</li> <li>Mentions alternatives (FDR, Holm)</li> </ul> </div> </details> <hr> <h3 id=what-is-the-two-child-problem-boy-girl-paradox-google-meta-interview-question>What is the Two-Child Problem (Boy-Girl Paradox)? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Conditional Probability</code>, <code>Paradox</code>, <code>Bayes</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>The Problem:</strong></p> <p>A family has two children. Given different information, what's P(both boys)?</p> <p><strong>Scenario 1:</strong> "At least one is a boy"</p> <p><strong>Scenario 2:</strong> "The eldest is a boy"</p> <p><strong>Solution:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Sample space: {BB, BG, GB, GG} where first is eldest</span>

<span class=c1># Scenario 1: At least one boy</span>
<span class=c1># Condition eliminates GG</span>
<span class=c1># Remaining: {BB, BG, GB}</span>
<span class=c1># P(both boys | at least one boy) = 1/3</span>

<span class=c1># Scenario 2: Eldest is boy</span>
<span class=c1># Condition eliminates {GG, GB}</span>
<span class=c1># Remaining: {BB, BG}</span>
<span class=c1># P(both boys | eldest is boy) = 1/2</span>
</code></pre></div> <p><strong>Simulation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=k>def</span><span class=w> </span><span class=nf>simulate_two_child</span><span class=p>(</span><span class=n>n_families</span><span class=o>=</span><span class=mi>100000</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Simulate two-child families&quot;&quot;&quot;</span>
    <span class=c1># 0 = girl, 1 = boy</span>
    <span class=n>eldest</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>n_families</span><span class=p>)</span>
    <span class=n>youngest</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>n_families</span><span class=p>)</span>

    <span class=c1># Scenario 1: At least one boy</span>
    <span class=n>at_least_one_boy</span> <span class=o>=</span> <span class=p>(</span><span class=n>eldest</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)</span> <span class=o>|</span> <span class=p>(</span><span class=n>youngest</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)</span>
    <span class=n>both_boys_given_one</span> <span class=o>=</span> <span class=p>((</span><span class=n>eldest</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>youngest</span> <span class=o>==</span> <span class=mi>1</span><span class=p>))[</span><span class=n>at_least_one_boy</span><span class=p>]</span>
    <span class=n>prob1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>both_boys_given_one</span><span class=p>)</span>

    <span class=c1># Scenario 2: Eldest is boy</span>
    <span class=n>eldest_is_boy</span> <span class=o>=</span> <span class=n>eldest</span> <span class=o>==</span> <span class=mi>1</span>
    <span class=n>both_boys_given_eldest</span> <span class=o>=</span> <span class=p>((</span><span class=n>eldest</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>youngest</span> <span class=o>==</span> <span class=mi>1</span><span class=p>))[</span><span class=n>eldest_is_boy</span><span class=p>]</span>
    <span class=n>prob2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>both_boys_given_eldest</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>prob1</span><span class=p>,</span> <span class=n>prob2</span>

<span class=n>p1</span><span class=p>,</span> <span class=n>p2</span> <span class=o>=</span> <span class=n>simulate_two_child</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(both boys | at least one boy) = </span><span class=si>{</span><span class=n>p1</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ‚âà 1/3&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(both boys | eldest is boy) = </span><span class=si>{</span><span class=n>p2</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ‚âà 1/2&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Bayes' Theorem Calculation:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Scenario 1: At least one boy</span>
<span class=c1># Prior: P(BB) = P(BG) = P(GB) = P(GG) = 1/4</span>

<span class=c1># P(at least one boy | BB) = 1</span>
<span class=c1># P(at least one boy | BG) = 1</span>
<span class=c1># P(at least one boy | GB) = 1</span>
<span class=c1># P(at least one boy | GG) = 0</span>

<span class=c1># P(at least one boy) = 3/4</span>

<span class=c1># P(BB | at least one boy) = P(at least one | BB)¬∑P(BB) / P(at least one)</span>
<span class=c1>#                          = 1 ¬∑ (1/4) / (3/4) = 1/3</span>
</code></pre></div> <p><strong>Famous Variant - Tuesday Boy:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># &quot;I have two children, one is a boy born on Tuesday&quot;</span>
<span class=c1># What&#39;s P(both boys)?</span>

<span class=c1># This is surprisingly DIFFERENT from 1/3!</span>

<span class=c1># Sample space: 14√ó14 = 196 equally likely outcomes</span>
<span class=c1># (day_eldest, sex_eldest) √ó (day_youngest, sex_youngest)</span>

<span class=k>def</span><span class=w> </span><span class=nf>tuesday_boy_problem</span><span class=p>():</span>
    <span class=n>days</span> <span class=o>=</span> <span class=mi>7</span>
    <span class=n>count_condition</span> <span class=o>=</span> <span class=mi>0</span>  <span class=c1># At least one Tuesday boy</span>
    <span class=n>count_both_boys</span> <span class=o>=</span> <span class=mi>0</span>   <span class=c1># Both boys given condition</span>

    <span class=k>for</span> <span class=n>day1</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>days</span><span class=p>):</span>
        <span class=k>for</span> <span class=n>sex1</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]:</span>  <span class=c1># 0=girl, 1=boy</span>
            <span class=k>for</span> <span class=n>day2</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>days</span><span class=p>):</span>
                <span class=k>for</span> <span class=n>sex2</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]:</span>
                    <span class=c1># Check condition: at least one Tuesday boy</span>
                    <span class=n>tuesday_boy</span> <span class=o>=</span> <span class=p>(</span><span class=n>sex1</span><span class=o>==</span><span class=mi>1</span> <span class=ow>and</span> <span class=n>day1</span><span class=o>==</span><span class=mi>2</span><span class=p>)</span> <span class=ow>or</span> <span class=p>(</span><span class=n>sex2</span><span class=o>==</span><span class=mi>1</span> <span class=ow>and</span> <span class=n>day2</span><span class=o>==</span><span class=mi>2</span><span class=p>)</span>

                    <span class=k>if</span> <span class=n>tuesday_boy</span><span class=p>:</span>
                        <span class=n>count_condition</span> <span class=o>+=</span> <span class=mi>1</span>
                        <span class=k>if</span> <span class=n>sex1</span> <span class=o>==</span> <span class=mi>1</span> <span class=ow>and</span> <span class=n>sex2</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
                            <span class=n>count_both_boys</span> <span class=o>+=</span> <span class=mi>1</span>

    <span class=k>return</span> <span class=n>count_both_boys</span> <span class=o>/</span> <span class=n>count_condition</span>

<span class=n>prob</span> <span class=o>=</span> <span class=n>tuesday_boy_problem</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(both boys | Tuesday boy) = </span><span class=si>{</span><span class=n>prob</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2> ‚âà 13/27 ‚âà 0.481&quot;</span><span class=p>)</span>
<span class=c1># NOT 1/3! The specific day information changes probability</span>
</code></pre></div> <p><strong>Why This Matters:</strong></p> <p>Subtle differences in information drastically change probabilities!</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Careful conditional probability reasoning.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Distinguishes the two scenarios clearly</li> <li>&#8531; vs &frac12; with explanation</li> <li>Can use Bayes or counting</li> <li>Mentions Tuesday boy variant</li> </ul> </div> </details> <hr> <h3 id=explain-the-st-petersburg-paradox-google-meta-interview-question>Explain the St. Petersburg Paradox - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Expected Value</code>, <code>Utility Theory</code>, <code>Paradox</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>The Paradox:</strong></p> <p>Game: Flip fair coin repeatedly until tails. You win $2^n where n = number of flips.</p> <table> <thead> <tr> <th>Outcome</th> <th>Probability</th> <th>Payoff</th> </tr> </thead> <tbody> <tr> <td>T</td> <td>&frac12;</td> <td>$2</td> </tr> <tr> <td>HT</td> <td>&frac14;</td> <td>$4</td> </tr> <tr> <td>HHT</td> <td>&#8539;</td> <td>$8</td> </tr> <tr> <td>HHH...T</td> <td>&frac12;^n</td> <td>$2^n</td> </tr> </tbody> </table> <p><strong>Expected Value:</strong></p> <div class=arithmatex>\[E[X] = \sum_{n=1}^\infty \frac{1}{2^n} \cdot 2^n = \sum_{n=1}^\infty 1 = \infty\]</div> <p><strong>The Paradox:</strong> Infinite expected value, but no one would pay much to play!</p> <p><strong>Simulation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=k>def</span><span class=w> </span><span class=nf>play_st_petersburg</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Play one game&quot;&quot;&quot;</span>
    <span class=n>n</span> <span class=o>=</span> <span class=mi>1</span>
    <span class=k>while</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>()</span> <span class=o>&gt;=</span> <span class=mf>0.5</span><span class=p>:</span>  <span class=c1># While heads</span>
        <span class=n>n</span> <span class=o>+=</span> <span class=mi>1</span>
    <span class=k>return</span> <span class=mi>2</span><span class=o>**</span><span class=n>n</span>

<span class=c1># Simulate many games</span>
<span class=n>payoffs</span> <span class=o>=</span> <span class=p>[</span><span class=n>play_st_petersburg</span><span class=p>()</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>)]</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean payoff: $</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>payoffs</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Median payoff: $</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>payoffs</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Max payoff: $</span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>payoffs</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Distribution is extremely skewed!</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>payoffs</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Payoff ($)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Frequency&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Distribution of Payoffs&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>log2</span><span class=p>(</span><span class=n>payoffs</span><span class=p>),</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;log‚ÇÇ(Payoff)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Frequency&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Log-scale Distribution&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Resolution 1: Utility Theory:</strong></p> <p>People maximize expected <em>utility</em>, not expected value.</p> <div class=highlight><pre><span></span><code><span class=c1># Log utility: U(x) = log(x)</span>

<span class=k>def</span><span class=w> </span><span class=nf>expected_utility_log</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Expected utility with log utility&quot;&quot;&quot;</span>
    <span class=n>eu</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>100</span><span class=p>):</span>  <span class=c1># Approximate infinite sum</span>
        <span class=n>prob</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=mi>2</span><span class=o>**</span><span class=n>n</span>
        <span class=n>payoff</span> <span class=o>=</span> <span class=mi>2</span><span class=o>**</span><span class=n>n</span>
        <span class=n>utility</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>payoff</span><span class=p>)</span>  <span class=c1># log utility</span>
        <span class=n>eu</span> <span class=o>+=</span> <span class=n>prob</span> <span class=o>*</span> <span class=n>utility</span>
    <span class=k>return</span> <span class=n>eu</span>

<span class=n>eu</span> <span class=o>=</span> <span class=n>expected_utility_log</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected utility (log): </span><span class=si>{</span><span class=n>eu</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Certainty equivalent: amount x where U(x) = E[U(game)]</span>
<span class=n>ce</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>eu</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Certainty equivalent: $</span><span class=si>{</span><span class=n>ce</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Person would pay ~$4-5, not infinite!</span>
</code></pre></div> <p><strong>Resolution 2: Finite Wealth:</strong></p> <p>Casino has finite wealth ‚Üí can't pay arbitrarily large payoffs.</p> <div class=highlight><pre><span></span><code><span class=c1># Casino has $1M</span>
<span class=n>max_payoff</span> <span class=o>=</span> <span class=mi>1_000_000</span>

<span class=c1># Find maximum n where 2^n ‚â§ 1M</span>
<span class=n>max_n</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>log2</span><span class=p>(</span><span class=n>max_payoff</span><span class=p>))</span>  <span class=c1># 19</span>

<span class=c1># Expected value with cap</span>
<span class=n>ev_capped</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=mi>2</span><span class=o>**</span><span class=n>n</span> <span class=o>/</span> <span class=mi>2</span><span class=o>**</span><span class=n>n</span> <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>max_n</span><span class=p>))</span> <span class=o>+</span> \
            <span class=n>max_payoff</span> <span class=o>/</span> <span class=mi>2</span><span class=o>**</span><span class=n>max_n</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected value (capped at $</span><span class=si>{</span><span class=n>max_payoff</span><span class=si>}</span><span class=s2>): $</span><span class=si>{</span><span class=n>ev_capped</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Now finite: ~$20</span>
</code></pre></div> <p><strong>Resolution 3: Diminishing Marginal Utility:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Square root utility: U(x) = ‚àöx</span>

<span class=k>def</span><span class=w> </span><span class=nf>expected_utility_sqrt</span><span class=p>():</span>
    <span class=n>eu</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>100</span><span class=p>):</span>
        <span class=n>prob</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=mi>2</span><span class=o>**</span><span class=n>n</span>
        <span class=n>payoff</span> <span class=o>=</span> <span class=mi>2</span><span class=o>**</span><span class=n>n</span>
        <span class=n>utility</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>payoff</span><span class=p>)</span>
        <span class=n>eu</span> <span class=o>+=</span> <span class=n>prob</span> <span class=o>*</span> <span class=n>utility</span>
    <span class=k>return</span> <span class=n>eu</span>

<span class=n>eu</span> <span class=o>=</span> <span class=n>expected_utility_sqrt</span><span class=p>()</span>
<span class=n>ce</span> <span class=o>=</span> <span class=n>eu</span><span class=o>**</span><span class=mi>2</span>  <span class=c1># Invert square root</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Certainty equivalent (‚àö utility): $</span><span class=si>{</span><span class=n>ce</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Deep understanding of expected value limitations.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Knows E[X] = ‚àû</li> <li>"But no one would pay infinite!"</li> <li>Mentions utility theory</li> <li>Discusses finite wealth constraint</li> </ul> </div> </details> <hr> <h3 id=what-is-the-gamblers-ruin-problem-google-amazon-interview-question>What is the Gambler's Ruin Problem? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Random Walk</code>, <code>Absorbing States</code>, <code>Markov Chain</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Problem Setup:</strong></p> <p>Gambler starts with $a, plays until wealth = $0 or $N. Each bet wins $1 with prob p, loses $1 with prob q=1-p.</p> <p><strong>Question:</strong> P(ruin | start at $a)?</p> <p><strong>Solution:</strong></p> <p>Let P_i = probability of ruin starting at $i.</p> <p>Boundary: P_0 = 1, P_N = 0</p> <p>Recurrence: <span class=arithmatex>\(P_i = p \cdot P_{i+1} + q \cdot P_{i-1}\)</span></p> <p><strong>Closed Form:</strong></p> <p>If p ‚â† &frac12;:</p> <div class=arithmatex>\[P_a = \frac{(q/p)^a - (q/p)^N}{1 - (q/p)^N}\]</div> <p>If p = &frac12; (fair game):</p> <div class=arithmatex>\[P_a = 1 - \frac{a}{N}\]</div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=k>def</span><span class=w> </span><span class=nf>gamblers_ruin_analytical</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Analytical solution&quot;&quot;&quot;</span>
    <span class=k>if</span> <span class=n>p</span> <span class=o>==</span> <span class=mf>0.5</span><span class=p>:</span>
        <span class=k>return</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>a</span> <span class=o>/</span> <span class=n>N</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>q</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>p</span>
        <span class=n>ratio</span> <span class=o>=</span> <span class=n>q</span> <span class=o>/</span> <span class=n>p</span>
        <span class=k>return</span> <span class=p>(</span><span class=n>ratio</span><span class=o>**</span><span class=n>a</span> <span class=o>-</span> <span class=n>ratio</span><span class=o>**</span><span class=n>N</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>ratio</span><span class=o>**</span><span class=n>N</span><span class=p>)</span>

<span class=k>def</span><span class=w> </span><span class=nf>gamblers_ruin_simulation</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>,</span> <span class=n>n_sims</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Monte Carlo simulation&quot;&quot;&quot;</span>
    <span class=n>ruins</span> <span class=o>=</span> <span class=mi>0</span>

    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_sims</span><span class=p>):</span>
        <span class=n>wealth</span> <span class=o>=</span> <span class=n>a</span>

        <span class=k>while</span> <span class=mi>0</span> <span class=o>&lt;</span> <span class=n>wealth</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>()</span> <span class=o>&lt;</span> <span class=n>p</span><span class=p>:</span>
                <span class=n>wealth</span> <span class=o>+=</span> <span class=mi>1</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>wealth</span> <span class=o>-=</span> <span class=mi>1</span>

        <span class=k>if</span> <span class=n>wealth</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>ruins</span> <span class=o>+=</span> <span class=mi>1</span>

    <span class=k>return</span> <span class=n>ruins</span> <span class=o>/</span> <span class=n>n_sims</span>

<span class=c1># Example: Start with $30, play until $0 or $100</span>
<span class=n>a</span> <span class=o>=</span> <span class=mi>30</span>
<span class=n>N</span> <span class=o>=</span> <span class=mi>100</span>

<span class=c1># Fair game (p=0.5)</span>
<span class=n>p</span> <span class=o>=</span> <span class=mf>0.5</span>
<span class=n>prob_analytical</span> <span class=o>=</span> <span class=n>gamblers_ruin_analytical</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
<span class=n>prob_simulation</span> <span class=o>=</span> <span class=n>gamblers_ruin_simulation</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Fair game (p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Analytical: P(ruin) = </span><span class=si>{</span><span class=n>prob_analytical</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Simulation: P(ruin) = </span><span class=si>{</span><span class=n>prob_simulation</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Unfavorable game (p=0.48)</span>
<span class=n>p</span> <span class=o>=</span> <span class=mf>0.48</span>
<span class=n>prob_analytical</span> <span class=o>=</span> <span class=n>gamblers_ruin_analytical</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
<span class=n>prob_simulation</span> <span class=o>=</span> <span class=n>gamblers_ruin_simulation</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Unfavorable game (p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Analytical: P(ruin) = </span><span class=si>{</span><span class=n>prob_analytical</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Simulation: P(ruin) = </span><span class=si>{</span><span class=n>prob_simulation</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Visualize P(ruin) vs Starting Wealth:</strong></p> <div class=highlight><pre><span></span><code><span class=n>N</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>starting_wealths</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>N</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>

<span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=p>[</span><span class=mf>0.45</span><span class=p>,</span> <span class=mf>0.48</span><span class=p>,</span> <span class=mf>0.50</span><span class=p>,</span> <span class=mf>0.52</span><span class=p>]:</span>
    <span class=n>probs</span> <span class=o>=</span> <span class=p>[</span><span class=n>gamblers_ruin_analytical</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span> <span class=k>for</span> <span class=n>a</span> <span class=ow>in</span> <span class=n>starting_wealths</span><span class=p>]</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>starting_wealths</span><span class=p>,</span> <span class=n>probs</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Starting wealth ($)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;P(ruin)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;Gambler&#39;s Ruin Probability&quot;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Key Insights:</strong></p> <ol> <li><strong>Fair game (p=0.5):</strong> Eventually go broke with prob 1 if N=‚àû</li> <li><strong>Unfavorable game (p&lt;0.5):</strong> Very likely to go broke</li> <li><strong>Favorable game (p&gt;0.5):</strong> Can win if enough capital</li> </ol> <p><strong>Expected Duration:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Expected # games until absorbing state</span>

<span class=k>def</span><span class=w> </span><span class=nf>expected_duration</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>):</span>
    <span class=k>if</span> <span class=n>p</span> <span class=o>==</span> <span class=mf>0.5</span><span class=p>:</span>
        <span class=k>return</span> <span class=n>a</span> <span class=o>*</span> <span class=p>(</span><span class=n>N</span> <span class=o>-</span> <span class=n>a</span><span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>q</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>p</span>
        <span class=n>P_ruin</span> <span class=o>=</span> <span class=n>gamblers_ruin_analytical</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
        <span class=k>return</span> <span class=p>(</span><span class=n>a</span> <span class=o>-</span> <span class=n>N</span> <span class=o>*</span> <span class=n>P_ruin</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=mi>2</span><span class=o>*</span><span class=n>p</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>

<span class=n>a</span><span class=p>,</span> <span class=n>N</span> <span class=o>=</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>100</span>
<span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=p>[</span><span class=mf>0.48</span><span class=p>,</span> <span class=mf>0.50</span><span class=p>,</span> <span class=mf>0.52</span><span class=p>]:</span>
    <span class=n>duration</span> <span class=o>=</span> <span class=n>expected_duration</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s2>: E[duration] = </span><span class=si>{</span><span class=n>duration</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> games&quot;</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Random walk &amp; Markov chain knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>States recurrence relation</li> <li>Knows closed form solution</li> <li>Fair game: linear in a/N</li> <li>Can simulate to verify</li> </ul> </div> </details> <hr> <h3 id=explain-benfords-law-meta-amazon-interview-question>Explain Benford's Law - Meta, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>First Digit Law</code>, <code>Applications</code>, <code>Fraud Detection</code> | <strong>Asked by:</strong> Meta, Amazon, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Benford's Law:</strong></p> <p>In many naturally occurring datasets, the leading digit d appears with probability:</p> <div class=arithmatex>\[P(d) = \log_{10}\left(1 + \frac{1}{d}\right)\]</div> <p><strong>Distribution:</strong></p> <table> <thead> <tr> <th>Digit</th> <th>Probability</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>30.1%</td> </tr> <tr> <td>2</td> <td>17.6%</td> </tr> <tr> <td>3</td> <td>12.5%</td> </tr> <tr> <td>4</td> <td>9.7%</td> </tr> <tr> <td>5</td> <td>7.9%</td> </tr> <tr> <td>6</td> <td>6.7%</td> </tr> <tr> <td>7</td> <td>5.8%</td> </tr> <tr> <td>8</td> <td>5.1%</td> </tr> <tr> <td>9</td> <td>4.6%</td> </tr> </tbody> </table> <p><strong>Why It Works:</strong></p> <p>Applies to data spanning multiple orders of magnitude with scale-invariance property.</p> <p><strong>Test with Real Data:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>collections</span><span class=w> </span><span class=kn>import</span> <span class=n>Counter</span>

<span class=k>def</span><span class=w> </span><span class=nf>benfords_law</span><span class=p>(</span><span class=n>d</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Theoretical probability for digit d&quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>log10</span><span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=mi>1</span><span class=o>/</span><span class=n>d</span><span class=p>)</span>

<span class=c1># Example 1: Population of US cities</span>
<span class=c1># (You&#39;d load real data, here we simulate)</span>
<span class=n>populations</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>lognormal</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>first_digits</span> <span class=o>=</span> <span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>p</span><span class=p>))[</span><span class=mi>0</span><span class=p>])</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>populations</span><span class=p>]</span>

<span class=c1># Count frequencies</span>
<span class=n>counts</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>first_digits</span><span class=p>)</span>
<span class=n>observed</span> <span class=o>=</span> <span class=p>[</span><span class=n>counts</span><span class=p>[</span><span class=n>d</span><span class=p>]</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>first_digits</span><span class=p>)</span> <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)]</span>
<span class=n>expected</span> <span class=o>=</span> <span class=p>[</span><span class=n>benfords_law</span><span class=p>(</span><span class=n>d</span><span class=p>)</span> <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)]</span>

<span class=c1># Plot</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=n>width</span> <span class=o>=</span> <span class=mf>0.35</span>

<span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>x</span> <span class=o>-</span> <span class=n>width</span><span class=o>/</span><span class=mi>2</span><span class=p>,</span> <span class=n>observed</span><span class=p>,</span> <span class=n>width</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Observed&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>x</span> <span class=o>+</span> <span class=n>width</span><span class=o>/</span><span class=mi>2</span><span class=p>,</span> <span class=n>expected</span><span class=p>,</span> <span class=n>width</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&quot;Benford&#39;s Law&quot;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;First Digit&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;Benford&#39;s Law: Population Data&quot;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Chi-Square Test:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chisquare</span>

<span class=c1># Test if data follows Benford&#39;s law</span>
<span class=n>observed_counts</span> <span class=o>=</span> <span class=p>[</span><span class=n>counts</span><span class=p>[</span><span class=n>d</span><span class=p>]</span> <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)]</span>
<span class=n>expected_counts</span> <span class=o>=</span> <span class=p>[</span><span class=n>benfords_law</span><span class=p>(</span><span class=n>d</span><span class=p>)</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>first_digits</span><span class=p>)</span> <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)]</span>

<span class=n>chi2</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>chisquare</span><span class=p>(</span><span class=n>observed_counts</span><span class=p>,</span> <span class=n>expected_counts</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Chi-square test:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  œá¬≤ = </span><span class=si>{</span><span class=n>chi2</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  p-value = </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=k>if</span> <span class=n>p_value</span> <span class=o>&gt;</span> <span class=mf>0.05</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;  ‚Üí Consistent with Benford&#39;s law&quot;</span><span class=p>)</span>
<span class=k>else</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;  ‚Üí Deviates from Benford&#39;s law&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Fraud Detection Application:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Example: Expense reports</span>

<span class=c1># Legitimate expenses (log-normal)</span>
<span class=n>legit</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>lognormal</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>

<span class=c1># Fraudulent expenses (made up, tend to use all digits equally)</span>
<span class=n>fraud</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>999</span><span class=p>,</span> <span class=mi>300</span><span class=p>)</span>

<span class=k>def</span><span class=w> </span><span class=nf>get_first_digit_dist</span><span class=p>(</span><span class=n>data</span><span class=p>):</span>
    <span class=n>first_digits</span> <span class=o>=</span> <span class=p>[</span><span class=nb>int</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>x</span><span class=p>))[</span><span class=mi>0</span><span class=p>])</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>data</span><span class=p>]</span>
    <span class=n>counts</span> <span class=o>=</span> <span class=n>Counter</span><span class=p>(</span><span class=n>first_digits</span><span class=p>)</span>
    <span class=k>return</span> <span class=p>[</span><span class=n>counts</span><span class=p>[</span><span class=n>d</span><span class=p>]</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>first_digits</span><span class=p>)</span> <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)]</span>

<span class=n>legit_dist</span> <span class=o>=</span> <span class=n>get_first_digit_dist</span><span class=p>(</span><span class=n>legit</span><span class=p>)</span>
<span class=n>fraud_dist</span> <span class=o>=</span> <span class=n>get_first_digit_dist</span><span class=p>(</span><span class=n>fraud</span><span class=p>)</span>
<span class=n>benfords</span> <span class=o>=</span> <span class=p>[</span><span class=n>benfords_law</span><span class=p>(</span><span class=n>d</span><span class=p>)</span> <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)]</span>

<span class=c1># Calculate deviation from Benford</span>
<span class=n>legit_dev</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>((</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>legit_dist</span><span class=p>)</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>benfords</span><span class=p>))</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>
<span class=n>fraud_dev</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>((</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>fraud_dist</span><span class=p>)</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>benfords</span><span class=p>))</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Deviation from Benford&#39;s law:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Legitimate: </span><span class=si>{</span><span class=n>legit_dev</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Fraudulent: </span><span class=si>{</span><span class=n>fraud_dev</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>When Benford's Law Applies:</strong></p> <ul> <li>Financial data (stock prices, expenses)</li> <li>Scientific data (physical constants, populations)</li> <li>Data spanning orders of magnitude</li> </ul> <p><strong>When It Doesn't Apply:</strong></p> <ul> <li>Assigned numbers (phone numbers, SSN)</li> <li>Data with artificial limits</li> <li>Uniform distributions</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Awareness of statistical patterns.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>log‚ÇÅ‚ÇÄ(1 + 1/d) formula</li> <li>"1 appears ~30% of time"</li> <li>Mentions fraud detection</li> <li>Knows scale-invariance property</li> </ul> </div> </details> <hr> <h3 id=what-is-the-hyperparameter-tuning-problem-in-bayesian-terms-google-meta-interview-question>What is the Hyperparameter Tuning Problem in Bayesian Terms? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Bayesian Optimization</code>, <code>ML</code>, <code>Probability</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Problem:</strong></p> <p>Given expensive black-box function f(x) (e.g., model validation accuracy), find x* that maximizes f.</p> <p><strong>Bayesian Optimization Approach:</strong></p> <ol> <li><strong>Prior:</strong> Gaussian Process over f</li> <li><strong>Acquisition:</strong> Balance exploration/exploitation</li> <li><strong>Update:</strong> Posterior after observing f(x)</li> </ol> <p><strong>Key Components:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>norm</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.optimize</span><span class=w> </span><span class=kn>import</span> <span class=n>minimize</span>

<span class=k>class</span><span class=w> </span><span class=nc>BayesianOptimization</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>X_observed</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>y_observed</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=k>def</span><span class=w> </span><span class=nf>gp_predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X_test</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Simplified GP prediction</span>
<span class=sd>        Returns: mean, std</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>X_observed</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>X_test</span><span class=p>)),</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>X_test</span><span class=p>))</span>

        <span class=c1># Simplified: use nearest neighbor</span>
        <span class=c1># (Real implementation uses kernel functions)</span>
        <span class=n>means</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=n>stds</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>X_test</span><span class=p>:</span>
            <span class=c1># Find nearest observed point</span>
            <span class=n>distances</span> <span class=o>=</span> <span class=p>[</span><span class=nb>abs</span><span class=p>(</span><span class=n>x</span> <span class=o>-</span> <span class=n>x_obs</span><span class=p>)</span> <span class=k>for</span> <span class=n>x_obs</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>X_observed</span><span class=p>]</span>
            <span class=n>nearest_idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>distances</span><span class=p>)</span>
            <span class=n>nearest_dist</span> <span class=o>=</span> <span class=n>distances</span><span class=p>[</span><span class=n>nearest_idx</span><span class=p>]</span>

            <span class=c1># Interpolate</span>
            <span class=n>mean</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>y_observed</span><span class=p>[</span><span class=n>nearest_idx</span><span class=p>]</span>
            <span class=n>std</span> <span class=o>=</span> <span class=mf>0.1</span> <span class=o>+</span> <span class=n>nearest_dist</span> <span class=o>*</span> <span class=mf>0.5</span>  <span class=c1># Uncertainty increases with distance</span>

            <span class=n>means</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>mean</span><span class=p>)</span>
            <span class=n>stds</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>std</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>means</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>stds</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>acquisition_ucb</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>kappa</span><span class=o>=</span><span class=mf>2.0</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Upper Confidence Bound acquisition&quot;&quot;&quot;</span>
        <span class=n>mean</span><span class=p>,</span> <span class=n>std</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gp_predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>mean</span> <span class=o>+</span> <span class=n>kappa</span> <span class=o>*</span> <span class=n>std</span>

    <span class=k>def</span><span class=w> </span><span class=nf>acquisition_ei</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>xi</span><span class=o>=</span><span class=mf>0.01</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Expected Improvement acquisition&quot;&quot;&quot;</span>
        <span class=n>mean</span><span class=p>,</span> <span class=n>std</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gp_predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>

        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>y_observed</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>

        <span class=n>best</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>y_observed</span><span class=p>)</span>

        <span class=c1># Expected improvement</span>
        <span class=n>z</span> <span class=o>=</span> <span class=p>(</span><span class=n>mean</span> <span class=o>-</span> <span class=n>best</span> <span class=o>-</span> <span class=n>xi</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>std</span> <span class=o>+</span> <span class=mf>1e-9</span><span class=p>)</span>
        <span class=n>ei</span> <span class=o>=</span> <span class=p>(</span><span class=n>mean</span> <span class=o>-</span> <span class=n>best</span> <span class=o>-</span> <span class=n>xi</span><span class=p>)</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>z</span><span class=p>)</span> <span class=o>+</span> <span class=n>std</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>z</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>ei</span>

    <span class=k>def</span><span class=w> </span><span class=nf>suggest_next</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>bounds</span><span class=p>,</span> <span class=n>acquisition</span><span class=o>=</span><span class=s1>&#39;ei&#39;</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Suggest next point to evaluate&quot;&quot;&quot;</span>
        <span class=c1># Grid search over acquisition function</span>
        <span class=n>X_candidates</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>bounds</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>bounds</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=mi>1000</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>acquisition</span> <span class=o>==</span> <span class=s1>&#39;ei&#39;</span><span class=p>:</span>
            <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>acquisition_ei</span><span class=p>(</span><span class=n>X_candidates</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>acquisition_ucb</span><span class=p>(</span><span class=n>X_candidates</span><span class=p>)</span>

        <span class=n>best_idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>X_candidates</span><span class=p>[</span><span class=n>best_idx</span><span class=p>]</span>

    <span class=k>def</span><span class=w> </span><span class=nf>observe</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Add observation&quot;&quot;&quot;</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>X_observed</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>y_observed</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>

<span class=c1># Example: Optimize noisy function</span>
<span class=k>def</span><span class=w> </span><span class=nf>objective</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;True function to optimize (unknown to optimizer)&quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>+</span> <span class=mf>0.1</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>()</span>

<span class=c1># Run Bayesian Optimization</span>
<span class=n>bo</span> <span class=o>=</span> <span class=n>BayesianOptimization</span><span class=p>()</span>
<span class=n>bounds</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>]</span>

<span class=c1># Initial random samples</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
    <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=n>bounds</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>bounds</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
    <span class=n>y</span> <span class=o>=</span> <span class=n>objective</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
    <span class=n>bo</span><span class=o>.</span><span class=n>observe</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>

<span class=c1># Iterative optimization</span>
<span class=k>for</span> <span class=n>iteration</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>20</span><span class=p>):</span>
    <span class=c1># Suggest next point</span>
    <span class=n>x_next</span> <span class=o>=</span> <span class=n>bo</span><span class=o>.</span><span class=n>suggest_next</span><span class=p>(</span><span class=n>bounds</span><span class=p>,</span> <span class=n>acquisition</span><span class=o>=</span><span class=s1>&#39;ei&#39;</span><span class=p>)</span>
    <span class=n>y_next</span> <span class=o>=</span> <span class=n>objective</span><span class=p>(</span><span class=n>x_next</span><span class=p>)</span>
    <span class=n>bo</span><span class=o>.</span><span class=n>observe</span><span class=p>(</span><span class=n>x_next</span><span class=p>,</span> <span class=n>y_next</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Iter </span><span class=si>{</span><span class=n>iteration</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>: x=</span><span class=si>{</span><span class=n>x_next</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, f(x)=</span><span class=si>{</span><span class=n>y_next</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, best=</span><span class=si>{</span><span class=nb>max</span><span class=p>(</span><span class=n>bo</span><span class=o>.</span><span class=n>y_observed</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=n>X_plot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>bounds</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>bounds</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=mi>200</span><span class=p>)</span>
<span class=n>y_true</span> <span class=o>=</span> <span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>X_plot</span><span class=p>]</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>X_plot</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=s1>&#39;k-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;True function&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>bo</span><span class=o>.</span><span class=n>X_observed</span><span class=p>,</span> <span class=n>bo</span><span class=o>.</span><span class=n>y_observed</span><span class=p>,</span> <span class=n>c</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>zorder</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Observations&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;f(x)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Bayesian Optimization Progress&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=n>best_so_far</span> <span class=o>=</span> <span class=p>[</span><span class=nb>max</span><span class=p>(</span><span class=n>bo</span><span class=o>.</span><span class=n>y_observed</span><span class=p>[:</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>])</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>bo</span><span class=o>.</span><span class=n>y_observed</span><span class=p>))]</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>best_so_far</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=nb>max</span><span class=p>(</span><span class=n>y_true</span><span class=p>),</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;True maximum&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Iteration&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Best f(x) found&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Convergence&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Acquisition Functions:</strong></p> <table> <thead> <tr> <th>Function</th> <th>Formula</th> <th>Trade-off</th> </tr> </thead> <tbody> <tr> <td>UCB</td> <td>Œº + Œ∫œÉ</td> <td>Œ∫ controls exploration</td> </tr> <tr> <td>EI</td> <td>E[max(0, f - f_best)]</td> <td>Probabilistic improvement</td> </tr> <tr> <td>PI</td> <td>P(f &gt; f_best)</td> <td>Binary improvement</td> </tr> </tbody> </table> <p><strong>Applications:</strong></p> <ul> <li>Hyperparameter tuning (learning rate, depth, etc.)</li> <li>Neural architecture search</li> <li>A/B test parameter optimization</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> ML + probability integration.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Mentions Gaussian Process</li> <li>Knows acquisition functions (EI, UCB)</li> <li>Exploration vs exploitation</li> <li>"Fewer expensive evaluations"</li> </ul> </div> </details> <hr> <h3 id=what-is-a-sufficient-statistic-give-examples-google-amazon-interview-question>What is a Sufficient Statistic? Give Examples - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Sufficient Statistics</code>, <code>Theory</code>, <code>Estimation</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Sufficient Statistic:</strong></p> <p>Statistic T(X) is sufficient for parameter Œ∏ if:</p> <div class=arithmatex>\[P(X | T(X), \theta) = P(X | T(X))\]</div> <p><strong>Meaning:</strong> Given T(X), the data X provides no additional information about Œ∏.</p> <p><strong>Factorization Theorem:</strong></p> <p>T(X) is sufficient iff:</p> <div class=arithmatex>\[f(x|\theta) = g(T(x), \theta) \cdot h(x)\]</div> <p><strong>Example 1 - Bernoulli:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>binom</span>

<span class=c1># Data: n Bernoulli trials</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
<span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=c1># Sufficient statistic: T(X) = sum(X)</span>
<span class=n>T</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>  <span class=c1># = 7</span>

<span class=c1># Given T=7 out of n=10, any sequence with 7 ones is equally likely</span>
<span class=c1># The order doesn&#39;t matter for estimating p!</span>

<span class=c1># MLE using full data</span>
<span class=n>p_mle_full</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>

<span class=c1># MLE using only sufficient statistic</span>
<span class=n>p_mle_suff</span> <span class=o>=</span> <span class=n>T</span> <span class=o>/</span> <span class=n>n</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;MLE from full data: </span><span class=si>{</span><span class=n>p_mle_full</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;MLE from sufficient stat: </span><span class=si>{</span><span class=n>p_mle_suff</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Identical!</span>
</code></pre></div> <p><strong>Example 2 - Normal Distribution:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># X‚ÇÅ,...,X‚Çô ~ N(Œº, œÉ¬≤) with œÉ¬≤ known</span>
<span class=c1># Sufficient statistic: T(X) = mean(X)</span>

<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>

<span class=c1># Estimate Œº using full data</span>
<span class=n>mu_mle_full</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=c1># Estimate Œº using only sufficient statistic (sample mean)</span>
<span class=n>T</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  <span class=c1># This is sufficient</span>
<span class=n>mu_mle_suff</span> <span class=o>=</span> <span class=n>T</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Œº MLE from full data: </span><span class=si>{</span><span class=n>mu_mle_full</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Œº MLE from sufficient stat: </span><span class=si>{</span><span class=n>mu_mle_suff</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># If both Œº and œÉ¬≤ unknown:</span>
<span class=c1># Sufficient statistic: (mean(X), variance(X))</span>
<span class=n>T</span> <span class=o>=</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>ddof</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Sufficient stat (Œº,œÉ¬≤ unknown): mean=</span><span class=si>{</span><span class=n>T</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, var=</span><span class=si>{</span><span class=n>T</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Example 3 - Uniform(0, Œ∏):</strong></p> <div class=highlight><pre><span></span><code><span class=c1># X‚ÇÅ,...,X‚Çô ~ Uniform(0, Œ∏)</span>
<span class=c1># Sufficient statistic: T(X) = max(X)</span>

<span class=n>true_theta</span> <span class=o>=</span> <span class=mi>10</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>true_theta</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>

<span class=c1># MLE: Œ∏ÃÇ = max(X)</span>
<span class=n>theta_mle</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>True Œ∏: </span><span class=si>{</span><span class=n>true_theta</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;MLE (using max only): </span><span class=si>{</span><span class=n>theta_mle</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># The maximum is sufficient - we don&#39;t need individual values!</span>
</code></pre></div> <p><strong>Minimal Sufficient Statistic:</strong></p> <p>Can't be reduced further without losing information.</p> <div class=highlight><pre><span></span><code><span class=c1># For Bernoulli: sum(X) is minimal sufficient</span>
<span class=c1># Can&#39;t do better than just counting successes</span>

<span class=c1># For Normal(Œº, œÉ¬≤): (mean, variance) is minimal sufficient</span>
<span class=c1># Need both for complete inference</span>
</code></pre></div> <p><strong>Why It Matters:</strong></p> <table> <thead> <tr> <th>Benefit</th> <th>Explanation</th> </tr> </thead> <tbody> <tr> <td>Data reduction</td> <td>Store T(X) instead of all data</td> </tr> <tr> <td>Efficient estimation</td> <td>Use T(X) for MLE</td> </tr> <tr> <td>Theory</td> <td>Basis for optimal tests/estimators</td> </tr> </tbody> </table> <p><strong>Checking Sufficiency:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Method: Show factorization</span>

<span class=c1># Bernoulli example:</span>
<span class=c1># L(p|x) = ‚àè p^x·µ¢(1-p)^(1-x·µ¢)</span>
<span class=c1>#        = p^Œ£x·µ¢ (1-p)^(n-Œ£x·µ¢)</span>
<span class=c1>#        = g(T(x), p) ¬∑ h(x)</span>
<span class=c1># where T(x) = Œ£x·µ¢, h(x) = 1</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Deep statistical theory.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Factorization theorem</li> <li>Examples: sum for Bernoulli, mean for normal</li> <li>"Captures all info about Œ∏"</li> <li>Mentions data reduction benefit</li> </ul> </div> </details> <hr> <h3 id=explain-the-rao-blackwell-theorem-google-microsoft-interview-question>Explain the Rao-Blackwell Theorem - Google, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Estimation Theory</code>, <code>UMVUE</code>, <code>Statistics</code> | <strong>Asked by:</strong> Google, Microsoft, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Rao-Blackwell Theorem:</strong></p> <p>Given: - Unbiased estimator Œ¥(X) for Œ∏ - Sufficient statistic T(X)</p> <p>Define: <span class=arithmatex>\(\delta^*(X) = E[\delta(X) | T(X)]\)</span></p> <p>Then: 1. Œ¥* is unbiased 2. <strong>Var(Œ¥*) ‚â§ Var(Œ¥)</strong> (improvement!)</p> <p><strong>Intuition:</strong> Conditioning on sufficient statistic T can only reduce variance.</p> <p><strong>Example - Bernoulli:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># X‚ÇÅ,...,X‚Çô ~ Bernoulli(p)</span>
<span class=c1># Goal: Estimate p</span>

<span class=n>n</span> <span class=o>=</span> <span class=mi>10</span>
<span class=n>p_true</span> <span class=o>=</span> <span class=mf>0.6</span>
<span class=n>n_sims</span> <span class=o>=</span> <span class=mi>10000</span>

<span class=c1># Original (crude) estimator: Œ¥(X) = X‚ÇÅ (just use first obs!)</span>
<span class=n>estimates_crude</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>estimates_rb</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_sims</span><span class=p>):</span>
    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>p_true</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

    <span class=c1># Crude estimator</span>
    <span class=n>delta</span> <span class=o>=</span> <span class=n>X</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>  <span class=c1># Just first observation</span>
    <span class=n>estimates_crude</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>delta</span><span class=p>)</span>

    <span class=c1># Rao-Blackwellized estimator</span>
    <span class=c1># T(X) = sum(X) is sufficient</span>
    <span class=c1># E[X‚ÇÅ | T(X) = sum(X)] = sum(X) / n</span>
    <span class=n>T</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
    <span class=n>delta_star</span> <span class=o>=</span> <span class=n>T</span> <span class=o>/</span> <span class=n>n</span>
    <span class=n>estimates_rb</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>delta_star</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True p: </span><span class=si>{</span><span class=n>p_true</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Crude estimator (X‚ÇÅ):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>estimates_crude</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_crude</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Rao-Blackwellized (XÃÑ):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>estimates_rb</span><span class=p>)</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_rb</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Theoretical variances</span>
<span class=n>var_crude</span> <span class=o>=</span> <span class=n>p_true</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_true</span><span class=p>)</span>  <span class=c1># Var(Bernoulli)</span>
<span class=n>var_rb</span> <span class=o>=</span> <span class=n>p_true</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_true</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span>  <span class=c1># Var(mean)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Theoretical reduction: </span><span class=si>{</span><span class=n>var_crude</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=n>var_rb</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>x&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Example - Normal:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># X ~ N(Œº, œÉ¬≤), œÉ¬≤ known</span>
<span class=c1># Crude estimator: median(X)</span>
<span class=c1># Sufficient statistic: mean(X)</span>

<span class=n>mu_true</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>sigma</span> <span class=o>=</span> <span class=mi>2</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>20</span>

<span class=n>estimates_median</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>estimates_mean</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mu_true</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

    <span class=c1># Crude: sample median</span>
    <span class=n>estimates_median</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>

    <span class=c1># RB: sample mean (conditioning on sufficient stat)</span>
    <span class=n>estimates_mean</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>X</span><span class=p>))</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Normal example:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Median variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_median</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_mean</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Improvement: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_median</span><span class=p>)</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_mean</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>x&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Proof Sketch:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Var(Œ¥) = E[Var(Œ¥|T)] + Var(E[Œ¥|T])</span>
<span class=c1>#        = E[Var(Œ¥|T)] + Var(Œ¥*)</span>
<span class=c1># </span>
<span class=c1># Since E[Var(Œ¥|T)] ‚â• 0:</span>
<span class=c1># Var(Œ¥) ‚â• Var(Œ¥*)</span>
</code></pre></div> <p><strong>Connection to UMVUE:</strong></p> <p>If Œ¥* is also complete, then it's the <strong>Uniformly Minimum Variance Unbiased Estimator</strong> (UMVUE).</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced estimation theory.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Condition on sufficient statistic"</li> <li>"Always reduces variance"</li> <li>Example: XÃÑ improves on X‚ÇÅ</li> <li>Mentions UMVUE connection</li> </ul> </div> </details> <hr> <h3 id=what-is-simpsons-paradox-provide-examples-most-tech-companies-interview-question>What is Simpson's Paradox? Provide Examples - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Paradox</code>, <code>Confounding</code>, <code>Causal Inference</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Simpson's Paradox:</strong></p> <p>A trend appears in subgroups but disappears/reverses when groups are combined.</p> <p><strong>Classic Example - UC Berkeley Admissions:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>

<span class=c1># Berkeley admission data (simplified)</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;Department&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;A&#39;</span><span class=p>,</span> <span class=s1>&#39;A&#39;</span><span class=p>,</span> <span class=s1>&#39;B&#39;</span><span class=p>,</span> <span class=s1>&#39;B&#39;</span><span class=p>],</span>
    <span class=s1>&#39;Gender&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Male&#39;</span><span class=p>,</span> <span class=s1>&#39;Female&#39;</span><span class=p>,</span> <span class=s1>&#39;Male&#39;</span><span class=p>,</span> <span class=s1>&#39;Female&#39;</span><span class=p>],</span>
    <span class=s1>&#39;Applied&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>825</span><span class=p>,</span> <span class=mi>108</span><span class=p>,</span> <span class=mi>560</span><span class=p>,</span> <span class=mi>25</span><span class=p>],</span>
    <span class=s1>&#39;Admitted&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>512</span><span class=p>,</span> <span class=mi>89</span><span class=p>,</span> <span class=mi>353</span><span class=p>,</span> <span class=mi>17</span><span class=p>]</span>
<span class=p>})</span>

<span class=n>data</span><span class=p>[</span><span class=s1>&#39;Rate&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;Admitted&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;Applied&#39;</span><span class=p>]</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;By Department:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=c1># Aggregate (ignoring department)</span>
<span class=n>total_male</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Gender&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Male&#39;</span><span class=p>][</span><span class=s1>&#39;Applied&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
<span class=n>total_female</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Gender&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Female&#39;</span><span class=p>][</span><span class=s1>&#39;Applied&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
<span class=n>admit_male</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Gender&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Male&#39;</span><span class=p>][</span><span class=s1>&#39;Admitted&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
<span class=n>admit_female</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Gender&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Female&#39;</span><span class=p>][</span><span class=s1>&#39;Admitted&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Overall:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Male: </span><span class=si>{</span><span class=n>admit_male</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>total_male</span><span class=si>}</span><span class=s2> = </span><span class=si>{</span><span class=n>admit_male</span><span class=o>/</span><span class=n>total_male</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Female: </span><span class=si>{</span><span class=n>admit_female</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>total_female</span><span class=si>}</span><span class=s2> = </span><span class=si>{</span><span class=n>admit_female</span><span class=o>/</span><span class=n>total_female</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Paradox: Males have higher overall rate, but females have higher/equal rate in each dept!</span>
</code></pre></div> <p><strong>Medical Example:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Treatment effectiveness paradox</span>

<span class=n>treatment_data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;Group&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Healthy&#39;</span><span class=p>,</span> <span class=s1>&#39;Healthy&#39;</span><span class=p>,</span> <span class=s1>&#39;Sick&#39;</span><span class=p>,</span> <span class=s1>&#39;Sick&#39;</span><span class=p>],</span>
    <span class=s1>&#39;Treatment&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Drug&#39;</span><span class=p>,</span> <span class=s1>&#39;Control&#39;</span><span class=p>,</span> <span class=s1>&#39;Drug&#39;</span><span class=p>,</span> <span class=s1>&#39;Control&#39;</span><span class=p>],</span>
    <span class=s1>&#39;Total&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>50</span><span class=p>,</span> <span class=mi>450</span><span class=p>,</span> <span class=mi>450</span><span class=p>,</span> <span class=mi>50</span><span class=p>],</span>
    <span class=s1>&#39;Recovered&#39;</span><span class=p>:</span> <span class=p>[</span><span class=mi>45</span><span class=p>,</span> <span class=mi>405</span><span class=p>,</span> <span class=mi>360</span><span class=p>,</span> <span class=mi>30</span><span class=p>]</span>
<span class=p>})</span>

<span class=n>treatment_data</span><span class=p>[</span><span class=s1>&#39;Recovery_Rate&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>treatment_data</span><span class=p>[</span><span class=s1>&#39;Recovered&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>treatment_data</span><span class=p>[</span><span class=s1>&#39;Total&#39;</span><span class=p>]</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>By Health Status:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>treatment_data</span><span class=p>)</span>

<span class=c1># Aggregate</span>
<span class=n>drug_total</span> <span class=o>=</span> <span class=n>treatment_data</span><span class=p>[</span><span class=n>treatment_data</span><span class=p>[</span><span class=s1>&#39;Treatment&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Drug&#39;</span><span class=p>][</span><span class=s1>&#39;Total&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
<span class=n>drug_recovered</span> <span class=o>=</span> <span class=n>treatment_data</span><span class=p>[</span><span class=n>treatment_data</span><span class=p>[</span><span class=s1>&#39;Treatment&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Drug&#39;</span><span class=p>][</span><span class=s1>&#39;Recovered&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

<span class=n>control_total</span> <span class=o>=</span> <span class=n>treatment_data</span><span class=p>[</span><span class=n>treatment_data</span><span class=p>[</span><span class=s1>&#39;Treatment&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Control&#39;</span><span class=p>][</span><span class=s1>&#39;Total&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
<span class=n>control_recovered</span> <span class=o>=</span> <span class=n>treatment_data</span><span class=p>[</span><span class=n>treatment_data</span><span class=p>[</span><span class=s1>&#39;Treatment&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;Control&#39;</span><span class=p>][</span><span class=s1>&#39;Recovered&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Overall:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Drug: </span><span class=si>{</span><span class=n>drug_recovered</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>drug_total</span><span class=si>}</span><span class=s2> = </span><span class=si>{</span><span class=n>drug_recovered</span><span class=o>/</span><span class=n>drug_total</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Control: </span><span class=si>{</span><span class=n>control_recovered</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>control_total</span><span class=si>}</span><span class=s2> = </span><span class=si>{</span><span class=n>control_recovered</span><span class=o>/</span><span class=n>control_total</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Drug better in both groups, but worse overall!</span>
<span class=c1># Reason: sick people more likely to get drug</span>
</code></pre></div> <p><strong>Visualization:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Simpson&#39;s paradox visualization</span>

<span class=c1># Group 1</span>
<span class=n>x1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
<span class=n>y1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>])</span>  <span class=c1># Positive trend</span>

<span class=c1># Group 2</span>
<span class=n>x2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>])</span>
<span class=n>y2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>])</span>  <span class=c1># Positive trend</span>

<span class=c1># Combined negative trend</span>
<span class=n>x_all</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>])</span>
<span class=n>y_all</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>y1</span><span class=p>,</span> <span class=n>y2</span><span class=p>])</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Group 1&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>x2</span><span class=p>,</span> <span class=n>y2</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Group 2&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.6</span><span class=p>)</span>

<span class=c1># Fit lines</span>
<span class=n>z1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>polyfit</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>z2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>polyfit</span><span class=p>(</span><span class=n>x2</span><span class=p>,</span> <span class=n>y2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>z_all</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>polyfit</span><span class=p>(</span><span class=n>x_all</span><span class=p>,</span> <span class=n>y_all</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>poly1d</span><span class=p>(</span><span class=n>z1</span><span class=p>)(</span><span class=n>x1</span><span class=p>),</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Group 1 trend&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x2</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>poly1d</span><span class=p>(</span><span class=n>z2</span><span class=p>)(</span><span class=n>x2</span><span class=p>),</span> <span class=s1>&#39;r-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Group 2 trend&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_all</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>poly1d</span><span class=p>(</span><span class=n>z_all</span><span class=p>)(</span><span class=n>x_all</span><span class=p>),</span> <span class=s1>&#39;k--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Combined trend&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;X&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Y&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&quot;Simpson&#39;s Paradox&quot;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Why It Happens:</strong></p> <p>Confounding variable Z affects both X and Y:</p> <ul> <li>Within each Z value: X ‚Üí Y positive</li> <li>Aggregated: X ‚Üí Y negative (Z confounds)</li> </ul> <p><strong>Resolution:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Use stratification or causal inference</span>

<span class=c1># Correct analysis: stratify by confounder</span>
<span class=k>for</span> <span class=n>dept</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>&#39;A&#39;</span><span class=p>,</span> <span class=s1>&#39;B&#39;</span><span class=p>]:</span>
    <span class=n>subset</span> <span class=o>=</span> <span class=n>data</span><span class=p>[</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Department&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=n>dept</span><span class=p>]</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Department </span><span class=si>{</span><span class=n>dept</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>subset</span><span class=p>[[</span><span class=s1>&#39;Gender&#39;</span><span class=p>,</span> <span class=s1>&#39;Rate&#39;</span><span class=p>]])</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Confounding awareness.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Berkeley admission example</li> <li>"Trend reverses when aggregated"</li> <li>Mentions confounding variable</li> <li>Knows to stratify</li> </ul> </div> </details> <hr> <h3 id=explain-the-delta-method-google-meta-interview-question>Explain the Delta Method - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Asymptotics</code>, <code>Central Limit Theorem</code>, <code>Approximation</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Delta Method:</strong></p> <p>If <span class=arithmatex>\(\sqrt{n}(\hat{\theta} - \theta) \xrightarrow{d} N(0, \sigma^2)\)</span>, then for smooth g:</p> <div class=arithmatex>\[\sqrt{n}(g(\hat{\theta}) - g(\theta)) \xrightarrow{d} N(0, [g'(\theta)]^2 \sigma^2)\]</div> <p><strong>Intuition:</strong> Use first-order Taylor approximation for asymptotic distribution of transformed estimator.</p> <p><strong>Example 1 - Bernoulli Variance:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Estimate variance of Bernoulli: Œ∏(1-Œ∏)</span>

<span class=n>p_true</span> <span class=o>=</span> <span class=mf>0.3</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_sims</span> <span class=o>=</span> <span class=mi>10000</span>

<span class=c1># Simulation</span>
<span class=n>estimates_var</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_sims</span><span class=p>):</span>
    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>p_true</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
    <span class=n>p_hat</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>

    <span class=c1># Plug-in estimator for variance</span>
    <span class=n>var_hat</span> <span class=o>=</span> <span class=n>p_hat</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_hat</span><span class=p>)</span>
    <span class=n>estimates_var</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>var_hat</span><span class=p>)</span>

<span class=c1># True variance</span>
<span class=n>true_var</span> <span class=o>=</span> <span class=n>p_true</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_true</span><span class=p>)</span>

<span class=c1># Delta method approximation</span>
<span class=c1># g(p) = p(1-p), g&#39;(p) = 1 - 2p</span>
<span class=n>g_prime</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=mi>2</span><span class=o>*</span><span class=n>p_true</span>

<span class=c1># Var(pÃÇ) = p(1-p)/n</span>
<span class=n>var_p_hat</span> <span class=o>=</span> <span class=n>p_true</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_true</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span>

<span class=c1># Delta method: Var(g(pÃÇ)) ‚âà [g&#39;(p)]¬≤ ¬∑ Var(pÃÇ)</span>
<span class=n>var_delta</span> <span class=o>=</span> <span class=p>(</span><span class=n>g_prime</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span> <span class=o>*</span> <span class=n>var_p_hat</span>
<span class=n>std_delta</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>var_delta</span><span class=p>)</span>

<span class=c1># Compare</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True variance: </span><span class=si>{</span><span class=n>true_var</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean estimate: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>estimates_var</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Std of estimates (simulation): </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>estimates_var</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Std (Delta method): </span><span class=si>{</span><span class=n>std_delta</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Plot</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>estimates_var</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Simulation&#39;</span><span class=p>)</span>

<span class=c1># Delta method normal approximation</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>true_var</span> <span class=o>-</span> <span class=mi>4</span><span class=o>*</span><span class=n>std_delta</span><span class=p>,</span> <span class=n>true_var</span> <span class=o>+</span> <span class=mi>4</span><span class=o>*</span><span class=n>std_delta</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>true_var</span><span class=p>,</span> <span class=n>std_delta</span><span class=p>),</span> <span class=s1>&#39;r-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Delta method&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>true_var</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;True value&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Estimated variance&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Delta Method Approximation&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Example 2 - Log Odds:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Transform: g(p) = log(p/(1-p))  [log-odds]</span>

<span class=n>p_true</span> <span class=o>=</span> <span class=mf>0.6</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>200</span>

<span class=n>estimates_logodds</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>p_true</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
    <span class=n>p_hat</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>

    <span class=c1># Avoid 0/1</span>
    <span class=n>p_hat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=n>p_hat</span><span class=p>,</span> <span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.99</span><span class=p>)</span>

    <span class=n>logodds_hat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>p_hat</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_hat</span><span class=p>))</span>
    <span class=n>estimates_logodds</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>logodds_hat</span><span class=p>)</span>

<span class=c1># True log-odds</span>
<span class=n>true_logodds</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>p_true</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_true</span><span class=p>))</span>

<span class=c1># Delta method</span>
<span class=c1># g(p) = log(p/(1-p))</span>
<span class=c1># g&#39;(p) = 1/(p(1-p))</span>
<span class=n>g_prime</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=n>p_true</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_true</span><span class=p>))</span>

<span class=n>var_p_hat</span> <span class=o>=</span> <span class=n>p_true</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_true</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span>
<span class=n>var_delta</span> <span class=o>=</span> <span class=p>(</span><span class=n>g_prime</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span> <span class=o>*</span> <span class=n>var_p_hat</span>
<span class=n>std_delta</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>var_delta</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Log-odds example:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True log-odds: </span><span class=si>{</span><span class=n>true_logodds</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Std (simulation): </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>estimates_logodds</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Std (Delta method): </span><span class=si>{</span><span class=n>std_delta</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Multivariate Delta Method:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># For vector Œ∏ÃÇ ‚Üí g(Œ∏ÃÇ)</span>

<span class=c1># Example: Ratio estimator</span>
<span class=c1># X ~ N(Œºx, œÉx¬≤), Y ~ N(Œºy, œÉy¬≤)</span>
<span class=c1># Estimate ratio R = Œºx/Œºy</span>

<span class=n>mu_x</span><span class=p>,</span> <span class=n>mu_y</span> <span class=o>=</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>5</span>
<span class=n>sigma_x</span><span class=p>,</span> <span class=n>sigma_y</span> <span class=o>=</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>100</span>

<span class=n>estimates_ratio</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mu_x</span><span class=p>,</span> <span class=n>sigma_x</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
    <span class=n>Y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mu_y</span><span class=p>,</span> <span class=n>sigma_y</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

    <span class=n>ratio</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span> <span class=o>/</span> <span class=n>Y</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
    <span class=n>estimates_ratio</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ratio</span><span class=p>)</span>

<span class=n>true_ratio</span> <span class=o>=</span> <span class=n>mu_x</span> <span class=o>/</span> <span class=n>mu_y</span>

<span class=c1># Multivariate delta method</span>
<span class=c1># g(Œºx, Œºy) = Œºx/Œºy</span>
<span class=c1># ‚àág = [1/Œºy, -Œºx/Œºy¬≤]</span>

<span class=n>gradient</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=o>/</span><span class=n>mu_y</span><span class=p>,</span> <span class=o>-</span><span class=n>mu_x</span><span class=o>/</span><span class=n>mu_y</span><span class=o>**</span><span class=mi>2</span><span class=p>])</span>

<span class=c1># Covariance matrix of (XÃÑ, »≤)</span>
<span class=n>cov_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=n>sigma_x</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=n>n</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>sigma_y</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=n>n</span><span class=p>]</span>
<span class=p>])</span>

<span class=c1># Var(g(Œ∏ÃÇ)) ‚âà ‚àág^T Œ£ ‚àág</span>
<span class=n>var_delta</span> <span class=o>=</span> <span class=n>gradient</span> <span class=o>@</span> <span class=n>cov_matrix</span> <span class=o>@</span> <span class=n>gradient</span>
<span class=n>std_delta</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>var_delta</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Ratio example:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True ratio: </span><span class=si>{</span><span class=n>true_ratio</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Std (simulation): </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>estimates_ratio</span><span class=p>)</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Std (Delta method): </span><span class=si>{</span><span class=n>std_delta</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Asymptotic theory knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Taylor expansion intuition</li> <li>Formula: [g'(Œ∏)]¬≤ œÉ¬≤</li> <li>"First-order approximation"</li> <li>Example: log-odds or ratio</li> </ul> </div> </details> <hr> <h3 id=what-is-the-likelihood-ratio-in-hypothesis-testing-google-amazon-interview-question>What is the Likelihood Ratio in Hypothesis Testing? - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Hypothesis Testing</code>, <code>Likelihood</code>, <code>Neyman-Pearson</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Likelihood Ratio:</strong></p> <div class=arithmatex>\[\Lambda(x) = \frac{L(\theta_1 | x)}{L(\theta_0 | x)} = \frac{P(X=x | H_1)}{P(X=x | H_0)}\]</div> <p><strong>Decision Rule:</strong> Reject H‚ÇÄ if Œõ(x) &gt; k (threshold)</p> <p><strong>Neyman-Pearson Lemma:</strong></p> <p>For testing H‚ÇÄ: Œ∏ = Œ∏‚ÇÄ vs H‚ÇÅ: Œ∏ = Œ∏‚ÇÅ, the LR test is <strong>most powerful</strong> (maximizes power for fixed Œ±).</p> <p><strong>Example - Normal Mean:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># H‚ÇÄ: Œº = 0 vs H‚ÇÅ: Œº = 1</span>
<span class=c1># X ~ N(Œº, œÉ¬≤=1)</span>

<span class=n>sigma</span> <span class=o>=</span> <span class=mi>1</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>20</span>
<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>

<span class=c1># Generate data under H‚ÇÅ</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
<span class=n>mu_0</span> <span class=o>=</span> <span class=mi>0</span>
<span class=n>mu_1</span> <span class=o>=</span> <span class=mi>1</span>

<span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mu_1</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
<span class=n>x_bar</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>

<span class=c1># Likelihood ratio</span>
<span class=c1># L(Œº|x) ‚àù exp(-n(xÃÑ-Œº)¬≤/(2œÉ¬≤))</span>

<span class=n>L_0</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>n</span> <span class=o>*</span> <span class=p>(</span><span class=n>x_bar</span> <span class=o>-</span> <span class=n>mu_0</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span> <span class=o>/</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>sigma</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>
<span class=n>L_1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>n</span> <span class=o>*</span> <span class=p>(</span><span class=n>x_bar</span> <span class=o>-</span> <span class=n>mu_1</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span> <span class=o>/</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>sigma</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>

<span class=n>LR</span> <span class=o>=</span> <span class=n>L_1</span> <span class=o>/</span> <span class=n>L_0</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Sample mean: </span><span class=si>{</span><span class=n>x_bar</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;L(Œº=0|x): </span><span class=si>{</span><span class=n>L_0</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;L(Œº=1|x): </span><span class=si>{</span><span class=n>L_1</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Likelihood Ratio: </span><span class=si>{</span><span class=n>LR</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Critical value</span>
<span class=c1># Under H‚ÇÄ, xÃÑ ~ N(0, œÉ¬≤/n)</span>
<span class=c1># Reject if xÃÑ &gt; c where P(xÃÑ &gt; c | H‚ÇÄ) = Œ±</span>

<span class=n>c</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alpha</span><span class=p>,</span> <span class=n>loc</span><span class=o>=</span><span class=n>mu_0</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>sigma</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Critical value: </span><span class=si>{</span><span class=n>c</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Decision: </span><span class=si>{</span><span class=s1>&#39;Reject H‚ÇÄ&#39;</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>x_bar</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=n>c</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s1>&#39;Fail to reject H‚ÇÄ&#39;</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Equivalence: LR test ‚Üî reject if xÃÑ &gt; c</span>
<span class=c1># LR &gt; k ‚Üî xÃÑ &gt; some threshold</span>
</code></pre></div> <p><strong>ROC Curve:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Vary threshold, plot TPR vs FPR</span>

<span class=k>def</span><span class=w> </span><span class=nf>compute_roc</span><span class=p>(</span><span class=n>mu_0</span><span class=p>,</span> <span class=n>mu_1</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>n_sims</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
    <span class=c1># Generate data under both hypotheses</span>
    <span class=n>data_H0</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mu_0</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=p>(</span><span class=n>n_sims</span><span class=p>,</span> <span class=n>n</span><span class=p>))</span>
    <span class=n>data_H1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mu_1</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=p>(</span><span class=n>n_sims</span><span class=p>,</span> <span class=n>n</span><span class=p>))</span>

    <span class=n>x_bar_H0</span> <span class=o>=</span> <span class=n>data_H0</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
    <span class=n>x_bar_H1</span> <span class=o>=</span> <span class=n>data_H1</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

    <span class=c1># Try different thresholds</span>
    <span class=n>thresholds</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>mu_0</span> <span class=o>-</span> <span class=mi>3</span><span class=o>*</span><span class=n>sigma</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>n</span><span class=p>),</span> 
                             <span class=n>mu_1</span> <span class=o>+</span> <span class=mi>3</span><span class=o>*</span><span class=n>sigma</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>n</span><span class=p>),</span> <span class=mi>100</span><span class=p>)</span>

    <span class=n>fpr</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=n>tpr</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=n>thresholds</span><span class=p>:</span>
        <span class=c1># False positive rate: P(reject | H‚ÇÄ)</span>
        <span class=n>fpr</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>x_bar_H0</span> <span class=o>&gt;</span> <span class=n>t</span><span class=p>))</span>

        <span class=c1># True positive rate: P(reject | H‚ÇÅ)</span>
        <span class=n>tpr</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>x_bar_H1</span> <span class=o>&gt;</span> <span class=n>t</span><span class=p>))</span>

    <span class=k>return</span> <span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span>

<span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span> <span class=o>=</span> <span class=n>compute_roc</span><span class=p>(</span><span class=n>mu_0</span><span class=p>,</span> <span class=n>mu_1</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;ROC curve&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=s1>&#39;k--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Random&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;False Positive Rate&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True Positive Rate&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;ROC Curve for Likelihood Ratio Test&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># AUC</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>auc</span>
<span class=n>roc_auc</span> <span class=o>=</span> <span class=n>auc</span><span class=p>(</span><span class=n>fpr</span><span class=p>,</span> <span class=n>tpr</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>AUC: </span><span class=si>{</span><span class=n>roc_auc</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Generalized Likelihood Ratio Test (GLRT):</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Composite hypotheses: unknown parameters</span>

<span class=c1># H‚ÇÄ: Œº = 0, œÉ unknown</span>
<span class=c1># H‚ÇÅ: Œº ‚â† 0, œÉ unknown</span>

<span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>

<span class=c1># MLE under H‚ÇÄ</span>
<span class=n>mu_0_mle</span> <span class=o>=</span> <span class=mi>0</span>
<span class=n>sigma_0_mle</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>((</span><span class=n>X</span> <span class=o>-</span> <span class=n>mu_0_mle</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>

<span class=c1># MLE under H‚ÇÅ (unconstrained)</span>
<span class=n>mu_1_mle</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
<span class=n>sigma_1_mle</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>((</span><span class=n>X</span> <span class=o>-</span> <span class=n>mu_1_mle</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>

<span class=c1># Likelihood ratio</span>
<span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
<span class=n>LR</span> <span class=o>=</span> <span class=p>(</span><span class=n>sigma_0_mle</span> <span class=o>/</span> <span class=n>sigma_1_mle</span><span class=p>)</span><span class=o>**</span><span class=n>n</span>

<span class=c1># Test statistic: -2 log(LR) ~ œá¬≤(df)</span>
<span class=n>test_stat</span> <span class=o>=</span> <span class=o>-</span><span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>LR</span><span class=p>)</span>

<span class=c1># Under H‚ÇÄ: ~ œá¬≤(1) [df = # params in H‚ÇÅ - # params in H‚ÇÄ]</span>
<span class=n>p_value</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>stats</span><span class=o>.</span><span class=n>chi2</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>test_stat</span><span class=p>,</span> <span class=n>df</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>GLRT:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Test statistic: </span><span class=si>{</span><span class=n>test_stat</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Hypothesis testing theory.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Ratio of likelihoods under H‚ÇÅ/H‚ÇÄ</li> <li>Neyman-Pearson lemma (most powerful)</li> <li>Connection to ROC</li> <li>GLRT for composite hypotheses</li> </ul> </div> </details> <hr> <h3 id=explain-the-bootstrap-method-most-tech-companies-interview-question>Explain the Bootstrap Method - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Resampling</code>, <code>Inference</code>, <code>Confidence Intervals</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Bootstrap:</strong></p> <p>Estimate sampling distribution of statistic by resampling from data with replacement.</p> <p><strong>Algorithm:</strong></p> <ol> <li>Original sample: <span class=arithmatex>\(X = \{x_1, ..., x_n\}\)</span></li> <li>For b = 1 to B:</li> <li>Draw <span class=arithmatex>\(X^*_b\)</span> by sampling n points from X with replacement</li> <li>Compute statistic <span class=arithmatex>\(\theta^*_b = T(X^*_b)\)</span></li> <li>Use <span class=arithmatex>\(\{\theta^*_1, ..., \theta^*_B\}\)</span> to approximate distribution of T</li> </ol> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># Original data</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>

<span class=c1># Statistic: median</span>
<span class=n>observed_median</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=c1># Bootstrap</span>
<span class=n>n_bootstrap</span> <span class=o>=</span> <span class=mi>10000</span>
<span class=n>bootstrap_medians</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_bootstrap</span><span class=p>):</span>
    <span class=c1># Resample with replacement</span>
    <span class=n>bootstrap_sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>),</span> <span class=n>replace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=n>bootstrap_medians</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>bootstrap_sample</span><span class=p>))</span>

<span class=n>bootstrap_medians</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>bootstrap_medians</span><span class=p>)</span>

<span class=c1># Bootstrap standard error</span>
<span class=n>se_bootstrap</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>bootstrap_medians</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Observed median: </span><span class=si>{</span><span class=n>observed_median</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Bootstrap SE: </span><span class=si>{</span><span class=n>se_bootstrap</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Bootstrap confidence interval (percentile method)</span>
<span class=n>ci_lower</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>bootstrap_medians</span><span class=p>,</span> <span class=mf>2.5</span><span class=p>)</span>
<span class=n>ci_upper</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>bootstrap_medians</span><span class=p>,</span> <span class=mf>97.5</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95% CI: [</span><span class=si>{</span><span class=n>ci_lower</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>ci_upper</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>]&quot;</span><span class=p>)</span>

<span class=c1># Plot</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>bootstrap_medians</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>observed_median</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Observed&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>ci_lower</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;green&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;95% CI&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>ci_upper</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;green&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Median&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Bootstrap Distribution of Median&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Types of Bootstrap CI:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># 1. Percentile method (above)</span>
<span class=n>ci_percentile</span> <span class=o>=</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>bootstrap_medians</span><span class=p>,</span> <span class=mf>2.5</span><span class=p>),</span>
                 <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>bootstrap_medians</span><span class=p>,</span> <span class=mf>97.5</span><span class=p>))</span>

<span class=c1># 2. Basic/Normal approximation</span>
<span class=n>ci_normal</span> <span class=o>=</span> <span class=p>(</span><span class=n>observed_median</span> <span class=o>-</span> <span class=mf>1.96</span> <span class=o>*</span> <span class=n>se_bootstrap</span><span class=p>,</span>
             <span class=n>observed_median</span> <span class=o>+</span> <span class=mf>1.96</span> <span class=o>*</span> <span class=n>se_bootstrap</span><span class=p>)</span>

<span class=c1># 3. BCa (bias-corrected and accelerated)</span>
<span class=c1># More complex, accounts for bias and skewness</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Percentile CI: </span><span class=si>{</span><span class=n>ci_percentile</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Normal CI: </span><span class=si>{</span><span class=n>ci_normal</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Bootstrap for Hypothesis Testing:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Test: H‚ÇÄ: median = 1 vs H‚ÇÅ: median ‚â† 1</span>

<span class=n>null_value</span> <span class=o>=</span> <span class=mi>1</span>

<span class=c1># Center bootstrap samples at null</span>
<span class=n>shifted_data</span> <span class=o>=</span> <span class=n>data</span> <span class=o>-</span> <span class=n>observed_median</span> <span class=o>+</span> <span class=n>null_value</span>

<span class=n>bootstrap_null</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_bootstrap</span><span class=p>):</span>
    <span class=n>bootstrap_sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>shifted_data</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>),</span> <span class=n>replace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=n>bootstrap_null</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>median</span><span class=p>(</span><span class=n>bootstrap_sample</span><span class=p>))</span>

<span class=c1># p-value: proportion of bootstrap stats as extreme as observed</span>
<span class=n>bootstrap_null</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>bootstrap_null</span><span class=p>)</span>
<span class=n>p_value</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>bootstrap_null</span> <span class=o>-</span> <span class=n>null_value</span><span class=p>)</span> <span class=o>&gt;=</span> 
                  <span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>observed_median</span> <span class=o>-</span> <span class=n>null_value</span><span class=p>))</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Bootstrap hypothesis test:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Comparison with Analytical:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># For mean of normal data, we have analytical SE</span>
<span class=n>data_normal</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>

<span class=c1># Analytical</span>
<span class=n>se_analytical</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>sem</span><span class=p>(</span><span class=n>data_normal</span><span class=p>)</span>

<span class=c1># Bootstrap</span>
<span class=n>bootstrap_means</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>):</span>
    <span class=n>bootstrap_sample</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>data_normal</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>data_normal</span><span class=p>),</span> <span class=n>replace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=n>bootstrap_means</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>bootstrap_sample</span><span class=p>))</span>

<span class=n>se_bootstrap</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>bootstrap_means</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Comparison for mean:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Analytical SE: </span><span class=si>{</span><span class=n>se_analytical</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Bootstrap SE: </span><span class=si>{</span><span class=n>se_bootstrap</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>When to Use Bootstrap:</strong></p> <table> <thead> <tr> <th>Scenario</th> <th>Bootstrap?</th> </tr> </thead> <tbody> <tr> <td>Complex statistic (median, ratio)</td> <td>‚úì Yes</td> </tr> <tr> <td>Small sample, non-normal</td> <td>‚úì Yes</td> </tr> <tr> <td>Simple mean, large n</td> <td>‚ñ≥ Optional (analytical works)</td> </tr> <tr> <td>Time series, dependence</td> <td>‚úó Need block bootstrap</td> </tr> </tbody> </table> <p><strong>Limitations:</strong></p> <ul> <li>Assumes sample represents population</li> <li>Can fail for extreme statistics (max, min)</li> <li>Computational cost</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Practical inference methods.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Resample with replacement"</li> <li>Explains SE and CI</li> <li>Mentions percentile method</li> <li>Knows when it's useful</li> </ul> </div> </details> <hr> <h3 id=what-is-the-curse-of-dimensionality-in-probability-google-meta-interview-question>What is the Curse of Dimensionality in Probability? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>High Dimensions</code>, <code>Geometry</code>, <code>ML</code> | <strong>Asked by:</strong> Google, Meta, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Curse of Dimensionality:</strong></p> <p>As dimensions increase, intuitions from low dimensions fail dramatically.</p> <p><strong>Phenomenon 1 - Volume Concentration:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Hypersphere volume as fraction of hypercube</span>

<span class=k>def</span><span class=w> </span><span class=nf>sphere_volume_fraction</span><span class=p>(</span><span class=n>d</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Volume of unit sphere / volume of unit cube in d dimensions&quot;&quot;&quot;</span>
    <span class=c1># Unit sphere: radius = 1/2 (to fit in unit cube)</span>
    <span class=c1># V_sphere = œÄ^(d/2) / Œì(d/2 + 1) * r^d</span>
    <span class=c1># V_cube = 1</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>scipy.special</span><span class=w> </span><span class=kn>import</span> <span class=n>gamma</span>
    <span class=n>r</span> <span class=o>=</span> <span class=mf>0.5</span>
    <span class=n>vol_sphere</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>pi</span><span class=o>**</span><span class=p>(</span><span class=n>d</span><span class=o>/</span><span class=mi>2</span><span class=p>)</span> <span class=o>/</span> <span class=n>gamma</span><span class=p>(</span><span class=n>d</span><span class=o>/</span><span class=mi>2</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>r</span><span class=o>**</span><span class=n>d</span>
    <span class=k>return</span> <span class=n>vol_sphere</span>

<span class=n>dims</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>21</span><span class=p>)</span>
<span class=n>fractions</span> <span class=o>=</span> <span class=p>[</span><span class=n>sphere_volume_fraction</span><span class=p>(</span><span class=n>d</span><span class=p>)</span> <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=n>dims</span><span class=p>]</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>dims</span><span class=p>,</span> <span class=n>fractions</span><span class=p>,</span> <span class=s1>&#39;bo-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Dimension&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Sphere volume / Cube volume&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Curse of Dimensionality: Volume Concentration&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>yscale</span><span class=p>(</span><span class=s1>&#39;log&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Sphere volume as </span><span class=si>% o</span><span class=s2>f cube:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>]:</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  d=</span><span class=si>{</span><span class=n>d</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>sphere_volume_fraction</span><span class=p>(</span><span class=n>d</span><span class=p>)</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>%&quot;</span><span class=p>)</span>
<span class=c1># Almost all volume is in corners!</span>
</code></pre></div> <p><strong>Phenomenon 2 - Distance Concentration:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># In high dimensions, all points are nearly equidistant</span>

<span class=k>def</span><span class=w> </span><span class=nf>distance_ratio_simulation</span><span class=p>(</span><span class=n>n_points</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>dimensions</span><span class=o>=</span><span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>]):</span>
    <span class=n>results</span> <span class=o>=</span> <span class=p>{}</span>

    <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=n>dimensions</span><span class=p>:</span>
        <span class=c1># Random points in unit hypercube</span>
        <span class=n>points</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>n_points</span><span class=p>,</span> <span class=n>d</span><span class=p>)</span>

        <span class=c1># Compute all pairwise distances</span>
        <span class=kn>from</span><span class=w> </span><span class=nn>scipy.spatial.distance</span><span class=w> </span><span class=kn>import</span> <span class=n>pdist</span>
        <span class=n>distances</span> <span class=o>=</span> <span class=n>pdist</span><span class=p>(</span><span class=n>points</span><span class=p>)</span>

        <span class=c1># Ratio of max to min distance</span>
        <span class=n>ratio</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>distances</span><span class=p>)</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=n>distances</span><span class=p>)</span>

        <span class=c1># Relative standard deviation</span>
        <span class=n>rel_std</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>distances</span><span class=p>)</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>distances</span><span class=p>)</span>

        <span class=n>results</span><span class=p>[</span><span class=n>d</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;mean&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>distances</span><span class=p>),</span>
            <span class=s1>&#39;std&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>distances</span><span class=p>),</span>
            <span class=s1>&#39;rel_std&#39;</span><span class=p>:</span> <span class=n>rel_std</span><span class=p>,</span>
            <span class=s1>&#39;ratio&#39;</span><span class=p>:</span> <span class=n>ratio</span>
        <span class=p>}</span>

    <span class=k>return</span> <span class=n>results</span>

<span class=n>results</span> <span class=o>=</span> <span class=n>distance_ratio_simulation</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Distance concentration:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>d</span><span class=p>,</span> <span class=n>stats</span> <span class=ow>in</span> <span class=n>results</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;d=</span><span class=si>{</span><span class=n>d</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Mean distance: </span><span class=si>{</span><span class=n>stats</span><span class=p>[</span><span class=s1>&#39;mean&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Rel. std: </span><span class=si>{</span><span class=n>stats</span><span class=p>[</span><span class=s1>&#39;rel_std&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Max/min ratio: </span><span class=si>{</span><span class=n>stats</span><span class=p>[</span><span class=s1>&#39;ratio&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># In high dims: all distances ‚âà same!</span>
</code></pre></div> <p><strong>Phenomenon 3 - Sampling Sparsity:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># To maintain same density, need exponentially more samples</span>

<span class=k>def</span><span class=w> </span><span class=nf>samples_needed</span><span class=p>(</span><span class=n>d</span><span class=p>,</span> <span class=n>density_per_dim</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Number of samples to maintain density&quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=n>density_per_dim</span> <span class=o>**</span> <span class=n>d</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Samples needed for fixed density:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]:</span>
    <span class=n>n</span> <span class=o>=</span> <span class=n>samples_needed</span><span class=p>(</span><span class=n>d</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;d=</span><span class=si>{</span><span class=n>d</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>n</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2> samples&quot;</span><span class=p>)</span>
<span class=c1># Explodes exponentially!</span>
</code></pre></div> <p><strong>Impact on ML:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># K-NN becomes useless in high dimensions</span>

<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.neighbors</span><span class=w> </span><span class=kn>import</span> <span class=n>KNeighborsClassifier</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>make_classification</span>
<span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>cross_val_score</span>

<span class=c1># Test k-NN performance vs dimensionality</span>
<span class=n>dimensions</span> <span class=o>=</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>]</span>
<span class=n>accuracies</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=n>dimensions</span><span class=p>:</span>
    <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>make_classification</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span> <span class=n>n_features</span><span class=o>=</span><span class=n>d</span><span class=p>,</span> 
                               <span class=n>n_informative</span><span class=o>=</span><span class=n>d</span><span class=p>,</span> <span class=n>n_redundant</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>

    <span class=n>knn</span> <span class=o>=</span> <span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
    <span class=n>scores</span> <span class=o>=</span> <span class=n>cross_val_score</span><span class=p>(</span><span class=n>knn</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>cv</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
    <span class=n>accuracies</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>scores</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>dimensions</span><span class=p>,</span> <span class=n>accuracies</span><span class=p>,</span> <span class=s1>&#39;ro-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Dimension&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Cross-val accuracy&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;k-NN Performance Degrades in High Dimensions&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;k&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Random&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Solutions:</strong></p> <table> <thead> <tr> <th>Problem</th> <th>Solution</th> </tr> </thead> <tbody> <tr> <td>Too many features</td> <td>Dimensionality reduction (PCA, etc.)</td> </tr> <tr> <td>Distance meaningless</td> <td>Use distance-agnostic methods</td> </tr> <tr> <td>Sparse data</td> <td>Regularization, feature selection</td> </tr> <tr> <td>Curse of volume</td> <td>Manifold assumption</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> High-dimensional intuition.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Volume concentrates in corners"</li> <li>"All points equidistant"</li> <li>"Need exponentially more data"</li> <li>Mentions PCA/regularization</li> </ul> </div> </details> <hr> <h3 id=explain-the-pitman-koopman-darmois-theorem-google-interview-question>Explain the Pitman-Koopman-Darmois Theorem - Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Exponential Family</code>, <code>Sufficient Statistics</code>, <code>Theory</code> | <strong>Asked by:</strong> Google, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Pitman-Koopman-Darmois Theorem:</strong></p> <p>If a distribution admits a sufficient statistic of fixed dimension (independent of sample size), then it must belong to the <strong>exponential family</strong>.</p> <p><strong>Exponential Family Form:</strong></p> <div class=arithmatex>\[f(x|\theta) = h(x) \exp\{\eta(\theta) \cdot T(x) - A(\theta)\}\]</div> <p>Where: - T(x): Sufficient statistic - Œ∑(Œ∏): Natural parameter - A(Œ∏): Log-partition function</p> <p><strong>Examples:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>

<span class=c1># 1. Bernoulli: exponential family</span>
<span class=c1># f(x|p) = p^x (1-p)^(1-x)</span>
<span class=c1>#        = exp{x log(p/(1-p)) + log(1-p)}</span>
<span class=c1># T(x) = x, Œ∑ = log(p/(1-p))</span>

<span class=c1># Sufficient statistic: sum(X) has fixed dimension 1</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.6</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Bernoulli sufficient stat: sum = </span><span class=si>{</span><span class=n>data</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># 2. Normal (Œº unknown, œÉ¬≤ known): exponential family</span>
<span class=c1># T(x) = mean(X)</span>

<span class=c1># 3. Uniform(0, Œ∏): NOT exponential family</span>
<span class=c1># Sufficient stat: max(X), but this changes with n!</span>
<span class=c1># No fixed-dimension sufficient statistic</span>

<span class=n>data_unif</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Uniform sufficient stat: max = </span><span class=si>{</span><span class=n>data_unif</span><span class=o>.</span><span class=n>max</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># This is sufficient but depends on n</span>
</code></pre></div> <p><strong>Why It Matters:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Exponential family has nice properties:</span>

<span class=c1># 1. Natural conjugate priors</span>
<span class=c1># Example: Bernoulli + Beta</span>

<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>beta</span><span class=p>,</span> <span class=n>binom</span>

<span class=c1># Prior: Beta(a, b)</span>
<span class=n>a</span><span class=p>,</span> <span class=n>b</span> <span class=o>=</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span>

<span class=c1># Data: n trials, k successes</span>
<span class=n>n</span><span class=p>,</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>60</span>

<span class=c1># Posterior: Beta(a+k, b+n-k)</span>
<span class=n>a_post</span> <span class=o>=</span> <span class=n>a</span> <span class=o>+</span> <span class=n>k</span>
<span class=n>b_post</span> <span class=o>=</span> <span class=n>b</span> <span class=o>+</span> <span class=n>n</span> <span class=o>-</span> <span class=n>k</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Conjugate prior example:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Prior: Beta(</span><span class=si>{</span><span class=n>a</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>b</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Data: </span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s2> successes&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Posterior: Beta(</span><span class=si>{</span><span class=n>a_post</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>b_post</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>

<span class=c1># 2. MLE has closed form</span>
<span class=c1># 3. Sufficient statistics compress data optimally</span>
</code></pre></div> <p><strong>Complete Proof Sketch:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Theorem: Fixed-dimension sufficient stat ‚Üí exponential family</span>

<span class=c1># Proof idea:</span>
<span class=c1># If T(X) is sufficient with fixed dimension d,</span>
<span class=c1># then by factorization theorem:</span>
<span class=c1># </span>
<span class=c1># f(x|Œ∏) = g(T(x), Œ∏) h(x)</span>
<span class=c1>#</span>
<span class=c1># For this to work for all n with T having fixed dimension,</span>
<span class=c1># must have exponential family structure.</span>

<span class=c1># Contrapositive: Not exponential family ‚Üí no fixed-dim sufficient stat</span>
<span class=c1># Example: Uniform(0, Œ∏) requires max(X), which grows with n</span>
</code></pre></div> <p><strong>Identifying Exponential Families:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Check if distribution can be written in form:</span>
<span class=c1># f(x|Œ∏) = h(x) exp{Œ∑(Œ∏)¬∑T(x) - A(Œ∏)}</span>

<span class=n>distributions</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;Bernoulli&#39;</span><span class=p>:</span> <span class=s1>&#39;Yes - T(x)=x&#39;</span><span class=p>,</span>
    <span class=s1>&#39;Normal&#39;</span><span class=p>:</span> <span class=s1>&#39;Yes - T(x)=(x, x¬≤) if both Œº,œÉ¬≤ unknown&#39;</span><span class=p>,</span>
    <span class=s1>&#39;Poisson&#39;</span><span class=p>:</span> <span class=s1>&#39;Yes - T(x)=x&#39;</span><span class=p>,</span>
    <span class=s1>&#39;Exponential&#39;</span><span class=p>:</span> <span class=s1>&#39;Yes - T(x)=x&#39;</span><span class=p>,</span>
    <span class=s1>&#39;Gamma&#39;</span><span class=p>:</span> <span class=s1>&#39;Yes - T(x)=(x, log x)&#39;</span><span class=p>,</span>
    <span class=s1>&#39;Beta&#39;</span><span class=p>:</span> <span class=s1>&#39;Yes - T(x)=(log x, log(1-x))&#39;</span><span class=p>,</span>
    <span class=s1>&#39;Uniform(0,Œ∏)&#39;</span><span class=p>:</span> <span class=s1>&#39;No - not exponential family&#39;</span><span class=p>,</span>
    <span class=s1>&#39;Cauchy&#39;</span><span class=p>:</span> <span class=s1>&#39;No - no sufficient statistic&#39;</span>
<span class=p>}</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Exponential family membership:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>dist</span><span class=p>,</span> <span class=n>status</span> <span class=ow>in</span> <span class=n>distributions</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>dist</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>status</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Deep theoretical knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Fixed-dimension sufficient stat ‚Üí exponential family"</li> <li>Knows exponential family form</li> <li>Examples: Bernoulli yes, Uniform no</li> <li>Mentions conjugate priors</li> </ul> </div> </details> <hr> <h3 id=what-is-the-cramer-rao-lower-bound-google-meta-interview-question>What is the Cram√©r-Rao Lower Bound? - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Estimation Theory</code>, <code>Fisher Information</code>, <code>Lower Bound</code> | <strong>Asked by:</strong> Google, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Cram√©r-Rao Lower Bound (CRLB):</strong></p> <p>For any unbiased estimator <span class=arithmatex>\(\hat{\theta}\)</span> of parameter Œ∏:</p> <div class=arithmatex>\[\text{Var}(\hat{\theta}) \geq \frac{1}{n \cdot I(\theta)}\]</div> <p>Where I(Œ∏) is the <strong>Fisher Information</strong>:</p> <div class=arithmatex>\[I(\theta) = E\left[\left(\frac{\partial}{\partial \theta} \log f(X|\theta)\right)^2\right]\]</div> <p><strong>Interpretation:</strong> No unbiased estimator can have variance below this bound.</p> <p><strong>Example - Bernoulli:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># X ~ Bernoulli(p)</span>
<span class=c1># Find CRLB for estimating p</span>

<span class=c1># Log-likelihood: log f(x|p) = x log(p) + (1-x) log(1-p)</span>
<span class=c1># Score: d/dp log f = x/p - (1-x)/(1-p)</span>

<span class=c1># Fisher information</span>
<span class=c1># I(p) = E[(d/dp log f)¬≤]</span>
<span class=c1>#      = E[(x/p - (1-x)/(1-p))¬≤]</span>
<span class=c1>#      = 1/(p(1-p))</span>

<span class=k>def</span><span class=w> </span><span class=nf>fisher_info_bernoulli</span><span class=p>(</span><span class=n>p</span><span class=p>):</span>
    <span class=k>return</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=n>p</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p</span><span class=p>))</span>

<span class=k>def</span><span class=w> </span><span class=nf>crlb_bernoulli</span><span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
    <span class=k>return</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=n>n</span> <span class=o>*</span> <span class=n>fisher_info_bernoulli</span><span class=p>(</span><span class=n>p</span><span class=p>))</span>

<span class=c1># Simulation</span>
<span class=n>p_true</span> <span class=o>=</span> <span class=mf>0.3</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>n_sims</span> <span class=o>=</span> <span class=mi>10000</span>

<span class=n>estimates</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_sims</span><span class=p>):</span>
    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>p_true</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
    <span class=n>p_hat</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
    <span class=n>estimates</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>p_hat</span><span class=p>)</span>

<span class=n>var_empirical</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates</span><span class=p>)</span>
<span class=n>crlb</span> <span class=o>=</span> <span class=n>crlb_bernoulli</span><span class=p>(</span><span class=n>p_true</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Bernoulli estimation:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True p: </span><span class=si>{</span><span class=n>p_true</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CRLB: </span><span class=si>{</span><span class=n>crlb</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Var(pÃÇ) empirical: </span><span class=si>{</span><span class=n>var_empirical</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Var(pÃÇ) theoretical: </span><span class=si>{</span><span class=n>p_true</span><span class=o>*</span><span class=p>(</span><span class=mi>1</span><span class=o>-</span><span class=n>p_true</span><span class=p>)</span><span class=o>/</span><span class=n>n</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Efficiency: </span><span class=si>{</span><span class=n>crlb</span><span class=o>/</span><span class=n>var_empirical</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># MLE for Bernoulli achieves CRLB (efficient!)</span>
</code></pre></div> <p><strong>Example - Normal:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># X ~ N(Œº, œÉ¬≤), œÉ¬≤ known</span>
<span class=c1># Estimate Œº</span>

<span class=n>sigma</span> <span class=o>=</span> <span class=mi>2</span>
<span class=n>mu_true</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>50</span>

<span class=c1># Fisher information</span>
<span class=c1># I(Œº) = n/œÉ¬≤</span>
<span class=n>fisher_info</span> <span class=o>=</span> <span class=n>n</span> <span class=o>/</span> <span class=n>sigma</span><span class=o>**</span><span class=mi>2</span>
<span class=n>crlb</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>fisher_info</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Normal estimation (Œº):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CRLB: </span><span class=si>{</span><span class=n>crlb</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Var(XÃÑ): </span><span class=si>{</span><span class=n>sigma</span><span class=o>**</span><span class=mi>2</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=n>n</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># XÃÑ achieves CRLB</span>
</code></pre></div> <p><strong>Efficiency:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Efficiency = CRLB / Var(estimator)</span>
<span class=c1># Efficient estimator: efficiency = 1</span>

<span class=k>def</span><span class=w> </span><span class=nf>compare_estimators</span><span class=p>(</span><span class=n>p_true</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>n_sims</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Compare different estimators for Bernoulli p&quot;&quot;&quot;</span>

    <span class=n>crlb</span> <span class=o>=</span> <span class=n>crlb_bernoulli</span><span class=p>(</span><span class=n>p_true</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

    <span class=n>estimators</span> <span class=o>=</span> <span class=p>{}</span>

    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_sims</span><span class=p>):</span>
        <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>p_true</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>

        <span class=c1># MLE: sample mean</span>
        <span class=n>estimators</span><span class=o>.</span><span class=n>setdefault</span><span class=p>(</span><span class=s1>&#39;MLE&#39;</span><span class=p>,</span> <span class=p>[])</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>

        <span class=c1># Inefficient: use only first half</span>
        <span class=n>estimators</span><span class=o>.</span><span class=n>setdefault</span><span class=p>(</span><span class=s1>&#39;Half&#39;</span><span class=p>,</span> <span class=p>[])</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>X</span><span class=p>[:</span><span class=n>n</span><span class=o>//</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Estimator comparison (p=</span><span class=si>{</span><span class=n>p_true</span><span class=si>}</span><span class=s2>, n=</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CRLB: </span><span class=si>{</span><span class=n>crlb</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>ests</span> <span class=ow>in</span> <span class=n>estimators</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
        <span class=n>var</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>ests</span><span class=p>)</span>
        <span class=n>eff</span> <span class=o>=</span> <span class=n>crlb</span> <span class=o>/</span> <span class=n>var</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Variance: </span><span class=si>{</span><span class=n>var</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Efficiency: </span><span class=si>{</span><span class=n>eff</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=n>compare_estimators</span><span class=p>(</span><span class=mf>0.3</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
</code></pre></div> <p><strong>Multivariate CRLB:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># For vector parameter Œ∏</span>
<span class=c1># Cov(Œ∏ÃÇ) ‚™∞ I(Œ∏)‚Åª¬π  (matrix inequality)</span>

<span class=c1># Example: Normal(Œº, œÉ¬≤), both unknown</span>

<span class=n>mu_true</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>sigma_true</span> <span class=o>=</span> <span class=mi>2</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>100</span>

<span class=c1># Fisher information matrix</span>
<span class=c1># I(Œº,œÉ¬≤) = [[n/œÉ¬≤, 0], [0, n/(2œÉ‚Å¥)]]</span>

<span class=n>I_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=n>n</span> <span class=o>/</span> <span class=n>sigma_true</span><span class=o>**</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=n>n</span> <span class=o>/</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>sigma_true</span><span class=o>**</span><span class=mi>4</span><span class=p>)]</span>
<span class=p>])</span>

<span class=c1># CRLB: inverse of Fisher information</span>
<span class=n>crlb_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>inv</span><span class=p>(</span><span class=n>I_matrix</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Multivariate CRLB:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Covariance lower bound:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>crlb_matrix</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Var(ŒºÃÇ) ‚â• </span><span class=si>{</span><span class=n>crlb_matrix</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span><span class=mi>0</span><span class=p>]</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Var(œÉÃÇ¬≤) ‚â• </span><span class=si>{</span><span class=n>crlb_matrix</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span><span class=mi>1</span><span class=p>]</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Visualization:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Plot CRLB vs p for Bernoulli</span>

<span class=n>p_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.99</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>50</span>

<span class=n>crlb_values</span> <span class=o>=</span> <span class=p>[</span><span class=n>crlb_bernoulli</span><span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>p_values</span><span class=p>]</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>p_values</span><span class=p>,</span> <span class=n>crlb_values</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;True p&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;CRLB for Var(pÃÇ)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Cram√©r-Rao Lower Bound (n=</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
<span class=c1># Hardest to estimate: p near 0.5</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced estimation theory.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Formula: 1/(n¬∑I(Œ∏))</li> <li>"Lower bound on variance"</li> <li>Knows Fisher Information</li> <li>Mentions efficiency</li> <li>Example: MLE achieves bound</li> </ul> </div> </details> <hr> <h3 id=what-is-the-difference-between-joint-marginal-and-conditional-distributions-most-tech-companies-interview-question>What is the Difference Between Joint, Marginal, and Conditional Distributions? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Distributions</code>, <code>Fundamentals</code>, <code>Probability</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Joint Distribution:</strong></p> <p>P(X, Y) - probability of X and Y together</p> <p><strong>Marginal Distribution:</strong></p> <p>P(X) = ‚àë_y P(X, Y=y) - distribution of X alone</p> <p><strong>Conditional Distribution:</strong></p> <p>P(X | Y) = P(X, Y) / P(Y) - distribution of X given Y</p> <p><strong>Example:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Joint distribution: dice rolls</span>
<span class=c1># X = first die, Y = second die</span>

<span class=c1># Create joint distribution</span>
<span class=n>outcomes</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>7</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>y</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>7</span><span class=p>):</span>
        <span class=n>outcomes</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>))</span>

<span class=n>joint</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>outcomes</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;X&#39;</span><span class=p>,</span> <span class=s1>&#39;Y&#39;</span><span class=p>])</span>
<span class=n>joint_prob</span> <span class=o>=</span> <span class=n>joint</span><span class=o>.</span><span class=n>groupby</span><span class=p>([</span><span class=s1>&#39;X&#39;</span><span class=p>,</span> <span class=s1>&#39;Y&#39;</span><span class=p>])</span><span class=o>.</span><span class=n>size</span><span class=p>()</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>joint</span><span class=p>)</span>

<span class=c1># Reshape to matrix</span>
<span class=n>joint_matrix</span> <span class=o>=</span> <span class=n>joint_prob</span><span class=o>.</span><span class=n>unstack</span><span class=p>(</span><span class=n>fill_value</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Joint Distribution P(X, Y):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>joint_matrix</span><span class=p>)</span>

<span class=c1># Marginal distributions</span>
<span class=n>marginal_X</span> <span class=o>=</span> <span class=n>joint_matrix</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># Sum over Y</span>
<span class=n>marginal_Y</span> <span class=o>=</span> <span class=n>joint_matrix</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># Sum over X</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Marginal P(X):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>marginal_X</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Marginal P(Y):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>marginal_Y</span><span class=p>)</span>

<span class=c1># Conditional distribution: P(X | Y=3)</span>
<span class=n>y_value</span> <span class=o>=</span> <span class=mi>3</span>
<span class=n>conditional_X_given_Y</span> <span class=o>=</span> <span class=n>joint_matrix</span><span class=p>[</span><span class=n>y_value</span><span class=p>]</span> <span class=o>/</span> <span class=n>marginal_Y</span><span class=p>[</span><span class=n>y_value</span><span class=p>]</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Conditional P(X | Y=</span><span class=si>{</span><span class=n>y_value</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>conditional_X_given_Y</span><span class=p>)</span>
</code></pre></div> <p><strong>Real Example - Customer Data:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Customer age and purchase amount</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=c1># Age groups: Young, Middle, Senior</span>
<span class=c1># Purchase: Low, Medium, High</span>

<span class=n>data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>({</span>
    <span class=s1>&#39;Age&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=s1>&#39;Young&#39;</span><span class=p>,</span> <span class=s1>&#39;Middle&#39;</span><span class=p>,</span> <span class=s1>&#39;Senior&#39;</span><span class=p>],</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=p>[</span><span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>]),</span>
    <span class=s1>&#39;Purchase&#39;</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=s1>&#39;Low&#39;</span><span class=p>,</span> <span class=s1>&#39;Mid&#39;</span><span class=p>,</span> <span class=s1>&#39;High&#39;</span><span class=p>],</span> <span class=mi>1000</span><span class=p>)</span>
<span class=p>})</span>

<span class=c1># Joint distribution</span>
<span class=n>joint</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>crosstab</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Age&#39;</span><span class=p>],</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;Purchase&#39;</span><span class=p>],</span> <span class=n>normalize</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Joint P(Age, Purchase):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>joint</span><span class=p>)</span>

<span class=c1># Marginal distributions</span>
<span class=n>marginal_age</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>crosstab</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Age&#39;</span><span class=p>],</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;Purchase&#39;</span><span class=p>],</span> <span class=n>normalize</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
<span class=n>marginal_purchase</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>crosstab</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Age&#39;</span><span class=p>],</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;Purchase&#39;</span><span class=p>],</span> <span class=n>normalize</span><span class=o>=</span><span class=s1>&#39;all&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Marginal P(Age):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>marginal_age</span><span class=p>)</span>

<span class=c1># Conditional: P(Purchase | Age=Young)</span>
<span class=n>conditional</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>crosstab</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=s1>&#39;Age&#39;</span><span class=p>],</span> <span class=n>data</span><span class=p>[</span><span class=s1>&#39;Purchase&#39;</span><span class=p>],</span> <span class=n>normalize</span><span class=o>=</span><span class=s1>&#39;index&#39;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Conditional P(Purchase | Age):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>conditional</span><span class=p>)</span>
</code></pre></div> <p><strong>Visualization:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Visualize joint vs marginals</span>

<span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>

<span class=c1># Joint distribution</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>joint_matrix</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;Blues&#39;</span><span class=p>,</span> <span class=n>aspect</span><span class=o>=</span><span class=s1>&#39;auto&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Joint P(X, Y)&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Y&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;X&#39;</span><span class=p>)</span>

<span class=c1># Marginal X</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>marginal_X</span><span class=o>.</span><span class=n>index</span><span class=p>,</span> <span class=n>marginal_X</span><span class=o>.</span><span class=n>values</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Marginal P(X)&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;X&#39;</span><span class=p>)</span>

<span class=c1># Marginal Y</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>marginal_Y</span><span class=o>.</span><span class=n>index</span><span class=p>,</span> <span class=n>marginal_Y</span><span class=o>.</span><span class=n>values</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Marginal P(Y)&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Y&#39;</span><span class=p>)</span>

<span class=c1># Conditional P(X|Y=3)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>conditional_X_given_Y</span><span class=o>.</span><span class=n>index</span><span class=p>,</span> <span class=n>conditional_X_given_Y</span><span class=o>.</span><span class=n>values</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;orange&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Conditional P(X | Y=</span><span class=si>{</span><span class=n>y_value</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;X&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Key Relationships:</strong></p> <table> <thead> <tr> <th>Relationship</th> <th>Formula</th> </tr> </thead> <tbody> <tr> <td>Marginal from joint</td> <td>P(X) = ‚àë_y P(X,y)</td> </tr> <tr> <td>Conditional from joint</td> <td>P(X|Y) = P(X,Y)/P(Y)</td> </tr> <tr> <td>Joint from conditional</td> <td>P(X,Y) = P(X|Y)P(Y)</td> </tr> <tr> <td>Independence</td> <td>P(X,Y) = P(X)P(Y)</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Basic probability concepts.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Clear definitions</li> <li>"Marginal = sum over other variables"</li> <li>"Conditional = joint / marginal"</li> <li>Can compute from each other</li> </ul> </div> </details> <hr> <h3 id=explain-the-expectation-maximization-em-algorithm-google-meta-interview-question>Explain the Expectation-Maximization (EM) Algorithm - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>EM</code>, <code>Latent Variables</code>, <code>ML</code> | <strong>Asked by:</strong> Google, Meta, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>EM Algorithm:</strong></p> <p>Iterative method to find MLE when data has latent (hidden) variables.</p> <p><strong>E-step:</strong> Compute expected value of log-likelihood w.r.t. latent variables</p> <p><strong>M-step:</strong> Maximize this expectation to update parameters</p> <p><strong>Example - Gaussian Mixture Model:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>norm</span>

<span class=k>class</span><span class=w> </span><span class=nc>GaussianMixture</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_components</span><span class=o>=</span><span class=mi>2</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>n_components</span> <span class=o>=</span> <span class=n>n_components</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>weights</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>means</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>stds</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=k>def</span><span class=w> </span><span class=nf>fit</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>max_iters</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>tol</span><span class=o>=</span><span class=mf>1e-4</span><span class=p>):</span>
        <span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
        <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_components</span>

        <span class=c1># Initialize</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>weights</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>k</span><span class=p>)</span> <span class=o>/</span> <span class=n>k</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>means</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>stds</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>k</span><span class=p>)</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>std</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>

        <span class=n>log_likelihoods</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>for</span> <span class=n>iteration</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_iters</span><span class=p>):</span>
            <span class=c1># E-step: Compute responsibilities</span>
            <span class=n>responsibilities</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>n</span><span class=p>,</span> <span class=n>k</span><span class=p>))</span>

            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>k</span><span class=p>):</span>
                <span class=n>responsibilities</span><span class=p>[:,</span> <span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>weights</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> \
                    <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>means</span><span class=p>[</span><span class=n>j</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>stds</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>

            <span class=c1># Normalize</span>
            <span class=n>responsibilities</span> <span class=o>/=</span> <span class=n>responsibilities</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdims</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

            <span class=c1># M-step: Update parameters</span>
            <span class=n>N</span> <span class=o>=</span> <span class=n>responsibilities</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>

            <span class=bp>self</span><span class=o>.</span><span class=n>weights</span> <span class=o>=</span> <span class=n>N</span> <span class=o>/</span> <span class=n>n</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>means</span> <span class=o>=</span> <span class=p>(</span><span class=n>responsibilities</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>X</span><span class=p>)</span> <span class=o>/</span> <span class=n>N</span>

            <span class=c1># Update standard deviations</span>
            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>k</span><span class=p>):</span>
                <span class=n>diff</span> <span class=o>=</span> <span class=n>X</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>means</span><span class=p>[</span><span class=n>j</span><span class=p>]</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>stds</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>((</span><span class=n>responsibilities</span><span class=p>[:,</span> <span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=n>diff</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>/</span> <span class=n>N</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>

            <span class=c1># Compute log-likelihood</span>
            <span class=n>log_likelihood</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_log_likelihood</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
            <span class=n>log_likelihoods</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>log_likelihood</span><span class=p>)</span>

            <span class=c1># Check convergence</span>
            <span class=k>if</span> <span class=n>iteration</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=ow>and</span> <span class=nb>abs</span><span class=p>(</span><span class=n>log_likelihoods</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=n>log_likelihoods</span><span class=p>[</span><span class=o>-</span><span class=mi>2</span><span class=p>])</span> <span class=o>&lt;</span> <span class=n>tol</span><span class=p>:</span>
                <span class=k>break</span>

        <span class=k>return</span> <span class=n>log_likelihoods</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_log_likelihood</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
        <span class=n>ll</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_components</span><span class=p>):</span>
            <span class=n>ll</span> <span class=o>+=</span> <span class=bp>self</span><span class=o>.</span><span class=n>weights</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>means</span><span class=p>[</span><span class=n>j</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>stds</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>
        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>ll</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

    <span class=k>def</span><span class=w> </span><span class=nf>predict_proba</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>X</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Predict cluster probabilities&quot;&quot;&quot;</span>
        <span class=n>n</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
        <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_components</span>
        <span class=n>probs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>n</span><span class=p>,</span> <span class=n>k</span><span class=p>))</span>

        <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>k</span><span class=p>):</span>
            <span class=n>probs</span><span class=p>[:,</span> <span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>weights</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>means</span><span class=p>[</span><span class=n>j</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>stds</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>

        <span class=n>probs</span> <span class=o>/=</span> <span class=n>probs</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdims</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>probs</span>

<span class=c1># Generate data from mixture</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=c1># True parameters</span>
<span class=n>true_weights</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.7</span><span class=p>]</span>
<span class=n>true_means</span> <span class=o>=</span> <span class=p>[</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>]</span>
<span class=n>true_stds</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>1.2</span><span class=p>]</span>

<span class=n>n_samples</span> <span class=o>=</span> <span class=mi>500</span>
<span class=n>components</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>n_samples</span><span class=p>,</span> <span class=n>p</span><span class=o>=</span><span class=n>true_weights</span><span class=p>)</span>
<span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>true_means</span><span class=p>[</span><span class=n>c</span><span class=p>],</span> <span class=n>true_stds</span><span class=p>[</span><span class=n>c</span><span class=p>])</span> 
    <span class=k>for</span> <span class=n>c</span> <span class=ow>in</span> <span class=n>components</span>
<span class=p>])</span>

<span class=c1># Fit GMM with EM</span>
<span class=n>gmm</span> <span class=o>=</span> <span class=n>GaussianMixture</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>log_likelihoods</span> <span class=o>=</span> <span class=n>gmm</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Learned parameters:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Weights: </span><span class=si>{</span><span class=n>gmm</span><span class=o>.</span><span class=n>weights</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Means: </span><span class=si>{</span><span class=n>gmm</span><span class=o>.</span><span class=n>means</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Stds: </span><span class=si>{</span><span class=n>gmm</span><span class=o>.</span><span class=n>stds</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>True parameters:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Weights: </span><span class=si>{</span><span class=n>true_weights</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Means: </span><span class=si>{</span><span class=n>true_means</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Stds: </span><span class=si>{</span><span class=n>true_stds</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize</span>
<span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>14</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=c1># Data and fitted components</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Data&#39;</span><span class=p>)</span>

<span class=n>x_plot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>min</span><span class=p>(),</span> <span class=n>X</span><span class=o>.</span><span class=n>max</span><span class=p>(),</span> <span class=mi>1000</span><span class=p>)</span>
<span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>):</span>
    <span class=n>y</span> <span class=o>=</span> <span class=n>gmm</span><span class=o>.</span><span class=n>weights</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>gmm</span><span class=o>.</span><span class=n>means</span><span class=p>[</span><span class=n>j</span><span class=p>],</span> <span class=n>gmm</span><span class=o>.</span><span class=n>stds</span><span class=p>[</span><span class=n>j</span><span class=p>])</span>
    <span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Component </span><span class=si>{</span><span class=n>j</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=c1># Total density</span>
<span class=n>total</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>gmm</span><span class=o>.</span><span class=n>weights</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>gmm</span><span class=o>.</span><span class=n>means</span><span class=p>[</span><span class=n>j</span><span class=p>],</span> <span class=n>gmm</span><span class=o>.</span><span class=n>stds</span><span class=p>[</span><span class=n>j</span><span class=p>])</span> 
            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>))</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>total</span><span class=p>,</span> <span class=s1>&#39;k--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Mixture&#39;</span><span class=p>)</span>

<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;X&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Fitted Gaussian Mixture&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>

<span class=c1># Log-likelihood convergence</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>log_likelihoods</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;Iteration&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Log-likelihood&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;EM Convergence&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Key Properties:</strong></p> <ol> <li><strong>Guaranteed improvement:</strong> Log-likelihood never decreases</li> <li><strong>Local maxima:</strong> May not find global optimum</li> <li><strong>Sensitive to initialization:</strong> Multiple random starts help</li> </ol> <p><strong>Applications:</strong></p> <ul> <li>Clustering (GMM)</li> <li>Hidden Markov Models</li> <li>Missing data imputation</li> <li>Topic modeling (LDA)</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> ML algorithms + probability.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>E-step: compute expectations</li> <li>M-step: maximize</li> <li>"Handles latent variables"</li> <li>Example: Gaussian mixture</li> <li>"Increases likelihood each iteration"</li> </ul> </div> </details> <hr> <h3 id=what-is-rejection-sampling-vs-importance-sampling-meta-google-interview-question>What is Rejection Sampling vs Importance Sampling? - Meta, Google Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Monte Carlo</code>, <code>Sampling</code>, <code>Simulation</code> | <strong>Asked by:</strong> Meta, Google, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Rejection Sampling:</strong></p> <p>Sample from target p(x) using proposal q(x):</p> <ol> <li>Sample x ~ q(x)</li> <li>Accept x with probability p(x)/(M¬∑q(x))</li> <li>Repeat until accepted</li> </ol> <p><strong>Importance Sampling:</strong></p> <p>Estimate E_p[f(X)] using samples from q(x):</p> <div class=arithmatex>\[E_p[f(X)] \approx \frac{1}{n}\sum_{i=1}^n f(x_i) \frac{p(x_i)}{q(x_i)}\]</div> <p><strong>Comparison:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>norm</span><span class=p>,</span> <span class=n>expon</span>

<span class=c1># Target: Standard normal truncated to [0, ‚àû)</span>
<span class=k>def</span><span class=w> </span><span class=nf>target_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=k>if</span> <span class=n>x</span> <span class=o>&lt;</span> <span class=mi>0</span><span class=p>:</span>
        <span class=k>return</span> <span class=mi>0</span>
    <span class=k>return</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># Normalized truncated normal</span>

<span class=c1># Proposal: Exponential(1)</span>
<span class=k>def</span><span class=w> </span><span class=nf>proposal_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>expon</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=c1># Find M: max(target/proposal)</span>
<span class=n>x_test</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>ratios</span> <span class=o>=</span> <span class=p>[</span><span class=n>target_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>/</span> <span class=n>proposal_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>x_test</span><span class=p>]</span>
<span class=n>M</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>ratios</span><span class=p>)</span> <span class=o>*</span> <span class=mf>1.1</span>  <span class=c1># Add margin</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;M = </span><span class=si>{</span><span class=n>M</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Method 1: Rejection Sampling</span>
<span class=k>def</span><span class=w> </span><span class=nf>rejection_sampling</span><span class=p>(</span><span class=n>n_samples</span><span class=p>):</span>
    <span class=n>samples</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=n>n_rejected</span> <span class=o>=</span> <span class=mi>0</span>

    <span class=k>while</span> <span class=nb>len</span><span class=p>(</span><span class=n>samples</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>n_samples</span><span class=p>:</span>
        <span class=c1># Propose</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

        <span class=c1># Accept/reject</span>
        <span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>u</span> <span class=o>&lt;</span> <span class=n>target_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>M</span> <span class=o>*</span> <span class=n>proposal_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)):</span>
            <span class=n>samples</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>n_rejected</span> <span class=o>+=</span> <span class=mi>1</span>

    <span class=n>acceptance_rate</span> <span class=o>=</span> <span class=n>n_samples</span> <span class=o>/</span> <span class=p>(</span><span class=n>n_samples</span> <span class=o>+</span> <span class=n>n_rejected</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>samples</span><span class=p>),</span> <span class=n>acceptance_rate</span>

<span class=n>samples_rejection</span><span class=p>,</span> <span class=n>acc_rate</span> <span class=o>=</span> <span class=n>rejection_sampling</span><span class=p>(</span><span class=mi>10000</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Rejection Sampling:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Acceptance rate: </span><span class=si>{</span><span class=n>acc_rate</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Method 2: Importance Sampling</span>
<span class=k>def</span><span class=w> </span><span class=nf>importance_sampling</span><span class=p>(</span><span class=n>n_samples</span><span class=p>):</span>
    <span class=c1># Sample from proposal</span>
    <span class=n>samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>exponential</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>n_samples</span><span class=p>)</span>

    <span class=c1># Compute weights</span>
    <span class=n>weights</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>target_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>/</span> <span class=n>proposal_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>samples</span><span class=p>])</span>

    <span class=k>return</span> <span class=n>samples</span><span class=p>,</span> <span class=n>weights</span>

<span class=n>samples_importance</span><span class=p>,</span> <span class=n>weights</span> <span class=o>=</span> <span class=n>importance_sampling</span><span class=p>(</span><span class=mi>10000</span><span class=p>)</span>

<span class=c1># Normalize weights</span>
<span class=n>weights_normalized</span> <span class=o>=</span> <span class=n>weights</span> <span class=o>/</span> <span class=n>weights</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

<span class=c1># Estimate mean</span>
<span class=n>true_mean</span> <span class=o>=</span> <span class=mf>0.798</span>  <span class=c1># For truncated normal [0,‚àû)</span>

<span class=n>mean_rejection</span> <span class=o>=</span> <span class=n>samples_rejection</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
<span class=n>mean_importance</span> <span class=o>=</span> <span class=p>(</span><span class=n>samples_importance</span> <span class=o>*</span> <span class=n>weights_normalized</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Mean estimation:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True: </span><span class=si>{</span><span class=n>true_mean</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Rejection: </span><span class=si>{</span><span class=n>mean_rejection</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Importance: </span><span class=si>{</span><span class=n>mean_importance</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualization</span>
<span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=c1># Rejection sampling</span>
<span class=n>x_plot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>target_vals</span> <span class=o>=</span> <span class=p>[</span><span class=n>target_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>x_plot</span><span class=p>]</span>
<span class=n>proposal_vals</span> <span class=o>=</span> <span class=p>[</span><span class=n>M</span> <span class=o>*</span> <span class=n>proposal_pdf</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=k>for</span> <span class=n>x</span> <span class=ow>in</span> <span class=n>x_plot</span><span class=p>]</span>

<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>fill_between</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>target_vals</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Target&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>proposal_vals</span><span class=p>,</span> <span class=s1>&#39;r-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;M¬∑Proposal&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Rejection Sampling Setup&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>

<span class=c1># Rejection sampling histogram</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>samples_rejection</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Samples&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>target_vals</span><span class=p>,</span> <span class=s1>&#39;k-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Target&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Rejection Sampling Result&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>

<span class=c1># Importance sampling (weighted histogram)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>samples_importance</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
             <span class=n>weights</span><span class=o>=</span><span class=n>weights_normalized</span><span class=o>*</span><span class=nb>len</span><span class=p>(</span><span class=n>samples_importance</span><span class=p>),</span> 
             <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Weighted samples&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>target_vals</span><span class=p>,</span> <span class=s1>&#39;k-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Target&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Importance Sampling Result&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Comparison Table:</strong></p> <table> <thead> <tr> <th>Aspect</th> <th>Rejection Sampling</th> <th>Importance Sampling</th> </tr> </thead> <tbody> <tr> <td>Output</td> <td>Exact samples from p(x)</td> <td>Weighted samples</td> </tr> <tr> <td>Efficiency</td> <td>Wastes rejected samples</td> <td>Uses all samples</td> </tr> <tr> <td>Requirement</td> <td>Need M bound</td> <td>Just need p(x)/q(x)</td> </tr> <tr> <td>Best use</td> <td>Generate samples</td> <td>Estimate expectations</td> </tr> <tr> <td>High dimensions</td> <td>Poor (low acceptance)</td> <td>Better</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Sampling methods knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Rejection: accept/reject mechanism</li> <li>Importance: reweight samples</li> <li>"Rejection gives exact samples"</li> <li>"Importance better for high-D"</li> <li>Mentions proposal distribution</li> </ul> </div> </details> <hr> <h3 id=explain-the-poisson-distribution-and-its-applications-most-tech-companies-interview-question>Explain the Poisson Distribution and Its Applications - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Distributions</code>, <code>Poisson</code>, <code>Applications</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Poisson Distribution:</strong></p> <p>Models number of events in fixed interval:</p> <div class=arithmatex>\[P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!}\]</div> <p>Where Œª = expected number of events</p> <p><strong>Properties:</strong></p> <ul> <li>E[X] = Œª</li> <li>Var(X) = Œª</li> <li>Sum of Poisson: X ~ Pois(Œª‚ÇÅ), Y ~ Pois(Œª‚ÇÇ) ‚Üí X+Y ~ Pois(Œª‚ÇÅ+Œª‚ÇÇ)</li> </ul> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>poisson</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Example: Website visitors per hour</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mi>5</span>  <span class=c1># Average 5 visitors/hour</span>

<span class=c1># PMF</span>
<span class=n>k</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>15</span><span class=p>)</span>
<span class=n>pmf</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>lambda_rate</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>pmf</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of events&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Poisson PMF (Œª=</span><span class=si>{</span><span class=n>lambda_rate</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Compare different Œª</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=k>for</span> <span class=n>lam</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]:</span>
    <span class=n>pmf</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>lam</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>pmf</span><span class=p>,</span> <span class=s1>&#39;o-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Œª=</span><span class=si>{</span><span class=n>lam</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>6</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;k&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;P(X=k)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Different Rates&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Simulation</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
<span class=n>samples</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>lambda_rate</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>samples</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>16</span><span class=p>),</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> 
         <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Simulation&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>pmf</span><span class=p>,</span> <span class=s1>&#39;ro-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Theory&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of events&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Simulation vs Theory&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Real Applications:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Application 1: Server requests</span>
<span class=k>def</span><span class=w> </span><span class=nf>server_load_analysis</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Model requests per minute&quot;&quot;&quot;</span>
    <span class=n>avg_requests</span> <span class=o>=</span> <span class=mi>50</span>

    <span class=c1># P(more than 60 requests)</span>
    <span class=n>prob_overload</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>poisson</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>60</span><span class=p>,</span> <span class=n>avg_requests</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(overload) = </span><span class=si>{</span><span class=n>prob_overload</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># 95th percentile (capacity planning)</span>
    <span class=n>capacity</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.95</span><span class=p>,</span> <span class=n>avg_requests</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95th percentile: </span><span class=si>{</span><span class=n>capacity</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> requests&quot;</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>capacity</span>

<span class=c1># Application 2: A/B test - rare events</span>
<span class=k>def</span><span class=w> </span><span class=nf>ab_test_poisson</span><span class=p>(</span><span class=n>control_rate</span><span class=p>,</span> <span class=n>treatment_rate</span><span class=p>,</span> <span class=n>n_days</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Test if treatment changes conversion rate&quot;&quot;&quot;</span>
    <span class=c1># Control: Œª‚ÇÄ = control_rate per day</span>
    <span class=c1># Treatment: Œª‚ÇÅ = treatment_rate per day</span>

    <span class=c1># Simulate</span>
    <span class=n>control_conversions</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>control_rate</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>n_days</span><span class=p>)</span>
    <span class=n>treatment_conversions</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>treatment_rate</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>n_days</span><span class=p>)</span>

    <span class=c1># Test difference</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>ttest_ind</span>
    <span class=n>t_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>ttest_ind</span><span class=p>(</span><span class=n>control_conversions</span><span class=p>,</span> <span class=n>treatment_conversions</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>A/B Test (Poisson events):&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Control: mean=</span><span class=si>{</span><span class=n>control_conversions</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, total=</span><span class=si>{</span><span class=n>control_conversions</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Treatment: mean=</span><span class=si>{</span><span class=n>treatment_conversions</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>, total=</span><span class=si>{</span><span class=n>treatment_conversions</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>p_value</span>

<span class=c1># Application 3: Call center staffing</span>
<span class=k>def</span><span class=w> </span><span class=nf>call_center_staffing</span><span class=p>(</span><span class=n>avg_calls_per_hour</span><span class=p>,</span> <span class=n>service_time_minutes</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Determine number of agents needed&quot;&quot;&quot;</span>
    <span class=n>lambda_per_minute</span> <span class=o>=</span> <span class=n>avg_calls_per_hour</span> <span class=o>/</span> <span class=mi>60</span>

    <span class=c1># Erlang C formula approximation</span>
    <span class=c1># For simplicity, use rule of thumb:</span>
    <span class=c1># Need enough capacity for 90th percentile</span>

    <span class=n>calls_90th</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.90</span><span class=p>,</span> <span class=n>lambda_per_minute</span><span class=p>)</span>
    <span class=n>agents_needed</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>calls_90th</span> <span class=o>*</span> <span class=n>service_time_minutes</span><span class=p>))</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Call center staffing:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Average: </span><span class=si>{</span><span class=n>lambda_per_minute</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> calls/minute&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;90th percentile: </span><span class=si>{</span><span class=n>calls_90th</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> calls/minute&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Agents needed: </span><span class=si>{</span><span class=n>agents_needed</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>agents_needed</span>

<span class=c1># Run examples</span>
<span class=n>server_load_analysis</span><span class=p>()</span>
<span class=n>ab_test_poisson</span><span class=p>(</span><span class=n>control_rate</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>treatment_rate</span><span class=o>=</span><span class=mf>3.5</span><span class=p>,</span> <span class=n>n_days</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
<span class=n>call_center_staffing</span><span class=p>(</span><span class=n>avg_calls_per_hour</span><span class=o>=</span><span class=mi>120</span><span class=p>,</span> <span class=n>service_time_minutes</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</code></pre></div> <p><strong>Poisson Approximation to Binomial:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># When n large, p small, np moderate: Binomial ‚âà Poisson</span>

<span class=n>n</span> <span class=o>=</span> <span class=mi>1000</span>
<span class=n>p</span> <span class=o>=</span> <span class=mf>0.005</span>
<span class=n>lambda_approx</span> <span class=o>=</span> <span class=n>n</span> <span class=o>*</span> <span class=n>p</span>

<span class=n>k</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>15</span><span class=p>)</span>

<span class=c1># Exact binomial</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>binom</span>
<span class=n>pmf_binom</span> <span class=o>=</span> <span class=n>binom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>

<span class=c1># Poisson approximation</span>
<span class=n>pmf_poisson</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>lambda_approx</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>k</span> <span class=o>-</span> <span class=mf>0.2</span><span class=p>,</span> <span class=n>pmf_binom</span><span class=p>,</span> <span class=n>width</span><span class=o>=</span><span class=mf>0.4</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Binomial&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>k</span> <span class=o>+</span> <span class=mf>0.2</span><span class=p>,</span> <span class=n>pmf_poisson</span><span class=p>,</span> <span class=n>width</span><span class=o>=</span><span class=mf>0.4</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Poisson approx&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;k&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Binomial(</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s1>, </span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s1>) ‚âà Poisson(</span><span class=si>{</span><span class=n>lambda_approx</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Error</span>
<span class=n>max_error</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>pmf_binom</span> <span class=o>-</span> <span class=n>pmf_poisson</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Max approximation error: </span><span class=si>{</span><span class=n>max_error</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Practical probability knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Formula: Œª·µèe‚ÅªŒª/k!</li> <li>"Count of rare events"</li> <li>E[X] = Var(X) = Œª</li> <li>Examples: web traffic, defects, calls</li> <li>Approximates binomial when n‚Üë, p‚Üì</li> </ul> </div> </details> <hr> <h3 id=what-is-the-law-of-total-probability-most-tech-companies-interview-question>What is the Law of Total Probability? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Probability Theory</code>, <code>Fundamentals</code>, <code>Partition</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Law of Total Probability:</strong></p> <p>If {B‚ÇÅ, B‚ÇÇ, ..., B‚Çô} partition the sample space:</p> <div class=arithmatex>\[P(A) = \sum_{i=1}^n P(A|B_i) P(B_i)\]</div> <p><strong>Continuous version:</strong></p> <div class=arithmatex>\[P(A) = \int P(A|B=b) P(B=b) db\]</div> <p><strong>Example - Medical Testing:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Disease prevalence by age group</span>
<span class=n>age_groups</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;Young&#39;</span><span class=p>,</span> <span class=s1>&#39;Middle&#39;</span><span class=p>,</span> <span class=s1>&#39;Senior&#39;</span><span class=p>]</span>
<span class=n>age_probs</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.30</span><span class=p>,</span> <span class=mf>0.50</span><span class=p>,</span> <span class=mf>0.20</span><span class=p>]</span>  <span class=c1># P(Age group)</span>

<span class=c1># Disease rate in each age group</span>
<span class=n>disease_rate</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;Young&#39;</span><span class=p>:</span> <span class=mf>0.01</span><span class=p>,</span>
    <span class=s1>&#39;Middle&#39;</span><span class=p>:</span> <span class=mf>0.05</span><span class=p>,</span>
    <span class=s1>&#39;Senior&#39;</span><span class=p>:</span> <span class=mf>0.15</span>
<span class=p>}</span>

<span class=c1># Law of total probability: P(Disease)</span>
<span class=n>p_disease</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>age_probs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>disease_rate</span><span class=p>[</span><span class=n>group</span><span class=p>]</span> 
                <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>group</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>age_groups</span><span class=p>))</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Law of Total Probability:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Disease) = &quot;</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=s2>&quot;&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>group</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>age_groups</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Disease|</span><span class=si>{</span><span class=n>group</span><span class=si>}</span><span class=s2>)¬∑P(</span><span class=si>{</span><span class=n>group</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=s2>&quot;&quot;</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>age_groups</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot; + &quot;</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=s2>&quot;&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>           = </span><span class=si>{</span><span class=n>p_disease</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Breakdown</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Contributions:&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>group</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>age_groups</span><span class=p>):</span>
    <span class=n>contrib</span> <span class=o>=</span> <span class=n>age_probs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>disease_rate</span><span class=p>[</span><span class=n>group</span><span class=p>]</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>group</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>age_probs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> √ó </span><span class=si>{</span><span class=n>disease_rate</span><span class=p>[</span><span class=n>group</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> = </span><span class=si>{</span><span class=n>contrib</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Example - Machine Learning:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Classification error rate</span>

<span class=c1># Classes and their proportions</span>
<span class=n>classes</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;A&#39;</span><span class=p>,</span> <span class=s1>&#39;B&#39;</span><span class=p>,</span> <span class=s1>&#39;C&#39;</span><span class=p>]</span>
<span class=n>class_probs</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>]</span>

<span class=c1># Error rate for each class</span>
<span class=n>error_rates</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;A&#39;</span><span class=p>:</span> <span class=mf>0.10</span><span class=p>,</span>
    <span class=s1>&#39;B&#39;</span><span class=p>:</span> <span class=mf>0.15</span><span class=p>,</span>
    <span class=s1>&#39;C&#39;</span><span class=p>:</span> <span class=mf>0.20</span>
<span class=p>}</span>

<span class=c1># Total error rate (law of total probability)</span>
<span class=n>total_error</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>class_probs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>error_rates</span><span class=p>[</span><span class=bp>cls</span><span class=p>]</span> 
                 <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=bp>cls</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>classes</span><span class=p>))</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>ML Example:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Overall error rate: </span><span class=si>{</span><span class=n>total_error</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Visualize</span>
<span class=n>fig</span><span class=p>,</span> <span class=n>axes</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>14</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=c1># Class distribution</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>classes</span><span class=p>,</span> <span class=n>class_probs</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Class Distribution P(Class)&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Error contributions</span>
<span class=n>contributions</span> <span class=o>=</span> <span class=p>[</span><span class=n>class_probs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>error_rates</span><span class=p>[</span><span class=bp>cls</span><span class=p>]</span> 
                <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=bp>cls</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>classes</span><span class=p>)]</span>

<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>classes</span><span class=p>,</span> <span class=n>contributions</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;orange&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>total_error</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> 
                <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Total error: </span><span class=si>{</span><span class=n>total_error</span><span class=si>:</span><span class=s1>.2%</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;Error Contribution by Class&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=s1>&#39;Contribution to total error&#39;</span><span class=p>)</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>axes</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Example - Continuous:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Mixture of normals</span>

<span class=c1># Component probabilities</span>
<span class=n>weights</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.7</span><span class=p>]</span>

<span class=c1># Component parameters</span>
<span class=n>means</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>5</span><span class=p>]</span>
<span class=n>stds</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>]</span>

<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>norm</span>

<span class=c1># Total density at x</span>
<span class=k>def</span><span class=w> </span><span class=nf>total_density</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=k>return</span> <span class=nb>sum</span><span class=p>(</span><span class=n>weights</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>means</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>stds</span><span class=p>[</span><span class=n>i</span><span class=p>])</span> 
              <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>weights</span><span class=p>)))</span>

<span class=c1># Plot</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=o>-</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>

<span class=c1># Individual components</span>
<span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>weights</span><span class=p>)):</span>
    <span class=n>y</span> <span class=o>=</span> <span class=n>weights</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>*</span> <span class=n>norm</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>means</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>stds</span><span class=p>[</span><span class=n>i</span><span class=p>])</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Component </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>

<span class=c1># Total density</span>
<span class=n>y_total</span> <span class=o>=</span> <span class=p>[</span><span class=n>total_density</span><span class=p>(</span><span class=n>xi</span><span class=p>)</span> <span class=k>for</span> <span class=n>xi</span> <span class=ow>in</span> <span class=n>x</span><span class=p>]</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y_total</span><span class=p>,</span> <span class=s1>&#39;k-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Total (Law of Total Prob)&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Continuous Law of Total Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Connection to Bayes:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Law of total probability gives denominator in Bayes&#39; theorem</span>

<span class=c1># P(B|A) = P(A|B)P(B) / P(A)</span>
<span class=c1>#</span>
<span class=c1># Where P(A) = Œ£·µ¢ P(A|B·µ¢)P(B·µ¢)  [Law of total probability]</span>

<span class=c1># Example: Disease testing</span>
<span class=n>p_pos_given_disease</span> <span class=o>=</span> <span class=mf>0.95</span>  <span class=c1># Sensitivity</span>
<span class=n>p_pos_given_no_disease</span> <span class=o>=</span> <span class=mf>0.05</span>  <span class=c1># FPR</span>
<span class=n>p_disease</span> <span class=o>=</span> <span class=mf>0.01</span>  <span class=c1># Prevalence</span>

<span class=c1># P(Positive) by law of total probability</span>
<span class=n>p_positive</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_pos_given_disease</span> <span class=o>*</span> <span class=n>p_disease</span> <span class=o>+</span> 
             <span class=n>p_pos_given_no_disease</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p_disease</span><span class=p>))</span>

<span class=c1># P(Disease | Positive) by Bayes</span>
<span class=n>p_disease_given_pos</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_pos_given_disease</span> <span class=o>*</span> <span class=n>p_disease</span><span class=p>)</span> <span class=o>/</span> <span class=n>p_positive</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Bayes + Law of Total Prob:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Positive) = </span><span class=si>{</span><span class=n>p_positive</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(Disease|Positive) = </span><span class=si>{</span><span class=n>p_disease_given_pos</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Fundamental probability rules.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Partition sample space"</li> <li>Formula: Œ£ P(A|B·µ¢)P(B·µ¢)</li> <li>"Weighted average over conditions"</li> <li>Connection to Bayes denominator</li> <li>Example: disease by age group</li> </ul> </div> </details> <hr> <h3 id=explain-the-geometric-distribution-google-amazon-interview-question>Explain the Geometric Distribution - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Distributions</code>, <code>Geometric</code>, <code>Waiting Time</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Geometric Distribution:</strong></p> <p>Number of trials until first success in Bernoulli trials.</p> <div class=arithmatex>\[P(X=k) = (1-p)^{k-1} p\]</div> <p><strong>Properties:</strong></p> <ul> <li>E[X] = 1/p</li> <li>Var(X) = (1-p)/p¬≤</li> <li><strong>Memoryless:</strong> P(X &gt; n+k | X &gt; n) = P(X &gt; k)</li> </ul> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>geom</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Example: Coin flips until heads</span>
<span class=n>p</span> <span class=o>=</span> <span class=mf>0.3</span>  <span class=c1># P(heads)</span>

<span class=c1># PMF</span>
<span class=n>k</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>21</span><span class=p>)</span>
<span class=n>pmf</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>

<span class=c1># PMF</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>pmf</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of trials until success&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Geometric PMF (p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Different p values</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=k>for</span> <span class=n>p_val</span> <span class=ow>in</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.8</span><span class=p>]:</span>
    <span class=n>pmf</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>p_val</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>pmf</span><span class=p>,</span> <span class=s1>&#39;o-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;p=</span><span class=si>{</span><span class=n>p_val</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>6</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;k&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;P(X=k)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Different Success Probabilities&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># CDF</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
<span class=n>cdf</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>cdf</span><span class=p>,</span> <span class=s1>&#39;bo-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>6</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;k&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;P(X ‚â§ k)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;CDF&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=c1># Properties</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Geometric(p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[X] = </span><span class=si>{</span><span class=n>geom</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>p</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> (theory: </span><span class=si>{</span><span class=mi>1</span><span class=o>/</span><span class=n>p</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Var(X) = </span><span class=si>{</span><span class=n>geom</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>p</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> (theory: </span><span class=si>{</span><span class=p>(</span><span class=mi>1</span><span class=o>-</span><span class=n>p</span><span class=p>)</span><span class=o>/</span><span class=n>p</span><span class=o>**</span><span class=mi>2</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Memoryless Property:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># &quot;The coin doesn&#39;t remember past failures&quot;</span>

<span class=n>p</span> <span class=o>=</span> <span class=mf>0.3</span>

<span class=c1># P(X &gt; 5)</span>
<span class=n>prob_more_than_5</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>geom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>

<span class=c1># P(X &gt; 10 | X &gt; 5) = P(X &gt; 5)</span>
<span class=c1># Conditional probability</span>
<span class=n>prob_10_given_5</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>geom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=n>p</span><span class=p>))</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>geom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=n>p</span><span class=p>))</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Memoryless property:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(X &gt; 5) = </span><span class=si>{</span><span class=n>prob_more_than_5</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(X &gt; 10 | X &gt; 5) = </span><span class=si>{</span><span class=n>prob_10_given_5</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Equal? </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>prob_more_than_5</span><span class=p>,</span><span class=w> </span><span class=n>prob_10_given_5</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Simulation</span>
<span class=n>n_sims</span> <span class=o>=</span> <span class=mi>100000</span>

<span class=c1># All trials</span>
<span class=n>trials</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>n_sims</span><span class=p>)</span>

<span class=c1># Conditional: given X &gt; 5</span>
<span class=n>conditional</span> <span class=o>=</span> <span class=n>trials</span><span class=p>[</span><span class=n>trials</span> <span class=o>&gt;</span> <span class=mi>5</span><span class=p>]</span> <span class=o>-</span> <span class=mi>5</span>  <span class=c1># Reset counter</span>

<span class=c1># Check distributions match</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>ks_2samp</span>
<span class=n>stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>ks_2samp</span><span class=p>(</span><span class=n>trials</span><span class=p>,</span> <span class=n>conditional</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>KS test p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;(High p-value confirms memoryless property)&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Applications:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Application 1: Customer acquisition</span>
<span class=k>def</span><span class=w> </span><span class=nf>customer_acquisition</span><span class=p>(</span><span class=n>conversion_rate</span><span class=o>=</span><span class=mf>0.05</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Expected ads until conversion&quot;&quot;&quot;</span>
    <span class=n>expected_ads</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>conversion_rate</span>

    <span class=c1># P(convert within 50 ads)</span>
    <span class=n>prob_within_50</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>50</span><span class=p>,</span> <span class=n>conversion_rate</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Customer acquisition (p=</span><span class=si>{</span><span class=n>conversion_rate</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected ads to convert: </span><span class=si>{</span><span class=n>expected_ads</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(convert within 50 ads): </span><span class=si>{</span><span class=n>prob_within_50</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># Budget planning: 95% confidence</span>
    <span class=n>ads_95</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.95</span><span class=p>,</span> <span class=n>conversion_rate</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;95th percentile: </span><span class=si>{</span><span class=n>ads_95</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ads&quot;</span><span class=p>)</span>

<span class=c1># Application 2: Reliability testing</span>
<span class=k>def</span><span class=w> </span><span class=nf>reliability_testing</span><span class=p>(</span><span class=n>failure_rate</span><span class=o>=</span><span class=mf>0.01</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Device testing until first failure&quot;&quot;&quot;</span>
    <span class=n>expected_tests</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>failure_rate</span>

    <span class=c1># P(survive at least 100 tests)</span>
    <span class=n>prob_survive_100</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>geom</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=n>failure_rate</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Reliability testing (p=</span><span class=si>{</span><span class=n>failure_rate</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected tests until failure: </span><span class=si>{</span><span class=n>expected_tests</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(survive ‚â•100 tests): </span><span class=si>{</span><span class=n>prob_survive_100</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Application 3: A/B test duration</span>
<span class=k>def</span><span class=w> </span><span class=nf>ab_test_duration</span><span class=p>(</span><span class=n>daily_conversion</span><span class=o>=</span><span class=mf>0.10</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Days until first conversion&quot;&quot;&quot;</span>
    <span class=n>expected_days</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>daily_conversion</span>

    <span class=c1># Distribution of wait time</span>
    <span class=n>days</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>31</span><span class=p>)</span>
    <span class=n>probs</span> <span class=o>=</span> <span class=n>geom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>days</span><span class=p>,</span> <span class=n>daily_conversion</span><span class=p>)</span>

    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>days</span><span class=p>,</span> <span class=n>probs</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Days until first conversion&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;A/B Test First Conversion (p=</span><span class=si>{</span><span class=n>daily_conversion</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>expected_days</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> 
               <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Expected: </span><span class=si>{</span><span class=n>expected_days</span><span class=si>:</span><span class=s1>.1f</span><span class=si>}</span><span class=s1> days&#39;</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>A/B test duration:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected days: </span><span class=si>{</span><span class=n>expected_days</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=n>customer_acquisition</span><span class=p>()</span>
<span class=n>reliability_testing</span><span class=p>()</span>
<span class=n>ab_test_duration</span><span class=p>()</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Discrete distributions knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Trials until first success"</li> <li>E[X] = 1/p</li> <li><strong>Memoryless property</strong></li> <li>Examples: waiting time, retries</li> <li>Relates to exponential (continuous)</li> </ul> </div> </details> <hr> <h3 id=what-is-power-analysis-in-hypothesis-testing-most-tech-companies-interview-question>What is Power Analysis in Hypothesis Testing? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Power</code>, <code>Sample Size</code>, <code>Hypothesis Testing</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Power:</strong></p> <p>Probability of correctly rejecting H‚ÇÄ when it's false.</p> <div class=arithmatex>\[\text{Power} = 1 - \beta = P(\text{reject } H_0 | H_1 \text{ true})\]</div> <p><strong>Four key quantities:</strong></p> <ol> <li><strong>Effect size</strong> (Œî)</li> <li><strong>Sample size</strong> (n)</li> <li><strong>Significance level</strong> (Œ±)</li> <li><strong>Power</strong> (1-Œ≤)</li> </ol> <p>Given any 3, can solve for the 4<sup>th</sup>.</p> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=k>def</span><span class=w> </span><span class=nf>power_analysis_proportion</span><span class=p>(</span><span class=n>p0</span><span class=p>,</span> <span class=n>p1</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.05</span><span class=p>,</span> <span class=n>power</span><span class=o>=</span><span class=mf>0.80</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Calculate sample size for proportion test</span>
<span class=sd>    H‚ÇÄ: p = p0 vs H‚ÇÅ: p = p1</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># Standard errors</span>
    <span class=n>se0</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>p0</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p0</span><span class=p>))</span>
    <span class=n>se1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>p1</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p1</span><span class=p>))</span>

    <span class=c1># Critical value for two-sided test</span>
    <span class=n>z_alpha</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alpha</span><span class=o>/</span><span class=mi>2</span><span class=p>)</span>
    <span class=n>z_beta</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=n>power</span><span class=p>)</span>

    <span class=c1># Sample size formula</span>
    <span class=n>n</span> <span class=o>=</span> <span class=p>((</span><span class=n>z_alpha</span> <span class=o>*</span> <span class=n>se0</span> <span class=o>+</span> <span class=n>z_beta</span> <span class=o>*</span> <span class=n>se1</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>p1</span> <span class=o>-</span> <span class=n>p0</span><span class=p>))</span><span class=o>**</span><span class=mi>2</span>

    <span class=k>return</span> <span class=nb>int</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>

<span class=c1># Example: A/B test</span>
<span class=n>p_control</span> <span class=o>=</span> <span class=mf>0.10</span>  <span class=c1># Current conversion rate</span>
<span class=n>p_treatment</span> <span class=o>=</span> <span class=mf>0.12</span>  <span class=c1># Target improvement</span>

<span class=n>n_needed</span> <span class=o>=</span> <span class=n>power_analysis_proportion</span><span class=p>(</span><span class=n>p_control</span><span class=p>,</span> <span class=n>p_treatment</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Power Analysis:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Control rate: </span><span class=si>{</span><span class=n>p_control</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Treatment rate: </span><span class=si>{</span><span class=n>p_treatment</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Effect size: </span><span class=si>{</span><span class=n>p_treatment</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>p_control</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Œ± = 0.05, Power = 0.80&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Sample size needed: </span><span class=si>{</span><span class=n>n_needed</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2> per group&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Power Curve:</strong></p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>compute_power</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>p0</span><span class=p>,</span> <span class=n>p1</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.05</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Compute power for given sample size&quot;&quot;&quot;</span>
    <span class=c1># Critical value</span>
    <span class=n>z_alpha</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alpha</span><span class=o>/</span><span class=mi>2</span><span class=p>)</span>

    <span class=c1># Under H‚ÇÅ</span>
    <span class=n>se0</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>p0</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p0</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span><span class=p>)</span>
    <span class=n>se1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>p1</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p1</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span><span class=p>)</span>

    <span class=c1># Critical region boundaries</span>
    <span class=n>critical_lower</span> <span class=o>=</span> <span class=n>p0</span> <span class=o>-</span> <span class=n>z_alpha</span> <span class=o>*</span> <span class=n>se0</span>
    <span class=n>critical_upper</span> <span class=o>=</span> <span class=n>p0</span> <span class=o>+</span> <span class=n>z_alpha</span> <span class=o>*</span> <span class=n>se0</span>

    <span class=c1># Power: P(fall in rejection region | H‚ÇÅ)</span>
    <span class=n>z_lower</span> <span class=o>=</span> <span class=p>(</span><span class=n>critical_lower</span> <span class=o>-</span> <span class=n>p1</span><span class=p>)</span> <span class=o>/</span> <span class=n>se1</span>
    <span class=n>z_upper</span> <span class=o>=</span> <span class=p>(</span><span class=n>critical_upper</span> <span class=o>-</span> <span class=n>p1</span><span class=p>)</span> <span class=o>/</span> <span class=n>se1</span>

    <span class=n>power</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>z_lower</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>z_upper</span><span class=p>))</span>

    <span class=k>return</span> <span class=n>power</span>

<span class=c1># Plot power vs sample size</span>
<span class=n>sample_sizes</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>100</span><span class=p>,</span> <span class=mi>5000</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>
<span class=n>powers</span> <span class=o>=</span> <span class=p>[</span><span class=n>compute_power</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>p_control</span><span class=p>,</span> <span class=n>p_treatment</span><span class=p>)</span> <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=n>sample_sizes</span><span class=p>]</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>sample_sizes</span><span class=p>,</span> <span class=n>powers</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=mf>0.80</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Target power=0.80&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>n_needed</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;green&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> 
            <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;n=</span><span class=si>{</span><span class=n>n_needed</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Sample size per group&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Power&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Power vs Sample Size&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Plot power vs effect size</span>
<span class=n>effect_sizes</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.005</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>
<span class=n>n_fixed</span> <span class=o>=</span> <span class=mi>1000</span>
<span class=n>powers</span> <span class=o>=</span> <span class=p>[</span><span class=n>compute_power</span><span class=p>(</span><span class=n>n_fixed</span><span class=p>,</span> <span class=n>p_control</span><span class=p>,</span> <span class=n>p_control</span> <span class=o>+</span> <span class=n>delta</span><span class=p>)</span> 
         <span class=k>for</span> <span class=n>delta</span> <span class=ow>in</span> <span class=n>effect_sizes</span><span class=p>]</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>effect_sizes</span> <span class=o>*</span> <span class=mi>100</span><span class=p>,</span> <span class=n>powers</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=mf>0.80</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Target power=0.80&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Effect size (%)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Power&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Power vs Effect Size (n=</span><span class=si>{</span><span class=n>n_fixed</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Simulation-based Power:</strong></p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>simulate_power</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>p0</span><span class=p>,</span> <span class=n>p1</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.05</span><span class=p>,</span> <span class=n>n_sims</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Estimate power via simulation&quot;&quot;&quot;</span>
    <span class=n>rejections</span> <span class=o>=</span> <span class=mi>0</span>

    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_sims</span><span class=p>):</span>
        <span class=c1># Generate data under H‚ÇÅ</span>
        <span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>p1</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
        <span class=n>p_hat</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>

        <span class=c1># Test H‚ÇÄ: p = p0</span>
        <span class=n>se</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>p0</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>p0</span><span class=p>)</span> <span class=o>/</span> <span class=n>n</span><span class=p>)</span>
        <span class=n>z</span> <span class=o>=</span> <span class=p>(</span><span class=n>p_hat</span> <span class=o>-</span> <span class=n>p0</span><span class=p>)</span> <span class=o>/</span> <span class=n>se</span>

        <span class=c1># Two-sided test</span>
        <span class=n>p_value</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>stats</span><span class=o>.</span><span class=n>norm</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=nb>abs</span><span class=p>(</span><span class=n>z</span><span class=p>)))</span>

        <span class=k>if</span> <span class=n>p_value</span> <span class=o>&lt;</span> <span class=n>alpha</span><span class=p>:</span>
            <span class=n>rejections</span> <span class=o>+=</span> <span class=mi>1</span>

    <span class=k>return</span> <span class=n>rejections</span> <span class=o>/</span> <span class=n>n_sims</span>

<span class=c1># Verify analytical power</span>
<span class=n>n_test</span> <span class=o>=</span> <span class=mi>2000</span>
<span class=n>power_analytical</span> <span class=o>=</span> <span class=n>compute_power</span><span class=p>(</span><span class=n>n_test</span><span class=p>,</span> <span class=n>p_control</span><span class=p>,</span> <span class=n>p_treatment</span><span class=p>)</span>
<span class=n>power_simulated</span> <span class=o>=</span> <span class=n>simulate_power</span><span class=p>(</span><span class=n>n_test</span><span class=p>,</span> <span class=n>p_control</span><span class=p>,</span> <span class=n>p_treatment</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Power validation (n=</span><span class=si>{</span><span class=n>n_test</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Analytical: </span><span class=si>{</span><span class=n>power_analytical</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Simulated: </span><span class=si>{</span><span class=n>power_simulated</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Trade-offs:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Explore Œ± vs power trade-off</span>

<span class=n>alphas</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.01</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.10</span><span class=p>]</span>
<span class=n>n</span> <span class=o>=</span> <span class=mi>1500</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Œ± vs Power trade-off (n=</span><span class=si>{</span><span class=n>n</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>alpha</span> <span class=ow>in</span> <span class=n>alphas</span><span class=p>:</span>
    <span class=n>power</span> <span class=o>=</span> <span class=n>compute_power</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>p_control</span><span class=p>,</span> <span class=n>p_treatment</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Œ± = </span><span class=si>{</span><span class=n>alpha</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>: Power = </span><span class=si>{</span><span class=n>power</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># More liberal Œ± ‚Üí higher power (but more Type I errors)</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Experimental design knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Power = 1 - Œ≤"</li> <li>"P(reject H‚ÇÄ | H‚ÇÅ true)"</li> <li>Four quantities: Œ±, power, n, effect</li> <li>"Need before collecting data"</li> <li>Trade-off: sample size vs power</li> </ul> </div> </details> <hr> <h3 id=explain-the-negative-binomial-distribution-google-amazon-interview-question>Explain the Negative Binomial Distribution - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Distributions</code>, <code>Negative Binomial</code>, <code>Waiting Time</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Negative Binomial:</strong></p> <p>Number of trials until r successes (generalization of geometric).</p> <div class=arithmatex>\[P(X=k) = \binom{k-1}{r-1} p^r (1-p)^{k-r}\]</div> <p><strong>Properties:</strong></p> <ul> <li>E[X] = r/p</li> <li>Var(X) = r(1-p)/p¬≤</li> <li>Sum of r independent Geometric(p)</li> </ul> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>nbinom</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Example: Trials until 5 successes</span>
<span class=n>r</span> <span class=o>=</span> <span class=mi>5</span>  <span class=c1># Number of successes</span>
<span class=n>p</span> <span class=o>=</span> <span class=mf>0.3</span>  <span class=c1># Success probability</span>

<span class=c1># PMF (scipy uses different parameterization: n=r, p=p)</span>
<span class=n>k</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>r</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>
<span class=n>pmf</span> <span class=o>=</span> <span class=n>nbinom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k</span> <span class=o>-</span> <span class=n>r</span><span class=p>,</span> <span class=n>r</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>  <span class=c1># k-r failures before r successes</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>bar</span><span class=p>(</span><span class=n>k</span><span class=p>,</span> <span class=n>pmf</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of trials until r successes&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Negative Binomial (r=</span><span class=si>{</span><span class=n>r</span><span class=si>}</span><span class=s1>, p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>r</span><span class=o>/</span><span class=n>p</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;E[X]=</span><span class=si>{</span><span class=n>r</span><span class=o>/</span><span class=n>p</span><span class=si>:</span><span class=s1>.1f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Different r values</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=k>for</span> <span class=n>r_val</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]:</span>
    <span class=n>k_plot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>r_val</span><span class=p>,</span> <span class=mi>80</span><span class=p>)</span>
    <span class=n>pmf</span> <span class=o>=</span> <span class=n>nbinom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>k_plot</span> <span class=o>-</span> <span class=n>r_val</span><span class=p>,</span> <span class=n>r_val</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>k_plot</span><span class=p>,</span> <span class=n>pmf</span><span class=p>,</span> <span class=s1>&#39;o-&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;r=</span><span class=si>{</span><span class=n>r_val</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;k (trials)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;P(X=k)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Different r (p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Negative Binomial(r=</span><span class=si>{</span><span class=n>r</span><span class=si>}</span><span class=s2>, p=</span><span class=si>{</span><span class=n>p</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[X] = </span><span class=si>{</span><span class=n>r</span><span class=o>/</span><span class=n>p</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Var(X) = </span><span class=si>{</span><span class=n>r</span><span class=o>*</span><span class=p>(</span><span class=mi>1</span><span class=o>-</span><span class=n>p</span><span class=p>)</span><span class=o>/</span><span class=n>p</span><span class=o>**</span><span class=mi>2</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Overdispersion Modeling:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Negative binomial for count data with variance &gt; mean</span>

<span class=c1># Compare Poisson vs Negative Binomial</span>

<span class=c1># Simulate overdispersed count data</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>

<span class=c1># Negative binomial can model overdispersion</span>
<span class=c1># Poisson has Var = Mean, NB has Var &gt; Mean</span>

<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>poisson</span>

<span class=c1># True: Negative Binomial</span>
<span class=n>r_true</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>p_true</span> <span class=o>=</span> <span class=mf>0.5</span>
<span class=n>data</span> <span class=o>=</span> <span class=n>nbinom</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>r_true</span><span class=p>,</span> <span class=n>p_true</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Data statistics:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Variance/Mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Fit Poisson (will be poor fit)</span>
<span class=n>lambda_mle</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>

<span class=c1># Fit Negative Binomial</span>
<span class=c1># (In practice, use MLE; here we use true params)</span>

<span class=c1># Compare fits</span>
<span class=n>count_range</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>30</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Data&#39;</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>

<span class=c1># Poisson fit</span>
<span class=n>poisson_pmf</span> <span class=o>=</span> <span class=n>poisson</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>count_range</span><span class=p>,</span> <span class=n>lambda_mle</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>count_range</span><span class=p>,</span> <span class=n>poisson_pmf</span><span class=p>,</span> <span class=s1>&#39;ro-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Poisson&#39;</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>6</span><span class=p>)</span>

<span class=c1># Negative Binomial fit</span>
<span class=n>nb_pmf</span> <span class=o>=</span> <span class=n>nbinom</span><span class=o>.</span><span class=n>pmf</span><span class=p>(</span><span class=n>count_range</span><span class=p>,</span> <span class=n>r_true</span><span class=p>,</span> <span class=n>p_true</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>count_range</span><span class=p>,</span> <span class=n>nb_pmf</span><span class=p>,</span> <span class=s1>&#39;bo-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Negative Binomial&#39;</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>6</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Count&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Negative Binomial handles overdispersion&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Applications:</strong></p> <ul> <li><strong>Customer retention:</strong> Trials until r customers acquired</li> <li><strong>Reliability:</strong> Tests until r failures</li> <li><strong>Overdispersed counts:</strong> When Poisson doesn't fit (Var &gt; Mean)</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Extended distributions knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Trials until r successes"</li> <li>Generalizes geometric (r=1)</li> <li>E[X] = r/p</li> <li>"Models overdispersion"</li> <li>Variance &gt; mean (vs Poisson)</li> </ul> </div> </details> <hr> <h3 id=what-is-the-exponential-distribution-most-tech-companies-interview-question>What is the Exponential Distribution? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Distributions</code>, <code>Exponential</code>, <code>Memoryless</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Exponential Distribution:</strong></p> <p>Continuous analog of geometric - time until event.</p> <div class=arithmatex>\[f(x) = \lambda e^{-\lambda x}, \quad x \geq 0\]</div> <p><strong>Properties:</strong></p> <ul> <li>E[X] = 1/Œª</li> <li>Var(X) = 1/Œª¬≤</li> <li><strong>Memoryless:</strong> P(X &gt; s+t | X &gt; s) = P(X &gt; t)</li> <li>CDF: <span class=arithmatex>\(F(x) = 1 - e^{-\lambda x}\)</span></li> </ul> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>expon</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Example: Server response time</span>
<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mi>2</span>  <span class=c1># Events per unit time (rate)</span>
<span class=n>mean_time</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>lambda_rate</span>  <span class=c1># Mean = 1/Œª</span>

<span class=c1># PDF and CDF</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>pdf</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>mean_time</span><span class=p>)</span>  <span class=c1># scipy uses scale=1/Œª</span>
<span class=n>cdf</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>mean_time</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>pdf</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>fill_between</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>pdf</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Time&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Exponential PDF (Œª=</span><span class=si>{</span><span class=n>lambda_rate</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>mean_time</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Mean=</span><span class=si>{</span><span class=n>mean_time</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>cdf</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Time&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;P(X ‚â§ x)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;CDF&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;:&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Exponential(Œª=</span><span class=si>{</span><span class=n>lambda_rate</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean: </span><span class=si>{</span><span class=n>mean_time</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Std: </span><span class=si>{</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Median: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>/</span><span class=n>lambda_rate</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Memoryless Property:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Time already waited doesn&#39;t affect future waiting time</span>

<span class=n>lambda_rate</span> <span class=o>=</span> <span class=mi>1</span>

<span class=c1># P(X &gt; 2)</span>
<span class=n>prob_gt_2</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>expon</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>)</span>

<span class=c1># P(X &gt; 5 | X &gt; 3) should equal P(X &gt; 2)</span>
<span class=n>prob_gt_5</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>expon</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>)</span>
<span class=n>prob_gt_3</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>expon</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>)</span>
<span class=n>prob_conditional</span> <span class=o>=</span> <span class=n>prob_gt_5</span> <span class=o>/</span> <span class=n>prob_gt_3</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Memoryless property:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(X &gt; 2) = </span><span class=si>{</span><span class=n>prob_gt_2</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(X &gt; 5 | X &gt; 3) = </span><span class=si>{</span><span class=n>prob_conditional</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Equal? </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>isclose</span><span class=p>(</span><span class=n>prob_gt_2</span><span class=p>,</span><span class=w> </span><span class=n>prob_conditional</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Simulation</span>
<span class=n>samples</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>100000</span><span class=p>)</span>

<span class=c1># Conditional samples</span>
<span class=n>conditional</span> <span class=o>=</span> <span class=n>samples</span><span class=p>[</span><span class=n>samples</span> <span class=o>&gt;</span> <span class=mi>3</span><span class=p>]</span> <span class=o>-</span> <span class=mi>3</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Simulation:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean of all samples: </span><span class=si>{</span><span class=n>samples</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean of conditional: </span><span class=si>{</span><span class=n>conditional</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=c1># Both have same mean!</span>
</code></pre></div> <p><strong>Applications:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Application 1: System reliability</span>
<span class=k>def</span><span class=w> </span><span class=nf>reliability_analysis</span><span class=p>(</span><span class=n>failure_rate</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>mission_time</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    failure_rate: failures per hour</span>
<span class=sd>    mission_time: hours</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># P(survive mission)</span>
    <span class=n>reliability</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>expon</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>mission_time</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>failure_rate</span><span class=p>)</span>

    <span class=c1># Mean time to failure</span>
    <span class=n>mttf</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>failure_rate</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Reliability Analysis:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Failure rate: </span><span class=si>{</span><span class=n>failure_rate</span><span class=si>}</span><span class=s2> per hour&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;MTTF: </span><span class=si>{</span><span class=n>mttf</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> hours&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(survive </span><span class=si>{</span><span class=n>mission_time</span><span class=si>}</span><span class=s2>h): </span><span class=si>{</span><span class=n>reliability</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># Time for 90% survival</span>
    <span class=n>t_90</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.10</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>failure_rate</span><span class=p>)</span>  <span class=c1># F(t) = 0.10</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;90% survive up to: </span><span class=si>{</span><span class=n>t_90</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> hours&quot;</span><span class=p>)</span>

<span class=c1># Application 2: Queue waiting time</span>
<span class=k>def</span><span class=w> </span><span class=nf>queue_analysis</span><span class=p>(</span><span class=n>arrival_rate</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    arrival_rate: customers per minute</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># Time between arrivals ~ Exp(arrival_rate)</span>
    <span class=n>mean_interarrival</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>arrival_rate</span>

    <span class=c1># P(wait &lt; 0.1 minutes)</span>
    <span class=n>prob_short_wait</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=n>mean_interarrival</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Queue Analysis:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Arrival rate: </span><span class=si>{</span><span class=n>arrival_rate</span><span class=si>}</span><span class=s2> per minute&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Mean interarrival: </span><span class=si>{</span><span class=n>mean_interarrival</span><span class=o>*</span><span class=mi>60</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> seconds&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P(next arrival &lt; 6 seconds): </span><span class=si>{</span><span class=n>prob_short_wait</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Application 3: Poisson process connection</span>
<span class=k>def</span><span class=w> </span><span class=nf>poisson_connection</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Exponential interarrival ‚Üí Poisson count&quot;&quot;&quot;</span>
    <span class=n>lambda_rate</span> <span class=o>=</span> <span class=mi>5</span>  <span class=c1># Rate</span>
    <span class=n>T</span> <span class=o>=</span> <span class=mi>10</span>  <span class=c1># Time interval</span>

    <span class=c1># Simulate Poisson process</span>
    <span class=n>interarrivals</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>

    <span class=c1># Count events in [0, T]</span>
    <span class=n>events_in_T</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10000</span><span class=p>):</span>
        <span class=n>times</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>expon</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=n>lambda_rate</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>100</span><span class=p>))</span>
        <span class=n>count</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>times</span> <span class=o>&lt;=</span> <span class=n>T</span><span class=p>)</span>
        <span class=n>events_in_T</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>count</span><span class=p>)</span>

    <span class=c1># Should be Poisson(ŒªT)</span>
    <span class=n>expected_count</span> <span class=o>=</span> <span class=n>lambda_rate</span> <span class=o>*</span> <span class=n>T</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Poisson Process:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Rate: </span><span class=si>{</span><span class=n>lambda_rate</span><span class=si>}</span><span class=s2> per unit time&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Interval: </span><span class=si>{</span><span class=n>T</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected count: </span><span class=si>{</span><span class=n>expected_count</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Simulated mean: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>events_in_T</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=n>reliability_analysis</span><span class=p>()</span>
<span class=n>queue_analysis</span><span class=p>()</span>
<span class=n>poisson_connection</span><span class=p>()</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Continuous distributions.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Formula: Œªe^(-Œªx)</li> <li>"Time until event"</li> <li><strong>Memoryless property</strong></li> <li>E[X] = 1/Œª</li> <li>Connection to Poisson process</li> <li>Examples: failures, queues</li> </ul> </div> </details> <hr> <h3 id=explain-variance-reduction-techniques-in-monte-carlo-google-meta-interview-question>Explain Variance Reduction Techniques in Monte Carlo - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Monte Carlo</code>, <code>Variance Reduction</code>, <code>Simulation</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Variance Reduction:</strong></p> <p>Techniques to reduce variance of Monte Carlo estimates while using same number of samples.</p> <p><strong>1. Antithetic Variables:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Estimate E[f(X)] where X ~ Uniform(0,1)</span>
<span class=k>def</span><span class=w> </span><span class=nf>f</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
    <span class=k>return</span> <span class=n>x</span><span class=o>**</span><span class=mi>2</span>

<span class=c1># Standard Monte Carlo</span>
<span class=k>def</span><span class=w> </span><span class=nf>standard_mc</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
    <span class=n>samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>f</span><span class=p>(</span><span class=n>samples</span><span class=p>))</span>

<span class=c1># Antithetic variables</span>
<span class=k>def</span><span class=w> </span><span class=nf>antithetic_mc</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
    <span class=c1># Use U and 1-U (negatively correlated)</span>
    <span class=n>u</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n</span><span class=o>//</span><span class=mi>2</span><span class=p>)</span>
    <span class=n>samples1</span> <span class=o>=</span> <span class=n>f</span><span class=p>(</span><span class=n>u</span><span class=p>)</span>
    <span class=n>samples2</span> <span class=o>=</span> <span class=n>f</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>u</span><span class=p>)</span>  <span class=c1># Antithetic</span>
    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>samples1</span><span class=p>,</span> <span class=n>samples2</span><span class=p>]))</span>

<span class=c1># Compare variances</span>
<span class=n>n_trials</span> <span class=o>=</span> <span class=mi>1000</span>
<span class=n>n_samples</span> <span class=o>=</span> <span class=mi>100</span>

<span class=n>estimates_standard</span> <span class=o>=</span> <span class=p>[</span><span class=n>standard_mc</span><span class=p>(</span><span class=n>n_samples</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_trials</span><span class=p>)]</span>
<span class=n>estimates_antithetic</span> <span class=o>=</span> <span class=p>[</span><span class=n>antithetic_mc</span><span class=p>(</span><span class=n>n_samples</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_trials</span><span class=p>)]</span>

<span class=n>true_value</span> <span class=o>=</span> <span class=mi>1</span><span class=o>/</span><span class=mi>3</span>  <span class=c1># ‚à´‚ÇÄ¬π x¬≤ dx</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Antithetic Variables:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True value: </span><span class=si>{</span><span class=n>true_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Standard MC variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_standard</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Antithetic variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_antithetic</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Variance reduction: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_standard</span><span class=p>)</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_antithetic</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>x&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>2. Control Variates:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Use correlation with known expectation</span>

<span class=k>def</span><span class=w> </span><span class=nf>control_variate_mc</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Estimate E[e^X] where X ~ N(0,1)</span>
<span class=sd>    Use Y = X as control (E[Y] = 0 is known)</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
    <span class=n>Y</span> <span class=o>=</span> <span class=n>X</span>  <span class=c1># Control variate</span>

    <span class=c1># Target</span>
    <span class=n>f_X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>

    <span class=c1># Optimal coefficient</span>
    <span class=n>cov_fY</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cov</span><span class=p>(</span><span class=n>f_X</span><span class=p>,</span> <span class=n>Y</span><span class=p>)[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>
    <span class=n>var_Y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>Y</span><span class=p>)</span>
    <span class=n>c</span> <span class=o>=</span> <span class=n>cov_fY</span> <span class=o>/</span> <span class=n>var_Y</span>

    <span class=c1># Controlled estimator</span>
    <span class=n>estimate</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>f_X</span> <span class=o>-</span> <span class=n>c</span> <span class=o>*</span> <span class=p>(</span><span class=n>Y</span> <span class=o>-</span> <span class=mi>0</span><span class=p>))</span>  <span class=c1># E[Y] = 0</span>

    <span class=k>return</span> <span class=n>estimate</span>

<span class=c1># Compare</span>
<span class=n>estimates_naive</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>estimates_cv</span> <span class=o>=</span> <span class=p>[]</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>):</span>
    <span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>100</span><span class=p>)</span>
    <span class=n>estimates_naive</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>X</span><span class=p>)))</span>
    <span class=n>estimates_cv</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>control_variate_mc</span><span class=p>(</span><span class=mi>100</span><span class=p>))</span>

<span class=n>true_value</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span>  <span class=c1># E[e^X] for X~N(0,1)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Control Variates:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True value: </span><span class=si>{</span><span class=n>true_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Naive variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_naive</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Control variate variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_cv</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Variance reduction: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_naive</span><span class=p>)</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_cv</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>x&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>3. Stratified Sampling:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Divide domain into strata, sample proportionally</span>

<span class=k>def</span><span class=w> </span><span class=nf>stratified_sampling</span><span class=p>(</span><span class=n>f</span><span class=p>,</span> <span class=n>n_samples</span><span class=p>,</span> <span class=n>n_strata</span><span class=o>=</span><span class=mi>4</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Estimate ‚à´‚ÇÄ¬π f(x) dx using stratification&quot;&quot;&quot;</span>
    <span class=n>estimates</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=c1># Divide [0,1] into strata</span>
    <span class=n>strata_size</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>n_strata</span>
    <span class=n>samples_per_stratum</span> <span class=o>=</span> <span class=n>n_samples</span> <span class=o>//</span> <span class=n>n_strata</span>

    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_strata</span><span class=p>):</span>
        <span class=c1># Sample uniformly within stratum</span>
        <span class=n>lower</span> <span class=o>=</span> <span class=n>i</span> <span class=o>*</span> <span class=n>strata_size</span>
        <span class=n>upper</span> <span class=o>=</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>strata_size</span>

        <span class=n>samples</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=n>lower</span><span class=p>,</span> <span class=n>upper</span><span class=p>,</span> <span class=n>samples_per_stratum</span><span class=p>)</span>
        <span class=n>stratum_estimate</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>f</span><span class=p>(</span><span class=n>samples</span><span class=p>))</span> <span class=o>*</span> <span class=n>strata_size</span>
        <span class=n>estimates</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>stratum_estimate</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>estimates</span><span class=p>)</span>

<span class=c1># Compare</span>
<span class=n>f</span> <span class=o>=</span> <span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>pi</span> <span class=o>*</span> <span class=n>x</span><span class=p>)</span>  <span class=c1># True integral = 2/œÄ</span>

<span class=n>estimates_standard</span> <span class=o>=</span> <span class=p>[</span><span class=n>standard_mc</span><span class=p>(</span><span class=mi>100</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>)]</span>
<span class=n>estimates_stratified</span> <span class=o>=</span> <span class=p>[</span><span class=n>stratified_sampling</span><span class=p>(</span><span class=n>f</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>)]</span>

<span class=n>true_value</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>/</span> <span class=n>np</span><span class=o>.</span><span class=n>pi</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Stratified Sampling:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True value: </span><span class=si>{</span><span class=n>true_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Standard variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_standard</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Stratified variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_stratified</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Variance reduction: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_standard</span><span class=p>)</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_stratified</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>x&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>4. Importance Sampling:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Sample from different distribution, reweight</span>

<span class=k>def</span><span class=w> </span><span class=nf>importance_sampling_mc</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Estimate E[X¬≤] for X ~ Exp(1) using importance sampling</span>
<span class=sd>    Proposal: Exp(2)</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=c1># Sample from proposal (faster decay)</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>expon</span>

    <span class=n>samples</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>n</span><span class=p>)</span>  <span class=c1># Exp(2)</span>

    <span class=c1># Target: Exp(1)</span>
    <span class=c1># Weights: p(x) / q(x)</span>
    <span class=n>weights</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>samples</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>expon</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>samples</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>

    <span class=c1># Weighted average</span>
    <span class=n>estimate</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>samples</span><span class=o>**</span><span class=mi>2</span> <span class=o>*</span> <span class=n>weights</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>estimate</span>

<span class=n>estimates_naive</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>estimates_is</span> <span class=o>=</span> <span class=p>[]</span>

<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>expon</span>

<span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>):</span>
    <span class=c1># Naive</span>
    <span class=n>samples_naive</span> <span class=o>=</span> <span class=n>expon</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>scale</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
    <span class=n>estimates_naive</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>samples_naive</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>

    <span class=c1># Importance sampling</span>
    <span class=n>estimates_is</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>importance_sampling_mc</span><span class=p>(</span><span class=mi>100</span><span class=p>))</span>

<span class=n>true_value</span> <span class=o>=</span> <span class=mi>2</span>  <span class=c1># E[X¬≤] for Exp(1)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Importance Sampling:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True value: </span><span class=si>{</span><span class=n>true_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Naive variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_naive</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Importance sampling variance: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_is</span><span class=p>)</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Variance reduction: </span><span class=si>{</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_naive</span><span class=p>)</span><span class=o>/</span><span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>estimates_is</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>x&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Summary:</strong></p> <table> <thead> <tr> <th>Technique</th> <th>Idea</th> <th>Best for</th> </tr> </thead> <tbody> <tr> <td>Antithetic</td> <td>Use negatively correlated samples</td> <td>Smooth functions</td> </tr> <tr> <td>Control variates</td> <td>Use correlation with known E[Y]</td> <td>Related known quantity</td> </tr> <tr> <td>Stratified</td> <td>Sample proportionally from strata</td> <td>Non-uniform importance</td> </tr> <tr> <td>Importance</td> <td>Sample from better distribution</td> <td>Rare events</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Advanced Monte Carlo methods.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>Lists multiple techniques</li> <li>Antithetic: 1-U</li> <li>Control: use E[Y] known</li> <li>Stratified: divide domain</li> <li>Importance: reweight samples</li> <li>"Reduce variance, same # samples"</li> </ul> </div> </details> <hr> <h3 id=what-is-the-chi-square-distribution-most-tech-companies-interview-question>What is the Chi-Square Distribution? - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü¢ Easy | <strong>Tags:</strong> <code>Distributions</code>, <code>Chi-Square</code>, <code>Hypothesis Testing</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Chi-Square Distribution:</strong></p> <p>Sum of k independent squared standard normals.</p> <div class=arithmatex>\[X = Z_1^2 + Z_2^2 + ... + Z_k^2 \sim \chi^2_k\]</div> <p><strong>Properties:</strong></p> <ul> <li>E[X] = k (degrees of freedom)</li> <li>Var(X) = 2k</li> <li>Non-negative, right-skewed</li> <li>As k‚Üí‚àû, approaches normal</li> </ul> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chi2</span><span class=p>,</span> <span class=n>norm</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># PDF for different df</span>
<span class=n>x</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=k>for</span> <span class=n>df</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>]:</span>
    <span class=n>pdf</span> <span class=o>=</span> <span class=n>chi2</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span>
    <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>pdf</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;df=</span><span class=si>{</span><span class=n>df</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Chi-Square PDF&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Verify: sum of squared normals</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>

<span class=n>df</span> <span class=o>=</span> <span class=mi>5</span>
<span class=n>n_samples</span> <span class=o>=</span> <span class=mi>10000</span>

<span class=c1># Method 1: Direct chi-square</span>
<span class=n>samples_direct</span> <span class=o>=</span> <span class=n>chi2</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>n_samples</span><span class=p>)</span>

<span class=c1># Method 2: Sum of squared normals</span>
<span class=n>samples_constructed</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>n_samples</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>samples_direct</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;chi2.rvs()&#39;</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>samples_constructed</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Sum of Z¬≤&#39;</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>

<span class=c1># Theoretical</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>chi2</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>df</span><span class=p>),</span> <span class=s1>&#39;k-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Theory&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;x&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Chi-Square (df=</span><span class=si>{</span><span class=n>df</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Chi-Square(df=</span><span class=si>{</span><span class=n>df</span><span class=si>}</span><span class=s2>):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;E[X] = </span><span class=si>{</span><span class=n>df</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Sample mean: </span><span class=si>{</span><span class=n>samples_direct</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Var(X) = </span><span class=si>{</span><span class=mi>2</span><span class=o>*</span><span class=n>df</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Sample variance: </span><span class=si>{</span><span class=n>samples_direct</span><span class=o>.</span><span class=n>var</span><span class=p>()</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Goodness-of-Fit Test:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Test if data follows hypothesized distribution</span>

<span class=c1># Example: Die fairness</span>
<span class=n>observed</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>45</span><span class=p>,</span> <span class=mi>52</span><span class=p>,</span> <span class=mi>48</span><span class=p>,</span> <span class=mi>55</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>50</span><span class=p>])</span>  <span class=c1># Rolls</span>
<span class=n>expected</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>50</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>50</span><span class=p>])</span>  <span class=c1># Fair die</span>

<span class=c1># Chi-square test statistic</span>
<span class=n>chi2_stat</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>((</span><span class=n>observed</span> <span class=o>-</span> <span class=n>expected</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span> <span class=o>/</span> <span class=n>expected</span><span class=p>)</span>

<span class=c1># p-value</span>
<span class=n>df</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>observed</span><span class=p>)</span> <span class=o>-</span> <span class=mi>1</span>  <span class=c1># k - 1</span>
<span class=n>p_value</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>chi2</span><span class=o>.</span><span class=n>cdf</span><span class=p>(</span><span class=n>chi2_stat</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Goodness-of-Fit Test:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Observed: </span><span class=si>{</span><span class=n>observed</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Expected: </span><span class=si>{</span><span class=n>expected</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;œá¬≤ statistic: </span><span class=si>{</span><span class=n>chi2_stat</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;df: </span><span class=si>{</span><span class=n>df</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Conclusion: </span><span class=si>{</span><span class=s1>&#39;Fair&#39;</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>p_value</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=mf>0.05</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s1>&#39;Biased&#39;</span><span class=si>}</span><span class=s2> die&quot;</span><span class=p>)</span>

<span class=c1># Visualize</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chisquare</span>
<span class=n>stat</span><span class=p>,</span> <span class=n>p</span> <span class=o>=</span> <span class=n>chisquare</span><span class=p>(</span><span class=n>observed</span><span class=p>,</span> <span class=n>expected</span><span class=p>)</span>

<span class=n>x_plot</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
<span class=n>pdf</span> <span class=o>=</span> <span class=n>chi2</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>x_plot</span><span class=p>,</span> <span class=n>pdf</span><span class=p>,</span> <span class=s1>&#39;b-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;œá¬≤(</span><span class=si>{</span><span class=n>df</span><span class=si>}</span><span class=s1>)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>chi2_stat</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Statistic=</span><span class=si>{</span><span class=n>chi2_stat</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=c1># Critical region</span>
<span class=n>critical</span> <span class=o>=</span> <span class=n>chi2</span><span class=o>.</span><span class=n>ppf</span><span class=p>(</span><span class=mf>0.95</span><span class=p>,</span> <span class=n>df</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>critical</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;orange&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Critical=</span><span class=si>{</span><span class=n>critical</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>fill_between</span><span class=p>(</span><span class=n>x_plot</span><span class=p>[</span><span class=n>x_plot</span> <span class=o>&gt;=</span> <span class=n>critical</span><span class=p>],</span> <span class=mi>0</span><span class=p>,</span> <span class=n>chi2</span><span class=o>.</span><span class=n>pdf</span><span class=p>(</span><span class=n>x_plot</span><span class=p>[</span><span class=n>x_plot</span> <span class=o>&gt;=</span> <span class=n>critical</span><span class=p>],</span> <span class=n>df</span><span class=p>),</span> 
                 <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;orange&#39;</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Rejection region (Œ±=0.05)&#39;</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;œá¬≤&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Density&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Chi-Square Goodness-of-Fit Test&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <p><strong>Independence Test:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Test independence in contingency table</span>

<span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>chi2_contingency</span>

<span class=c1># Example: Gender vs Product preference</span>
<span class=n>observed</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
    <span class=p>[</span><span class=mi>30</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span>  <span class=c1># Male</span>
    <span class=p>[</span><span class=mi>20</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>20</span><span class=p>]</span>   <span class=c1># Female</span>
<span class=p>])</span>

<span class=n>chi2_stat</span><span class=p>,</span> <span class=n>p_value</span><span class=p>,</span> <span class=n>dof</span><span class=p>,</span> <span class=n>expected</span> <span class=o>=</span> <span class=n>chi2_contingency</span><span class=p>(</span><span class=n>observed</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Independence Test:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Observed:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>observed</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Expected (if independent):&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>expected</span><span class=o>.</span><span class=n>round</span><span class=p>(</span><span class=mi>2</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>œá¬≤ statistic: </span><span class=si>{</span><span class=n>chi2_stat</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;df: </span><span class=si>{</span><span class=n>dof</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;p-value: </span><span class=si>{</span><span class=n>p_value</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Conclusion: </span><span class=si>{</span><span class=s1>&#39;Independent&#39;</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>p_value</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=mf>0.05</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s1>&#39;Dependent&#39;</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Applications:</strong></p> <ul> <li>Goodness-of-fit tests</li> <li>Independence tests</li> <li>Variance estimation</li> <li>Confidence intervals for variance</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Statistical testing knowledge.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"Sum of squared normals"</li> <li>E[X] = df, Var = 2¬∑df</li> <li>Goodness-of-fit test</li> <li>Independence test</li> <li>Non-negative, right-skewed</li> </ul> </div> </details> <hr> <h3 id=explain-the-multiple-comparisons-problem-most-tech-companies-interview-question>Explain the Multiple Comparisons Problem - Most Tech Companies Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Multiple Testing</code>, <code>FWER</code>, <code>FDR</code> | <strong>Asked by:</strong> Google, Amazon, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Multiple Comparisons Problem:</strong></p> <p>When performing many hypothesis tests, probability of at least one false positive increases dramatically.</p> <div class=arithmatex>\[P(\text{at least one false positive}) = 1 - (1-\alpha)^m\]</div> <p>For m tests at Œ±=0.05: - m=1: 5% - m=10: 40% - m=20: 64% - m=100: 99.4%</p> <p><strong>Demonstration:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Simulate multiple testing</span>
<span class=k>def</span><span class=w> </span><span class=nf>simulate_multiple_tests</span><span class=p>(</span><span class=n>n_tests</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.05</span><span class=p>,</span> <span class=n>n_sims</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;All null hypotheses are true&quot;&quot;&quot;</span>
    <span class=n>false_positives</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_sims</span><span class=p>):</span>
        <span class=c1># Generate data under null</span>
        <span class=n>p_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n_tests</span><span class=p>)</span>

        <span class=c1># Count false positives</span>
        <span class=n>fp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>p_values</span> <span class=o>&lt;</span> <span class=n>alpha</span><span class=p>)</span>
        <span class=n>false_positives</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>fp</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>false_positives</span><span class=p>)</span>

<span class=c1># Test different numbers of comparisons</span>
<span class=n>test_counts</span> <span class=o>=</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>50</span><span class=p>,</span> <span class=mi>100</span><span class=p>]</span>
<span class=n>fwer_empirical</span> <span class=o>=</span> <span class=p>[]</span>
<span class=n>fwer_theoretical</span> <span class=o>=</span> <span class=p>[]</span>

<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>

<span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=n>test_counts</span><span class=p>:</span>
    <span class=n>fp</span> <span class=o>=</span> <span class=n>simulate_multiple_tests</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>alpha</span><span class=p>)</span>
    <span class=n>fwer_empirical</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>fp</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>))</span>  <span class=c1># At least one FP</span>
    <span class=n>fwer_theoretical</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alpha</span><span class=p>)</span><span class=o>**</span><span class=n>m</span><span class=p>)</span>

<span class=c1># Plot</span>
<span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>

<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>test_counts</span><span class=p>,</span> <span class=n>fwer_empirical</span><span class=p>,</span> <span class=s1>&#39;bo-&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>markersize</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Simulated&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>test_counts</span><span class=p>,</span> <span class=n>fwer_theoretical</span><span class=p>,</span> <span class=s1>&#39;r--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;Theoretical&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axhline</span><span class=p>(</span><span class=n>alpha</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;green&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;:&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Target Œ±=</span><span class=si>{</span><span class=n>alpha</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of tests&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;P(at least one false positive)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Family-Wise Error Rate&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=c1># Distribution of false positives</span>
<span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=n>m</span> <span class=o>=</span> <span class=mi>20</span>
<span class=n>fp</span> <span class=o>=</span> <span class=n>simulate_multiple_tests</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>alpha</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>fp</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>m</span><span class=o>+</span><span class=mi>1</span><span class=p>),</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.7</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of false positives&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Probability&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;False Positives (m=</span><span class=si>{</span><span class=n>m</span><span class=si>}</span><span class=s1> tests, all null true)&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>axvline</span><span class=p>(</span><span class=n>fp</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;red&#39;</span><span class=p>,</span> <span class=n>linestyle</span><span class=o>=</span><span class=s1>&#39;--&#39;</span><span class=p>,</span> <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> 
            <span class=n>label</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;Mean=</span><span class=si>{</span><span class=n>fp</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=kc>True</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>

<span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Multiple Comparisons Problem:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Œ± = </span><span class=si>{</span><span class=n>alpha</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=k>for</span> <span class=n>m</span><span class=p>,</span> <span class=n>fwer</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>test_counts</span><span class=p>,</span> <span class=n>fwer_theoretical</span><span class=p>):</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;m=</span><span class=si>{</span><span class=n>m</span><span class=si>:</span><span class=s2>3d</span><span class=si>}</span><span class=s2> tests: FWER = </span><span class=si>{</span><span class=n>fwer</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Correction Methods:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Generate test scenario</span>
<span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
<span class=n>m</span> <span class=o>=</span> <span class=mi>20</span>

<span class=c1># 80% true nulls, 20% false nulls</span>
<span class=n>n_true_null</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=mf>0.8</span> <span class=o>*</span> <span class=n>m</span><span class=p>)</span>
<span class=n>n_false_null</span> <span class=o>=</span> <span class=n>m</span> <span class=o>-</span> <span class=n>n_true_null</span>

<span class=c1># p-values</span>
<span class=n>p_true_null</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>n_true_null</span><span class=p>)</span>
<span class=n>p_false_null</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>beta</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=n>n_false_null</span><span class=p>)</span>  <span class=c1># Small p-values</span>

<span class=n>p_values</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>p_true_null</span><span class=p>,</span> <span class=n>p_false_null</span><span class=p>])</span>
<span class=n>truth</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=kc>False</span><span class=p>]</span><span class=o>*</span><span class=n>n_true_null</span> <span class=o>+</span> <span class=p>[</span><span class=kc>True</span><span class=p>]</span><span class=o>*</span><span class=n>n_false_null</span><span class=p>)</span>

<span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>

<span class=c1># Method 1: No correction</span>
<span class=n>reject_none</span> <span class=o>=</span> <span class=n>p_values</span> <span class=o>&lt;</span> <span class=n>alpha</span>

<span class=c1># Method 2: Bonferroni</span>
<span class=n>reject_bonf</span> <span class=o>=</span> <span class=n>p_values</span> <span class=o>&lt;</span> <span class=n>alpha</span> <span class=o>/</span> <span class=n>m</span>

<span class=c1># Method 3: Holm-Bonferroni</span>
<span class=n>sorted_idx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>p_values</span><span class=p>)</span>
<span class=n>reject_holm</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>bool</span><span class=p>)</span>

<span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>idx</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>sorted_idx</span><span class=p>):</span>
    <span class=k>if</span> <span class=n>p_values</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>alpha</span> <span class=o>/</span> <span class=p>(</span><span class=n>m</span> <span class=o>-</span> <span class=n>i</span><span class=p>):</span>
        <span class=n>reject_holm</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>=</span> <span class=kc>True</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=k>break</span>

<span class=c1># Method 4: Benjamini-Hochberg (FDR)</span>
<span class=n>sorted_p</span> <span class=o>=</span> <span class=n>p_values</span><span class=p>[</span><span class=n>sorted_idx</span><span class=p>]</span>
<span class=n>thresholds</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>m</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>m</span> <span class=o>*</span> <span class=n>alpha</span>
<span class=n>comparisons</span> <span class=o>=</span> <span class=n>sorted_p</span> <span class=o>&lt;=</span> <span class=n>thresholds</span>

<span class=n>reject_bh</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>bool</span><span class=p>)</span>
<span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>any</span><span class=p>(</span><span class=n>comparisons</span><span class=p>):</span>
    <span class=n>k</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>comparisons</span><span class=p>)[</span><span class=mi>0</span><span class=p>])</span>
    <span class=n>reject_bh</span><span class=p>[</span><span class=n>sorted_idx</span><span class=p>[:</span><span class=n>k</span><span class=o>+</span><span class=mi>1</span><span class=p>]]</span> <span class=o>=</span> <span class=kc>True</span>

<span class=c1># Evaluate</span>
<span class=n>methods</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;No correction&#39;</span><span class=p>:</span> <span class=n>reject_none</span><span class=p>,</span>
    <span class=s1>&#39;Bonferroni&#39;</span><span class=p>:</span> <span class=n>reject_bonf</span><span class=p>,</span>
    <span class=s1>&#39;Holm&#39;</span><span class=p>:</span> <span class=n>reject_holm</span><span class=p>,</span>
    <span class=s1>&#39;Benjamini-Hochberg&#39;</span><span class=p>:</span> <span class=n>reject_bh</span>
<span class=p>}</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Correction Method Comparison:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;True situation: </span><span class=si>{</span><span class=n>n_true_null</span><span class=si>}</span><span class=s2> nulls true, </span><span class=si>{</span><span class=n>n_false_null</span><span class=si>}</span><span class=s2> nulls false</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>reject</span> <span class=ow>in</span> <span class=n>methods</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
    <span class=n>tp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>reject</span> <span class=o>&amp;</span> <span class=n>truth</span><span class=p>)</span>  <span class=c1># True positives</span>
    <span class=n>fp</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>reject</span> <span class=o>&amp;</span> <span class=o>~</span><span class=n>truth</span><span class=p>)</span>  <span class=c1># False positives</span>
    <span class=n>fn</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>~</span><span class=n>reject</span> <span class=o>&amp;</span> <span class=n>truth</span><span class=p>)</span>  <span class=c1># False negatives</span>

    <span class=n>power</span> <span class=o>=</span> <span class=n>tp</span> <span class=o>/</span> <span class=n>n_false_null</span> <span class=k>if</span> <span class=n>n_false_null</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=k>else</span> <span class=mi>0</span>
    <span class=n>fdr</span> <span class=o>=</span> <span class=n>fp</span> <span class=o>/</span> <span class=n>reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=k>if</span> <span class=n>reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=k>else</span> <span class=mi>0</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Rejections: </span><span class=si>{</span><span class=n>reject</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  True positives: </span><span class=si>{</span><span class=n>tp</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  False positives: </span><span class=si>{</span><span class=n>fp</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Power: </span><span class=si>{</span><span class=n>power</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  FDR: </span><span class=si>{</span><span class=n>fdr</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>()</span>
</code></pre></div> <p><strong>When to Use Each:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Controls</th> <th>Use When</th> </tr> </thead> <tbody> <tr> <td>Bonferroni</td> <td>FWER</td> <td>Few tests, need strict control</td> </tr> <tr> <td>Holm</td> <td>FWER</td> <td>Uniformly better than Bonferroni</td> </tr> <tr> <td>BH</td> <td>FDR</td> <td>Many tests, exploratory</td> </tr> <tr> <td>No correction</td> <td>Nothing</td> <td>Single planned test only!</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Multiple testing awareness.</p> <p><strong>Strong answer signals:</strong></p> <ul> <li>"More tests ‚Üí more false positives"</li> <li>Formula: 1-(1-Œ±)^m</li> <li>Bonferroni: Œ±/m</li> <li>BH for FDR control</li> <li>"Critical in A/B testing, genomics"</li> </ul> </div> </details> <hr> <h2 id=quick-reference-100-interview-questions>Quick Reference: 100+ Interview Questions</h2> <table> <thead> <tr> <th>Sno</th> <th>Question Title</th> <th>Practice Links</th> <th>Companies Asking</th> <th>Difficulty</th> <th>Topics</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>Basic Probability Concepts: Definitions of Sample Space, Event, Outcome</td> <td><a href=https://en.wikipedia.org/wiki/Probability>Wikipedia: Probability</a></td> <td>Google, Amazon, Microsoft</td> <td>Easy</td> <td>Fundamental Concepts</td> </tr> <tr> <td>2</td> <td>Conditional Probability and Independence</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Conditional Probability</a></td> <td>Google, Facebook, Amazon</td> <td>Medium</td> <td>Conditional Probability, Independence</td> </tr> <tr> <td>3</td> <td>Bayes‚Äô Theorem: Statement and Application</td> <td><a href=https://en.wikipedia.org/wiki/Bayes%27_theorem>Wikipedia: Bayes' Theorem</a></td> <td>Google, Amazon, Microsoft</td> <td>Medium</td> <td>Bayesian Inference</td> </tr> <tr> <td>4</td> <td>Law of Total Probability</td> <td><a href=https://en.wikipedia.org/wiki/Law_of_total_probability>Wikipedia: Law of Total Probability</a></td> <td>Google, Facebook</td> <td>Medium</td> <td>Theoretical Probability</td> </tr> <tr> <td>5</td> <td>Expected Value and Variance</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Expected Value</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Random Variables, Moments</td> </tr> <tr> <td>6</td> <td>Probability Distributions: Discrete vs. Continuous</td> <td><a href=https://en.wikipedia.org/wiki/Probability_distribution>Wikipedia: Probability Distribution</a></td> <td>Google, Amazon, Microsoft</td> <td>Easy</td> <td>Distributions</td> </tr> <tr> <td>7</td> <td>Binomial Distribution: Definition and Applications</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library>Khan Academy: Binomial Distribution</a></td> <td>Amazon, Facebook</td> <td>Medium</td> <td>Discrete Distributions</td> </tr> <tr> <td>8</td> <td>Poisson Distribution: Characteristics and Uses</td> <td><a href=https://en.wikipedia.org/wiki/Poisson_distribution>Wikipedia: Poisson Distribution</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Discrete Distributions</td> </tr> <tr> <td>9</td> <td>Exponential Distribution: Properties and Applications</td> <td><a href=https://en.wikipedia.org/wiki/Exponential_distribution>Wikipedia: Exponential Distribution</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Continuous Distributions</td> </tr> <tr> <td>10</td> <td>Normal Distribution and the Central Limit Theorem</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data>Khan Academy: Normal Distribution</a></td> <td>Google, Microsoft, Facebook</td> <td>Medium</td> <td>Continuous Distributions, CLT</td> </tr> <tr> <td>11</td> <td>Law of Large Numbers</td> <td><a href=https://en.wikipedia.org/wiki/Law_of_large_numbers>Wikipedia: Law of Large Numbers</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Statistical Convergence</td> </tr> <tr> <td>12</td> <td>Covariance and Correlation: Definitions and Differences</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitatively>Khan Academy: Covariance and Correlation</a></td> <td>Google, Facebook</td> <td>Medium</td> <td>Statistics, Dependency</td> </tr> <tr> <td>13</td> <td>Moment Generating Functions (MGFs)</td> <td><a href=https://en.wikipedia.org/wiki/Moment-generating_function>Wikipedia: Moment-generating function</a></td> <td>Amazon, Microsoft</td> <td>Hard</td> <td>Random Variables, Advanced Concepts</td> </tr> <tr> <td>14</td> <td>Markov Chains: Basics and Applications</td> <td><a href=https://en.wikipedia.org/wiki/Markov_chain>Wikipedia: Markov chain</a></td> <td>Google, Amazon, Facebook</td> <td>Hard</td> <td>Stochastic Processes</td> </tr> <tr> <td>15</td> <td>Introduction to Stochastic Processes</td> <td><a href=https://en.wikipedia.org/wiki/Stochastic_process>Wikipedia: Stochastic process</a></td> <td>Google, Microsoft</td> <td>Hard</td> <td>Advanced Probability</td> </tr> <tr> <td>16</td> <td>Difference Between Independent and Mutually Exclusive Events</td> <td><a href=https://en.wikipedia.org/wiki/Independence_(probability_theory)>Wikipedia: Independent events</a></td> <td>Google, Facebook</td> <td>Easy</td> <td>Fundamental Concepts</td> </tr> <tr> <td>17</td> <td>Geometric Distribution: Concept and Use Cases</td> <td><a href=https://en.wikipedia.org/wiki/Geometric_distribution>Wikipedia: Geometric distribution</a></td> <td>Amazon, Microsoft</td> <td>Medium</td> <td>Discrete Distributions</td> </tr> <tr> <td>18</td> <td>Hypergeometric Distribution: When to Use It</td> <td><a href=https://en.wikipedia.org/wiki/Hypergeometric_distribution>Wikipedia: Hypergeometric distribution</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Discrete Distributions</td> </tr> <tr> <td>19</td> <td>Confidence Intervals: Definition and Calculation</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/confidence-intervals>Khan Academy: Confidence intervals</a></td> <td>Microsoft, Facebook</td> <td>Medium</td> <td>Inferential Statistics</td> </tr> <tr> <td>20</td> <td>Hypothesis Testing: p-values, Type I and Type II Errors</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/significance-tests>Khan Academy: Hypothesis testing</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Inferential Statistics</td> </tr> <tr> <td>21</td> <td>Chi-Squared Test: Basics and Applications</td> <td><a href=https://en.wikipedia.org/wiki/Chi-squared_test>Wikipedia: Chi-squared test</a></td> <td>Amazon, Microsoft</td> <td>Medium</td> <td>Inferential Statistics</td> </tr> <tr> <td>22</td> <td>Permutations and Combinations</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Permutations and Combinations</a></td> <td>Google, Facebook</td> <td>Easy</td> <td>Combinatorics</td> </tr> <tr> <td>23</td> <td>The Birthday Problem and Its Implications</td> <td><a href=https://en.wikipedia.org/wiki/Birthday_problem>Wikipedia: Birthday problem</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Probability Puzzles</td> </tr> <tr> <td>24</td> <td>The Monty Hall Problem</td> <td><a href=https://en.wikipedia.org/wiki/Monty_Hall_problem>Wikipedia: Monty Hall problem</a></td> <td>Google, Facebook</td> <td>Medium</td> <td>Probability Puzzles, Conditional Probability</td> </tr> <tr> <td>25</td> <td>Marginal vs. Conditional Probabilities</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Conditional Probability</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Theoretical Concepts</td> </tr> <tr> <td>26</td> <td>Real-World Application of Bayes‚Äô Theorem</td> <td><a href=https://towardsdatascience.com/bayes-theorem-in-machine-learning-6a8b5e9ad0f3>Towards Data Science: Bayes‚Äô Theorem Applications</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Bayesian Inference</td> </tr> <tr> <td>27</td> <td>Probability Mass Function (PMF) vs. Probability Density Function (PDF)</td> <td><a href=https://en.wikipedia.org/wiki/Probability_density_function>Wikipedia: Probability density function</a></td> <td>Amazon, Facebook</td> <td>Medium</td> <td>Distributions</td> </tr> <tr> <td>28</td> <td>Cumulative Distribution Function (CDF): Definition and Uses</td> <td><a href=https://en.wikipedia.org/wiki/Cumulative_distribution_function>Wikipedia: Cumulative distribution function</a></td> <td>Google, Microsoft</td> <td>Medium</td> <td>Distributions</td> </tr> <tr> <td>29</td> <td>Determining Independence of Events</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Independent Events</a></td> <td>Google, Amazon</td> <td>Easy</td> <td>Fundamental Concepts</td> </tr> <tr> <td>30</td> <td>Entropy in Information Theory</td> <td><a href=https://en.wikipedia.org/wiki/Entropy_(information_theory)>Wikipedia: Entropy (information theory)</a></td> <td>Google, Facebook</td> <td>Hard</td> <td>Information Theory, Probability</td> </tr> <tr> <td>31</td> <td>Joint Probability Distributions</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/probability-library>Khan Academy: Joint Probability</a></td> <td>Microsoft, Amazon</td> <td>Medium</td> <td>Multivariate Distributions</td> </tr> <tr> <td>32</td> <td>Conditional Expectation</td> <td><a href=https://en.wikipedia.org/wiki/Conditional_expectation>Wikipedia: Conditional expectation</a></td> <td>Google, Facebook</td> <td>Hard</td> <td>Advanced Concepts</td> </tr> <tr> <td>33</td> <td>Sampling Methods: With and Without Replacement</td> <td><a href=https://www.khanacademy.org/math/statistics-probability>Khan Academy: Sampling</a></td> <td>Amazon, Microsoft</td> <td>Easy</td> <td>Sampling, Combinatorics</td> </tr> <tr> <td>34</td> <td>Risk Modeling Using Probability</td> <td><a href=https://www.investopedia.com/terms/r/risk-analysis.asp>Investopedia: Risk Analysis</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Applications, Finance</td> </tr> <tr> <td>35</td> <td>In-Depth: Central Limit Theorem and Its Importance</td> <td><a href=https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data>Khan Academy: Central Limit Theorem</a></td> <td>Google, Microsoft</td> <td>Medium</td> <td>Theoretical Concepts, Distributions</td> </tr> <tr> <td>36</td> <td>Variance under Linear Transformations</td> <td><a href=https://en.wikipedia.org/wiki/Variance>Wikipedia: Variance</a></td> <td>Amazon, Facebook</td> <td>Hard</td> <td>Advanced Statistics</td> </tr> <tr> <td>37</td> <td>Quantiles: Definition and Interpretation</td> <td><a href=https://www.khanacademy.org/math/statistics-probability>Khan Academy: Percentiles</a></td> <td>Google, Amazon</td> <td>Medium</td> <td>Descriptive Statistics</td> </tr> <tr> <td>38</td> <td>Common Probability Puzzles and Brain Teasers</td> <td><a href=https://brilliant.org/wiki/probability/ >Brilliant.org: Probability Puzzles</a></td> <td>Google, Facebook</td> <td>Medium</td> <td>Puzzles, Recreational Mathematics</td> </tr> <tr> <td>39</td> <td>Real-World Applications of Probability in Data Science</td> <td><a href=https://towardsdatascience.com/ >Towards Data Science</a> <em>(Search for probability applications in DS)</em></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Applications, Data Science</td> </tr> <tr> <td>40</td> <td>Advanced Topic: Introduction to Stochastic Calculus</td> <td><a href=https://en.wikipedia.org/wiki/Stochastic_calculus>Wikipedia: Stochastic calculus</a></td> <td>Microsoft, Amazon</td> <td>Hard</td> <td>Advanced Probability, Finance</td> </tr> </tbody> </table> <hr> <h2 id=questions-asked-in-google-interview>Questions asked in Google interview</h2> <ul> <li>Bayes‚Äô Theorem: Statement and Application </li> <li>Conditional Probability and Independence </li> <li>The Birthday Problem </li> <li>The Monty Hall Problem </li> <li>Normal Distribution and the Central Limit Theorem </li> <li>Law of Large Numbers </li> </ul> <h2 id=questions-asked-in-facebook-interview>Questions asked in Facebook interview</h2> <ul> <li>Conditional Probability and Independence </li> <li>Bayes‚Äô Theorem </li> <li>Chi-Squared Test </li> <li>The Monty Hall Problem </li> <li>Entropy in Information Theory </li> </ul> <h2 id=questions-asked-in-amazon-interview>Questions asked in Amazon interview</h2> <ul> <li>Basic Probability Concepts </li> <li>Bayes‚Äô Theorem </li> <li>Expected Value and Variance </li> <li>Binomial and Poisson Distributions </li> <li>Permutations and Combinations </li> <li>Real-World Applications of Bayes‚Äô Theorem </li> </ul> <h2 id=questions-asked-in-microsoft-interview>Questions asked in Microsoft interview</h2> <ul> <li>Bayes‚Äô Theorem </li> <li>Markov Chains </li> <li>Stochastic Processes </li> <li>Central Limit Theorem </li> <li>Variance under Linear Transformations </li> </ul> <hr> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2020 - <script>document.write(/\d{4}/.exec(Date())[0])</script> ‚Ä¢ <strong>Kuldeep Singh Sidhu</strong> ‚Ä¢ <u><a href=https://choosealicense.com/licenses/agpl-3.0/ target=‚Äù_blank‚Äù>License</a></u> ‚Ä¢ <u><a href=/privacy>Privacy Policy</a></u> ‚Ä¢ <u><a href=/contact>Contact</a></u> ‚Ä¢ </div> </div> <div class=md-social> <a href=https://github.com/singhsidhukuldeep/ target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M8 0c4.42 0 8 3.58 8 8a8.01 8.01 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27s-1.36.09-2 .27c-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8"/></svg> </a> <a href=https://linkedin.com/in/singhsidhukuldeep target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href=https://twitter.com/kuldeep_s_s target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> <a href=https://stackoverflow.com/u/7182350/ target=_blank rel=noopener title=stackoverflow.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 384 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M290.7 311 95 269.7 86.8 309l195.7 41zm51-87L188.2 95.7l-25.5 30.8 153.5 128.3zm-31.2 39.7L129.2 179l-16.7 36.5L293.7 300zM262 32l-32 24 119.3 160.3 32-24zm20.5 328h-200v39.7h200zm39.7 80H42.7V320h-40v160h359.5V320h-40z"/></svg> </a> <a href=https://huggingface.co/singhsidhukuldeep target=_blank rel=noopener title=huggingface.co class=md-social__link> <svg width=500 height=463 viewbox="0 0 500 463" fill=none xmlns=http://www.w3.org/2000/svg> <path fill=white d="M496.592 369.699C500.563 381.093 499.61 393.227 494.315 403.778C490.503 411.48 485.05 417.441 478.379 422.769C470.331 429.099 460.324 434.48 448.253 439.65C433.852 445.77 416.274 451.52 408.226 453.63C387.63 458.958 367.829 462.334 347.762 462.493C319.066 462.756 294.34 456.004 276.762 438.753C267.656 439.861 258.443 440.494 249.178 440.494C240.389 440.494 231.706 439.967 223.076 438.912C205.445 456.057 180.825 462.756 152.234 462.493C132.168 462.334 112.366 458.958 91.7177 453.63C83.7229 451.52 66.145 445.77 51.7439 439.65C39.6723 434.48 29.6656 429.099 21.6708 422.769C14.9467 417.441 9.49334 411.48 5.68127 403.778C0.439661 393.227 -0.566304 381.093 3.45755 369.699C-0.248631 360.994 -1.20165 351.024 1.71035 339.998C3.03399 334.987 5.20476 330.344 7.95792 326.229C7.37552 324.067 6.89901 321.851 6.58134 319.424C4.56941 304.97 9.59923 291.781 19.0765 281.547C23.7357 276.43 28.7655 272.895 34.0071 270.627C30.1421 254.273 28.1302 237.445 28.1302 220.247C28.1302 98.5969 127.085 0 249.178 0C291.111 0 330.343 11.6058 363.805 31.8633C369.84 35.5561 375.77 39.5126 381.436 43.7329C384.242 45.8431 387.048 48.006 389.748 50.2744C392.501 52.49 395.201 54.8112 397.796 57.1851C405.632 64.3069 412.991 71.9562 419.715 80.133C421.992 82.8235 424.163 85.6194 426.28 88.4681C430.569 94.1128 434.54 99.9685 438.193 106.035C443.752 115.109 448.623 124.604 452.859 134.469C455.665 141.064 458.101 147.816 460.271 154.727C463.501 165.067 465.99 175.723 467.684 186.696C468.213 190.336 468.69 194.028 469.06 197.721C469.802 205.107 470.225 212.598 470.225 220.247C470.225 237.234 468.213 253.904 464.454 269.994C470.278 272.262 475.784 275.955 480.92 281.547C490.397 291.781 495.427 305.022 493.415 319.477C493.098 321.851 492.621 324.067 492.039 326.229C494.792 330.344 496.963 334.987 498.286 339.998C501.198 351.024 500.245 360.994 496.592 369.699Z"/> <path fill=black d="M433.839 221.75C433.839 120.838 351.531 39.0323 250 39.0323C148.469 39.0323 66.1613 120.838 66.1613 221.75C66.1613 322.662 148.469 404.468 250 404.468C351.531 404.468 433.839 322.662 433.839 221.75ZM45 221.75C45 109.222 136.782 18 250 18C363.218 18 455 109.222 455 221.75C455 334.278 363.218 425.5 250 425.5C136.782 425.5 45 334.278 45 221.75Z"/> <path fill=white d="M250 405.5C352.173 405.5 435 323.232 435 221.75C435 120.268 352.173 38 250 38C147.827 38 65 120.268 65 221.75C65 323.232 147.827 405.5 250 405.5Z"/> <path fill=white d="M202.198 404.174C216.789 383.118 215.755 367.316 195.735 347.627C175.715 327.943 164.062 299.145 164.062 299.145C164.062 299.145 159.709 282.419 149.794 283.958C139.88 285.497 132.6 310.492 153.368 325.783C174.135 341.069 149.232 351.456 141.242 337.099C133.252 322.741 111.435 285.831 100.121 278.772C88.8117 271.713 80.8483 275.668 83.5151 290.218C86.182 304.769 133.48 340.036 128.878 347.668C124.276 355.296 108.058 338.7 108.058 338.7C108.058 338.7 57.3079 293.255 46.2587 305.097C35.2096 316.94 54.641 326.863 82.3328 343.359C110.03 359.85 112.177 364.206 108.248 370.446C104.314 376.685 43.1836 325.971 37.4417 347.47C31.705 368.969 99.8291 375.209 95.6247 390.051C91.4203 404.899 47.6372 361.958 38.6823 378.689C29.7221 395.425 100.465 415.088 101.038 415.234C123.889 421.067 181.924 433.426 202.198 404.174Z"/> <path fill=black d="M90.9935 255C82.4744 255 74.8603 258.477 69.551 264.784C66.2675 268.69 62.8367 274.986 62.5578 284.414C58.985 283.394 55.5489 282.824 52.3391 282.824C44.183 282.824 36.8163 285.93 31.6069 291.573C24.9137 298.815 21.9407 307.715 23.2351 316.62C23.8508 320.861 25.2768 324.663 27.4079 328.182C22.9142 331.795 19.6044 336.826 18.0047 342.876C16.7524 347.619 15.4685 357.497 22.1722 367.673C21.746 368.337 21.3461 369.027 20.9725 369.733C16.9418 377.336 16.684 385.927 20.2411 393.928C25.6346 406.054 39.0368 415.608 65.0625 425.863C81.2536 432.242 96.0661 436.321 96.1976 436.357C117.603 441.874 136.962 444.677 153.721 444.677C184.525 444.677 206.578 435.301 219.27 416.811C239.697 387.036 236.776 359.803 210.346 333.552C195.717 319.026 185.993 297.607 183.967 292.906C179.884 278.986 169.086 263.513 151.138 263.513H151.133C149.622 263.513 148.096 263.633 146.592 263.869C138.73 265.097 131.858 269.595 126.949 276.361C121.65 269.814 116.504 264.606 111.847 261.667C104.827 257.243 97.813 255 90.9935 255ZM90.9935 275.917C93.6771 275.917 96.9553 277.051 100.57 279.331C111.794 286.406 133.452 323.403 141.382 337.793C144.039 342.614 148.581 344.654 152.669 344.654C160.783 344.654 167.118 336.638 153.411 326.451C132.8 311.124 140.03 286.072 149.87 284.529C150.301 284.461 150.727 284.43 151.138 284.43C160.083 284.43 164.03 299.751 164.03 299.751C164.03 299.751 175.595 328.616 195.465 348.346C215.334 368.08 216.36 383.919 201.879 405.024C192.002 419.415 173.096 421.292 153.721 421.292C133.626 421.292 112.99 417.772 101.445 414.796C100.877 414.65 30.7019 396.255 39.5946 379.48C41.089 376.661 43.5516 375.532 46.6509 375.532C59.1744 375.532 81.9535 394.054 91.746 394.054C93.935 394.054 95.5662 392.371 96.1976 390.112C100.555 374.522 32.6646 369.738 38.3633 348.189C39.3683 344.377 42.094 342.829 45.9248 342.834C62.4737 342.834 99.6021 371.756 107.385 371.756C107.979 371.756 108.405 371.584 108.637 371.218C112.536 364.964 110.74 359.872 83.257 343.343C55.7738 326.808 36.1428 317.588 47.114 305.718C48.3768 304.347 50.1659 303.741 52.3391 303.741C69.0248 303.746 108.447 339.398 108.447 339.398C108.447 339.398 119.087 350.395 125.523 350.395C127.001 350.395 128.259 349.815 129.111 348.382C133.673 340.737 86.7366 305.388 84.0898 290.804C82.2955 280.921 85.3474 275.917 90.9935 275.917Z"/> <path fill=white d="M296.9 404.174C282.31 383.118 283.343 367.316 303.363 347.627C323.383 327.943 335.037 299.145 335.037 299.145C335.037 299.145 339.39 282.419 349.304 283.958C359.219 285.497 366.498 310.492 345.731 325.783C324.963 341.069 349.866 351.456 357.856 337.099C365.846 322.741 387.663 285.831 398.978 278.772C410.287 271.713 418.25 275.668 415.583 290.218C412.916 304.769 365.618 340.036 370.22 347.668C374.822 355.296 391.041 338.7 391.041 338.7C391.041 338.7 441.791 293.255 452.84 305.097C463.889 316.94 444.457 326.863 416.766 343.359C389.068 359.85 386.921 364.206 390.85 370.446C394.784 376.685 455.915 325.971 461.657 347.47C467.393 368.969 399.269 375.209 403.474 390.051C407.678 404.899 451.461 361.958 460.416 378.689C469.376 395.425 398.633 415.088 398.06 415.234C375.209 421.067 317.175 433.426 296.9 404.174Z"/> <path fill=black d="M408.105 255C416.624 255 424.238 258.477 429.547 264.784C432.831 268.69 436.262 274.986 436.541 284.414C440.113 283.394 443.549 282.824 446.759 282.824C454.915 282.824 462.282 285.93 467.491 291.573C474.185 298.815 477.158 307.715 475.863 316.62C475.248 320.861 473.822 324.663 471.69 328.182C476.184 331.795 479.494 336.826 481.094 342.876C482.346 347.619 483.63 357.497 476.926 367.673C477.352 368.337 477.752 369.027 478.126 369.733C482.157 377.336 482.414 385.927 478.857 393.928C473.464 406.054 460.062 415.608 434.036 425.863C417.845 432.242 403.032 436.321 402.901 436.357C381.495 441.874 362.136 444.677 345.377 444.677C314.573 444.677 292.52 435.301 279.829 416.811C259.402 387.036 262.322 359.803 288.753 333.552C303.381 319.026 313.105 297.607 315.131 292.906C319.214 278.986 330.012 263.513 347.961 263.513H347.966C349.476 263.513 351.002 263.633 352.507 263.869C360.368 265.097 367.24 269.595 372.15 276.361C377.449 269.814 382.595 264.606 387.252 261.667C394.271 257.243 401.285 255 408.105 255ZM408.105 275.917C405.421 275.917 402.143 277.051 398.528 279.331C387.304 286.406 365.646 323.403 357.716 337.793C355.059 342.614 350.518 344.654 346.429 344.654C338.315 344.654 331.98 336.638 345.687 326.451C366.299 311.124 359.069 286.072 349.229 284.529C348.797 284.461 348.371 284.43 347.961 284.43C339.015 284.43 335.069 299.751 335.069 299.751C335.069 299.751 323.503 328.616 303.634 348.346C283.764 368.08 282.738 383.919 297.219 405.024C307.096 419.415 326.002 421.292 345.377 421.292C365.472 421.292 386.108 417.772 397.653 414.796C398.221 414.65 468.397 396.255 459.504 379.48C458.009 376.661 455.547 375.532 452.447 375.532C439.924 375.532 417.145 394.054 407.352 394.054C405.163 394.054 403.532 392.371 402.901 390.112C398.543 374.522 466.434 369.738 460.735 348.189C459.73 344.377 457.004 342.829 453.174 342.834C436.625 342.834 399.496 371.756 391.714 371.756C391.119 371.756 390.693 371.584 390.461 371.218C386.562 364.964 388.358 359.872 415.841 343.343C443.325 326.808 462.956 317.588 451.984 305.718C450.722 304.347 448.932 303.741 446.759 303.741C430.074 303.746 390.651 339.398 390.651 339.398C390.651 339.398 380.011 350.395 373.576 350.395C372.097 350.395 370.84 349.815 369.987 348.382C365.425 340.737 412.362 305.388 415.009 290.804C416.803 280.921 413.751 275.917 408.105 275.917Z"/> <path fill=#0E1116 d="M319.277 228.901C319.277 205.236 288.585 241.304 250.637 241.465C212.692 241.306 182 205.238 182 228.901C182 244.591 189.507 270.109 209.669 285.591C213.681 271.787 235.726 260.729 238.877 262.317C243.364 264.578 243.112 270.844 250.637 276.365C258.163 270.844 257.911 264.58 262.398 262.317C265.551 260.729 287.594 271.787 291.605 285.591C311.767 270.109 319.275 244.591 319.275 228.903L319.277 228.901Z"/> <path fill=#FF323D d="M262.4 262.315C257.913 264.576 258.165 270.842 250.639 276.363C243.114 270.842 243.366 264.578 238.879 262.315C235.726 260.727 213.683 271.785 209.672 285.589C219.866 293.417 233.297 298.678 250.627 298.806C250.631 298.806 250.635 298.806 250.641 298.806C250.646 298.806 250.65 298.806 250.656 298.806C267.986 298.68 281.417 293.417 291.611 285.589C287.6 271.785 265.555 260.727 262.404 262.315H262.4Z"/> <path fill=black d="M373 196C382.389 196 390 188.389 390 179C390 169.611 382.389 162 373 162C363.611 162 356 169.611 356 179C356 188.389 363.611 196 373 196Z"/> <path fill=black d="M128 196C137.389 196 145 188.389 145 179C145 169.611 137.389 162 128 162C118.611 162 111 169.611 111 179C111 188.389 118.611 196 128 196Z"/> <path fill=#0E1116 d="M313.06 171.596C319.796 173.968 322.476 187.779 329.281 184.171C342.167 177.337 347.06 161.377 340.208 148.524C333.356 135.671 317.354 130.792 304.467 137.626C291.58 144.46 286.688 160.419 293.54 173.272C296.774 179.339 307.039 169.475 313.06 171.596Z"/> <path fill=#0E1116 d="M188.554 171.596C181.818 173.968 179.138 187.779 172.334 184.171C159.447 177.337 154.555 161.377 161.407 148.524C168.259 135.671 184.26 130.792 197.147 137.626C210.034 144.46 214.926 160.419 208.074 173.272C204.84 179.339 194.575 169.475 188.554 171.596Z"/> </svg> </a> <a href=http://kuldeepsinghsidhu.com target=_blank rel=noopener title=kuldeepsinghsidhu.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0M5.78 8.75a9.64 9.64 0 0 0 1.363 4.177q.383.64.857 1.215c.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a10 10 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.51 6.51 0 0 0 4.666 5.5q-.184-.271-.352-.552c-.715-1.192-1.437-2.874-1.581-4.948m-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948q.18-.295.353-.552a6.51 6.51 0 0 0-4.666 5.5m10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948q-.18.296-.353.552a6.51 6.51 0 0 0 4.666-5.5Zm2.733-1.5a6.51 6.51 0 0 0-4.666-5.5q.184.272.353.552c.714 1.192 1.436 2.874 1.58 4.948Z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "search.highlight", "search.share", "search.suggest", "content.tooltips", "navigation.instant.progress", "navigation.path", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.60a45f97.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../javascripts/xfile.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>