<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A curated list of system design questions for Data Science and Machine Learning interviews"><meta name=author content="Kuldeep Singh Sidhu"><link href=../Machine-Learning/ rel=prev><link href=../Natural-Language-Processing/ rel=next><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.50"><title>System Design Interview Questions (DS & ML) - Data Science Interview preparation</title><link rel=stylesheet href=../../assets/stylesheets/main.a40c8224.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-EVGNTG49J7"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-EVGNTG49J7",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-EVGNTG49J7",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link href=../../assets/stylesheets/glightbox.min.css rel=stylesheet><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style><script src=../../assets/javascripts/glightbox.min.js></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#system-design-interview-questions-ds-ml class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <!-- Add announcement here, including arbitrary HTML --> üëÄ This project is in early stages of development. <strong> ü§ó Please <a href=/Contribute>contribute content</a> if possible! ü§ù</strong><br> <small>ü´µ You can <b> <a href=/Contribute>SUBMIT</a></b> simple text/markdown content, I will format it! üôå</small> <meta name=google-adsense-account content=ca-pub-4988388949365963> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4988388949365963" crossorigin=anonymous></script> </div> </aside> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="Data Science Interview preparation" class="md-header__button md-logo" aria-label="Data Science Interview preparation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Data Science Interview preparation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> System Design Interview Questions (DS & ML) </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=deep-purple data-md-color-accent=purple aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="Data Science Interview preparation" class="md-nav__button md-logo" aria-label="Data Science Interview preparation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 576 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M9.4 86.6c-12.5-12.5-12.5-32.7 0-45.2s32.8-12.5 45.3 0l192 192c12.5 12.5 12.5 32.8 0 45.3l-192 192c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L178.7 256zM256 416h288c17.7 0 32 14.3 32 32s-14.3 32-32 32H256c-17.7 0-32-14.3-32-32s14.3-32 32-32"/></svg> </a> Data Science Interview preparation </label> <div class=md-nav__source> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> singhsidhukuldeep/singhsidhukuldeep.github.io </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> üè° Home </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> üë®üèø‚Äçüè´ Interview Questions </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> üë®üèø‚Äçüè´ Interview Questions </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../flashcards/ class=md-nav__link> <span class=md-ellipsis> üìá Flashcards </span> </a> </li> <li class=md-nav__item> <a href=../data-structures-algorithms/ class=md-nav__link> <span class=md-ellipsis> DSA (Data Structures & Algorithms) </span> </a> </li> <li class=md-nav__item> <a href=../Machine-Learning/ class=md-nav__link> <span class=md-ellipsis> Machine Learning </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> System Design </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> System Design </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#premium-interview-questions class=md-nav__link> <span class=md-ellipsis> Premium Interview Questions </span> </a> <nav class=md-nav aria-label="Premium Interview Questions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-recommendation-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Recommendation System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-real-time-fraud-detection-system-amazon-paypal-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Real-Time Fraud Detection System - Amazon, PayPal Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-feature-store-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Feature Store - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-serving-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Serving System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-monitoring-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Monitoring System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-distributed-training-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Distributed Training System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ab-testing-platform-netflix-airbnb-interview-question class=md-nav__link> <span class=md-ellipsis> Design an A/B Testing Platform - Netflix, Airbnb Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-pipeline-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Pipeline for ML - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scale-requirements class=md-nav__link> <span class=md-ellipsis> Scale Requirements </span> </a> </li> <li class=md-nav__item> <a href=#architecture class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=#production-implementation-320-lines class=md-nav__link> <span class=md-ellipsis> Production Implementation (320 lines) </span> </a> </li> <li class=md-nav__item> <a href=#technology-stack-comparison class=md-nav__link> <span class=md-ellipsis> Technology Stack Comparison </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-solutions class=md-nav__link> <span class=md-ellipsis> Common Pitfalls &amp; Solutions </span> </a> </li> <li class=md-nav__item> <a href=#real-world-examples class=md-nav__link> <span class=md-ellipsis> Real-World Examples </span> </a> </li> <li class=md-nav__item> <a href=#monitoring-debugging class=md-nav__link> <span class=md-ellipsis> Monitoring &amp; Debugging </span> </a> <nav class=md-nav aria-label="Monitoring & Debugging"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-model-registry-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Registry - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scale-requirements_1 class=md-nav__link> <span class=md-ellipsis> Scale Requirements </span> </a> </li> <li class=md-nav__item> <a href=#architecture_1 class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=#production-implementation-280-lines class=md-nav__link> <span class=md-ellipsis> Production Implementation (280 lines) </span> </a> </li> <li class=md-nav__item> <a href=#technology-stack-comparison_1 class=md-nav__link> <span class=md-ellipsis> Technology Stack Comparison </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-solutions_1 class=md-nav__link> <span class=md-ellipsis> Common Pitfalls &amp; Solutions </span> </a> </li> <li class=md-nav__item> <a href=#real-world-examples_1 class=md-nav__link> <span class=md-ellipsis> Real-World Examples </span> </a> </li> <li class=md-nav__item> <a href=#model-card-generation class=md-nav__link> <span class=md-ellipsis> Model Card Generation </span> </a> <nav class=md-nav aria-label="Model Card Generation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-low-latency-inference-service-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Low-Latency Inference Service - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scale-requirements_2 class=md-nav__link> <span class=md-ellipsis> Scale Requirements </span> </a> </li> <li class=md-nav__item> <a href=#architecture_2 class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=#latency-budget-breakdown class=md-nav__link> <span class=md-ellipsis> Latency Budget Breakdown </span> </a> </li> <li class=md-nav__item> <a href=#production-implementation-300-lines class=md-nav__link> <span class=md-ellipsis> Production Implementation (300 lines) </span> </a> </li> <li class=md-nav__item> <a href=#optimization-techniques-comparison class=md-nav__link> <span class=md-ellipsis> Optimization Techniques Comparison </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-solutions_2 class=md-nav__link> <span class=md-ellipsis> Common Pitfalls &amp; Solutions </span> </a> </li> <li class=md-nav__item> <a href=#real-world-examples_2 class=md-nav__link> <span class=md-ellipsis> Real-World Examples </span> </a> </li> <li class=md-nav__item> <a href=#monitoring-metrics class=md-nav__link> <span class=md-ellipsis> Monitoring Metrics </span> </a> <nav class=md-nav aria-label="Monitoring Metrics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-search-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Search System - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scale-requirements_3 class=md-nav__link> <span class=md-ellipsis> Scale Requirements </span> </a> </li> <li class=md-nav__item> <a href=#architecture_3 class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=#production-implementation-310-lines class=md-nav__link> <span class=md-ellipsis> Production Implementation (310 lines) </span> </a> </li> <li class=md-nav__item> <a href=#ranking-stage-comparison class=md-nav__link> <span class=md-ellipsis> Ranking Stage Comparison </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-solutions_3 class=md-nav__link> <span class=md-ellipsis> Common Pitfalls &amp; Solutions </span> </a> </li> <li class=md-nav__item> <a href=#real-world-examples_3 class=md-nav__link> <span class=md-ellipsis> Real-World Examples </span> </a> </li> <li class=md-nav__item> <a href=#evaluation-metrics class=md-nav__link> <span class=md-ellipsis> Evaluation Metrics </span> </a> <nav class=md-nav aria-label="Evaluation Metrics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-data-warehouse-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Warehouse - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-stream-processing-system-uber-netflix-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Stream Processing System - Uber, Netflix Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-labeling-pipeline-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Labeling Pipeline - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-neural-network-optimizer-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Neural Network Optimizer - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-retraining-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Retraining System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-vector-search-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Vector Search System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-embedding-service-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Embedding Service - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-content-moderation-system-meta-youtube-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Content Moderation System - Meta, YouTube Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-notification-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Notification System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-cache-invalidation-strategy-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Cache Invalidation Strategy - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-feature-flag-system-netflix-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Feature Flag System - Netflix, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-rate-limiter-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Rate Limiter - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-batch-prediction-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Batch Prediction System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-cicd-pipeline-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a CI/CD Pipeline for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-time-series-forecasting-system-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Time Series Forecasting System - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-computer-vision-pipeline-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Computer Vision Pipeline - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-nlp-pipeline-for-production-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an NLP Pipeline for Production - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-graph-neural-network-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Graph Neural Network System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-reinforcement-learning-system-google-deepmind-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Reinforcement Learning System - Google, DeepMind Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-explainability-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Explainability System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-federated-learning-system-google-apple-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Federated Learning System - Google, Apple Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-multi-tenant-ml-platform-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Multi-Tenant ML Platform - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-cost-optimization-system-for-ml-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Cost Optimization System for ML - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-automl-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an AutoML System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-active-learning-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Active Learning System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-online-learning-system-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Online Learning System - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-knowledge-graph-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Knowledge Graph for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-system-for-edge-devices-apple-tesla-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML System for Edge Devices - Apple, Tesla Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-containerization-strategy-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Containerization Strategy for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-quality-framework-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Quality Framework - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-compression-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Compression System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-transfer-learning-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Transfer Learning System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-ensembling-system-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Ensembling System - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-synthetic-data-generation-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Synthetic Data Generation System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-augmentation-pipeline-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Augmentation Pipeline - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-testing-framework-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Testing Framework - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-shadow-testing-system-netflix-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Shadow Testing System - Netflix, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-blue-green-deployment-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Blue-Green Deployment for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-governance-system-google-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Governance System - Google, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-experiment-tracking-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Experiment Tracking System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-hyperparameter-optimization-service-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Hyperparameter Optimization Service - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-feature-selection-system-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Feature Selection System - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-drift-detection-system-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Drift Detection System - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-performance-degradation-detection-system-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Performance Degradation Detection System - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-real-time-analytics-dashboard-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Real-Time Analytics Dashboard - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-model-marketplace-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Model Marketplace - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-neural-architecture-search-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Neural Architecture Search System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-debugging-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Debugging System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-observability-platform-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Observability Platform - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-catalog-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Catalog System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-metadata-management-system-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Metadata Management System - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-platform-for-multi-cloud-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Platform for Multi-Cloud - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-disaster-recovery-system-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Disaster Recovery System for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-security-and-adversarial-robustness-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Security and Adversarial Robustness System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-compliance-and-audit-system-microsoft-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Compliance and Audit System - Microsoft, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-real-time-feature-computation-system-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Real-Time Feature Computation System - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-streaming-feature-engineering-system-uber-netflix-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Streaming Feature Engineering System - Uber, Netflix Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-lifecycle-management-system-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Lifecycle Management System - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-chatbotconversational-ai-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Chatbot/Conversational AI System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-document-processing-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Document Processing System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-video-understanding-system-google-youtube-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Video Understanding System - Google, YouTube Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-audiospeech-processing-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Audio/Speech Processing System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-multimodal-fusion-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Multimodal Fusion System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-few-shot-learning-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Few-Shot Learning System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-zero-shot-learning-system-google-openai-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Zero-Shot Learning System - Google, OpenAI Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-continual-learning-system-google-deepmind-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Continual Learning System - Google, DeepMind Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-fairness-and-bias-detection-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Fairness and Bias Detection System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-watermarking-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Watermarking System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-cross-lingual-ml-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Cross-Lingual ML System - Google, Meta Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#quick-reference-30-system-design-questions class=md-nav__link> <span class=md-ellipsis> Quick Reference: 30 System Design Questions </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-google-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Google interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-amazon-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Amazon interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-facebook-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Facebook interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-microsoft-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Microsoft interview </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../Natural-Language-Processing/ class=md-nav__link> <span class=md-ellipsis> Natural Language Processing (NLP) </span> </a> </li> <li class=md-nav__item> <a href=../Probability/ class=md-nav__link> <span class=md-ellipsis> Probability </span> </a> </li> <li class=md-nav__item> <a href=../AB-testing/ class=md-nav__link> <span class=md-ellipsis> A/B Testing </span> </a> </li> <li class=md-nav__item> <a href=../SQL-Interview-Questions/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../Scikit-Learn/ class=md-nav__link> <span class=md-ellipsis> Scikit-Learn </span> </a> </li> <li class=md-nav__item> <a href=../LangChain/ class=md-nav__link> <span class=md-ellipsis> LangChain </span> </a> </li> <li class=md-nav__item> <a href=../LangGraph/ class=md-nav__link> <span class=md-ellipsis> LangGraph </span> </a> </li> <li class=md-nav__item> <a href=../Interview-Question-Resources/ class=md-nav__link> <span class=md-ellipsis> Interview Question Resources </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> üìù Cheat Sheets </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> üìù Cheat Sheets </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Cheat-Sheets/Django/ class=md-nav__link> <span class=md-ellipsis> Django </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Flask/ class=md-nav__link> <span class=md-ellipsis> Flask </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Hypothesis-Tests/ class=md-nav__link> <span class=md-ellipsis> Hypothesis Tests </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Keras/ class=md-nav__link> <span class=md-ellipsis> Keras </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/NumPy/ class=md-nav__link> <span class=md-ellipsis> NumPy </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/PySpark/ class=md-nav__link> <span class=md-ellipsis> PySpark </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/PyTorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Python/ class=md-nav__link> <span class=md-ellipsis> Python </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/RegEx/ class=md-nav__link> <span class=md-ellipsis> Regular Expressions (RegEx) </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/Sk-learn/ class=md-nav__link> <span class=md-ellipsis> Scikit Learn </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/SQL/ class=md-nav__link> <span class=md-ellipsis> SQL </span> </a> </li> <li class=md-nav__item> <a href=../../Cheat-Sheets/tensorflow/ class=md-nav__link> <span class=md-ellipsis> TensorFlow </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> ‚Äçüéì ML Topics </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> ‚Äçüéì ML Topics </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Machine-Learning/ARIMA/ class=md-nav__link> <span class=md-ellipsis> ARIMA </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Activation%20functions/ class=md-nav__link> <span class=md-ellipsis> Activation functions </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Collaborative%20Filtering/ class=md-nav__link> <span class=md-ellipsis> Collaborative Filtering </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Confusion%20Matrix/ class=md-nav__link> <span class=md-ellipsis> Confusion Matrix </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/DBSCAN/ class=md-nav__link> <span class=md-ellipsis> DBSCAN </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Decision%20Trees/ class=md-nav__link> <span class=md-ellipsis> Decision Trees </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Gradient%20Boosting/ class=md-nav__link> <span class=md-ellipsis> Gradient Boosting </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/K-means%20clustering/ class=md-nav__link> <span class=md-ellipsis> K-means clustering </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Linear%20Regression/ class=md-nav__link> <span class=md-ellipsis> Linear Regression </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Logistic%20Regression/ class=md-nav__link> <span class=md-ellipsis> Logistic Regression </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Loss%20Function%20MAE%2C%20RMSE/ class=md-nav__link> <span class=md-ellipsis> Loss Function MAE, RMSE </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Neural%20Networks/ class=md-nav__link> <span class=md-ellipsis> Neural Networks </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Normal%20Distribution/ class=md-nav__link> <span class=md-ellipsis> Normal Distribution </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Normalization%20Regularisation/ class=md-nav__link> <span class=md-ellipsis> Normalization Regularisation </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Overfitting%2C%20Underfitting/ class=md-nav__link> <span class=md-ellipsis> Overfitting, Underfitting </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/PCA/ class=md-nav__link> <span class=md-ellipsis> PCA </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Random%20Forest/ class=md-nav__link> <span class=md-ellipsis> Random Forest </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Support%20Vector%20Machines/ class=md-nav__link> <span class=md-ellipsis> Support Vector Machines </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/Unbalanced%2C%20Skewed%20data/ class=md-nav__link> <span class=md-ellipsis> Unbalanced, Skewed data </span> </a> </li> <li class=md-nav__item> <a href=../../Machine-Learning/kNN/ class=md-nav__link> <span class=md-ellipsis> kNN </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> üë®üèæ‚Äçüíª Online Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> üë®üèæ‚Äçüíª Online Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Online-Material/Online-Material-for-Learning/ class=md-nav__link> <span class=md-ellipsis> Online Study Material </span> </a> </li> <li class=md-nav__item> <a href=../../Online-Material/popular-resources/ class=md-nav__link> <span class=md-ellipsis> Popular Blogs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../projects/ class=md-nav__link> <span class=md-ellipsis> üì≥ Projects </span> </a> </li> <li class=md-nav__item> <a href=../../Contribute/ class=md-nav__link> <span class=md-ellipsis> ü§ù Contribute </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#premium-interview-questions class=md-nav__link> <span class=md-ellipsis> Premium Interview Questions </span> </a> <nav class=md-nav aria-label="Premium Interview Questions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-recommendation-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Recommendation System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-real-time-fraud-detection-system-amazon-paypal-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Real-Time Fraud Detection System - Amazon, PayPal Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-feature-store-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Feature Store - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-serving-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Serving System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-monitoring-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Monitoring System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-distributed-training-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Distributed Training System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ab-testing-platform-netflix-airbnb-interview-question class=md-nav__link> <span class=md-ellipsis> Design an A/B Testing Platform - Netflix, Airbnb Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-pipeline-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Pipeline for ML - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scale-requirements class=md-nav__link> <span class=md-ellipsis> Scale Requirements </span> </a> </li> <li class=md-nav__item> <a href=#architecture class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=#production-implementation-320-lines class=md-nav__link> <span class=md-ellipsis> Production Implementation (320 lines) </span> </a> </li> <li class=md-nav__item> <a href=#technology-stack-comparison class=md-nav__link> <span class=md-ellipsis> Technology Stack Comparison </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-solutions class=md-nav__link> <span class=md-ellipsis> Common Pitfalls &amp; Solutions </span> </a> </li> <li class=md-nav__item> <a href=#real-world-examples class=md-nav__link> <span class=md-ellipsis> Real-World Examples </span> </a> </li> <li class=md-nav__item> <a href=#monitoring-debugging class=md-nav__link> <span class=md-ellipsis> Monitoring &amp; Debugging </span> </a> <nav class=md-nav aria-label="Monitoring & Debugging"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-model-registry-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Registry - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scale-requirements_1 class=md-nav__link> <span class=md-ellipsis> Scale Requirements </span> </a> </li> <li class=md-nav__item> <a href=#architecture_1 class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=#production-implementation-280-lines class=md-nav__link> <span class=md-ellipsis> Production Implementation (280 lines) </span> </a> </li> <li class=md-nav__item> <a href=#technology-stack-comparison_1 class=md-nav__link> <span class=md-ellipsis> Technology Stack Comparison </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-solutions_1 class=md-nav__link> <span class=md-ellipsis> Common Pitfalls &amp; Solutions </span> </a> </li> <li class=md-nav__item> <a href=#real-world-examples_1 class=md-nav__link> <span class=md-ellipsis> Real-World Examples </span> </a> </li> <li class=md-nav__item> <a href=#model-card-generation class=md-nav__link> <span class=md-ellipsis> Model Card Generation </span> </a> <nav class=md-nav aria-label="Model Card Generation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-low-latency-inference-service-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Low-Latency Inference Service - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scale-requirements_2 class=md-nav__link> <span class=md-ellipsis> Scale Requirements </span> </a> </li> <li class=md-nav__item> <a href=#architecture_2 class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=#latency-budget-breakdown class=md-nav__link> <span class=md-ellipsis> Latency Budget Breakdown </span> </a> </li> <li class=md-nav__item> <a href=#production-implementation-300-lines class=md-nav__link> <span class=md-ellipsis> Production Implementation (300 lines) </span> </a> </li> <li class=md-nav__item> <a href=#optimization-techniques-comparison class=md-nav__link> <span class=md-ellipsis> Optimization Techniques Comparison </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-solutions_2 class=md-nav__link> <span class=md-ellipsis> Common Pitfalls &amp; Solutions </span> </a> </li> <li class=md-nav__item> <a href=#real-world-examples_2 class=md-nav__link> <span class=md-ellipsis> Real-World Examples </span> </a> </li> <li class=md-nav__item> <a href=#monitoring-metrics class=md-nav__link> <span class=md-ellipsis> Monitoring Metrics </span> </a> <nav class=md-nav aria-label="Monitoring Metrics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-search-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Search System - Google, Amazon Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#scale-requirements_3 class=md-nav__link> <span class=md-ellipsis> Scale Requirements </span> </a> </li> <li class=md-nav__item> <a href=#architecture_3 class=md-nav__link> <span class=md-ellipsis> Architecture </span> </a> </li> <li class=md-nav__item> <a href=#production-implementation-310-lines class=md-nav__link> <span class=md-ellipsis> Production Implementation (310 lines) </span> </a> </li> <li class=md-nav__item> <a href=#ranking-stage-comparison class=md-nav__link> <span class=md-ellipsis> Ranking Stage Comparison </span> </a> </li> <li class=md-nav__item> <a href=#common-pitfalls-solutions_3 class=md-nav__link> <span class=md-ellipsis> Common Pitfalls &amp; Solutions </span> </a> </li> <li class=md-nav__item> <a href=#real-world-examples_3 class=md-nav__link> <span class=md-ellipsis> Real-World Examples </span> </a> </li> <li class=md-nav__item> <a href=#evaluation-metrics class=md-nav__link> <span class=md-ellipsis> Evaluation Metrics </span> </a> <nav class=md-nav aria-label="Evaluation Metrics"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#design-a-data-warehouse-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Warehouse - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-stream-processing-system-uber-netflix-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Stream Processing System - Uber, Netflix Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-labeling-pipeline-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Labeling Pipeline - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-neural-network-optimizer-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Neural Network Optimizer - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-retraining-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Retraining System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-vector-search-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Vector Search System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-embedding-service-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Embedding Service - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-content-moderation-system-meta-youtube-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Content Moderation System - Meta, YouTube Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-notification-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Notification System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-cache-invalidation-strategy-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Cache Invalidation Strategy - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-feature-flag-system-netflix-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Feature Flag System - Netflix, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-rate-limiter-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Rate Limiter - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-batch-prediction-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Batch Prediction System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-cicd-pipeline-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a CI/CD Pipeline for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-time-series-forecasting-system-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Time Series Forecasting System - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-computer-vision-pipeline-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Computer Vision Pipeline - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-nlp-pipeline-for-production-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an NLP Pipeline for Production - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-graph-neural-network-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Graph Neural Network System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-reinforcement-learning-system-google-deepmind-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Reinforcement Learning System - Google, DeepMind Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-explainability-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Explainability System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-federated-learning-system-google-apple-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Federated Learning System - Google, Apple Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-multi-tenant-ml-platform-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Multi-Tenant ML Platform - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-cost-optimization-system-for-ml-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Cost Optimization System for ML - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-automl-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an AutoML System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-active-learning-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Active Learning System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-online-learning-system-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Online Learning System - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-knowledge-graph-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Knowledge Graph for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-system-for-edge-devices-apple-tesla-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML System for Edge Devices - Apple, Tesla Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-containerization-strategy-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Containerization Strategy for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-quality-framework-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Quality Framework - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-compression-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Compression System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-transfer-learning-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Transfer Learning System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-ensembling-system-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Ensembling System - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-synthetic-data-generation-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Synthetic Data Generation System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-augmentation-pipeline-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Augmentation Pipeline - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-testing-framework-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Testing Framework - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-shadow-testing-system-netflix-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Shadow Testing System - Netflix, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-blue-green-deployment-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Blue-Green Deployment for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-governance-system-google-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Governance System - Google, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-experiment-tracking-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Experiment Tracking System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-hyperparameter-optimization-service-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Hyperparameter Optimization Service - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-feature-selection-system-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Feature Selection System - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-drift-detection-system-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Drift Detection System - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-performance-degradation-detection-system-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Performance Degradation Detection System - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-real-time-analytics-dashboard-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Real-Time Analytics Dashboard - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-model-marketplace-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Model Marketplace - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-neural-architecture-search-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Neural Architecture Search System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-debugging-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Debugging System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-observability-platform-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Observability Platform - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-data-catalog-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Data Catalog System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-metadata-management-system-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Metadata Management System - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-platform-for-multi-cloud-amazon-google-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Platform for Multi-Cloud - Amazon, Google Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-disaster-recovery-system-for-ml-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Disaster Recovery System for ML - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-security-and-adversarial-robustness-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Security and Adversarial Robustness System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-ml-compliance-and-audit-system-microsoft-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an ML Compliance and Audit System - Microsoft, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-real-time-feature-computation-system-netflix-uber-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Real-Time Feature Computation System - Netflix, Uber Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-streaming-feature-engineering-system-uber-netflix-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Streaming Feature Engineering System - Uber, Netflix Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-lifecycle-management-system-amazon-microsoft-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Lifecycle Management System - Amazon, Microsoft Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-chatbotconversational-ai-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Chatbot/Conversational AI System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-document-processing-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Document Processing System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-video-understanding-system-google-youtube-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Video Understanding System - Google, YouTube Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-an-audiospeech-processing-system-google-amazon-interview-question class=md-nav__link> <span class=md-ellipsis> Design an Audio/Speech Processing System - Google, Amazon Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-multimodal-fusion-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Multimodal Fusion System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-few-shot-learning-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Few-Shot Learning System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-zero-shot-learning-system-google-openai-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Zero-Shot Learning System - Google, OpenAI Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-continual-learning-system-google-deepmind-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Continual Learning System - Google, DeepMind Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-fairness-and-bias-detection-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Fairness and Bias Detection System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-model-watermarking-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Model Watermarking System - Google, Meta Interview Question </span> </a> </li> <li class=md-nav__item> <a href=#design-a-cross-lingual-ml-system-google-meta-interview-question class=md-nav__link> <span class=md-ellipsis> Design a Cross-Lingual ML System - Google, Meta Interview Question </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#quick-reference-30-system-design-questions class=md-nav__link> <span class=md-ellipsis> Quick Reference: 30 System Design Questions </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-google-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Google interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-amazon-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Amazon interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-facebook-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Facebook interview </span> </a> </li> <li class=md-nav__item> <a href=#questions-asked-in-microsoft-interview class=md-nav__link> <span class=md-ellipsis> Questions asked in Microsoft interview </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/edit/master/docs/Interview-Questions/System-design.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/singhsidhukuldeep/singhsidhukuldeep.github.io/raw/master/docs/Interview-Questions/System-design.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=system-design-interview-questions-ds-ml>System Design Interview Questions (DS &amp; ML)</h1> <!-- ![Total Questions](https://img.shields.io/badge/Total%20Questions-0-blue?style=flat&labelColor=black&color=blue)
![Unanswered Questions](https://img.shields.io/badge/Unanswered%20Questions-0-blue?style=flat&labelColor=black&color=yellow)
![Answered Questions](https://img.shields.io/badge/Answered%20Questions-0-blue?style=flat&labelColor=black&color=success) --> <p>This document provides a curated list of system design questions tailored for Data Science and Machine Learning interviews. The questions focus on designing scalable, robust, and maintainable systems‚Äîfrom end-to-end ML pipelines and data ingestion frameworks to model serving, monitoring, and MLOps architectures. Use the practice links provided to dive deeper into each topic.</p> <hr> <h2 id=premium-interview-questions>Premium Interview Questions</h2> <h3 id=design-a-recommendation-system-google-amazon-interview-question>Design a Recommendation System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>ML Systems</code>, <code>Recommendations</code> | <strong>Asked by:</strong> Google, Amazon, Netflix, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Scale Requirements:</strong> - <strong>Users:</strong> 100M+ daily active users - <strong>Items:</strong> 10M+ products/content - <strong>Latency:</strong> &lt;50ms p99 - <strong>Throughput:</strong> 1M+ QPS - <strong>Personalization:</strong> Real-time signals</p> <p><strong>Detailed Architecture:</strong></p> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User Activity‚îÇ (clicks, views, purchases, time spent)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Feature Engineering              ‚îÇ
‚îÇ  - Real-time: last 1hr behavior         ‚îÇ
‚îÇ  - Batch: 7d/30d aggregates             ‚îÇ
‚îÇ  - User profile: demographics, history  ‚îÇ
‚îÇ  - Context: time, device, location      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Candidate Generation (Retrieval)    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ 1. Collaborative Filtering (ALS)   ‚îÇ ‚îÇ ‚Üí 1000 candidates
‚îÇ  ‚îÇ 2. Content-based (embeddings)      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 3. Trending/Popular items          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ 4. Graph-based (item2item)         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Ranking (Scoring)              ‚îÇ
‚îÇ  Two-Tower Neural Network               ‚îÇ
‚îÇ  - User tower: user embeddings          ‚îÇ
‚îÇ  - Item tower: item embeddings          ‚îÇ
‚îÇ  - Features: 100+ features              ‚îÇ
‚îÇ  - Model: DLRM, DCN, DeepFM             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚Üí Top 100
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Re-ranking (Filtering)          ‚îÇ
‚îÇ  - Diversity: avoid similar items       ‚îÇ
‚îÇ  - Business rules: inventory, policies  ‚îÇ
‚îÇ  - Explore/exploit: Thompson sampling   ‚îÇ
‚îÇ  - Deduplication                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚Üí Top 20
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Results   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p><strong>Implementation Details:</strong></p> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>RecommendationSystem</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>feature_store</span> <span class=o>=</span> <span class=n>FeatureStore</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>candidate_gen</span> <span class=o>=</span> <span class=n>CandidateGenerator</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>ranker</span> <span class=o>=</span> <span class=n>TwoTowerRanker</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>reranker</span> <span class=o>=</span> <span class=n>Reranker</span><span class=p>()</span>

    <span class=k>def</span><span class=w> </span><span class=nf>get_recommendations</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>context</span><span class=p>:</span> <span class=nb>dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
        <span class=c1># 1. Feature retrieval (&lt;10ms)</span>
        <span class=n>user_features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>feature_store</span><span class=o>.</span><span class=n>get_user_features</span><span class=p>(</span><span class=n>user_id</span><span class=p>)</span>
        <span class=n>context_features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extract_context</span><span class=p>(</span><span class=n>context</span><span class=p>)</span>

        <span class=c1># 2. Candidate generation (&lt;20ms)</span>
        <span class=c1># Retrieve ~1000 candidates from multiple sources</span>
        <span class=n>cf_candidates</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>candidate_gen</span><span class=o>.</span><span class=n>collaborative_filter</span><span class=p>(</span><span class=n>user_id</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>500</span><span class=p>)</span>
        <span class=n>content_candidates</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>candidate_gen</span><span class=o>.</span><span class=n>content_based</span><span class=p>(</span><span class=n>user_features</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
        <span class=n>trending</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>candidate_gen</span><span class=o>.</span><span class=n>get_trending</span><span class=p>(</span><span class=n>k</span><span class=o>=</span><span class=mi>200</span><span class=p>)</span>

        <span class=n>all_candidates</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>cf_candidates</span> <span class=o>+</span> <span class=n>content_candidates</span> <span class=o>+</span> <span class=n>trending</span><span class=p>)</span>

        <span class=c1># 3. Ranking (&lt;15ms)</span>
        <span class=c1># Score all candidates with neural network</span>
        <span class=n>candidate_features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>feature_store</span><span class=o>.</span><span class=n>get_item_features</span><span class=p>(</span><span class=n>all_candidates</span><span class=p>)</span>
        <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ranker</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>user_features</span><span class=p>,</span> <span class=n>candidate_features</span><span class=p>,</span> <span class=n>context_features</span><span class=p>)</span>

        <span class=n>top_100</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>all_candidates</span><span class=p>,</span> <span class=n>scores</span><span class=p>),</span> <span class=n>key</span><span class=o>=</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>reverse</span><span class=o>=</span><span class=kc>True</span><span class=p>)[:</span><span class=mi>100</span><span class=p>]</span>

        <span class=c1># 4. Re-ranking (&lt;5ms)</span>
        <span class=c1># Apply business rules and diversification</span>
        <span class=n>final_recs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reranker</span><span class=o>.</span><span class=n>rerank</span><span class=p>(</span>
            <span class=n>candidates</span><span class=o>=</span><span class=n>top_100</span><span class=p>,</span>
            <span class=n>diversity_weight</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span>
            <span class=n>explore_rate</span><span class=o>=</span><span class=mf>0.1</span>
        <span class=p>)</span>

        <span class=k>return</span> <span class=p>[</span><span class=n>item_id</span> <span class=k>for</span> <span class=n>item_id</span><span class=p>,</span> <span class=n>_</span> <span class=ow>in</span> <span class=n>final_recs</span><span class=p>[:</span><span class=mi>20</span><span class=p>]]</span>

<span class=c1># Candidate Generation with ANN</span>
<span class=k>class</span><span class=w> </span><span class=nc>CandidateGenerator</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=nf>collaborative_filter</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>k</span><span class=p>:</span> <span class=nb>int</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Use Approximate Nearest Neighbors for fast retrieval&quot;&quot;&quot;</span>
        <span class=n>user_embedding</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>get_user_embedding</span><span class=p>(</span><span class=n>user_id</span><span class=p>)</span>  <span class=c1># 128-dim vector</span>

        <span class=c1># HNSW index for fast ANN search</span>
        <span class=c1># Search through 10M items in &lt;5ms</span>
        <span class=n>similar_items</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ann_index</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>user_embedding</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=n>k</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>similar_items</span>

<span class=c1># Two-Tower Ranking Model</span>
<span class=k>class</span><span class=w> </span><span class=nc>TwoTowerRanker</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>user_tower</span> <span class=o>=</span> <span class=n>UserTower</span><span class=p>(</span><span class=n>input_dim</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span> <span class=n>output_dim</span><span class=o>=</span><span class=mi>128</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>item_tower</span> <span class=o>=</span> <span class=n>ItemTower</span><span class=p>(</span><span class=n>input_dim</span><span class=o>=</span><span class=mi>150</span><span class=p>,</span> <span class=n>output_dim</span><span class=o>=</span><span class=mi>128</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>user_feats</span><span class=p>,</span> <span class=n>item_feats</span><span class=p>,</span> <span class=n>context_feats</span><span class=p>):</span>
        <span class=n>user_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>user_tower</span><span class=p>(</span><span class=n>user_feats</span><span class=p>)</span>
        <span class=n>item_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>item_tower</span><span class=p>(</span><span class=n>item_feats</span><span class=p>)</span>

        <span class=c1># Dot product for scoring</span>
        <span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>user_emb</span><span class=p>,</span> <span class=n>item_emb</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>scores</span>
</code></pre></div> <p><strong>Key Components Deep Dive:</strong></p> <table> <thead> <tr> <th>Component</th> <th>Technology</th> <th>Scale</th> <th>Purpose</th> </tr> </thead> <tbody> <tr> <td><strong>Feature Store</strong></td> <td>Redis, DynamoDB</td> <td>&lt;5ms p99</td> <td>Real-time feature serving</td> </tr> <tr> <td><strong>ANN Index</strong></td> <td>FAISS, ScaNN</td> <td>10M vectors</td> <td>Fast similarity search</td> </tr> <tr> <td><strong>Ranking Model</strong></td> <td>TensorFlow Serving</td> <td>5ms inference</td> <td>Score candidates</td> </tr> <tr> <td><strong>A/B Testing</strong></td> <td>Custom platform</td> <td>1000+ concurrent tests</td> <td>Online evaluation</td> </tr> <tr> <td><strong>Monitoring</strong></td> <td>Prometheus, Grafana</td> <td>Real-time</td> <td>Track metrics</td> </tr> </tbody> </table> <p><strong>Cold Start Solutions:</strong></p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>handle_cold_start</span><span class=p>(</span><span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>user_data</span><span class=p>:</span> <span class=nb>dict</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Strategies for new users/items&quot;&quot;&quot;</span>

    <span class=c1># New User:</span>
    <span class=k>if</span> <span class=n>is_new_user</span><span class=p>(</span><span class=n>user_id</span><span class=p>):</span>
        <span class=c1># 1. Use demographic-based recommendations</span>
        <span class=n>recs</span> <span class=o>=</span> <span class=n>get_popular_for_demographic</span><span class=p>(</span><span class=n>user_data</span><span class=p>[</span><span class=s1>&#39;age&#39;</span><span class=p>],</span> <span class=n>user_data</span><span class=p>[</span><span class=s1>&#39;location&#39;</span><span class=p>])</span>

        <span class=c1># 2. Quick onboarding survey</span>
        <span class=n>preferences</span> <span class=o>=</span> <span class=n>get_user_preferences</span><span class=p>(</span><span class=n>user_id</span><span class=p>)</span>
        <span class=n>recs</span> <span class=o>+=</span> <span class=n>content_based_on_preferences</span><span class=p>(</span><span class=n>preferences</span><span class=p>)</span>

        <span class=c1># 3. Thompson sampling for exploration</span>
        <span class=n>recs</span> <span class=o>+=</span> <span class=n>explore_diverse_content</span><span class=p>(</span><span class=n>explore_rate</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>

    <span class=c1># New Item:</span>
    <span class=k>if</span> <span class=n>is_new_item</span><span class=p>(</span><span class=n>item_id</span><span class=p>):</span>
        <span class=c1># 1. Content-based: use item metadata</span>
        <span class=n>similar_items</span> <span class=o>=</span> <span class=n>find_similar_by_content</span><span class=p>(</span><span class=n>item_id</span><span class=p>)</span>

        <span class=c1># 2. Cold start boost in ranking</span>
        <span class=n>boost_score</span> <span class=o>=</span> <span class=mf>0.1</span>  <span class=c1># Temporary boost</span>

        <span class=c1># 3. Show to exploratory users first</span>
        <span class=n>target_users</span> <span class=o>=</span> <span class=n>get_early_adopter_users</span><span class=p>()</span>
</code></pre></div> <p><strong>Metrics &amp; Evaluation:</strong></p> <table> <thead> <tr> <th>Metric Category</th> <th>Examples</th> <th>Target</th> </tr> </thead> <tbody> <tr> <td><strong>Online Metrics</strong></td> <td>CTR, Conversion, Watch time</td> <td>CTR: 5-15%</td> </tr> <tr> <td><strong>Engagement</strong></td> <td>Session length, Return rate</td> <td>+10% retention</td> </tr> <tr> <td><strong>Business</strong></td> <td>Revenue, GMV</td> <td>+5% revenue</td> </tr> <tr> <td><strong>Diversity</strong></td> <td>ILS (Intra-list similarity)</td> <td>ILS &lt; 0.7</td> </tr> <tr> <td><strong>Freshness</strong></td> <td>Avg item age</td> <td>&lt;3 days</td> </tr> <tr> <td><strong>Serendipity</strong></td> <td>Unexpected but relevant</td> <td>20% of recs</td> </tr> </tbody> </table> <p><strong>Common Pitfalls:</strong></p> <p>‚ùå <strong>Filter bubble:</strong> Showing only similar items ‚Üí Add diversity ‚ùå <strong>Popularity bias:</strong> Always recommending popular items ‚Üí Balance with personalization ‚ùå <strong>Position bias:</strong> Higher positions get more clicks ‚Üí Debias training data ‚ùå <strong>Feedback loop:</strong> Model reinforces itself ‚Üí Use exploration ‚ùå <strong>Recency bias:</strong> Only recent items ‚Üí Balance with evergreen content</p> <p><strong>Trade-offs:</strong></p> <table> <thead> <tr> <th>Aspect</th> <th>Option A</th> <th>Option B</th> <th>Netflix's Choice</th> </tr> </thead> <tbody> <tr> <td>Candidate Gen</td> <td>Collaborative Filter</td> <td>Deep Learning</td> <td>Both (ensemble)</td> </tr> <tr> <td>Ranking</td> <td>LightGBM</td> <td>Neural Network</td> <td>Neural (DLRM)</td> </tr> <tr> <td>Serving</td> <td>CPU</td> <td>GPU</td> <td>CPU for latency</td> </tr> <tr> <td>Update Freq</td> <td>Real-time</td> <td>Batch (daily)</td> <td>Near real-time (hourly)</td> </tr> </tbody> </table> <p><strong>Real-World Examples:</strong></p> <ul> <li><strong>Netflix:</strong> 80% of watch time from recommendations, saves $1B/year in retention</li> <li><strong>Amazon:</strong> 35% of revenue from recommendations</li> <li><strong>YouTube:</strong> 70% of watch time from recommendations</li> <li><strong>Spotify:</strong> Discover Weekly has 40M+ active users</li> </ul> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Multi-stage architecture understanding, cold-start problem, scale considerations.</p> <p><strong>Strong answer signals:</strong> - Explains funnel approach (1000 ‚Üí 100 ‚Üí 20) - Discusses latency budget breakdown - Knows specific algorithms (ALS, FAISS, Two-Tower) - Addresses cold-start for both users and items - Mentions diversity/exploration tradeoffs - Talks about position bias and debiasing - Discusses A/B testing challenges (novelty effect, network effects)</p> </div> </details> <hr> <h3 id=design-a-real-time-fraud-detection-system-amazon-paypal-interview-question>Design a Real-Time Fraud Detection System - Amazon, PayPal Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Real-Time</code>, <code>Anomaly Detection</code> | <strong>Asked by:</strong> Amazon, PayPal, Stripe</p> <details class=success> <summary>View Answer</summary> <p><strong>Scale Requirements:</strong> - <strong>Transactions:</strong> 10M+ per day (115 TPS, 1000+ peak) - <strong>Latency:</strong> &lt;100ms p99 (to not block checkout) - <strong>False Positive Rate:</strong> &lt;1% (user experience) - <strong>Fraud Catch Rate:</strong> &gt;80% (business requirement) - <strong>Data Volume:</strong> 1TB+ transaction data/day</p> <p><strong>Detailed Architecture:</strong></p> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Transaction  ‚îÇ (amount, merchant, location, device, etc.)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Kafka Stream (partitioned)         ‚îÇ
‚îÇ   - Partition by user_id for ordering   ‚îÇ
‚îÇ   - Retention: 7 days for replay        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Real-Time Feature Engineering        ‚îÇ
‚îÇ  (Flink / Spark Streaming)              ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  1. Velocity Features:                  ‚îÇ
‚îÇ     - Transactions last 5/30/60 min     ‚îÇ
‚îÇ     - Amount spent last 1 hour          ‚îÇ
‚îÇ     - Unique merchants last 24h         ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  2. Anomaly Features:                   ‚îÇ
‚îÇ     - Unusual location (&gt;500km from     ‚îÇ
‚îÇ       last transaction)                 ‚îÇ
‚îÇ     - New device fingerprint            ‚îÇ
‚îÇ     - Unusual time (3am for daytime user)‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  3. Network Features:                   ‚îÇ
‚îÇ     - Merchant risk score               ‚îÇ
‚îÇ     - IP reputation                     ‚îÇ
‚îÇ     - Email/phone shared with fraudsters‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Feature Store Lookup            ‚îÇ
‚îÇ   Online:  Redis (1-5ms)                ‚îÇ
‚îÇ   Batch:   Cassandra/BigQuery           ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ   - User historical patterns            ‚îÇ
‚îÇ   - Device fingerprints                 ‚îÇ
‚îÇ   - Merchant metadata                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Multi-Layer Detection           ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Layer 1: Rule Engine (&lt;10ms)           ‚îÇ
‚îÇ   ‚îú‚îÄ Blacklist check                    ‚îÇ
‚îÇ   ‚îú‚îÄ Amount thresholds                  ‚îÇ
‚îÇ   ‚îî‚îÄ Basic velocity rules               ‚îÇ
‚îÇ   ‚Üí Block: 5% of fraud                  ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Layer 2: ML Model (&lt;50ms)              ‚îÇ
‚îÇ   ‚îú‚îÄ Gradient Boosting (XGBoost)        ‚îÇ
‚îÇ   ‚îú‚îÄ Features: 200+                     ‚îÇ
‚îÇ   ‚îî‚îÄ Score: 0-1 fraud probability       ‚îÇ
‚îÇ   ‚Üí Catch: 70% of fraud                 ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Layer 3: Deep Learning (&lt;80ms)         ‚îÇ
‚îÇ   ‚îú‚îÄ LSTM for sequence modeling         ‚îÇ
‚îÇ   ‚îú‚îÄ Graph Neural Network               ‚îÇ
‚îÇ   ‚îî‚îÄ Catches complex patterns           ‚îÇ
‚îÇ   ‚Üí Catch additional: 10% of fraud      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Decision Logic                  ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  if score &gt; 0.9:                        ‚îÇ
‚îÇ      ‚Üí BLOCK (hard decline)             ‚îÇ
‚îÇ  elif score &gt; 0.7:                      ‚îÇ
‚îÇ      ‚Üí CHALLENGE (2FA, 3DS)             ‚îÇ
‚îÇ  elif score &gt; 0.5:                      ‚îÇ
‚îÇ      ‚Üí REVIEW (async manual review)     ‚îÇ
‚îÇ  else:                                  ‚îÇ
‚îÇ      ‚Üí APPROVE                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       Feedback Loop &amp; Labeling          ‚îÇ
‚îÇ   - User disputes (chargebacks)         ‚îÇ
‚îÇ   - Manual review decisions             ‚îÇ
‚îÇ   - Confirmed fraud cases               ‚îÇ
‚îÇ   ‚Üí Retrain models weekly               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>FraudDetectionSystem</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>rule_engine</span> <span class=o>=</span> <span class=n>RuleEngine</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>ml_model</span> <span class=o>=</span> <span class=n>load_model</span><span class=p>(</span><span class=s1>&#39;xgboost_v23.pkl&#39;</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>deep_model</span> <span class=o>=</span> <span class=n>load_model</span><span class=p>(</span><span class=s1>&#39;lstm_v5.pt&#39;</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>feature_store</span> <span class=o>=</span> <span class=n>FeatureStore</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>decision_thresholds</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;block&#39;</span><span class=p>:</span> <span class=mf>0.9</span><span class=p>,</span>
            <span class=s1>&#39;challenge&#39;</span><span class=p>:</span> <span class=mf>0.7</span><span class=p>,</span>
            <span class=s1>&#39;review&#39;</span><span class=p>:</span> <span class=mf>0.5</span>
        <span class=p>}</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>detect_fraud</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>transaction</span><span class=p>:</span> <span class=nb>dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
        <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>

        <span class=c1># Step 1: Quick rule check (&lt;5ms)</span>
        <span class=n>rule_result</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>rule_engine</span><span class=o>.</span><span class=n>check</span><span class=p>(</span><span class=n>transaction</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>rule_result</span><span class=p>[</span><span class=s1>&#39;action&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;BLOCK&#39;</span><span class=p>:</span>
            <span class=k>return</span> <span class=p>{</span>
                <span class=s1>&#39;decision&#39;</span><span class=p>:</span> <span class=s1>&#39;BLOCK&#39;</span><span class=p>,</span>
                <span class=s1>&#39;reason&#39;</span><span class=p>:</span> <span class=n>rule_result</span><span class=p>[</span><span class=s1>&#39;reason&#39;</span><span class=p>],</span>
                <span class=s1>&#39;latency_ms&#39;</span><span class=p>:</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>
            <span class=p>}</span>

        <span class=c1># Step 2: Feature engineering (parallel)</span>
        <span class=n>features</span> <span class=o>=</span> <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_compute_realtime_features</span><span class=p>(</span><span class=n>transaction</span><span class=p>),</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_fetch_historical_features</span><span class=p>(</span><span class=n>transaction</span><span class=p>[</span><span class=s1>&#39;user_id&#39;</span><span class=p>]),</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_fetch_merchant_features</span><span class=p>(</span><span class=n>transaction</span><span class=p>[</span><span class=s1>&#39;merchant_id&#39;</span><span class=p>])</span>
        <span class=p>)</span>
        <span class=n>feature_vector</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_combine_features</span><span class=p>(</span><span class=o>*</span><span class=n>features</span><span class=p>)</span>  <span class=c1># 200+ features</span>

        <span class=c1># Step 3: ML scoring (&lt;30ms)</span>
        <span class=n>ml_score</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ml_model</span><span class=o>.</span><span class=n>predict_proba</span><span class=p>(</span><span class=n>feature_vector</span><span class=p>)[</span><span class=mi>0</span><span class=p>][</span><span class=mi>1</span><span class=p>]</span>

        <span class=c1># Step 4: Deep learning (only for borderline cases)</span>
        <span class=k>if</span> <span class=mf>0.4</span> <span class=o>&lt;</span> <span class=n>ml_score</span> <span class=o>&lt;</span> <span class=mf>0.8</span><span class=p>:</span>
            <span class=c1># Get transaction sequence for user</span>
            <span class=n>sequence</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_transaction_sequence</span><span class=p>(</span><span class=n>transaction</span><span class=p>[</span><span class=s1>&#39;user_id&#39;</span><span class=p>])</span>
            <span class=n>dl_score</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>deep_model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>sequence</span><span class=p>)</span>
            <span class=n>final_score</span> <span class=o>=</span> <span class=mf>0.6</span> <span class=o>*</span> <span class=n>ml_score</span> <span class=o>+</span> <span class=mf>0.4</span> <span class=o>*</span> <span class=n>dl_score</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>final_score</span> <span class=o>=</span> <span class=n>ml_score</span>

        <span class=c1># Step 5: Make decision</span>
        <span class=n>decision</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_make_decision</span><span class=p>(</span><span class=n>final_score</span><span class=p>)</span>

        <span class=c1># Step 6: Log for monitoring</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_log_decision</span><span class=p>(</span><span class=n>transaction</span><span class=p>,</span> <span class=n>final_score</span><span class=p>,</span> <span class=n>decision</span><span class=p>)</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;decision&#39;</span><span class=p>:</span> <span class=n>decision</span><span class=p>,</span>
            <span class=s1>&#39;score&#39;</span><span class=p>:</span> <span class=n>final_score</span><span class=p>,</span>
            <span class=s1>&#39;latency_ms&#39;</span><span class=p>:</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>
        <span class=p>}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_make_decision</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>score</span><span class=p>:</span> <span class=nb>float</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
        <span class=k>if</span> <span class=n>score</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>decision_thresholds</span><span class=p>[</span><span class=s1>&#39;block&#39;</span><span class=p>]:</span>
            <span class=k>return</span> <span class=s1>&#39;BLOCK&#39;</span>
        <span class=k>elif</span> <span class=n>score</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>decision_thresholds</span><span class=p>[</span><span class=s1>&#39;challenge&#39;</span><span class=p>]:</span>
            <span class=k>return</span> <span class=s1>&#39;CHALLENGE&#39;</span>  <span class=c1># Ask for 2FA</span>
        <span class=k>elif</span> <span class=n>score</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>decision_thresholds</span><span class=p>[</span><span class=s1>&#39;review&#39;</span><span class=p>]:</span>
            <span class=k>return</span> <span class=s1>&#39;REVIEW&#39;</span>  <span class=c1># Manual review queue</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>return</span> <span class=s1>&#39;APPROVE&#39;</span>

<span class=c1># Real-time Feature Engineering</span>
<span class=k>class</span><span class=w> </span><span class=nc>RealtimeFeatureEngine</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=nf>compute_velocity_features</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Compute velocity over different time windows&quot;&quot;&quot;</span>
        <span class=n>now</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>

        <span class=c1># Count transactions in time windows</span>
        <span class=n>txns_5min</span> <span class=o>=</span> <span class=n>redis_client</span><span class=o>.</span><span class=n>zcount</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;txn:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>now</span> <span class=o>-</span> <span class=mi>300</span><span class=p>,</span> <span class=n>now</span><span class=p>)</span>
        <span class=n>txns_30min</span> <span class=o>=</span> <span class=n>redis_client</span><span class=o>.</span><span class=n>zcount</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;txn:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>now</span> <span class=o>-</span> <span class=mi>1800</span><span class=p>,</span> <span class=n>now</span><span class=p>)</span>
        <span class=n>txns_1hour</span> <span class=o>=</span> <span class=n>redis_client</span><span class=o>.</span><span class=n>zcount</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;txn:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>now</span> <span class=o>-</span> <span class=mi>3600</span><span class=p>,</span> <span class=n>now</span><span class=p>)</span>

        <span class=c1># Amount velocity</span>
        <span class=n>amounts_1hour</span> <span class=o>=</span> <span class=n>redis_client</span><span class=o>.</span><span class=n>zrangebyscore</span><span class=p>(</span>
            <span class=sa>f</span><span class=s1>&#39;amt:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span> <span class=n>now</span> <span class=o>-</span> <span class=mi>3600</span><span class=p>,</span> <span class=n>now</span>
        <span class=p>)</span>
        <span class=n>total_amount_1hour</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=nb>float</span><span class=p>(</span><span class=n>a</span><span class=p>)</span> <span class=k>for</span> <span class=n>a</span> <span class=ow>in</span> <span class=n>amounts_1hour</span><span class=p>)</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;txn_count_5min&#39;</span><span class=p>:</span> <span class=n>txns_5min</span><span class=p>,</span>
            <span class=s1>&#39;txn_count_30min&#39;</span><span class=p>:</span> <span class=n>txns_30min</span><span class=p>,</span>
            <span class=s1>&#39;txn_count_1hour&#39;</span><span class=p>:</span> <span class=n>txns_1hour</span><span class=p>,</span>
            <span class=s1>&#39;total_amount_1hour&#39;</span><span class=p>:</span> <span class=n>total_amount_1hour</span><span class=p>,</span>
            <span class=s1>&#39;avg_amount_1hour&#39;</span><span class=p>:</span> <span class=n>total_amount_1hour</span> <span class=o>/</span> <span class=nb>max</span><span class=p>(</span><span class=n>txns_1hour</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
        <span class=p>}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>compute_anomaly_features</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>transaction</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span> <span class=n>user_profile</span><span class=p>:</span> <span class=nb>dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Detect anomalies based on user history&quot;&quot;&quot;</span>
        <span class=n>features</span> <span class=o>=</span> <span class=p>{}</span>

        <span class=c1># Location anomaly</span>
        <span class=n>last_location</span> <span class=o>=</span> <span class=n>user_profile</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;last_location&#39;</span><span class=p>)</span>
        <span class=n>curr_location</span> <span class=o>=</span> <span class=p>(</span><span class=n>transaction</span><span class=p>[</span><span class=s1>&#39;lat&#39;</span><span class=p>],</span> <span class=n>transaction</span><span class=p>[</span><span class=s1>&#39;lon&#39;</span><span class=p>])</span>
        <span class=k>if</span> <span class=n>last_location</span><span class=p>:</span>
            <span class=n>distance_km</span> <span class=o>=</span> <span class=n>haversine_distance</span><span class=p>(</span><span class=n>last_location</span><span class=p>,</span> <span class=n>curr_location</span><span class=p>)</span>
            <span class=n>time_diff_hours</span> <span class=o>=</span> <span class=p>(</span><span class=n>transaction</span><span class=p>[</span><span class=s1>&#39;timestamp&#39;</span><span class=p>]</span> <span class=o>-</span> <span class=n>user_profile</span><span class=p>[</span><span class=s1>&#39;last_txn_time&#39;</span><span class=p>])</span> <span class=o>/</span> <span class=mi>3600</span>
            <span class=n>features</span><span class=p>[</span><span class=s1>&#39;distance_from_last&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>distance_km</span>
            <span class=n>features</span><span class=p>[</span><span class=s1>&#39;impossible_travel&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span> <span class=k>if</span> <span class=n>distance_km</span> <span class=o>&gt;</span> <span class=mi>1000</span> <span class=ow>and</span> <span class=n>time_diff_hours</span> <span class=o>&lt;</span> <span class=mi>2</span> <span class=k>else</span> <span class=mi>0</span>

        <span class=c1># Amount anomaly (Z-score)</span>
        <span class=n>avg_amount</span> <span class=o>=</span> <span class=n>user_profile</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;avg_transaction_amount&#39;</span><span class=p>,</span> <span class=mi>100</span><span class=p>)</span>
        <span class=n>std_amount</span> <span class=o>=</span> <span class=n>user_profile</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;std_transaction_amount&#39;</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>
        <span class=n>features</span><span class=p>[</span><span class=s1>&#39;amount_zscore&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>transaction</span><span class=p>[</span><span class=s1>&#39;amount&#39;</span><span class=p>]</span> <span class=o>-</span> <span class=n>avg_amount</span><span class=p>)</span> <span class=o>/</span> <span class=n>std_amount</span>

        <span class=c1># Time anomaly</span>
        <span class=n>typical_hours</span> <span class=o>=</span> <span class=n>user_profile</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;typical_transaction_hours&#39;</span><span class=p>,</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>])</span>
        <span class=n>current_hour</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>fromtimestamp</span><span class=p>(</span><span class=n>transaction</span><span class=p>[</span><span class=s1>&#39;timestamp&#39;</span><span class=p>])</span><span class=o>.</span><span class=n>hour</span>
        <span class=n>features</span><span class=p>[</span><span class=s1>&#39;unusual_time&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span> <span class=k>if</span> <span class=n>current_hour</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>typical_hours</span> <span class=k>else</span> <span class=mi>0</span>

        <span class=k>return</span> <span class=n>features</span>
</code></pre></div> <p><strong>Feature Engineering Details:</strong></p> <table> <thead> <tr> <th>Feature Type</th> <th>Examples</th> <th>Window</th> <th>Storage</th> </tr> </thead> <tbody> <tr> <td><strong>Velocity</strong></td> <td>Transaction count, amount sum</td> <td>5min, 30min, 1h, 24h</td> <td>Redis sorted sets</td> </tr> <tr> <td><strong>Anomaly</strong></td> <td>Distance from last txn, unusual time</td> <td>Real-time</td> <td>Computed on-the-fly</td> </tr> <tr> <td><strong>Historical</strong></td> <td>Avg transaction amount, preferred merchants</td> <td>30d, 90d</td> <td>Cassandra</td> </tr> <tr> <td><strong>Network</strong></td> <td>IP reputation, email risk score</td> <td>Updated daily</td> <td>PostgreSQL</td> </tr> <tr> <td><strong>Behavioral</strong></td> <td>Spending pattern, transaction sequence</td> <td>90d</td> <td>Feature store</td> </tr> </tbody> </table> <p><strong>Model Architecture:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># XGBoost Model (Primary)</span>
<span class=n>model</span> <span class=o>=</span> <span class=n>xgb</span><span class=o>.</span><span class=n>XGBClassifier</span><span class=p>(</span>
    <span class=n>n_estimators</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span>
    <span class=n>max_depth</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
    <span class=n>learning_rate</span><span class=o>=</span><span class=mf>0.05</span><span class=p>,</span>
    <span class=n>subsample</span><span class=o>=</span><span class=mf>0.8</span><span class=p>,</span>
    <span class=n>colsample_bytree</span><span class=o>=</span><span class=mf>0.8</span><span class=p>,</span>
    <span class=n>scale_pos_weight</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>  <span class=c1># Handle class imbalance (1:10 fraud:legit)</span>
    <span class=n>eval_metric</span><span class=o>=</span><span class=s1>&#39;auc&#39;</span>
<span class=p>)</span>

<span class=c1># Features: 200+</span>
<span class=n>feature_groups</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;transaction&#39;</span><span class=p>:</span> <span class=mi>20</span><span class=p>,</span>      <span class=c1># amount, merchant, category</span>
    <span class=s1>&#39;velocity&#39;</span><span class=p>:</span> <span class=mi>30</span><span class=p>,</span>         <span class=c1># counts and amounts over time windows</span>
    <span class=s1>&#39;anomaly&#39;</span><span class=p>:</span> <span class=mi>15</span><span class=p>,</span>          <span class=c1># deviations from user profile</span>
    <span class=s1>&#39;network&#39;</span><span class=p>:</span> <span class=mi>40</span><span class=p>,</span>          <span class=c1># IP, device, email risk</span>
    <span class=s1>&#39;behavioral&#39;</span><span class=p>:</span> <span class=mi>50</span><span class=p>,</span>       <span class=c1># spending patterns</span>
    <span class=s1>&#39;merchant&#39;</span><span class=p>:</span> <span class=mi>25</span><span class=p>,</span>         <span class=c1># merchant risk, category</span>
    <span class=s1>&#39;temporal&#39;</span><span class=p>:</span> <span class=mi>20</span>          <span class=c1># time-based features</span>
<span class=p>}</span>

<span class=c1># LSTM for Sequential Modeling</span>
<span class=k>class</span><span class=w> </span><span class=nc>FraudLSTM</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>lstm</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LSTM</span><span class=p>(</span><span class=n>input_size</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span> <span class=n>hidden_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
            <span class=n>nn</span><span class=o>.</span><span class=n>Sigmoid</span><span class=p>()</span>
        <span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>sequence</span><span class=p>):</span>
        <span class=c1># sequence: [batch, seq_len, 50 features]</span>
        <span class=n>lstm_out</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lstm</span><span class=p>(</span><span class=n>sequence</span><span class=p>)</span>
        <span class=n>last_hidden</span> <span class=o>=</span> <span class=n>lstm_out</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span>  <span class=c1># Take last timestep</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>last_hidden</span><span class=p>)</span>
</code></pre></div> <p><strong>Decision Threshold Tuning:</strong></p> <table> <thead> <tr> <th>Threshold</th> <th>FPR</th> <th>Fraud Catch Rate</th> <th>Business Impact</th> </tr> </thead> <tbody> <tr> <td>0.95</td> <td>0.1%</td> <td>50%</td> <td>Block $10M fraud, lose $1M revenue</td> </tr> <tr> <td>0.90</td> <td>0.5%</td> <td>70%</td> <td>Block $14M fraud, lose $5M revenue</td> </tr> <tr> <td>0.85</td> <td>1.0%</td> <td>80%</td> <td>Block $16M fraud, lose $10M revenue</td> </tr> <tr> <td>0.80</td> <td>2.0%</td> <td>85%</td> <td>Block $17M fraud, lose $20M revenue</td> </tr> </tbody> </table> <p><strong>Common Pitfalls:</strong></p> <p>‚ùå <strong>Class imbalance:</strong> Fraud is 0.1-1% of transactions ‚Üí Use SMOTE, class weights ‚ùå <strong>Data leakage:</strong> Using future information ‚Üí Strict point-in-time features ‚ùå <strong>Concept drift:</strong> Fraud patterns change weekly ‚Üí Retrain frequently ‚ùå <strong>False positives:</strong> Blocking good customers ‚Üí Tune thresholds carefully ‚ùå <strong>Label delay:</strong> Chargebacks take 30-60 days ‚Üí Use confirmed fraud + disputes</p> <p><strong>Real-World Numbers (Stripe, PayPal):</strong></p> <ul> <li><strong>Fraud rate:</strong> 0.5-1.5% of transactions</li> <li><strong>Chargeback cost:</strong> $20-50 per transaction (fees + lost goods)</li> <li><strong>False positive cost:</strong> Lost revenue + customer churn</li> <li><strong>Detection latency:</strong> 50-100ms typical</li> <li><strong>Model update frequency:</strong> Weekly to daily</li> <li><strong>Feature count:</strong> 100-500 features</li> </ul> <p><strong>Monitoring &amp; Alerting:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Key metrics to monitor</span>
<span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;fraud_catch_rate&#39;</span><span class=p>:</span> <span class=mf>0.80</span><span class=p>,</span>  <span class=c1># Alert if drops below 75%</span>
    <span class=s1>&#39;false_positive_rate&#39;</span><span class=p>:</span> <span class=mf>0.01</span><span class=p>,</span>  <span class=c1># Alert if exceeds 1.5%</span>
    <span class=s1>&#39;p99_latency_ms&#39;</span><span class=p>:</span> <span class=mi>100</span><span class=p>,</span>  <span class=c1># Alert if exceeds 150ms</span>
    <span class=s1>&#39;model_score_distribution&#39;</span><span class=p>:</span> <span class=kc>None</span><span class=p>,</span>  <span class=c1># Alert on significant shift</span>
    <span class=s1>&#39;feature_null_rate&#39;</span><span class=p>:</span> <span class=mf>0.02</span><span class=p>,</span>  <span class=c1># Alert if exceeds 5%</span>
    <span class=s1>&#39;data_drift_psi&#39;</span><span class=p>:</span> <span class=mf>0.15</span>  <span class=c1># Alert if PSI &gt; 0.25</span>
<span class=p>}</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Real-time ML systems, feature engineering under latency constraints, handling class imbalance.</p> <p><strong>Strong answer signals:</strong> - Multi-layer defense (rules + ML + DL) - Discusses velocity features and time windows - Addresses cold start (new users, new merchants) - Talks about false positive cost vs fraud cost tradeoff - Mentions feedback loop and model retraining - Explains how to handle label delay (chargebacks) - Discusses A/B testing challenges (can't show fraud to users!)</p> </div> </details> <hr> <h3 id=design-an-ml-feature-store-google-amazon-interview-question>Design an ML Feature Store - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>MLOps</code>, <code>Infrastructure</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Scale Requirements:</strong> - <strong>Features:</strong> 10,000+ features across 100+ ML models - <strong>Online Serving:</strong> &lt;5ms p99 latency - <strong>Throughput:</strong> 1M+ feature requests/second - <strong>Training Data:</strong> Petabyte-scale offline feature retrieval - <strong>Freshness:</strong> Real-time features (&lt;1 min latency)</p> <p><strong>Detailed Architecture:</strong></p> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Feature Definition Layer                 ‚îÇ
‚îÇ  - Python SDK for defining features                   ‚îÇ
‚îÇ  - Schema validation and type checking                ‚îÇ
‚îÇ  - Version control integration                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Feature Computation Layer                   ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  Batch (Spark/Dask):          Streaming (Flink):     ‚îÇ
‚îÇ  - Daily aggregates            - Real-time counts     ‚îÇ
‚îÇ  - Historical features         - Windowed aggregates  ‚îÇ
‚îÇ  - Complex transformations     - Event-driven updates ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Feature Storage Layer                    ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Online Store     ‚îÇ   ‚îÇ   Offline Store     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (Low Latency)     ‚îÇ   ‚îÇ   (Training Data)   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ   ‚îÇ                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Redis/DynamoDB     ‚îÇ   ‚îÇ S3/BigQuery/Delta  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Key-value lookup ‚îÇ   ‚îÇ - Point-in-time    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - &lt;5ms p99         ‚îÇ   ‚îÇ   joins            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Hot features     ‚îÇ   ‚îÇ - Historical data  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Feature Registry (Metadata)                ‚îÇ
‚îÇ  - Schema &amp; types                                     ‚îÇ
‚îÇ  - Lineage (data sources ‚Üí features ‚Üí models)        ‚îÇ
‚îÇ  - Statistics (min, max, missing %)                  ‚îÇ
‚îÇ  - Access control &amp; governance                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>datetime</span><span class=w> </span><span class=kn>import</span> <span class=n>datetime</span><span class=p>,</span> <span class=n>timedelta</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Dict</span>
<span class=kn>import</span><span class=w> </span><span class=nn>redis</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>

<span class=c1># Feature Definition</span>
<span class=k>class</span><span class=w> </span><span class=nc>FeatureStore</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>online_store</span> <span class=o>=</span> <span class=n>redis</span><span class=o>.</span><span class=n>Redis</span><span class=p>(</span><span class=n>host</span><span class=o>=</span><span class=s1>&#39;localhost&#39;</span><span class=p>,</span> <span class=n>port</span><span class=o>=</span><span class=mi>6379</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>offline_store</span> <span class=o>=</span> <span class=n>BigQueryClient</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>registry</span> <span class=o>=</span> <span class=n>FeatureRegistry</span><span class=p>()</span>

    <span class=c1># Define a feature</span>
    <span class=nd>@feature</span><span class=p>(</span>
        <span class=n>name</span><span class=o>=</span><span class=s2>&quot;user_purchase_count_7d&quot;</span><span class=p>,</span>
        <span class=n>entity</span><span class=o>=</span><span class=s2>&quot;user&quot;</span><span class=p>,</span>
        <span class=n>value_type</span><span class=o>=</span><span class=n>ValueType</span><span class=o>.</span><span class=n>INT64</span><span class=p>,</span>
        <span class=n>ttl</span><span class=o>=</span><span class=n>timedelta</span><span class=p>(</span><span class=n>days</span><span class=o>=</span><span class=mi>7</span><span class=p>),</span>
        <span class=n>online</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>offline</span><span class=o>=</span><span class=kc>True</span>
    <span class=p>)</span>
    <span class=k>def</span><span class=w> </span><span class=nf>user_purchase_count_7d</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>timestamp</span><span class=p>:</span> <span class=n>datetime</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Count user purchases in last 7 days&quot;&quot;&quot;</span>
        <span class=n>start_date</span> <span class=o>=</span> <span class=n>timestamp</span> <span class=o>-</span> <span class=n>timedelta</span><span class=p>(</span><span class=n>days</span><span class=o>=</span><span class=mi>7</span><span class=p>)</span>

        <span class=c1># For batch/training (point-in-time correct)</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>context</span> <span class=o>==</span> <span class=s2>&quot;offline&quot;</span><span class=p>:</span>
            <span class=n>query</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;</span>
<span class=s2>            SELECT user_id, COUNT(*) as purchase_count</span>
<span class=s2>            FROM purchases</span>
<span class=s2>            WHERE user_id = &#39;</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>&#39;</span>
<span class=s2>              AND purchase_timestamp &gt;= &#39;</span><span class=si>{</span><span class=n>start_date</span><span class=si>}</span><span class=s2>&#39;</span>
<span class=s2>              AND purchase_timestamp &lt; &#39;</span><span class=si>{</span><span class=n>timestamp</span><span class=si>}</span><span class=s2>&#39;</span>
<span class=s2>            GROUP BY user_id</span>
<span class=s2>            &quot;&quot;&quot;</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>offline_store</span><span class=o>.</span><span class=n>query</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>

        <span class=c1># For online serving (real-time)</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=c1># Pre-computed and cached in Redis</span>
            <span class=n>key</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;user:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>:purchase_count_7d&quot;</span>
            <span class=k>return</span> <span class=nb>int</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>online_store</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>key</span><span class=p>)</span> <span class=ow>or</span> <span class=mi>0</span><span class=p>)</span>

    <span class=c1># Get features for online serving</span>
    <span class=k>def</span><span class=w> </span><span class=nf>get_online_features</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>entity_rows</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>Dict</span><span class=p>],</span>  <span class=c1># e.g., [{&quot;user_id&quot;: &quot;123&quot;}, ...]</span>
        <span class=n>feature_refs</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span>   <span class=c1># e.g., [&quot;user_purchase_count_7d&quot;, ...]</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Fast batch retrieval for inference</span>
<span class=sd>        Target latency: &lt;5ms for 10 features</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=c1># Parallel Redis MGET for performance</span>
        <span class=n>pipeline</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>online_store</span><span class=o>.</span><span class=n>pipeline</span><span class=p>()</span>

        <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>entity_rows</span><span class=p>:</span>
            <span class=n>entity_key</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;user:</span><span class=si>{</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;user_id&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span>
            <span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>feature_refs</span><span class=p>:</span>
                <span class=n>key</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>entity_key</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>&quot;</span>
                <span class=n>pipeline</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>key</span><span class=p>)</span>

        <span class=c1># Execute all at once</span>
        <span class=n>values</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>execute</span><span class=p>()</span>

        <span class=c1># Parse results</span>
        <span class=n>idx</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>entity_rows</span><span class=p>:</span>
            <span class=n>feature_dict</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;user_id&quot;</span><span class=p>:</span> <span class=n>row</span><span class=p>[</span><span class=s2>&quot;user_id&quot;</span><span class=p>]}</span>
            <span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>feature_refs</span><span class=p>:</span>
                <span class=n>feature_dict</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span> <span class=o>=</span> <span class=n>values</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
                <span class=n>idx</span> <span class=o>+=</span> <span class=mi>1</span>
            <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>feature_dict</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>results</span><span class=p>)</span>

    <span class=c1># Get features for training (point-in-time correct)</span>
    <span class=k>def</span><span class=w> </span><span class=nf>get_historical_features</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>entity_df</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span>  <span class=c1># user_id, timestamp</span>
        <span class=n>feature_refs</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Point-in-time correct joins for training data</span>
<span class=sd>        Prevents data leakage</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=c1># Generate SQL with point-in-time joins</span>
        <span class=n>query</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_build_pit_query</span><span class=p>(</span><span class=n>entity_df</span><span class=p>,</span> <span class=n>feature_refs</span><span class=p>)</span>

        <span class=c1># Execute on data warehouse</span>
        <span class=n>result</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>offline_store</span><span class=o>.</span><span class=n>query</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>result</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_build_pit_query</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>entity_df</span><span class=p>,</span> <span class=n>features</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Build SQL for point-in-time correct feature retrieval</span>

<span class=sd>        Example: If training data point is at 2024-01-15,</span>
<span class=sd>        only use features computed from data BEFORE 2024-01-15</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>base_query</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;</span>
<span class=s2>        WITH entity_timestamps AS (</span>
<span class=s2>            SELECT user_id, event_timestamp</span>
<span class=s2>            FROM training_events</span>
<span class=s2>        )</span>
<span class=s2>        &quot;&quot;&quot;</span>

        <span class=c1># For each feature, join with timestamp constraint</span>
        <span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>features</span><span class=p>:</span>
            <span class=n>base_query</span> <span class=o>+=</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;</span>
<span class=s2>            LEFT JOIN LATERAL (</span>
<span class=s2>                SELECT </span><span class=si>{</span><span class=n>feature</span><span class=si>}</span>
<span class=s2>                FROM feature_values_</span><span class=si>{</span><span class=n>feature</span><span class=si>}</span>
<span class=s2>                WHERE entity_id = entity_timestamps.user_id</span>
<span class=s2>                  AND feature_timestamp &lt;= entity_timestamps.event_timestamp</span>
<span class=s2>                ORDER BY feature_timestamp DESC</span>
<span class=s2>                LIMIT 1</span>
<span class=s2>            ) AS </span><span class=si>{</span><span class=n>feature</span><span class=si>}</span><span class=s2>_values ON TRUE</span>
<span class=s2>            &quot;&quot;&quot;</span>

        <span class=k>return</span> <span class=n>base_query</span>

<span class=c1># Batch Feature Computation (Spark)</span>
<span class=k>class</span><span class=w> </span><span class=nc>BatchFeatureCompute</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=nf>compute_daily_features</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>date</span><span class=p>:</span> <span class=n>datetime</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Run daily to compute batch features&quot;&quot;&quot;</span>

        <span class=c1># Example: Compute user purchase count for all users</span>
        <span class=n>query</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;</span>
<span class=s2>        SELECT</span>
<span class=s2>            user_id,</span>
<span class=s2>            COUNT(*) as purchase_count_7d,</span>
<span class=s2>            SUM(amount) as total_spent_7d,</span>
<span class=s2>            AVG(amount) as avg_order_value_7d</span>
<span class=s2>        FROM purchases</span>
<span class=s2>        WHERE purchase_date BETWEEN {date - 7d} AND </span><span class=si>{date}</span>
<span class=s2>        GROUP BY user_id</span>
<span class=s2>        &quot;&quot;&quot;</span>

        <span class=n>df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>

        <span class=c1># Write to both stores</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_write_to_online_store</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_write_to_offline_store</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>date</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_write_to_online_store</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>:</span> <span class=n>DataFrame</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Write to Redis for low-latency serving&quot;&quot;&quot;</span>
        <span class=c1># Batch write to Redis</span>
        <span class=n>pipeline</span> <span class=o>=</span> <span class=n>redis_client</span><span class=o>.</span><span class=n>pipeline</span><span class=p>()</span>

        <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>df</span><span class=o>.</span><span class=n>collect</span><span class=p>():</span>
            <span class=n>key</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;user:</span><span class=si>{</span><span class=n>row</span><span class=o>.</span><span class=n>user_id</span><span class=si>}</span><span class=s2>:purchase_count_7d&quot;</span>
            <span class=n>pipeline</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>key</span><span class=p>,</span> <span class=n>row</span><span class=o>.</span><span class=n>purchase_count_7d</span><span class=p>,</span> <span class=n>ex</span><span class=o>=</span><span class=mi>7</span><span class=o>*</span><span class=mi>24</span><span class=o>*</span><span class=mi>3600</span><span class=p>)</span>  <span class=c1># 7 day TTL</span>

        <span class=n>pipeline</span><span class=o>.</span><span class=n>execute</span><span class=p>()</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_write_to_offline_store</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>:</span> <span class=n>DataFrame</span><span class=p>,</span> <span class=n>date</span><span class=p>:</span> <span class=n>datetime</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Write to data warehouse for training&quot;&quot;&quot;</span>
        <span class=c1># Append to partitioned table</span>
        <span class=n>df</span><span class=o>.</span><span class=n>write</span><span class=o>.</span><span class=n>partitionBy</span><span class=p>(</span><span class=s2>&quot;date&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>mode</span><span class=p>(</span><span class=s2>&quot;append&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>saveAsTable</span><span class=p>(</span>
            <span class=s2>&quot;feature_store.user_features&quot;</span>
        <span class=p>)</span>

<span class=c1># Streaming Feature Computation (Flink)</span>
<span class=k>class</span><span class=w> </span><span class=nc>StreamingFeatureCompute</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=nf>process_realtime_event</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>event</span><span class=p>:</span> <span class=nb>dict</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Process events in real-time (Kafka ‚Üí Flink ‚Üí Redis)&quot;&quot;&quot;</span>
        <span class=n>user_id</span> <span class=o>=</span> <span class=n>event</span><span class=p>[</span><span class=s1>&#39;user_id&#39;</span><span class=p>]</span>

        <span class=c1># Update velocity features</span>
        <span class=n>current_count</span> <span class=o>=</span> <span class=n>redis_client</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;user:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>:txn_count_1hr&quot;</span><span class=p>)</span> <span class=ow>or</span> <span class=mi>0</span>
        <span class=n>redis_client</span><span class=o>.</span><span class=n>incr</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;user:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>:txn_count_1hr&quot;</span><span class=p>)</span>
        <span class=n>redis_client</span><span class=o>.</span><span class=n>expire</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;user:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>:txn_count_1hr&quot;</span><span class=p>,</span> <span class=mi>3600</span><span class=p>)</span>

        <span class=c1># Update windowed aggregates</span>
        <span class=n>redis_client</span><span class=o>.</span><span class=n>zadd</span><span class=p>(</span>
            <span class=sa>f</span><span class=s2>&quot;user:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>:recent_purchases&quot;</span><span class=p>,</span>
            <span class=p>{</span><span class=n>event</span><span class=p>[</span><span class=s1>&#39;purchase_id&#39;</span><span class=p>]:</span> <span class=n>event</span><span class=p>[</span><span class=s1>&#39;timestamp&#39;</span><span class=p>]}</span>
        <span class=p>)</span>

        <span class=c1># Remove old events outside window</span>
        <span class=n>cutoff</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=mi>3600</span>
        <span class=n>redis_client</span><span class=o>.</span><span class=n>zremrangebyscore</span><span class=p>(</span>
            <span class=sa>f</span><span class=s2>&quot;user:</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>:recent_purchases&quot;</span><span class=p>,</span>
            <span class=mi>0</span><span class=p>,</span>
            <span class=n>cutoff</span>
        <span class=p>)</span>
</code></pre></div> <p><strong>Key Components Deep Dive:</strong></p> <table> <thead> <tr> <th>Component</th> <th>Technology</th> <th>Purpose</th> <th>Scale</th> </tr> </thead> <tbody> <tr> <td><strong>Online Store</strong></td> <td>Redis Cluster</td> <td>Real-time serving</td> <td>&lt;5ms p99, 1M QPS</td> </tr> <tr> <td><strong>Offline Store</strong></td> <td>BigQuery/Delta Lake</td> <td>Training data</td> <td>PB-scale, point-in-time joins</td> </tr> <tr> <td><strong>Registry</strong></td> <td>PostgreSQL</td> <td>Metadata &amp; lineage</td> <td>10K+ features</td> </tr> <tr> <td><strong>Batch Compute</strong></td> <td>Spark</td> <td>Daily aggregates</td> <td>Process TB data</td> </tr> <tr> <td><strong>Stream Compute</strong></td> <td>Flink/Spark Streaming</td> <td>Real-time updates</td> <td>100K events/sec</td> </tr> <tr> <td><strong>Feature SDK</strong></td> <td>Python</td> <td>Define features</td> <td>Type-safe, versioned</td> </tr> </tbody> </table> <p><strong>Point-in-Time Correctness:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># WRONG: Data leakage - using future information</span>
<span class=k>def</span><span class=w> </span><span class=nf>get_features_WRONG</span><span class=p>(</span><span class=n>user_id</span><span class=p>,</span> <span class=n>prediction_timestamp</span><span class=p>):</span>
    <span class=c1># This query looks at ALL data, including future data!</span>
    <span class=k>return</span> <span class=n>db</span><span class=o>.</span><span class=n>query</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;&quot;&quot;</span>
<span class=s2>        SELECT AVG(purchase_amount)</span>
<span class=s2>        FROM purchases</span>
<span class=s2>        WHERE user_id = &#39;</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>&#39;</span>
<span class=s2>    &quot;&quot;&quot;</span><span class=p>)</span>

<span class=c1># CORRECT: Point-in-time join</span>
<span class=k>def</span><span class=w> </span><span class=nf>get_features_CORRECT</span><span class=p>(</span><span class=n>user_id</span><span class=p>,</span> <span class=n>prediction_timestamp</span><span class=p>):</span>
    <span class=c1># Only use data from BEFORE prediction time</span>
    <span class=k>return</span> <span class=n>db</span><span class=o>.</span><span class=n>query</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;&quot;&quot;</span>
<span class=s2>        SELECT AVG(purchase_amount)</span>
<span class=s2>        FROM purchases</span>
<span class=s2>        WHERE user_id = &#39;</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>&#39;</span>
<span class=s2>          AND purchase_timestamp &lt; &#39;</span><span class=si>{</span><span class=n>prediction_timestamp</span><span class=si>}</span><span class=s2>&#39;</span>
<span class=s2>    &quot;&quot;&quot;</span><span class=p>)</span>
</code></pre></div> <p><strong>Feature Freshness Trade-offs:</strong></p> <table> <thead> <tr> <th>Feature Type</th> <th>Computation</th> <th>Latency</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td><strong>Batch</strong></td> <td>Daily Spark job</td> <td>24 hours</td> <td>Historical patterns</td> </tr> <tr> <td><strong>Mini-batch</strong></td> <td>Hourly job</td> <td>1 hour</td> <td>Near real-time</td> </tr> <tr> <td><strong>Streaming</strong></td> <td>Flink/Kafka</td> <td>&lt;1 minute</td> <td>Velocity features</td> </tr> <tr> <td><strong>On-demand</strong></td> <td>Computed at request</td> <td>&lt;5ms</td> <td>Session features</td> </tr> </tbody> </table> <p><strong>Common Pitfalls:</strong></p> <p>‚ùå <strong>Data leakage:</strong> Not using point-in-time joins ‚Üí Wrong model performance ‚ùå <strong>Train-serve skew:</strong> Different feature computation in training vs serving ‚ùå <strong>Missing features:</strong> No handling for entities without features ‚Üí Model errors ‚ùå <strong>Stale features:</strong> Not monitoring feature freshness ‚Üí Degraded predictions ‚ùå <strong>Schema changes:</strong> Breaking changes to feature definitions ‚Üí Production errors</p> <p><strong>Monitoring:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Key metrics</span>
<span class=n>feature_metrics</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;online_latency_p99_ms&#39;</span><span class=p>:</span> <span class=mi>5</span><span class=p>,</span>
    <span class=s1>&#39;online_error_rate&#39;</span><span class=p>:</span> <span class=mf>0.001</span><span class=p>,</span>
    <span class=s1>&#39;feature_null_rate&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;user_purchase_count_7d&#39;</span><span class=p>:</span> <span class=mf>0.02</span><span class=p>,</span>  <span class=c1># 2% nulls acceptable</span>
        <span class=s1>&#39;user_age&#39;</span><span class=p>:</span> <span class=mf>0.10</span>  <span class=c1># 10% nulls (optional feature)</span>
    <span class=p>},</span>
    <span class=s1>&#39;feature_staleness_minutes&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;batch_features&#39;</span><span class=p>:</span> <span class=mi>24</span> <span class=o>*</span> <span class=mi>60</span><span class=p>,</span>  <span class=c1># Daily</span>
        <span class=s1>&#39;streaming_features&#39;</span><span class=p>:</span> <span class=mi>5</span>      <span class=c1># 5 min max</span>
    <span class=p>},</span>
    <span class=s1>&#39;train_serve_skew&#39;</span><span class=p>:</span> <span class=mf>0.05</span>  <span class=c1># Feature distributions should match</span>
<span class=p>}</span>
</code></pre></div> <p><strong>Real-World Examples:</strong></p> <ul> <li><strong>Uber:</strong> Michelangelo feature store, 10K+ features, serves 100M+ predictions/day</li> <li><strong>Airbnb:</strong> Zipline feature store, reduces feature engineering from weeks to days</li> <li><strong>DoorDash:</strong> Feature store reduced model development time by 50%</li> <li><strong>Netflix:</strong> Feature store serves 1B+ feature requests/day</li> </ul> <p><strong>Tools Comparison:</strong></p> <table> <thead> <tr> <th>Tool</th> <th>Pros</th> <th>Cons</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td><strong>Feast</strong></td> <td>Open-source, flexible</td> <td>Limited UI</td> <td>Custom deployments</td> </tr> <tr> <td><strong>Tecton</strong></td> <td>Enterprise, managed</td> <td>Expensive</td> <td>Large orgs</td> </tr> <tr> <td><strong>Vertex AI</strong></td> <td>GCP integrated</td> <td>Vendor lock-in</td> <td>GCP users</td> </tr> <tr> <td><strong>SageMaker</strong></td> <td>AWS integrated</td> <td>Limited features</td> <td>AWS users</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding of train-serve consistency, point-in-time correctness, scaling challenges.</p> <p><strong>Strong answer signals:</strong> - Explains point-in-time joins for preventing data leakage - Discusses online vs offline stores with specific latency numbers - Mentions feature freshness and staleness monitoring - Knows about train-serve skew and how to detect it - Talks about feature versioning and backward compatibility - Discusses feature sharing across teams and governance</p> </div> </details> <hr> <h3 id=design-a-model-serving-system-google-amazon-interview-question>Design a Model Serving System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Deployment</code>, <code>Serving</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Scale Requirements:</strong> - <strong>Throughput:</strong> 100K+ requests/second - <strong>Latency:</strong> &lt;50ms p99 (&lt; 10ms for simple models) - <strong>Models:</strong> 100+ models simultaneously - <strong>GPU Utilization:</strong> &gt;70% (expensive hardware) - <strong>Availability:</strong> 99.99% uptime</p> <p><strong>Detailed Architecture:</strong></p> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          API Gateway / Load Balancer    ‚îÇ
‚îÇ  - Rate limiting (1000 QPS/user)        ‚îÇ
‚îÇ  - Authentication &amp; authorization        ‚îÇ
‚îÇ  - Traffic routing by model version     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Model Server Fleet              ‚îÇ
‚îÇ  (Kubernetes pods with auto-scaling)    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ  Server 1  ‚îÇ  ‚îÇ  Server 2  ‚îÇ  ...  ‚îÇ
‚îÇ  ‚îÇ  CPU/GPU   ‚îÇ  ‚îÇ  CPU/GPU   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ            ‚îÇ  ‚îÇ            ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ Model A v1 ‚îÇ  ‚îÇ Model A v2 ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ Model B    ‚îÇ  ‚îÇ Model C    ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Optimization Layer             ‚îÇ
‚îÇ  - Request batching (collect 10-100ms)  ‚îÇ
‚îÇ  - Result caching (Redis)               ‚îÇ
‚îÇ  - Feature caching                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Model Registry &amp; Storage        ‚îÇ
‚îÇ  - S3/GCS: Model artifacts              ‚îÇ
‚îÇ  - Versioning &amp; metadata                ‚îÇ
‚îÇ  - Lazy loading / preloading            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Monitoring:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Prometheus + Grafana + Alerts          ‚îÇ
‚îÇ  - Latency (p50, p95, p99)              ‚îÇ
‚îÇ  - Throughput (QPS)                     ‚îÇ
‚îÇ  - GPU utilization                      ‚îÇ
‚îÇ  - Model drift                          ‚îÇ
‚îÇ  - Error rates                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>fastapi</span><span class=w> </span><span class=kn>import</span> <span class=n>FastAPI</span><span class=p>,</span> <span class=n>HTTPException</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Dict</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
<span class=kn>from</span><span class=w> </span><span class=nn>collections</span><span class=w> </span><span class=kn>import</span> <span class=n>defaultdict</span>
<span class=kn>import</span><span class=w> </span><span class=nn>time</span>

<span class=n>app</span> <span class=o>=</span> <span class=n>FastAPI</span><span class=p>()</span>

<span class=k>class</span><span class=w> </span><span class=nc>ModelServer</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>models</span> <span class=o>=</span> <span class=p>{}</span>  <span class=c1># model_name -&gt; model</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>batchers</span> <span class=o>=</span> <span class=p>{}</span>  <span class=c1># model_name -&gt; RequestBatcher</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>cache</span> <span class=o>=</span> <span class=n>RedisCache</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>metrics</span> <span class=o>=</span> <span class=n>PrometheusMetrics</span><span class=p>()</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>load_model</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>version</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Load model from registry&quot;&quot;&quot;</span>
        <span class=c1># Download from S3/GCS</span>
        <span class=n>model_path</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;s3://models/</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>version</span><span class=si>}</span><span class=s2>/model.pt&quot;</span>

        <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
            <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;cuda&quot;</span><span class=p>)</span>
            <span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>model_path</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
            <span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>script</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>  <span class=c1># TorchScript for optimization</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&quot;cpu&quot;</span><span class=p>)</span>
            <span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>model_path</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
            <span class=c1># Quantize for CPU inference</span>
            <span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>quantization</span><span class=o>.</span><span class=n>quantize_dynamic</span><span class=p>(</span>
                <span class=n>model</span><span class=p>,</span> <span class=p>{</span><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>},</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>qint8</span>
            <span class=p>)</span>

        <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>models</span><span class=p>[</span><span class=n>model_name</span><span class=p>]</span> <span class=o>=</span> <span class=n>model</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>batchers</span><span class=p>[</span><span class=n>model_name</span><span class=p>]</span> <span class=o>=</span> <span class=n>RequestBatcher</span><span class=p>(</span><span class=n>max_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>max_wait_ms</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>

        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Loaded </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2> v</span><span class=si>{</span><span class=n>version</span><span class=si>}</span><span class=s2> on </span><span class=si>{</span><span class=n>device</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=nd>@app</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=s2>&quot;/predict/</span><span class=si>{model_name}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>features</span><span class=p>:</span> <span class=n>Dict</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Prediction endpoint with batching and caching</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>

        <span class=c1># Step 1: Check cache</span>
        <span class=n>cache_key</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_compute_cache_key</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>
        <span class=n>cached_result</span> <span class=o>=</span> <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>cache</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cache_key</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>cached_result</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>increment</span><span class=p>(</span><span class=s2>&quot;cache_hit&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=n>model_name</span><span class=p>)</span>
            <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;prediction&quot;</span><span class=p>:</span> <span class=n>cached_result</span><span class=p>,</span> <span class=s2>&quot;cached&quot;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}</span>

        <span class=c1># Step 2: Add to batch</span>
        <span class=n>future</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>Future</span><span class=p>()</span>
        <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>batchers</span><span class=p>[</span><span class=n>model_name</span><span class=p>]</span><span class=o>.</span><span class=n>add_request</span><span class=p>(</span><span class=n>features</span><span class=p>,</span> <span class=n>future</span><span class=p>)</span>

        <span class=c1># Wait for batch processing</span>
        <span class=n>prediction</span> <span class=o>=</span> <span class=k>await</span> <span class=n>future</span>

        <span class=c1># Step 3: Cache result</span>
        <span class=k>await</span> <span class=bp>self</span><span class=o>.</span><span class=n>cache</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>cache_key</span><span class=p>,</span> <span class=n>prediction</span><span class=p>,</span> <span class=n>ttl</span><span class=o>=</span><span class=mi>3600</span><span class=p>)</span>

        <span class=n>latency_ms</span> <span class=o>=</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>observe</span><span class=p>(</span><span class=s2>&quot;prediction_latency&quot;</span><span class=p>,</span> <span class=n>latency_ms</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=n>model_name</span><span class=p>)</span>

        <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;prediction&quot;</span><span class=p>:</span> <span class=n>prediction</span><span class=p>,</span> <span class=s2>&quot;cached&quot;</span><span class=p>:</span> <span class=kc>False</span><span class=p>}</span>

<span class=k>class</span><span class=w> </span><span class=nc>RequestBatcher</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Batch requests for GPU efficiency</span>
<span class=sd>    Trade-off: Slight latency increase for much higher throughput</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>max_batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>max_wait_ms</span><span class=o>=</span><span class=mi>50</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>max_batch_size</span> <span class=o>=</span> <span class=n>max_batch_size</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>max_wait_ms</span> <span class=o>=</span> <span class=n>max_wait_ms</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>queue</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>processing</span> <span class=o>=</span> <span class=kc>False</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>add_request</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>features</span><span class=p>,</span> <span class=n>future</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Add request to batch queue&quot;&quot;&quot;</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>features</span><span class=p>,</span> <span class=n>future</span><span class=p>))</span>

        <span class=c1># Start batch processing if not already running</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>processing</span><span class=p>:</span>
            <span class=n>asyncio</span><span class=o>.</span><span class=n>create_task</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_process_batch</span><span class=p>())</span>

        <span class=c1># Or if queue is full</span>
        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>)</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_batch_size</span><span class=p>:</span>
            <span class=n>asyncio</span><span class=o>.</span><span class=n>create_task</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_process_batch</span><span class=p>())</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>_process_batch</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Process accumulated requests as batch&quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>processing</span> <span class=ow>or</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=k>return</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>processing</span> <span class=o>=</span> <span class=kc>True</span>

        <span class=c1># Wait for more requests (up to max_wait_ms)</span>
        <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>max_wait_ms</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>)</span>

        <span class=c1># Get batch</span>
        <span class=n>batch_size</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>max_batch_size</span><span class=p>)</span>
        <span class=n>batch</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>[:</span><span class=n>batch_size</span><span class=p>]</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>queue</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>[</span><span class=n>batch_size</span><span class=p>:]</span>

        <span class=c1># Prepare batch tensor</span>
        <span class=n>features_list</span> <span class=o>=</span> <span class=p>[</span><span class=n>item</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>batch</span><span class=p>]</span>
        <span class=n>futures</span> <span class=o>=</span> <span class=p>[</span><span class=n>item</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>batch</span><span class=p>]</span>

        <span class=c1># Convert to tensor</span>
        <span class=n>batch_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span>
            <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>_features_to_array</span><span class=p>(</span><span class=n>f</span><span class=p>)</span> <span class=k>for</span> <span class=n>f</span> <span class=ow>in</span> <span class=n>features_list</span><span class=p>])</span>
        <span class=p>)</span>

        <span class=c1># Run inference</span>
        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
            <span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch_tensor</span><span class=p>)</span>

        <span class=c1># Return results to individual futures</span>
        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>future</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>futures</span><span class=p>):</span>
            <span class=n>future</span><span class=o>.</span><span class=n>set_result</span><span class=p>(</span><span class=n>predictions</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>())</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>processing</span> <span class=o>=</span> <span class=kc>False</span>

        <span class=c1># Process remaining queue if any</span>
        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>asyncio</span><span class=o>.</span><span class=n>create_task</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_process_batch</span><span class=p>())</span>

<span class=c1># GPU Optimization</span>
<span class=k>class</span><span class=w> </span><span class=nc>GPUOptimizedServer</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Optimize for GPU serving&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>use_amp</span> <span class=o>=</span> <span class=kc>True</span>  <span class=c1># Automatic Mixed Precision</span>

    <span class=k>def</span><span class=w> </span><span class=nf>load_optimized_model</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Load model with optimizations&quot;&quot;&quot;</span>

        <span class=c1># TensorRT optimization (NVIDIA)</span>
        <span class=kn>import</span><span class=w> </span><span class=nn>torch_tensorrt</span>

        <span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>

        <span class=c1># Compile with TensorRT</span>
        <span class=n>trt_model</span> <span class=o>=</span> <span class=n>torch_tensorrt</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span>
            <span class=n>model</span><span class=p>,</span>
            <span class=n>inputs</span><span class=o>=</span><span class=p>[</span><span class=n>torch_tensorrt</span><span class=o>.</span><span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>784</span><span class=p>])],</span>
            <span class=n>enabled_precisions</span><span class=o>=</span><span class=p>{</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>},</span>  <span class=c1># FP16 for speed</span>
            <span class=n>workspace_size</span><span class=o>=</span><span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=mi>30</span>  <span class=c1># 1GB</span>
        <span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>trt_model</span>

    <span class=nd>@torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>amp</span><span class=o>.</span><span class=n>autocast</span><span class=p>()</span>  <span class=c1># Mixed precision</span>
    <span class=k>def</span><span class=w> </span><span class=nf>predict</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch_tensor</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Inference with AMP&quot;&quot;&quot;</span>
        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>batch_tensor</span><span class=p>)</span>

<span class=c1># A/B Testing Support</span>
<span class=k>class</span><span class=w> </span><span class=nc>ABTestingServer</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Route traffic to different model versions&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>model_versions</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;model_a&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;v1&#39;</span><span class=p>:</span> <span class=mf>0.9</span><span class=p>,</span> <span class=s1>&#39;v2&#39;</span><span class=p>:</span> <span class=mf>0.1</span><span class=p>},</span>  <span class=c1># 90% v1, 10% v2</span>
            <span class=s1>&#39;model_b&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;v1&#39;</span><span class=p>:</span> <span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;v2&#39;</span><span class=p>:</span> <span class=mf>0.5</span><span class=p>}</span>   <span class=c1># 50/50 split</span>
        <span class=p>}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>get_model_version</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Deterministic assignment based on user_id&quot;&quot;&quot;</span>
        <span class=kn>import</span><span class=w> </span><span class=nn>hashlib</span>

        <span class=c1># Hash user_id to get consistent assignment</span>
        <span class=n>hash_value</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>hashlib</span><span class=o>.</span><span class=n>md5</span><span class=p>(</span><span class=n>user_id</span><span class=o>.</span><span class=n>encode</span><span class=p>())</span><span class=o>.</span><span class=n>hexdigest</span><span class=p>(),</span> <span class=mi>16</span><span class=p>)</span>
        <span class=n>bucket</span> <span class=o>=</span> <span class=p>(</span><span class=n>hash_value</span> <span class=o>%</span> <span class=mi>100</span><span class=p>)</span> <span class=o>/</span> <span class=mf>100.0</span>

        <span class=c1># Assign to version based on bucket</span>
        <span class=n>cumulative</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=k>for</span> <span class=n>version</span><span class=p>,</span> <span class=n>weight</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>model_versions</span><span class=p>[</span><span class=n>model_name</span><span class=p>]</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=n>cumulative</span> <span class=o>+=</span> <span class=n>weight</span>
            <span class=k>if</span> <span class=n>bucket</span> <span class=o>&lt;</span> <span class=n>cumulative</span><span class=p>:</span>
                <span class=k>return</span> <span class=n>version</span>

        <span class=k>return</span> <span class=s1>&#39;v1&#39;</span>  <span class=c1># Default</span>

<span class=c1># Auto-scaling based on metrics</span>
<span class=k>class</span><span class=w> </span><span class=nc>AutoScaler</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Scale model servers based on load&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=nf>should_scale_up</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>metrics</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Decide if we need more servers&quot;&quot;&quot;</span>
        <span class=n>conditions</span> <span class=o>=</span> <span class=p>[</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;cpu_usage&#39;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>80</span><span class=p>,</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;gpu_usage&#39;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>85</span><span class=p>,</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;p99_latency_ms&#39;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>100</span><span class=p>,</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;queue_size&#39;</span><span class=p>]</span> <span class=o>&gt;</span> <span class=mi>1000</span>
        <span class=p>]</span>

        <span class=k>return</span> <span class=nb>any</span><span class=p>(</span><span class=n>conditions</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>should_scale_down</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>metrics</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Decide if we can reduce servers&quot;&quot;&quot;</span>
        <span class=n>conditions</span> <span class=o>=</span> <span class=p>[</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;cpu_usage&#39;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=mi>30</span><span class=p>,</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;gpu_usage&#39;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=mi>30</span><span class=p>,</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;p99_latency_ms&#39;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=mi>20</span><span class=p>,</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;queue_size&#39;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=mi>100</span>
        <span class=p>]</span>

        <span class=k>return</span> <span class=nb>all</span><span class=p>(</span><span class=n>conditions</span><span class=p>)</span>
</code></pre></div> <p><strong>Latency Optimization Techniques:</strong></p> <table> <thead> <tr> <th>Technique</th> <th>Latency Gain</th> <th>Throughput Gain</th> <th>Trade-off</th> </tr> </thead> <tbody> <tr> <td><strong>Request Batching</strong></td> <td>+10-50ms</td> <td>5-10x</td> <td>Latency vs throughput</td> </tr> <tr> <td><strong>Model Quantization</strong></td> <td>2-4x faster</td> <td>2-4x</td> <td>Slight accuracy drop</td> </tr> <tr> <td><strong>TensorRT/ONNX</strong></td> <td>2-5x faster</td> <td>2-5x</td> <td>Hardware specific</td> </tr> <tr> <td><strong>Result Caching</strong></td> <td>10-100x faster</td> <td>10-100x</td> <td>Staleness</td> </tr> <tr> <td><strong>Feature Caching</strong></td> <td>5-20ms saved</td> <td>N/A</td> <td>Memory usage</td> </tr> <tr> <td><strong>Mixed Precision (FP16)</strong></td> <td>2-3x faster</td> <td>2-3x</td> <td>GPU only</td> </tr> </tbody> </table> <p><strong>Model Format Comparison:</strong></p> <table> <thead> <tr> <th>Format</th> <th>Speed</th> <th>Portability</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td><strong>PyTorch (.pt)</strong></td> <td>Baseline</td> <td>Python only</td> <td>Development</td> </tr> <tr> <td><strong>TorchScript</strong></td> <td>1.5-2x</td> <td>Python/C++</td> <td>Production (PyTorch)</td> </tr> <tr> <td><strong>ONNX</strong></td> <td>2-3x</td> <td>Any framework</td> <td>Cross-platform</td> </tr> <tr> <td><strong>TensorRT</strong></td> <td>3-5x</td> <td>NVIDIA GPU only</td> <td>High-performance GPU</td> </tr> <tr> <td><strong>Quantized INT8</strong></td> <td>3-4x (CPU)</td> <td>CPU optimized</td> <td>Edge/mobile</td> </tr> </tbody> </table> <p><strong>Common Pitfalls:</strong></p> <p>‚ùå <strong>Cold start:</strong> Model loading takes 10-30s ‚Üí Warm pools, lazy loading ‚ùå <strong>GPU underutilization:</strong> &lt;50% utilization ‚Üí Use batching, shared GPUs ‚ùå <strong>Memory leaks:</strong> OOM after hours ‚Üí Proper cleanup, monitoring ‚ùå <strong>Version conflicts:</strong> Model dependencies clash ‚Üí Containerization ‚ùå <strong>No graceful degradation:</strong> Model unavailable ‚Üí Fallback to simpler model</p> <p><strong>Monitoring Dashboard:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Key metrics to track</span>
<span class=n>serving_metrics</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;latency_p50_ms&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>,</span>
    <span class=s1>&#39;latency_p95_ms&#39;</span><span class=p>:</span> <span class=mi>30</span><span class=p>,</span>
    <span class=s1>&#39;latency_p99_ms&#39;</span><span class=p>:</span> <span class=mi>50</span><span class=p>,</span>
    <span class=s1>&#39;qps&#39;</span><span class=p>:</span> <span class=mi>10000</span><span class=p>,</span>
    <span class=s1>&#39;error_rate&#39;</span><span class=p>:</span> <span class=mf>0.001</span><span class=p>,</span>
    <span class=s1>&#39;gpu_utilization_%&#39;</span><span class=p>:</span> <span class=mi>75</span><span class=p>,</span>
    <span class=s1>&#39;gpu_memory_used_gb&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>,</span>
    <span class=s1>&#39;batch_size_avg&#39;</span><span class=p>:</span> <span class=mi>24</span><span class=p>,</span>
    <span class=s1>&#39;cache_hit_rate&#39;</span><span class=p>:</span> <span class=mf>0.30</span><span class=p>,</span>
    <span class=s1>&#39;model_load_time_s&#39;</span><span class=p>:</span> <span class=mi>15</span>
<span class=p>}</span>

<span class=c1># Alerts</span>
<span class=n>alerts</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;p99_latency &gt; 100ms&#39;</span><span class=p>:</span> <span class=s1>&#39;High latency&#39;</span><span class=p>,</span>
    <span class=s1>&#39;error_rate &gt; 0.01&#39;</span><span class=p>:</span> <span class=s1>&#39;High error rate&#39;</span><span class=p>,</span>
    <span class=s1>&#39;gpu_util &lt; 40%&#39;</span><span class=p>:</span> <span class=s1>&#39;Underutilized GPU&#39;</span><span class=p>,</span>
    <span class=s1>&#39;qps drops &gt; 50%&#39;</span><span class=p>:</span> <span class=s1>&#39;Traffic drop&#39;</span>
<span class=p>}</span>
</code></pre></div> <p><strong>Real-World Examples:</strong></p> <ul> <li><strong>Google:</strong> TensorFlow Serving handles billions of predictions/day</li> <li><strong>Amazon:</strong> SageMaker serves models with auto-scaling, multi-model endpoints</li> <li><strong>Uber:</strong> Michelangelo serves 100M+ predictions/day with &lt;10ms p99</li> <li><strong>Netflix:</strong> Serves 1000+ models for recommendations, &lt;50ms latency</li> </ul> <p><strong>Deployment Patterns:</strong></p> <table> <thead> <tr> <th>Pattern</th> <th>Pros</th> <th>Cons</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td><strong>Single model per server</strong></td> <td>Simple, isolated</td> <td>Expensive</td> <td>High-value models</td> </tr> <tr> <td><strong>Multi-model per server</strong></td> <td>Cost-effective</td> <td>Resource contention</td> <td>Many small models</td> </tr> <tr> <td><strong>Serverless (Lambda)</strong></td> <td>No management</td> <td>Cold start, limited</td> <td>Infrequent inference</td> </tr> <tr> <td><strong>Edge deployment</strong></td> <td>Low latency, offline</td> <td>Limited compute</td> <td>Mobile apps</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding of GPU optimization, batching strategies, latency vs throughput trade-offs.</p> <p><strong>Strong answer signals:</strong> - Discusses dynamic batching with specific wait times - Knows model optimization formats (TensorRT, ONNX, quantization) - Mentions A/B testing for model versions - Talks about GPU utilization and multi-model serving - Discusses graceful degradation and fallback strategies - Knows about cold start problem and solutions</p> </div> </details> <hr> <h3 id=design-a-model-monitoring-system-google-amazon-interview-question>Design a Model Monitoring System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>MLOps</code>, <code>Monitoring</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Scale Requirements:</strong> - <strong>Models Monitored:</strong> 100+ models in production - <strong>Predictions:</strong> 1B+ predictions/day - <strong>Monitoring Frequency:</strong> Real-time (streaming) + batch (daily) - <strong>Alert Latency:</strong> &lt;5 minutes for critical issues - <strong>Data Retention:</strong> 90 days detailed, 1 year aggregated</p> <p><strong>Detailed Architecture:</strong></p> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Production Predictions                 ‚îÇ
‚îÇ  (Model serving logs every prediction)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Streaming Pipeline (Kafka)            ‚îÇ
‚îÇ  - Prediction logs                             ‚îÇ
‚îÇ  - Features used                               ‚îÇ
‚îÇ  - Model version                               ‚îÇ
‚îÇ  - Latency, errors                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Real-Time Monitoring Layer             ‚îÇ
‚îÇ  (Flink/Spark Streaming)                       ‚îÇ
‚îÇ                                                ‚îÇ
‚îÇ  1. Data Quality Checks:                       ‚îÇ
‚îÇ     - Schema validation                        ‚îÇ
‚îÇ     - Missing value detection                  ‚îÇ
‚îÇ     - Range/distribution checks                ‚îÇ
‚îÇ                                                ‚îÇ
‚îÇ  2. Data Drift Detection:                      ‚îÇ
‚îÇ     - PSI (Population Stability Index)         ‚îÇ
‚îÇ     - KL Divergence                            ‚îÇ
‚îÇ     - Kolmogorov-Smirnov test                  ‚îÇ
‚îÇ                                                ‚îÇ
‚îÇ  3. Performance Monitoring:                    ‚îÇ
‚îÇ     - Latency (p50, p95, p99)                  ‚îÇ
‚îÇ     - Throughput (QPS)                         ‚îÇ
‚îÇ     - Error rates                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Ground Truth Collection                ‚îÇ
‚îÇ  (Delayed labels via user feedback)            ‚îÇ
‚îÇ  - User clicks/conversions                     ‚îÇ
‚îÇ  - Manual labels                               ‚îÇ
‚îÇ  - Downstream outcomes                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Model Performance Analysis             ‚îÇ
‚îÇ  (Daily batch jobs)                            ‚îÇ
‚îÇ                                                ‚îÇ
‚îÇ  - Accuracy, Precision, Recall                 ‚îÇ
‚îÇ  - AUC, F1 score                               ‚îÇ
‚îÇ  - Per-segment performance                     ‚îÇ
‚îÇ  - Calibration metrics                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Alerting &amp; Visualization                ‚îÇ
‚îÇ                                                ‚îÇ
‚îÇ  - Prometheus + Grafana dashboards             ‚îÇ
‚îÇ  - PagerDuty alerts                            ‚îÇ
‚îÇ  - Weekly performance reports                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>List</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>

<span class=k>class</span><span class=w> </span><span class=nc>ModelMonitor</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>model_name</span> <span class=o>=</span> <span class=n>model_name</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_load_baseline_stats</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>alert_thresholds</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;psi&#39;</span><span class=p>:</span> <span class=mf>0.2</span><span class=p>,</span>
            <span class=s1>&#39;kl_divergence&#39;</span><span class=p>:</span> <span class=mf>0.1</span><span class=p>,</span>
            <span class=s1>&#39;accuracy_drop&#39;</span><span class=p>:</span> <span class=mf>0.05</span><span class=p>,</span>
            <span class=s1>&#39;p99_latency_ms&#39;</span><span class=p>:</span> <span class=mi>100</span><span class=p>,</span>
            <span class=s1>&#39;error_rate&#39;</span><span class=p>:</span> <span class=mf>0.01</span>
        <span class=p>}</span>

    <span class=c1># 1. DATA QUALITY MONITORING</span>
    <span class=k>def</span><span class=w> </span><span class=nf>check_data_quality</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>batch</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Real-time data quality checks&quot;&quot;&quot;</span>
        <span class=n>issues</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=c1># Schema validation</span>
        <span class=n>expected_cols</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;feature_names&#39;</span><span class=p>])</span>
        <span class=n>actual_cols</span> <span class=o>=</span> <span class=nb>set</span><span class=p>(</span><span class=n>batch</span><span class=o>.</span><span class=n>columns</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>expected_cols</span> <span class=o>!=</span> <span class=n>actual_cols</span><span class=p>:</span>
            <span class=n>issues</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
                <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;SCHEMA_DRIFT&#39;</span><span class=p>,</span>
                <span class=s1>&#39;severity&#39;</span><span class=p>:</span> <span class=s1>&#39;CRITICAL&#39;</span><span class=p>,</span>
                <span class=s1>&#39;message&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s1>&#39;Missing columns: </span><span class=si>{</span><span class=n>expected_cols</span><span class=w> </span><span class=o>-</span><span class=w> </span><span class=n>actual_cols</span><span class=si>}</span><span class=s1>&#39;</span>
            <span class=p>})</span>

        <span class=c1># Missing values</span>
        <span class=n>missing_pct</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>isnull</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
        <span class=n>high_missing</span> <span class=o>=</span> <span class=n>missing_pct</span><span class=p>[</span><span class=n>missing_pct</span> <span class=o>&gt;</span> <span class=mf>0.1</span><span class=p>]</span>
        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>high_missing</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>issues</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
                <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;HIGH_MISSING_VALUES&#39;</span><span class=p>,</span>
                <span class=s1>&#39;severity&#39;</span><span class=p>:</span> <span class=s1>&#39;WARNING&#39;</span><span class=p>,</span>
                <span class=s1>&#39;features&#39;</span><span class=p>:</span> <span class=n>high_missing</span><span class=o>.</span><span class=n>to_dict</span><span class=p>()</span>
            <span class=p>})</span>

        <span class=c1># Range validation</span>
        <span class=k>for</span> <span class=n>col</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>select_dtypes</span><span class=p>(</span><span class=n>include</span><span class=o>=</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>number</span><span class=p>])</span><span class=o>.</span><span class=n>columns</span><span class=p>:</span>
            <span class=n>baseline_min</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;ranges&#39;</span><span class=p>][</span><span class=n>col</span><span class=p>][</span><span class=s1>&#39;min&#39;</span><span class=p>]</span>
            <span class=n>baseline_max</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;ranges&#39;</span><span class=p>][</span><span class=n>col</span><span class=p>][</span><span class=s1>&#39;max&#39;</span><span class=p>]</span>

            <span class=n>current_min</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=n>col</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>()</span>
            <span class=n>current_max</span> <span class=o>=</span> <span class=n>batch</span><span class=p>[</span><span class=n>col</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span>

            <span class=k>if</span> <span class=n>current_min</span> <span class=o>&lt;</span> <span class=n>baseline_min</span> <span class=o>*</span> <span class=mf>0.5</span> <span class=ow>or</span> <span class=n>current_max</span> <span class=o>&gt;</span> <span class=n>baseline_max</span> <span class=o>*</span> <span class=mi>2</span><span class=p>:</span>
                <span class=n>issues</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
                    <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;OUT_OF_RANGE&#39;</span><span class=p>,</span>
                    <span class=s1>&#39;severity&#39;</span><span class=p>:</span> <span class=s1>&#39;WARNING&#39;</span><span class=p>,</span>
                    <span class=s1>&#39;feature&#39;</span><span class=p>:</span> <span class=n>col</span><span class=p>,</span>
                    <span class=s1>&#39;baseline&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s1>&#39;[</span><span class=si>{</span><span class=n>baseline_min</span><span class=si>}</span><span class=s1>, </span><span class=si>{</span><span class=n>baseline_max</span><span class=si>}</span><span class=s1>]&#39;</span><span class=p>,</span>
                    <span class=s1>&#39;current&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s1>&#39;[</span><span class=si>{</span><span class=n>current_min</span><span class=si>}</span><span class=s1>, </span><span class=si>{</span><span class=n>current_max</span><span class=si>}</span><span class=s1>]&#39;</span>
                <span class=p>})</span>

        <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;issues&#39;</span><span class=p>:</span> <span class=n>issues</span><span class=p>,</span> <span class=s1>&#39;passed&#39;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>issues</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>}</span>

    <span class=c1># 2. DATA DRIFT DETECTION</span>
    <span class=k>def</span><span class=w> </span><span class=nf>detect_data_drift</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>current_data</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Detect feature distribution drift&quot;&quot;&quot;</span>
        <span class=n>drift_results</span> <span class=o>=</span> <span class=p>{}</span>

        <span class=k>for</span> <span class=n>feature</span> <span class=ow>in</span> <span class=n>current_data</span><span class=o>.</span><span class=n>columns</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>feature</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;distributions&#39;</span><span class=p>]:</span>
                <span class=c1># PSI (Population Stability Index)</span>
                <span class=n>psi</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_calculate_psi</span><span class=p>(</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;distributions&#39;</span><span class=p>][</span><span class=n>feature</span><span class=p>],</span>
                    <span class=n>current_data</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span>
                <span class=p>)</span>

                <span class=c1># KL Divergence</span>
                <span class=n>kl_div</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_calculate_kl_divergence</span><span class=p>(</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;distributions&#39;</span><span class=p>][</span><span class=n>feature</span><span class=p>],</span>
                    <span class=n>current_data</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span>
                <span class=p>)</span>

                <span class=c1># Kolmogorov-Smirnov test</span>
                <span class=n>ks_stat</span><span class=p>,</span> <span class=n>ks_pvalue</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>ks_2samp</span><span class=p>(</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;distributions&#39;</span><span class=p>][</span><span class=n>feature</span><span class=p>],</span>
                    <span class=n>current_data</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span>
                <span class=p>)</span>

                <span class=n>drift_results</span><span class=p>[</span><span class=n>feature</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
                    <span class=s1>&#39;psi&#39;</span><span class=p>:</span> <span class=n>psi</span><span class=p>,</span>
                    <span class=s1>&#39;kl_divergence&#39;</span><span class=p>:</span> <span class=n>kl_div</span><span class=p>,</span>
                    <span class=s1>&#39;ks_statistic&#39;</span><span class=p>:</span> <span class=n>ks_stat</span><span class=p>,</span>
                    <span class=s1>&#39;ks_pvalue&#39;</span><span class=p>:</span> <span class=n>ks_pvalue</span><span class=p>,</span>
                    <span class=s1>&#39;drifted&#39;</span><span class=p>:</span> <span class=n>psi</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>alert_thresholds</span><span class=p>[</span><span class=s1>&#39;psi&#39;</span><span class=p>]</span>
                <span class=p>}</span>

        <span class=k>return</span> <span class=n>drift_results</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_calculate_psi</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>baseline</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>current</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Population Stability Index</span>
<span class=sd>        PSI &lt; 0.1: No significant drift</span>
<span class=sd>        0.1 &lt; PSI &lt; 0.2: Moderate drift</span>
<span class=sd>        PSI &gt; 0.2: Significant drift</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=c1># Create bins from baseline</span>
        <span class=n>breakpoints</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>baseline</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=n>bins</span> <span class=o>+</span> <span class=mi>1</span><span class=p>))</span>
        <span class=n>breakpoints</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>+=</span> <span class=mf>0.001</span>  <span class=c1># Include max value</span>

        <span class=c1># Calculate distributions</span>
        <span class=n>baseline_counts</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>baseline</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=n>breakpoints</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>current_counts</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>current</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=n>breakpoints</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>

        <span class=c1># Convert to percentages</span>
        <span class=n>baseline_pct</span> <span class=o>=</span> <span class=n>baseline_counts</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>baseline</span><span class=p>)</span>
        <span class=n>current_pct</span> <span class=o>=</span> <span class=n>current_counts</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>current</span><span class=p>)</span>

        <span class=c1># Avoid division by zero</span>
        <span class=n>baseline_pct</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>baseline_pct</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=mf>0.0001</span><span class=p>,</span> <span class=n>baseline_pct</span><span class=p>)</span>
        <span class=n>current_pct</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>current_pct</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=mf>0.0001</span><span class=p>,</span> <span class=n>current_pct</span><span class=p>)</span>

        <span class=c1># PSI formula</span>
        <span class=n>psi</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>((</span><span class=n>current_pct</span> <span class=o>-</span> <span class=n>baseline_pct</span><span class=p>)</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>current_pct</span> <span class=o>/</span> <span class=n>baseline_pct</span><span class=p>))</span>
        <span class=k>return</span> <span class=n>psi</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_calculate_kl_divergence</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>baseline</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>current</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;KL Divergence: D_KL(P||Q)&quot;&quot;&quot;</span>
        <span class=c1># Create histograms</span>
        <span class=n>hist_range</span> <span class=o>=</span> <span class=p>(</span><span class=nb>min</span><span class=p>(</span><span class=n>baseline</span><span class=o>.</span><span class=n>min</span><span class=p>(),</span> <span class=n>current</span><span class=o>.</span><span class=n>min</span><span class=p>()),</span>
                     <span class=nb>max</span><span class=p>(</span><span class=n>baseline</span><span class=o>.</span><span class=n>max</span><span class=p>(),</span> <span class=n>current</span><span class=o>.</span><span class=n>max</span><span class=p>()))</span>

        <span class=n>p</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>baseline</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=n>bins</span><span class=p>,</span> <span class=nb>range</span><span class=o>=</span><span class=n>hist_range</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
        <span class=n>q</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>current</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=n>bins</span><span class=p>,</span> <span class=nb>range</span><span class=o>=</span><span class=n>hist_range</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

        <span class=c1># Normalize and avoid zeros</span>
        <span class=n>p</span> <span class=o>=</span> <span class=n>p</span> <span class=o>/</span> <span class=n>p</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
        <span class=n>q</span> <span class=o>=</span> <span class=n>q</span> <span class=o>/</span> <span class=n>q</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
        <span class=n>p</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>p</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=mf>1e-10</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span>
        <span class=n>q</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>q</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=mf>1e-10</span><span class=p>,</span> <span class=n>q</span><span class=p>)</span>

        <span class=c1># KL divergence</span>
        <span class=n>kl</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>p</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>p</span> <span class=o>/</span> <span class=n>q</span><span class=p>))</span>
        <span class=k>return</span> <span class=n>kl</span>

    <span class=c1># 3. MODEL PERFORMANCE MONITORING</span>
    <span class=k>def</span><span class=w> </span><span class=nf>monitor_model_performance</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>predictions</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span>
        <span class=n>actuals</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span>
        <span class=n>prediction_times</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>float</span><span class=p>]</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Monitor model accuracy and performance&quot;&quot;&quot;</span>
        <span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>accuracy_score</span><span class=p>,</span> <span class=n>roc_auc_score</span><span class=p>,</span> <span class=n>precision_recall_fscore_support</span>

        <span class=n>metrics</span> <span class=o>=</span> <span class=p>{}</span>

        <span class=c1># Classification metrics (if labels available)</span>
        <span class=k>if</span> <span class=n>actuals</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>actuals</span><span class=p>,</span> <span class=n>predictions</span> <span class=o>&gt;</span> <span class=mf>0.5</span><span class=p>)</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;auc&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>roc_auc_score</span><span class=p>(</span><span class=n>actuals</span><span class=p>,</span> <span class=n>predictions</span><span class=p>)</span>

            <span class=n>precision</span><span class=p>,</span> <span class=n>recall</span><span class=p>,</span> <span class=n>f1</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>precision_recall_fscore_support</span><span class=p>(</span>
                <span class=n>actuals</span><span class=p>,</span> <span class=n>predictions</span> <span class=o>&gt;</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;binary&#39;</span>
            <span class=p>)</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;precision&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>precision</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;recall&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>recall</span>
            <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;f1&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>f1</span>

            <span class=c1># Check for degradation</span>
            <span class=n>baseline_accuracy</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>]</span>
            <span class=k>if</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>baseline_accuracy</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>alert_thresholds</span><span class=p>[</span><span class=s1>&#39;accuracy_drop&#39;</span><span class=p>]:</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_trigger_alert</span><span class=p>({</span>
                    <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;ACCURACY_DROP&#39;</span><span class=p>,</span>
                    <span class=s1>&#39;severity&#39;</span><span class=p>:</span> <span class=s1>&#39;CRITICAL&#39;</span><span class=p>,</span>
                    <span class=s1>&#39;baseline&#39;</span><span class=p>:</span> <span class=n>baseline_accuracy</span><span class=p>,</span>
                    <span class=s1>&#39;current&#39;</span><span class=p>:</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>],</span>
                    <span class=s1>&#39;drop&#39;</span><span class=p>:</span> <span class=n>baseline_accuracy</span> <span class=o>-</span> <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>]</span>
                <span class=p>})</span>

        <span class=c1># Latency monitoring</span>
        <span class=n>latency_p50</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>prediction_times</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>
        <span class=n>latency_p95</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>prediction_times</span><span class=p>,</span> <span class=mi>95</span><span class=p>)</span>
        <span class=n>latency_p99</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>percentile</span><span class=p>(</span><span class=n>prediction_times</span><span class=p>,</span> <span class=mi>99</span><span class=p>)</span>

        <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency_ms&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;p50&#39;</span><span class=p>:</span> <span class=n>latency_p50</span><span class=p>,</span>
            <span class=s1>&#39;p95&#39;</span><span class=p>:</span> <span class=n>latency_p95</span><span class=p>,</span>
            <span class=s1>&#39;p99&#39;</span><span class=p>:</span> <span class=n>latency_p99</span>
        <span class=p>}</span>

        <span class=k>if</span> <span class=n>latency_p99</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>alert_thresholds</span><span class=p>[</span><span class=s1>&#39;p99_latency_ms&#39;</span><span class=p>]:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_trigger_alert</span><span class=p>({</span>
                <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;HIGH_LATENCY&#39;</span><span class=p>,</span>
                <span class=s1>&#39;severity&#39;</span><span class=p>:</span> <span class=s1>&#39;WARNING&#39;</span><span class=p>,</span>
                <span class=s1>&#39;p99_latency&#39;</span><span class=p>:</span> <span class=n>latency_p99</span><span class=p>,</span>
                <span class=s1>&#39;threshold&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>alert_thresholds</span><span class=p>[</span><span class=s1>&#39;p99_latency_ms&#39;</span><span class=p>]</span>
            <span class=p>})</span>

        <span class=k>return</span> <span class=n>metrics</span>

    <span class=c1># 4. PREDICTION DRIFT (MODEL OUTPUT DISTRIBUTION)</span>
    <span class=k>def</span><span class=w> </span><span class=nf>monitor_prediction_drift</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>predictions</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Check if prediction distribution has changed&quot;&quot;&quot;</span>
        <span class=c1># For classification: check score distribution</span>
        <span class=n>score_buckets</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.4</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.6</span><span class=p>,</span> <span class=mf>0.7</span><span class=p>,</span> <span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.9</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>]</span>
        <span class=n>current_dist</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>histogram</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=n>score_buckets</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
        <span class=n>current_dist</span> <span class=o>=</span> <span class=n>current_dist</span> <span class=o>/</span> <span class=n>current_dist</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>

        <span class=n>baseline_dist</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;prediction_distribution&#39;</span><span class=p>]</span>

        <span class=c1># Chi-square test</span>
        <span class=n>chi_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>chisquare</span><span class=p>(</span><span class=n>current_dist</span><span class=p>,</span> <span class=n>baseline_dist</span><span class=p>)</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;chi_square_statistic&#39;</span><span class=p>:</span> <span class=n>chi_stat</span><span class=p>,</span>
            <span class=s1>&#39;p_value&#39;</span><span class=p>:</span> <span class=n>p_value</span><span class=p>,</span>
            <span class=s1>&#39;drifted&#39;</span><span class=p>:</span> <span class=n>p_value</span> <span class=o>&lt;</span> <span class=mf>0.05</span><span class=p>,</span>  <span class=c1># Significant at 5% level</span>
            <span class=s1>&#39;current_distribution&#39;</span><span class=p>:</span> <span class=n>current_dist</span><span class=o>.</span><span class=n>tolist</span><span class=p>(),</span>
            <span class=s1>&#39;baseline_distribution&#39;</span><span class=p>:</span> <span class=n>baseline_dist</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
        <span class=p>}</span>

    <span class=c1># 5. BUSINESS METRICS MONITORING</span>
    <span class=k>def</span><span class=w> </span><span class=nf>monitor_business_metrics</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>predictions</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>,</span> <span class=n>outcomes</span><span class=p>:</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Monitor business impact&quot;&quot;&quot;</span>
        <span class=c1># Example: For a recommendation system</span>
        <span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;ctr&#39;</span><span class=p>:</span> <span class=n>outcomes</span><span class=p>[</span><span class=s1>&#39;clicked&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span>
            <span class=s1>&#39;conversion_rate&#39;</span><span class=p>:</span> <span class=n>outcomes</span><span class=p>[</span><span class=s1>&#39;converted&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span>
            <span class=s1>&#39;revenue_per_impression&#39;</span><span class=p>:</span> <span class=n>outcomes</span><span class=p>[</span><span class=s1>&#39;revenue&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span>
            <span class=s1>&#39;engagement_time&#39;</span><span class=p>:</span> <span class=n>outcomes</span><span class=p>[</span><span class=s1>&#39;time_spent&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
        <span class=p>}</span>

        <span class=c1># Compare with baseline</span>
        <span class=k>for</span> <span class=n>metric</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>metrics</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=n>baseline</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>baseline_stats</span><span class=p>[</span><span class=s1>&#39;business_metrics&#39;</span><span class=p>][</span><span class=n>metric</span><span class=p>]</span>
            <span class=n>change_pct</span> <span class=o>=</span> <span class=p>(</span><span class=n>value</span> <span class=o>-</span> <span class=n>baseline</span><span class=p>)</span> <span class=o>/</span> <span class=n>baseline</span> <span class=o>*</span> <span class=mi>100</span>

            <span class=k>if</span> <span class=nb>abs</span><span class=p>(</span><span class=n>change_pct</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>10</span><span class=p>:</span>  <span class=c1># 10% change threshold</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_trigger_alert</span><span class=p>({</span>
                    <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;BUSINESS_METRIC_CHANGE&#39;</span><span class=p>,</span>
                    <span class=s1>&#39;severity&#39;</span><span class=p>:</span> <span class=s1>&#39;WARNING&#39;</span><span class=p>,</span>
                    <span class=s1>&#39;metric&#39;</span><span class=p>:</span> <span class=n>metric</span><span class=p>,</span>
                    <span class=s1>&#39;baseline&#39;</span><span class=p>:</span> <span class=n>baseline</span><span class=p>,</span>
                    <span class=s1>&#39;current&#39;</span><span class=p>:</span> <span class=n>value</span><span class=p>,</span>
                    <span class=s1>&#39;change_pct&#39;</span><span class=p>:</span> <span class=n>change_pct</span>
                <span class=p>})</span>

        <span class=k>return</span> <span class=n>metrics</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_trigger_alert</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>alert</span><span class=p>:</span> <span class=n>Dict</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Send alert to monitoring system&quot;&quot;&quot;</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;üö® ALERT: </span><span class=si>{</span><span class=n>alert</span><span class=p>[</span><span class=s1>&#39;type&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> - </span><span class=si>{</span><span class=n>alert</span><span class=p>[</span><span class=s1>&#39;severity&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=c1># Send to PagerDuty, Slack, etc.</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_send_to_pagerduty</span><span class=p>(</span><span class=n>alert</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_send_to_slack</span><span class=p>(</span><span class=n>alert</span><span class=p>)</span>
</code></pre></div> <p><strong>Monitoring Dashboard Metrics:</strong></p> <table> <thead> <tr> <th>Category</th> <th>Metrics</th> <th>Frequency</th> <th>Alert Threshold</th> </tr> </thead> <tbody> <tr> <td><strong>Data Quality</strong></td> <td>Missing %, Schema drift</td> <td>Real-time</td> <td>Missing &gt; 10%</td> </tr> <tr> <td><strong>Data Drift</strong></td> <td>PSI, KL divergence</td> <td>Hourly</td> <td>PSI &gt; 0.2</td> </tr> <tr> <td><strong>Model Performance</strong></td> <td>Accuracy, AUC, F1</td> <td>Daily</td> <td>Accuracy drop &gt; 5%</td> </tr> <tr> <td><strong>Latency</strong></td> <td>p50, p95, p99</td> <td>Real-time</td> <td>p99 &gt; 100ms</td> </tr> <tr> <td><strong>Throughput</strong></td> <td>QPS, Requests/day</td> <td>Real-time</td> <td>Drop &gt; 20%</td> </tr> <tr> <td><strong>Business Metrics</strong></td> <td>CTR, Conversion, Revenue</td> <td>Daily</td> <td>Change &gt; 10%</td> </tr> <tr> <td><strong>Prediction Drift</strong></td> <td>Score distribution</td> <td>Daily</td> <td>Chi-square p &lt; 0.05</td> </tr> <tr> <td><strong>Error Rate</strong></td> <td>4xx, 5xx errors</td> <td>Real-time</td> <td>Error rate &gt; 1%</td> </tr> </tbody> </table> <p><strong>Drift Detection Thresholds:</strong></p> <div class=highlight><pre><span></span><code><span class=n>drift_severity</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;psi&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;low&#39;</span><span class=p>:</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>),</span>      <span class=c1># No action needed</span>
        <span class=s1>&#39;medium&#39;</span><span class=p>:</span> <span class=p>(</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>),</span>  <span class=c1># Investigate</span>
        <span class=s1>&#39;high&#39;</span><span class=p>:</span> <span class=p>(</span><span class=mf>0.2</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;inf&#39;</span><span class=p>))</span>  <span class=c1># Retrain model</span>
    <span class=p>},</span>
    <span class=s1>&#39;kl_divergence&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;low&#39;</span><span class=p>:</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.05</span><span class=p>),</span>
        <span class=s1>&#39;medium&#39;</span><span class=p>:</span> <span class=p>(</span><span class=mf>0.05</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>),</span>
        <span class=s1>&#39;high&#39;</span><span class=p>:</span> <span class=p>(</span><span class=mf>0.1</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;inf&#39;</span><span class=p>))</span>
    <span class=p>}</span>
<span class=p>}</span>
</code></pre></div> <p><strong>Common Pitfalls:</strong></p> <p>‚ùå <strong>No ground truth collection:</strong> Can't measure accuracy ‚Üí Implement feedback loops ‚ùå <strong>Alert fatigue:</strong> Too many false alerts ‚Üí Tune thresholds carefully ‚ùå <strong>Only monitoring overall metrics:</strong> Masked subgroup degradation ‚Üí Monitor per-segment ‚ùå <strong>Ignoring business metrics:</strong> Technical metrics don't capture value ‚Üí Track CTR, revenue ‚ùå <strong>No automated response:</strong> Manual investigation is slow ‚Üí Auto-trigger retraining</p> <p><strong>Real-World Examples:</strong></p> <ul> <li><strong>Uber:</strong> Monitors 1000+ models, detects drift within 1 hour, auto-triggers retraining</li> <li><strong>Netflix:</strong> Per-title model monitoring, catches regional content drift</li> <li><strong>Airbnb:</strong> Monitors search ranking models, detects seasonal drift automatically</li> <li><strong>Stripe:</strong> Real-time fraud model monitoring, &lt;5 min alert latency</li> </ul> <p><strong>Automated Remediation:</strong></p> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>AutoRemediation</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=nf>handle_drift</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>drift_severity</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Automated response to drift&quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=n>drift_severity</span> <span class=o>==</span> <span class=s1>&#39;high&#39;</span><span class=p>:</span>
            <span class=c1># Trigger model retraining</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>trigger_retraining_pipeline</span><span class=p>()</span>

            <span class=c1># Meanwhile, rollback to previous version</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>rollback_model_version</span><span class=p>()</span>

        <span class=k>elif</span> <span class=n>drift_severity</span> <span class=o>==</span> <span class=s1>&#39;medium&#39;</span><span class=p>:</span>
            <span class=c1># Increase monitoring frequency</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>increase_monitoring_frequency</span><span class=p>()</span>

            <span class=c1># Alert data science team</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>alert_team</span><span class=p>()</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding of drift detection, monitoring at scale, automated alerting.</p> <p><strong>Strong answer signals:</strong> - Discusses multiple drift detection methods (PSI, KL, KS test) - Mentions both data drift and concept drift - Talks about delayed ground truth labels - Knows about per-segment monitoring (not just overall) - Discusses business metrics in addition to technical metrics - Mentions automated retraining triggers - Talks about alert fatigue and threshold tuning</p> </div> </details> <hr> <h3 id=design-a-distributed-training-system-google-amazon-interview-question>Design a Distributed Training System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Deep Learning</code>, <code>Scale</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Scale Requirements:</strong> - <strong>Model Size:</strong> 1B - 175B parameters (GPT-3 scale) - <strong>Dataset:</strong> 1TB - 1PB training data - <strong>GPUs:</strong> 100-10,000 GPUs - <strong>Training Time:</strong> Days to weeks - <strong>Throughput:</strong> 1000+ samples/second - <strong>Communication:</strong> 100 GB/s+ bandwidth</p> <p><strong>Detailed Architecture:</strong></p> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             Orchestration Layer                       ‚îÇ
‚îÇ  Kubernetes + Kubeflow / Ray / Slurm                  ‚îÇ
‚îÇ  - Resource allocation                                ‚îÇ
‚îÇ  - Fault tolerance &amp; checkpointing                    ‚îÇ
‚îÇ  - Job scheduling                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Data Parallelism (Most Common)               ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  GPU 1: Model copy 1 ‚Üí Batch 1 ‚Üí Gradients           ‚îÇ
‚îÇ  GPU 2: Model copy 2 ‚Üí Batch 2 ‚Üí Gradients           ‚îÇ
‚îÇ  GPU 3: Model copy 3 ‚Üí Batch 3 ‚Üí Gradients           ‚îÇ
‚îÇ  GPU 4: Model copy 4 ‚Üí Batch 4 ‚Üí Gradients           ‚îÇ
‚îÇ                         ‚Üì                             ‚îÇ
‚îÇ              All-Reduce (Average gradients)           ‚îÇ
‚îÇ                         ‚Üì                             ‚îÇ
‚îÇ              Update all model copies                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

For VERY large models:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Model Parallelism (Layers split)             ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  GPU 1: Layers 1-25    ‚Üí Forward ‚Üí Activation        ‚îÇ
‚îÇ  GPU 2: Layers 26-50   ‚Üí Forward ‚Üí Activation        ‚îÇ
‚îÇ  GPU 3: Layers 51-75   ‚Üí Forward ‚Üí Activation        ‚îÇ
‚îÇ  GPU 4: Layers 76-100  ‚Üí Forward ‚Üí Output            ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  Backward pass flows in reverse                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       Pipeline Parallelism (Micro-batching)           ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  Time  ‚îÇ  GPU 1  ‚îÇ  GPU 2  ‚îÇ  GPU 3  ‚îÇ  GPU 4       ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ    ‚îÇ
‚îÇ   t1   ‚îÇ Batch 1 ‚îÇ    -    ‚îÇ    -    ‚îÇ    -         ‚îÇ
‚îÇ   t2   ‚îÇ Batch 2 ‚îÇ Batch 1 ‚îÇ    -    ‚îÇ    -         ‚îÇ
‚îÇ   t3   ‚îÇ Batch 3 ‚îÇ Batch 2 ‚îÇ Batch 1 ‚îÇ    -         ‚îÇ
‚îÇ   t4   ‚îÇ Batch 4 ‚îÇ Batch 3 ‚îÇ Batch 2 ‚îÇ Batch 1      ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ  Minimize bubble (idle time) with micro-batches       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch.distributed</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>dist</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.nn.parallel</span><span class=w> </span><span class=kn>import</span> <span class=n>DistributedDataParallel</span> <span class=k>as</span> <span class=n>DDP</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.data.distributed</span><span class=w> </span><span class=kn>import</span> <span class=n>DistributedSampler</span>

<span class=c1># 1. DATA PARALLEL (Most Common) - PyTorch</span>
<span class=k>def</span><span class=w> </span><span class=nf>setup_distributed</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Initialize distributed training&quot;&quot;&quot;</span>
    <span class=c1># Initialize process group</span>
    <span class=n>dist</span><span class=o>.</span><span class=n>init_process_group</span><span class=p>(</span>
        <span class=n>backend</span><span class=o>=</span><span class=s1>&#39;nccl&#39;</span><span class=p>,</span>  <span class=c1># NVIDIA Collective Communications Library</span>
        <span class=n>init_method</span><span class=o>=</span><span class=s1>&#39;env://&#39;</span><span class=p>,</span>  <span class=c1># Use environment variables</span>
        <span class=n>world_size</span><span class=o>=</span><span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;WORLD_SIZE&#39;</span><span class=p>]),</span>  <span class=c1># Total GPUs</span>
        <span class=n>rank</span><span class=o>=</span><span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;RANK&#39;</span><span class=p>])</span>  <span class=c1># This GPU&#39;s rank</span>
    <span class=p>)</span>

<span class=k>def</span><span class=w> </span><span class=nf>train_data_parallel</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>train_dataset</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Data parallel training&quot;&quot;&quot;</span>
    <span class=c1># Setup</span>
    <span class=n>setup_distributed</span><span class=p>()</span>
    <span class=n>local_rank</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;LOCAL_RANK&#39;</span><span class=p>])</span>
    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;cuda:</span><span class=si>{</span><span class=n>local_rank</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

    <span class=c1># Wrap model with DDP</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>DDP</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>device_ids</span><span class=o>=</span><span class=p>[</span><span class=n>local_rank</span><span class=p>])</span>

    <span class=c1># Distributed sampler (each GPU gets different data)</span>
    <span class=n>sampler</span> <span class=o>=</span> <span class=n>DistributedSampler</span><span class=p>(</span>
        <span class=n>train_dataset</span><span class=p>,</span>
        <span class=n>num_replicas</span><span class=o>=</span><span class=n>dist</span><span class=o>.</span><span class=n>get_world_size</span><span class=p>(),</span>
        <span class=n>rank</span><span class=o>=</span><span class=n>dist</span><span class=o>.</span><span class=n>get_rank</span><span class=p>(),</span>
        <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span>
    <span class=p>)</span>

    <span class=n>dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span>
        <span class=n>train_dataset</span><span class=p>,</span>
        <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span>
        <span class=n>sampler</span><span class=o>=</span><span class=n>sampler</span><span class=p>,</span>
        <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
        <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span>
    <span class=p>)</span>

    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>1e-4</span><span class=p>)</span>

    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
        <span class=c1># Set epoch for shuffling</span>
        <span class=n>sampler</span><span class=o>.</span><span class=n>set_epoch</span><span class=p>(</span><span class=n>epoch</span><span class=p>)</span>

        <span class=k>for</span> <span class=n>batch_idx</span><span class=p>,</span> <span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
            <span class=n>data</span><span class=p>,</span> <span class=n>target</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>target</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>

            <span class=c1># Forward pass</span>
            <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>

            <span class=c1># Backward pass</span>
            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
            <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>  <span class=c1># Gradients are automatically all-reduced by DDP</span>

            <span class=c1># Update weights</span>
            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

            <span class=c1># Logging (only rank 0)</span>
            <span class=k>if</span> <span class=n>dist</span><span class=o>.</span><span class=n>get_rank</span><span class=p>()</span> <span class=o>==</span> <span class=mi>0</span> <span class=ow>and</span> <span class=n>batch_idx</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s1>, Loss: </span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

        <span class=c1># Checkpoint (only rank 0)</span>
        <span class=k>if</span> <span class=n>dist</span><span class=o>.</span><span class=n>get_rank</span><span class=p>()</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
                <span class=s1>&#39;epoch&#39;</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
                <span class=s1>&#39;model_state_dict&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>module</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
                <span class=s1>&#39;optimizer_state_dict&#39;</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
            <span class=p>},</span> <span class=sa>f</span><span class=s1>&#39;checkpoint_epoch_</span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s1>.pt&#39;</span><span class=p>)</span>

<span class=c1># 2. MODEL PARALLEL - For Large Models</span>
<span class=k>class</span><span class=w> </span><span class=nc>ModelParallelTransformer</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Split large model across GPUs&quot;&quot;&quot;</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>96</span><span class=p>,</span> <span class=n>hidden_size</span><span class=o>=</span><span class=mi>12288</span><span class=p>):</span>
        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>

        <span class=c1># Split layers across 4 GPUs</span>
        <span class=n>layers_per_gpu</span> <span class=o>=</span> <span class=n>num_layers</span> <span class=o>//</span> <span class=mi>4</span>

        <span class=c1># GPU 0: First 25% of layers</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layers_0</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=p>[</span>
            <span class=n>TransformerBlock</span><span class=p>(</span><span class=n>hidden_size</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>layers_per_gpu</span><span class=p>)</span>
        <span class=p>])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:0&#39;</span><span class=p>)</span>

        <span class=c1># GPU 1: Next 25%</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layers_1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=p>[</span>
            <span class=n>TransformerBlock</span><span class=p>(</span><span class=n>hidden_size</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>layers_per_gpu</span><span class=p>)</span>
        <span class=p>])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:1&#39;</span><span class=p>)</span>

        <span class=c1># GPU 2: Next 25%</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layers_2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=p>[</span>
            <span class=n>TransformerBlock</span><span class=p>(</span><span class=n>hidden_size</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>layers_per_gpu</span><span class=p>)</span>
        <span class=p>])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:2&#39;</span><span class=p>)</span>

        <span class=c1># GPU 3: Last 25%</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>layers_3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=p>[</span>
            <span class=n>TransformerBlock</span><span class=p>(</span><span class=n>hidden_size</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>layers_per_gpu</span><span class=p>)</span>
        <span class=p>])</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:3&#39;</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>output</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>hidden_size</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:3&#39;</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Move through GPUs sequentially</span>
        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:0&#39;</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layers_0</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:1&#39;</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layers_1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:2&#39;</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layers_2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda:3&#39;</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>layers_3</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>output</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>x</span>

<span class=c1># 3. PIPELINE PARALLEL - Deepspeed, Megatron-LM</span>
<span class=kn>from</span><span class=w> </span><span class=nn>deepspeed.pipe</span><span class=w> </span><span class=kn>import</span> <span class=n>PipelineModule</span><span class=p>,</span> <span class=n>LayerSpec</span>

<span class=k>def</span><span class=w> </span><span class=nf>pipeline_parallel</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Pipeline parallelism with DeepSpeed&quot;&quot;&quot;</span>
    <span class=c1># Define model as sequence of layers</span>
    <span class=n>layers</span> <span class=o>=</span> <span class=p>[</span>
        <span class=n>LayerSpec</span><span class=p>(</span><span class=n>TransformerBlock</span><span class=p>,</span> <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>hidden_size</span><span class=p>,))</span>
        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>96</span><span class=p>)</span>
    <span class=p>]</span>

    <span class=c1># DeepSpeed will automatically partition across GPUs</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>PipelineModule</span><span class=p>(</span>
        <span class=n>layers</span><span class=o>=</span><span class=n>layers</span><span class=p>,</span>
        <span class=n>num_stages</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>  <span class=c1># 4 GPUs</span>
        <span class=n>partition_method</span><span class=o>=</span><span class=s1>&#39;uniform&#39;</span>  <span class=c1># or &#39;balanced&#39;</span>
    <span class=p>)</span>

    <span class=c1># Training with micro-batches</span>
    <span class=n>engine</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>deepspeed</span><span class=o>.</span><span class=n>initialize</span><span class=p>(</span>
        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
        <span class=n>config</span><span class=o>=</span><span class=p>{</span>
            <span class=s1>&#39;train_micro_batch_size_per_gpu&#39;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>
            <span class=s1>&#39;gradient_accumulation_steps&#39;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>
            <span class=s1>&#39;pipeline&#39;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s1>&#39;pipe_partitioned&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
                <span class=s1>&#39;grad_partitioned&#39;</span><span class=p>:</span> <span class=kc>True</span>
            <span class=p>}</span>
        <span class=p>}</span>
    <span class=p>)</span>

    <span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>dataloader</span><span class=p>:</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>engine</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
        <span class=n>engine</span><span class=o>.</span><span class=n>backward</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span>
        <span class=n>engine</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>

<span class=c1># 4. ZERO OPTIMIZER (Memory Optimization)</span>
<span class=kn>from</span><span class=w> </span><span class=nn>deepspeed</span><span class=w> </span><span class=kn>import</span> <span class=n>DeepSpeedConfig</span>

<span class=k>def</span><span class=w> </span><span class=nf>train_with_zero</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;ZeRO: Memory-optimized distributed training&quot;&quot;&quot;</span>
    <span class=c1># ZeRO Stage 1: Partition optimizer states</span>
    <span class=c1># ZeRO Stage 2: + Partition gradients</span>
    <span class=c1># ZeRO Stage 3: + Partition model parameters</span>

    <span class=n>config</span> <span class=o>=</span> <span class=p>{</span>
        <span class=s2>&quot;train_batch_size&quot;</span><span class=p>:</span> <span class=mi>128</span><span class=p>,</span>
        <span class=s2>&quot;gradient_accumulation_steps&quot;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>
        <span class=s2>&quot;zero_optimization&quot;</span><span class=p>:</span> <span class=p>{</span>
            <span class=s2>&quot;stage&quot;</span><span class=p>:</span> <span class=mi>3</span><span class=p>,</span>  <span class=c1># Full ZeRO</span>
            <span class=s2>&quot;offload_optimizer&quot;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s2>&quot;device&quot;</span><span class=p>:</span> <span class=s2>&quot;cpu&quot;</span><span class=p>,</span>  <span class=c1># Offload to CPU RAM</span>
                <span class=s2>&quot;pin_memory&quot;</span><span class=p>:</span> <span class=kc>True</span>
            <span class=p>},</span>
            <span class=s2>&quot;offload_param&quot;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s2>&quot;device&quot;</span><span class=p>:</span> <span class=s2>&quot;cpu&quot;</span>
            <span class=p>}</span>
        <span class=p>},</span>
        <span class=s2>&quot;fp16&quot;</span><span class=p>:</span> <span class=p>{</span>
            <span class=s2>&quot;enabled&quot;</span><span class=p>:</span> <span class=kc>True</span>  <span class=c1># Mixed precision</span>
        <span class=p>}</span>
    <span class=p>}</span>

    <span class=n>model_engine</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>deepspeed</span><span class=o>.</span><span class=n>initialize</span><span class=p>(</span>
        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
        <span class=n>model_parameters</span><span class=o>=</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
        <span class=n>config</span><span class=o>=</span><span class=n>config</span>
    <span class=p>)</span>

<span class=c1># 5. GRADIENT ACCUMULATION (Simulate larger batch)</span>
<span class=k>def</span><span class=w> </span><span class=nf>train_with_gradient_accumulation</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>dataloader</span><span class=p>,</span> <span class=n>accumulation_steps</span><span class=o>=</span><span class=mi>4</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Accumulate gradients before update&quot;&quot;&quot;</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>

        <span class=c1># Scale loss by accumulation steps</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>loss</span> <span class=o>/</span> <span class=n>accumulation_steps</span>
        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>

        <span class=c1># Update every N steps</span>
        <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=n>accumulation_steps</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
            <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
            <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</code></pre></div> <p><strong>Parallelism Strategy Decision Tree:</strong></p> <table> <thead> <tr> <th>Model Size</th> <th>Data Size</th> <th>Strategy</th> <th>Example</th> </tr> </thead> <tbody> <tr> <td>&lt;1B params</td> <td>Large</td> <td><strong>Data Parallel</strong></td> <td>ResNet, BERT-base</td> </tr> <tr> <td>1-10B params</td> <td>Large</td> <td><strong>Data Parallel + ZeRO</strong></td> <td>GPT-2, BERT-large</td> </tr> <tr> <td>10-100B params</td> <td>Large</td> <td><strong>Model + Data Parallel</strong></td> <td>GPT-3, BLOOM</td> </tr> <tr> <td>&gt;100B params</td> <td>Large</td> <td><strong>Pipeline + Model + Data</strong></td> <td>GPT-4, PaLM</td> </tr> </tbody> </table> <p><strong>Communication Patterns:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Communication</th> <th>Use Case</th> <th>Efficiency</th> </tr> </thead> <tbody> <tr> <td><strong>All-Reduce</strong></td> <td>All-to-all gradient sync</td> <td>Data parallel</td> <td>High</td> </tr> <tr> <td><strong>Point-to-Point</strong></td> <td>Sequential activation passing</td> <td>Model parallel</td> <td>Medium</td> </tr> <tr> <td><strong>Broadcast</strong></td> <td>Scatter parameters</td> <td>Parameter server</td> <td>Medium</td> </tr> <tr> <td><strong>Reduce-Scatter</strong></td> <td>Gradient partitioning</td> <td>ZeRO optimizer</td> <td>High</td> </tr> </tbody> </table> <p><strong>Optimization Techniques:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># 1. Mixed Precision Training (FP16)</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.cuda.amp</span><span class=w> </span><span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>

<span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>

<span class=k>for</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span> <span class=ow>in</span> <span class=n>dataloader</span><span class=p>:</span>
    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>

    <span class=c1># Forward in FP16</span>
    <span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>

    <span class=c1># Backward with gradient scaling</span>
    <span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
    <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
    <span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>

<span class=c1># 2. Gradient Checkpointing (Memory Savings)</span>
<span class=kn>from</span><span class=w> </span><span class=nn>torch.utils.checkpoint</span><span class=w> </span><span class=kn>import</span> <span class=n>checkpoint</span>

<span class=k>class</span><span class=w> </span><span class=nc>CheckpointedBlock</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=c1># Don&#39;t store activations, recompute in backward</span>
        <span class=k>return</span> <span class=n>checkpoint</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_forward</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>layer</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>

<span class=c1># 3. Gradient Compression</span>
<span class=k>class</span><span class=w> </span><span class=nc>GradientCompressor</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=nf>compress</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tensor</span><span class=p>,</span> <span class=n>compression_ratio</span><span class=o>=</span><span class=mf>0.01</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Top-k gradient sparsification&quot;&quot;&quot;</span>
        <span class=n>numel</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span>
        <span class=n>k</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>numel</span> <span class=o>*</span> <span class=n>compression_ratio</span><span class=p>))</span>

        <span class=c1># Keep only top-k gradients</span>
        <span class=n>values</span><span class=p>,</span> <span class=n>indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>tensor</span><span class=o>.</span><span class=n>abs</span><span class=p>()</span><span class=o>.</span><span class=n>flatten</span><span class=p>(),</span> <span class=n>k</span><span class=p>)</span>
        <span class=n>compressed</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>tensor</span><span class=o>.</span><span class=n>flatten</span><span class=p>())</span>
        <span class=n>compressed</span><span class=p>[</span><span class=n>indices</span><span class=p>]</span> <span class=o>=</span> <span class=n>tensor</span><span class=o>.</span><span class=n>flatten</span><span class=p>()[</span><span class=n>indices</span><span class=p>]</span>

        <span class=k>return</span> <span class=n>compressed</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>tensor</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</code></pre></div> <p><strong>Fault Tolerance:</strong></p> <div class=highlight><pre><span></span><code><span class=k>class</span><span class=w> </span><span class=nc>FaultTolerantTrainer</span><span class=p>:</span>
    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>checkpoint_freq</span><span class=o>=</span><span class=mi>100</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>checkpoint_freq</span> <span class=o>=</span> <span class=n>checkpoint_freq</span>

    <span class=k>def</span><span class=w> </span><span class=nf>save_checkpoint</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>epoch</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>path</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Save training state&quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=n>dist</span><span class=o>.</span><span class=n>get_rank</span><span class=p>()</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>  <span class=c1># Only rank 0 saves</span>
            <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
                <span class=s1>&#39;epoch&#39;</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
                <span class=s1>&#39;model_state_dict&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
                <span class=s1>&#39;optimizer_state_dict&#39;</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
                <span class=s1>&#39;rng_state&#39;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>get_rng_state</span><span class=p>(),</span>
                <span class=s1>&#39;cuda_rng_state&#39;</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_rng_state_all</span><span class=p>()</span>
            <span class=p>},</span> <span class=n>path</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>load_checkpoint</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>path</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Resume from checkpoint&quot;&quot;&quot;</span>
        <span class=n>checkpoint</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>path</span><span class=p>)</span>
        <span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;model_state_dict&#39;</span><span class=p>])</span>
        <span class=n>optimizer</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;optimizer_state_dict&#39;</span><span class=p>])</span>
        <span class=n>torch</span><span class=o>.</span><span class=n>set_rng_state</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;rng_state&#39;</span><span class=p>])</span>
        <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>set_rng_state_all</span><span class=p>(</span><span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;cuda_rng_state&#39;</span><span class=p>])</span>
        <span class=k>return</span> <span class=n>checkpoint</span><span class=p>[</span><span class=s1>&#39;epoch&#39;</span><span class=p>]</span>
</code></pre></div> <p><strong>Performance Metrics:</strong></p> <table> <thead> <tr> <th>Metric</th> <th>Target</th> <th>Calculation</th> </tr> </thead> <tbody> <tr> <td><strong>Throughput</strong></td> <td>1000+ samples/sec</td> <td>Samples / Time</td> </tr> <tr> <td><strong>GPU Utilization</strong></td> <td>&gt;80%</td> <td>Compute time / Total time</td> </tr> <tr> <td><strong>Communication Overhead</strong></td> <td>&lt;20%</td> <td>Comm time / Total time</td> </tr> <tr> <td><strong>Scaling Efficiency</strong></td> <td>&gt;90%</td> <td>Speedup(N GPUs) / N</td> </tr> <tr> <td><strong>Memory Efficiency</strong></td> <td>&gt;70% GPU RAM used</td> <td>Used memory / Total memory</td> </tr> </tbody> </table> <p><strong>Common Pitfalls:</strong></p> <p>‚ùå <strong>Small batch size per GPU:</strong> Underutilizes GPU ‚Üí Use at least 32-64 ‚ùå <strong>Slow data loading:</strong> GPU waits for CPU ‚Üí Use multiple workers, pin_memory ‚ùå <strong>Not using mixed precision:</strong> 2x slower ‚Üí Use FP16/BF16 ‚ùå <strong>Synchronization bottlenecks:</strong> Frequent all-reduce ‚Üí Gradient accumulation ‚ùå <strong>Imbalanced pipeline stages:</strong> GPU idle time ‚Üí Balance layer distribution</p> <p><strong>Real-World Examples:</strong></p> <ul> <li><strong>Google PaLM (540B):</strong> 6144 TPUs, model + data + pipeline parallelism</li> <li><strong>Meta LLAMA-2 (70B):</strong> 2000 A100 GPUs, ZeRO-3 + pipeline parallelism</li> <li><strong>OpenAI GPT-3 (175B):</strong> 10,000 V100 GPUs, model parallelism</li> <li><strong>Stability AI (2B):</strong> 256 A100 GPUs, data parallel with DeepSpeed</li> </ul> <p><strong>Cost Optimization:</strong></p> <table> <thead> <tr> <th>GPU Type</th> <th>Price/hr</th> <th>Speed</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td><strong>V100</strong></td> <td>$2-3</td> <td>Baseline</td> <td>Legacy workloads</td> </tr> <tr> <td><strong>A100</strong></td> <td>$4-6</td> <td>2x V100</td> <td>Most efficient</td> </tr> <tr> <td><strong>H100</strong></td> <td>$8-10</td> <td>3x V100</td> <td>Cutting edge</td> </tr> <tr> <td><strong>TPU v4</strong></td> <td>$3-5</td> <td>Comparable to A100</td> <td>Google ecosystem</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Knowledge of distributed training strategies, communication patterns, optimization techniques.</p> <p><strong>Strong answer signals:</strong> - Knows when to use data vs model vs pipeline parallelism - Discusses communication overhead and all-reduce - Mentions ZeRO optimizer for memory efficiency - Talks about gradient checkpointing and mixed precision - Knows about fault tolerance and checkpointing - Discusses scaling efficiency metrics - Mentions pipeline bubbles and how to minimize them</p> </div> </details> <hr> <h3 id=design-an-ab-testing-platform-netflix-airbnb-interview-question>Design an A/B Testing Platform - Netflix, Airbnb Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Experimentation</code> | <strong>Asked by:</strong> Netflix, Airbnb, Uber</p> <details class=success> <summary>View Answer</summary> <p><strong>Scale Requirements:</strong> - <strong>Concurrent Experiments:</strong> 100-1000+ active tests - <strong>Users:</strong> 100M+ users in experiments - <strong>Events:</strong> 10B+ events/day - <strong>Experiment Duration:</strong> 1-4 weeks typical - <strong>Statistical Power:</strong> 80%+ with 5% significance - <strong>Analysis Latency:</strong> Real-time dashboards + daily reports</p> <p><strong>Detailed Architecture:</strong></p> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Experiment Configuration                 ‚îÇ
‚îÇ  - Define variants (A, B, C)                       ‚îÇ
‚îÇ  - Traffic allocation (50/50, 90/10, etc.)         ‚îÇ
‚îÇ  - Target audience (location, platform, etc.)      ‚îÇ
‚îÇ  - Metrics (primary, secondary, guardrails)        ‚îÇ
‚îÇ  - Duration &amp; sample size calculation              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Assignment Service (User Bucketing)         ‚îÇ
‚îÇ                                                    ‚îÇ
‚îÇ  Input: user_id, experiment_id                     ‚îÇ
‚îÇ  Output: variant (A or B)                          ‚îÇ
‚îÇ                                                    ‚îÇ
‚îÇ  hash(user_id + experiment_id) % 100               ‚îÇ
‚îÇ    ‚Üí Deterministic, consistent assignment          ‚îÇ
‚îÇ    ‚Üí Same user always gets same variant            ‚îÇ
‚îÇ    ‚Üí No database lookup needed                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         User Experience (Application)              ‚îÇ
‚îÇ                                                    ‚îÇ
‚îÇ  if variant == &#39;A&#39;:                                ‚îÇ
‚îÇ      show_old_checkout_flow()                      ‚îÇ
‚îÇ  elif variant == &#39;B&#39;:                              ‚îÇ
‚îÇ      show_new_checkout_flow()                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Event Tracking (Kafka Stream)             ‚îÇ
‚îÇ                                                    ‚îÇ
‚îÇ  - Exposure events (user saw variant)              ‚îÇ
‚îÇ  - Action events (clicks, purchases, etc.)         ‚îÇ
‚îÇ  - Metadata (timestamp, user_id, variant, etc.)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       Data Pipeline (Batch Processing)             ‚îÇ
‚îÇ                                                    ‚îÇ
‚îÇ  Daily Spark jobs:                                 ‚îÇ
‚îÇ  - Join exposure + outcome events                  ‚îÇ
‚îÇ  - Calculate metrics per variant                   ‚îÇ
‚îÇ  - Run statistical tests                           ‚îÇ
‚îÇ  - Detect Sample Ratio Mismatch (SRM)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Statistical Analysis Engine                ‚îÇ
‚îÇ                                                    ‚îÇ
‚îÇ  - T-test for continuous metrics                   ‚îÇ
‚îÇ  - Z-test for proportions                          ‚îÇ
‚îÇ  - Sequential testing (early stopping)             ‚îÇ
‚îÇ  - Multiple testing correction (Bonferroni)        ‚îÇ
‚îÇ  - Variance reduction (CUPED, stratification)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      Dashboard &amp; Reporting (Real-time)             ‚îÇ
‚îÇ                                                    ‚îÇ
‚îÇ  - Experiment status &amp; health                      ‚îÇ
‚îÇ  - Metric movements (% change, confidence)         ‚îÇ
‚îÇ  - Statistical significance &amp; p-values             ‚îÇ
‚îÇ  - Sample Ratio Mismatch alerts                    ‚îÇ
‚îÇ  - Interaction effects detection                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <p><strong>Implementation:</strong></p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>hashlib</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy</span><span class=w> </span><span class=kn>import</span> <span class=n>stats</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>List</span><span class=p>,</span> <span class=n>Tuple</span>

<span class=c1># 1. ASSIGNMENT SERVICE</span>
<span class=k>class</span><span class=w> </span><span class=nc>ExperimentAssignmentService</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Deterministic user assignment to experiment variants&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>experiments</span> <span class=o>=</span> <span class=p>{}</span>  <span class=c1># experiment_id -&gt; config</span>

    <span class=k>def</span><span class=w> </span><span class=nf>assign_variant</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>experiment_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Deterministic assignment using hash function</span>
<span class=sd>        Same user always gets same variant</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>experiment</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>experiments</span><span class=p>[</span><span class=n>experiment_id</span><span class=p>]</span>

        <span class=c1># Hash user_id + experiment_id for randomization</span>
        <span class=n>hash_input</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>user_id</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>experiment_id</span><span class=si>}</span><span class=s2>&quot;</span>
        <span class=n>hash_value</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>hashlib</span><span class=o>.</span><span class=n>md5</span><span class=p>(</span><span class=n>hash_input</span><span class=o>.</span><span class=n>encode</span><span class=p>())</span><span class=o>.</span><span class=n>hexdigest</span><span class=p>(),</span> <span class=mi>16</span><span class=p>)</span>

        <span class=c1># Convert to bucket (0-99)</span>
        <span class=n>bucket</span> <span class=o>=</span> <span class=n>hash_value</span> <span class=o>%</span> <span class=mi>100</span>

        <span class=c1># Assign to variant based on traffic allocation</span>
        <span class=n>cumulative</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=k>for</span> <span class=n>variant</span><span class=p>,</span> <span class=n>allocation</span> <span class=ow>in</span> <span class=n>experiment</span><span class=p>[</span><span class=s1>&#39;traffic_allocation&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=n>cumulative</span> <span class=o>+=</span> <span class=n>allocation</span>
            <span class=k>if</span> <span class=n>bucket</span> <span class=o>&lt;</span> <span class=n>cumulative</span><span class=p>:</span>
                <span class=k>return</span> <span class=n>variant</span>

        <span class=k>return</span> <span class=s1>&#39;control&#39;</span>  <span class=c1># Default</span>

    <span class=k>def</span><span class=w> </span><span class=nf>should_include_user</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>user</span><span class=p>:</span> <span class=n>Dict</span><span class=p>,</span>
        <span class=n>experiment_config</span><span class=p>:</span> <span class=n>Dict</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>bool</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Check if user qualifies for experiment&quot;&quot;&quot;</span>
        <span class=n>targeting</span> <span class=o>=</span> <span class=n>experiment_config</span><span class=p>[</span><span class=s1>&#39;targeting&#39;</span><span class=p>]</span>

        <span class=c1># Check filters</span>
        <span class=k>if</span> <span class=s1>&#39;countries&#39;</span> <span class=ow>in</span> <span class=n>targeting</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>user</span><span class=p>[</span><span class=s1>&#39;country&#39;</span><span class=p>]</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>targeting</span><span class=p>[</span><span class=s1>&#39;countries&#39;</span><span class=p>]:</span>
                <span class=k>return</span> <span class=kc>False</span>

        <span class=k>if</span> <span class=s1>&#39;platforms&#39;</span> <span class=ow>in</span> <span class=n>targeting</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>user</span><span class=p>[</span><span class=s1>&#39;platform&#39;</span><span class=p>]</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>targeting</span><span class=p>[</span><span class=s1>&#39;platforms&#39;</span><span class=p>]:</span>
                <span class=k>return</span> <span class=kc>False</span>

        <span class=k>if</span> <span class=s1>&#39;user_segments&#39;</span> <span class=ow>in</span> <span class=n>targeting</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>user</span><span class=p>[</span><span class=s1>&#39;segment&#39;</span><span class=p>]</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>targeting</span><span class=p>[</span><span class=s1>&#39;user_segments&#39;</span><span class=p>]:</span>
                <span class=k>return</span> <span class=kc>False</span>

        <span class=k>return</span> <span class=kc>True</span>

<span class=c1># 2. EVENT TRACKING</span>
<span class=k>class</span><span class=w> </span><span class=nc>ExperimentEventTracker</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Track exposure and outcome events&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=nf>track_exposure</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>experiment_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>variant</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>timestamp</span><span class=p>:</span> <span class=nb>int</span>
    <span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Log when user is exposed to experiment&quot;&quot;&quot;</span>
        <span class=n>event</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;event_type&#39;</span><span class=p>:</span> <span class=s1>&#39;exposure&#39;</span><span class=p>,</span>
            <span class=s1>&#39;user_id&#39;</span><span class=p>:</span> <span class=n>user_id</span><span class=p>,</span>
            <span class=s1>&#39;experiment_id&#39;</span><span class=p>:</span> <span class=n>experiment_id</span><span class=p>,</span>
            <span class=s1>&#39;variant&#39;</span><span class=p>:</span> <span class=n>variant</span><span class=p>,</span>
            <span class=s1>&#39;timestamp&#39;</span><span class=p>:</span> <span class=n>timestamp</span>
        <span class=p>}</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_send_to_kafka</span><span class=p>(</span><span class=s1>&#39;experiment_events&#39;</span><span class=p>,</span> <span class=n>event</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>track_outcome</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>experiment_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>metric_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>metric_value</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
        <span class=n>timestamp</span><span class=p>:</span> <span class=nb>int</span>
    <span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Log outcome metric (conversion, revenue, etc.)&quot;&quot;&quot;</span>
        <span class=n>event</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;event_type&#39;</span><span class=p>:</span> <span class=s1>&#39;outcome&#39;</span><span class=p>,</span>
            <span class=s1>&#39;user_id&#39;</span><span class=p>:</span> <span class=n>user_id</span><span class=p>,</span>
            <span class=s1>&#39;experiment_id&#39;</span><span class=p>:</span> <span class=n>experiment_id</span><span class=p>,</span>
            <span class=s1>&#39;metric_name&#39;</span><span class=p>:</span> <span class=n>metric_name</span><span class=p>,</span>
            <span class=s1>&#39;metric_value&#39;</span><span class=p>:</span> <span class=n>metric_value</span><span class=p>,</span>
            <span class=s1>&#39;timestamp&#39;</span><span class=p>:</span> <span class=n>timestamp</span>
        <span class=p>}</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_send_to_kafka</span><span class=p>(</span><span class=s1>&#39;experiment_events&#39;</span><span class=p>,</span> <span class=n>event</span><span class=p>)</span>

<span class=c1># 3. STATISTICAL ANALYSIS</span>
<span class=k>class</span><span class=w> </span><span class=nc>ExperimentAnalyzer</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Analyze experiment results&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>=</span> <span class=mf>0.05</span>  <span class=c1># Significance level (5%)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>power</span> <span class=o>=</span> <span class=mf>0.80</span>  <span class=c1># Statistical power (80%)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>calculate_sample_size</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>baseline_rate</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
        <span class=n>minimum_detectable_effect</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>
        <span class=n>alpha</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.05</span><span class=p>,</span>
        <span class=n>power</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.80</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Calculate required sample size per variant</span>
<span class=sd>        For detecting a minimum effect with desired power</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=kn>from</span><span class=w> </span><span class=nn>statsmodels.stats.power</span><span class=w> </span><span class=kn>import</span> <span class=n>zt_ind_solve_power</span>

        <span class=c1># Effect size (Cohen&#39;s h for proportions)</span>
        <span class=n>p1</span> <span class=o>=</span> <span class=n>baseline_rate</span>
        <span class=n>p2</span> <span class=o>=</span> <span class=n>baseline_rate</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>minimum_detectable_effect</span><span class=p>)</span>

        <span class=n>effect_size</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>arcsin</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>p2</span><span class=p>))</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>arcsin</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>p1</span><span class=p>)))</span>

        <span class=c1># Calculate sample size</span>
        <span class=n>n</span> <span class=o>=</span> <span class=n>zt_ind_solve_power</span><span class=p>(</span>
            <span class=n>effect_size</span><span class=o>=</span><span class=n>effect_size</span><span class=p>,</span>
            <span class=n>alpha</span><span class=o>=</span><span class=n>alpha</span><span class=p>,</span>
            <span class=n>power</span><span class=o>=</span><span class=n>power</span><span class=p>,</span>
            <span class=n>alternative</span><span class=o>=</span><span class=s1>&#39;two-sided&#39;</span>
        <span class=p>)</span>

        <span class=k>return</span> <span class=nb>int</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>

    <span class=k>def</span><span class=w> </span><span class=nf>analyze_experiment</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>control_metrics</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span>
        <span class=n>treatment_metrics</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Run statistical test on experiment results</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>n_control</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>control_metrics</span><span class=p>)</span>
        <span class=n>n_treatment</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>treatment_metrics</span><span class=p>)</span>

        <span class=n>mean_control</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>control_metrics</span><span class=p>)</span>
        <span class=n>mean_treatment</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>treatment_metrics</span><span class=p>)</span>

        <span class=c1># Relative lift</span>
        <span class=n>relative_lift</span> <span class=o>=</span> <span class=p>(</span><span class=n>mean_treatment</span> <span class=o>-</span> <span class=n>mean_control</span><span class=p>)</span> <span class=o>/</span> <span class=n>mean_control</span>

        <span class=c1># T-test for continuous metrics</span>
        <span class=n>t_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>ttest_ind</span><span class=p>(</span>
            <span class=n>treatment_metrics</span><span class=p>,</span>
            <span class=n>control_metrics</span><span class=p>,</span>
            <span class=n>equal_var</span><span class=o>=</span><span class=kc>False</span>  <span class=c1># Welch&#39;s t-test</span>
        <span class=p>)</span>

        <span class=c1># Confidence interval (95%)</span>
        <span class=n>se_diff</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span>
            <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>control_metrics</span><span class=p>)</span> <span class=o>/</span> <span class=n>n_control</span> <span class=o>+</span>
            <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>treatment_metrics</span><span class=p>)</span> <span class=o>/</span> <span class=n>n_treatment</span>
        <span class=p>)</span>
        <span class=n>ci_lower</span> <span class=o>=</span> <span class=p>(</span><span class=n>mean_treatment</span> <span class=o>-</span> <span class=n>mean_control</span><span class=p>)</span> <span class=o>-</span> <span class=mf>1.96</span> <span class=o>*</span> <span class=n>se_diff</span>
        <span class=n>ci_upper</span> <span class=o>=</span> <span class=p>(</span><span class=n>mean_treatment</span> <span class=o>-</span> <span class=n>mean_control</span><span class=p>)</span> <span class=o>+</span> <span class=mf>1.96</span> <span class=o>*</span> <span class=n>se_diff</span>

        <span class=n>is_significant</span> <span class=o>=</span> <span class=n>p_value</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;control_mean&#39;</span><span class=p>:</span> <span class=n>mean_control</span><span class=p>,</span>
            <span class=s1>&#39;treatment_mean&#39;</span><span class=p>:</span> <span class=n>mean_treatment</span><span class=p>,</span>
            <span class=s1>&#39;absolute_lift&#39;</span><span class=p>:</span> <span class=n>mean_treatment</span> <span class=o>-</span> <span class=n>mean_control</span><span class=p>,</span>
            <span class=s1>&#39;relative_lift&#39;</span><span class=p>:</span> <span class=n>relative_lift</span><span class=p>,</span>
            <span class=s1>&#39;p_value&#39;</span><span class=p>:</span> <span class=n>p_value</span><span class=p>,</span>
            <span class=s1>&#39;is_significant&#39;</span><span class=p>:</span> <span class=n>is_significant</span><span class=p>,</span>
            <span class=s1>&#39;confidence_interval&#39;</span><span class=p>:</span> <span class=p>(</span><span class=n>ci_lower</span><span class=p>,</span> <span class=n>ci_upper</span><span class=p>),</span>
            <span class=s1>&#39;sample_size_control&#39;</span><span class=p>:</span> <span class=n>n_control</span><span class=p>,</span>
            <span class=s1>&#39;sample_size_treatment&#39;</span><span class=p>:</span> <span class=n>n_treatment</span>
        <span class=p>}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>check_sample_ratio_mismatch</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>n_control</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
        <span class=n>n_treatment</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>
        <span class=n>expected_ratio</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.5</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Sample Ratio Mismatch (SRM) detection</span>
<span class=sd>        Checks if traffic split matches expected ratio</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>total</span> <span class=o>=</span> <span class=n>n_control</span> <span class=o>+</span> <span class=n>n_treatment</span>
        <span class=n>expected_control</span> <span class=o>=</span> <span class=n>total</span> <span class=o>*</span> <span class=n>expected_ratio</span>
        <span class=n>expected_treatment</span> <span class=o>=</span> <span class=n>total</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>expected_ratio</span><span class=p>)</span>

        <span class=c1># Chi-square test</span>
        <span class=n>observed</span> <span class=o>=</span> <span class=p>[</span><span class=n>n_control</span><span class=p>,</span> <span class=n>n_treatment</span><span class=p>]</span>
        <span class=n>expected</span> <span class=o>=</span> <span class=p>[</span><span class=n>expected_control</span><span class=p>,</span> <span class=n>expected_treatment</span><span class=p>]</span>

        <span class=n>chi_stat</span><span class=p>,</span> <span class=n>p_value</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>chisquare</span><span class=p>(</span><span class=n>observed</span><span class=p>,</span> <span class=n>expected</span><span class=p>)</span>

        <span class=n>has_srm</span> <span class=o>=</span> <span class=n>p_value</span> <span class=o>&lt;</span> <span class=mf>0.001</span>  <span class=c1># Very strict threshold</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;n_control&#39;</span><span class=p>:</span> <span class=n>n_control</span><span class=p>,</span>
            <span class=s1>&#39;n_treatment&#39;</span><span class=p>:</span> <span class=n>n_treatment</span><span class=p>,</span>
            <span class=s1>&#39;expected_ratio&#39;</span><span class=p>:</span> <span class=n>expected_ratio</span><span class=p>,</span>
            <span class=s1>&#39;actual_ratio&#39;</span><span class=p>:</span> <span class=n>n_control</span> <span class=o>/</span> <span class=n>total</span><span class=p>,</span>
            <span class=s1>&#39;p_value&#39;</span><span class=p>:</span> <span class=n>p_value</span><span class=p>,</span>
            <span class=s1>&#39;has_srm&#39;</span><span class=p>:</span> <span class=n>has_srm</span>
        <span class=p>}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>apply_cuped</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>post_metrics</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span>
        <span class=n>pre_metrics</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        CUPED (Controlled-experiment Using Pre-Experiment Data)</span>
<span class=sd>        Variance reduction technique using covariates</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=c1># Calculate theta (optimal coefficient)</span>
        <span class=n>cov</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>cov</span><span class=p>(</span><span class=n>post_metrics</span><span class=p>,</span> <span class=n>pre_metrics</span><span class=p>)[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span>
        <span class=n>var_pre</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>pre_metrics</span><span class=p>)</span>
        <span class=n>theta</span> <span class=o>=</span> <span class=n>cov</span> <span class=o>/</span> <span class=n>var_pre</span>

        <span class=c1># Adjust post-experiment metric</span>
        <span class=n>adjusted_metrics</span> <span class=o>=</span> <span class=n>post_metrics</span> <span class=o>-</span> <span class=n>theta</span> <span class=o>*</span> <span class=p>(</span><span class=n>pre_metrics</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>pre_metrics</span><span class=p>))</span>

        <span class=c1># Variance reduction</span>
        <span class=n>var_original</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>post_metrics</span><span class=p>)</span>
        <span class=n>var_adjusted</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>var</span><span class=p>(</span><span class=n>adjusted_metrics</span><span class=p>)</span>
        <span class=n>variance_reduction</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=p>(</span><span class=n>var_adjusted</span> <span class=o>/</span> <span class=n>var_original</span><span class=p>)</span>

        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Variance reduced by </span><span class=si>{</span><span class=n>variance_reduction</span><span class=si>:</span><span class=s2>.1%</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>adjusted_metrics</span>

    <span class=k>def</span><span class=w> </span><span class=nf>sequential_testing</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>control_data</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>float</span><span class=p>],</span>
        <span class=n>treatment_data</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>float</span><span class=p>],</span>
        <span class=n>looks</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Sequential testing for early stopping</span>
<span class=sd>        Allows peeking at results without inflating false positive rate</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=c1># Always-valid p-values (mixture sequential probability ratio test)</span>
        <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>looks</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
            <span class=c1># Get data up to this point</span>
            <span class=n>idx</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>control_data</span><span class=p>)</span> <span class=o>*</span> <span class=n>i</span> <span class=o>/</span> <span class=n>looks</span><span class=p>)</span>
            <span class=n>control_subset</span> <span class=o>=</span> <span class=n>control_data</span><span class=p>[:</span><span class=n>idx</span><span class=p>]</span>
            <span class=n>treatment_subset</span> <span class=o>=</span> <span class=n>treatment_data</span><span class=p>[:</span><span class=n>idx</span><span class=p>]</span>

            <span class=c1># Run test</span>
            <span class=n>result</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>analyze_experiment</span><span class=p>(</span>
                <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>control_subset</span><span class=p>),</span>
                <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>treatment_subset</span><span class=p>)</span>
            <span class=p>)</span>

            <span class=c1># Adjusted alpha for multiple looks (Bonferroni correction)</span>
            <span class=n>adjusted_alpha</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>/</span> <span class=n>looks</span>
            <span class=n>result</span><span class=p>[</span><span class=s1>&#39;adjusted_alpha&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>adjusted_alpha</span>
            <span class=n>result</span><span class=p>[</span><span class=s1>&#39;can_stop&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>result</span><span class=p>[</span><span class=s1>&#39;p_value&#39;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>adjusted_alpha</span>

            <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>

            <span class=k>if</span> <span class=n>result</span><span class=p>[</span><span class=s1>&#39;can_stop&#39;</span><span class=p>]:</span>
                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Can stop early at look </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>looks</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
                <span class=k>break</span>

        <span class=k>return</span> <span class=n>results</span>

<span class=c1># 4. INTERACTION EFFECTS</span>
<span class=k>class</span><span class=w> </span><span class=nc>InteractionEffectsDetector</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Detect when multiple experiments interfere&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=nf>detect_interaction</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>exp1_assignment</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span>  <span class=c1># 0 or 1</span>
        <span class=n>exp2_assignment</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span>  <span class=c1># 0 or 1</span>
        <span class=n>outcome</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        2-way ANOVA to detect interaction effects</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>f_oneway</span>

        <span class=c1># Four groups: (exp1=0, exp2=0), (exp1=1, exp2=0), etc.</span>
        <span class=n>group_00</span> <span class=o>=</span> <span class=n>outcome</span><span class=p>[(</span><span class=n>exp1_assignment</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>exp2_assignment</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)]</span>
        <span class=n>group_01</span> <span class=o>=</span> <span class=n>outcome</span><span class=p>[(</span><span class=n>exp1_assignment</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>exp2_assignment</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)]</span>
        <span class=n>group_10</span> <span class=o>=</span> <span class=n>outcome</span><span class=p>[(</span><span class=n>exp1_assignment</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>exp2_assignment</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)]</span>
        <span class=n>group_11</span> <span class=o>=</span> <span class=n>outcome</span><span class=p>[(</span><span class=n>exp1_assignment</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>exp2_assignment</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)]</span>

        <span class=c1># Main effect of exp1</span>
        <span class=n>exp1_control</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>group_00</span><span class=p>,</span> <span class=n>group_01</span><span class=p>])</span>
        <span class=n>exp1_treatment</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>group_10</span><span class=p>,</span> <span class=n>group_11</span><span class=p>])</span>
        <span class=n>_</span><span class=p>,</span> <span class=n>p_exp1</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>ttest_ind</span><span class=p>(</span><span class=n>exp1_treatment</span><span class=p>,</span> <span class=n>exp1_control</span><span class=p>)</span>

        <span class=c1># Main effect of exp2</span>
        <span class=n>exp2_control</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>group_00</span><span class=p>,</span> <span class=n>group_10</span><span class=p>])</span>
        <span class=n>exp2_treatment</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>group_01</span><span class=p>,</span> <span class=n>group_11</span><span class=p>])</span>
        <span class=n>_</span><span class=p>,</span> <span class=n>p_exp2</span> <span class=o>=</span> <span class=n>stats</span><span class=o>.</span><span class=n>ttest_ind</span><span class=p>(</span><span class=n>exp2_treatment</span><span class=p>,</span> <span class=n>exp2_control</span><span class=p>)</span>

        <span class=c1># Interaction effect</span>
        <span class=c1># If interaction exists: effect of exp1 differs based on exp2</span>
        <span class=n>effect_exp1_when_exp2_control</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>group_10</span><span class=p>)</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>group_00</span><span class=p>)</span>
        <span class=n>effect_exp1_when_exp2_treatment</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>group_11</span><span class=p>)</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>group_01</span><span class=p>)</span>
        <span class=n>interaction_magnitude</span> <span class=o>=</span> <span class=nb>abs</span><span class=p>(</span>
            <span class=n>effect_exp1_when_exp2_treatment</span> <span class=o>-</span> <span class=n>effect_exp1_when_exp2_control</span>
        <span class=p>)</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;exp1_significant&#39;</span><span class=p>:</span> <span class=n>p_exp1</span> <span class=o>&lt;</span> <span class=mf>0.05</span><span class=p>,</span>
            <span class=s1>&#39;exp2_significant&#39;</span><span class=p>:</span> <span class=n>p_exp2</span> <span class=o>&lt;</span> <span class=mf>0.05</span><span class=p>,</span>
            <span class=s1>&#39;interaction_magnitude&#39;</span><span class=p>:</span> <span class=n>interaction_magnitude</span><span class=p>,</span>
            <span class=s1>&#39;has_interaction&#39;</span><span class=p>:</span> <span class=n>interaction_magnitude</span> <span class=o>&gt;</span> <span class=mf>0.01</span>  <span class=c1># Threshold</span>
        <span class=p>}</span>
</code></pre></div> <p><strong>Key Formulas:</strong></p> <table> <thead> <tr> <th>Concept</th> <th>Formula</th> <th>Purpose</th> </tr> </thead> <tbody> <tr> <td><strong>Sample Size</strong></td> <td><span class=arithmatex>\(n = \frac{2(Z_{\alpha/2} + Z_\beta)^2 \sigma^2}{\delta^2}\)</span></td> <td>Required users per variant</td> </tr> <tr> <td><strong>T-statistic</strong></td> <td><span class=arithmatex>\(t = \frac{\bar{X}_B - \bar{X}_A}{\sqrt{s^2(\frac{1}{n_A} + \frac{1}{n_B})}}\)</span></td> <td>Statistical significance</td> </tr> <tr> <td><strong>Confidence Interval</strong></td> <td><span class=arithmatex>\(CI = \bar{X} \pm Z_{\alpha/2} \times SE\)</span></td> <td>Range of true effect</td> </tr> <tr> <td><strong>Relative Lift</strong></td> <td><span class=arithmatex>\(\frac{\bar{X}_B - \bar{X}_A}{\bar{X}_A} \times 100\%\)</span></td> <td>% improvement</td> </tr> <tr> <td><strong>Statistical Power</strong></td> <td><span class=arithmatex>\(1 - \beta\)</span></td> <td>Probability of detecting true effect</td> </tr> </tbody> </table> <p><strong>Common Pitfalls:</strong></p> <p>‚ùå <strong>Peeking:</strong> Looking at results too early ‚Üí Inflated false positives (use sequential testing) ‚ùå <strong>Sample Ratio Mismatch:</strong> Unequal traffic split ‚Üí Check randomization ‚ùå <strong>Multiple testing:</strong> Testing many metrics ‚Üí Apply Bonferroni correction ‚ùå <strong>Not accounting for novelty effect:</strong> New feature gets attention ‚Üí Run for 2+ weeks ‚ùå <strong>Ignoring interaction effects:</strong> Conflicting experiments ‚Üí Use orthogonal assignment</p> <p><strong>Real-World Examples:</strong></p> <ul> <li><strong>Netflix:</strong> 1000+ concurrent tests, watches for interactions, uses CUPED for variance reduction</li> <li><strong>Airbnb:</strong> ERF (Experiment Reporting Framework), automated SRM detection, layered experiments</li> <li><strong>Uber:</strong> XP platform, sequential testing, handles &gt;100M users</li> <li><strong>Booking.com:</strong> 1000+ active experiments, isolated experiment layers</li> </ul> <p><strong>Advanced Techniques:</strong></p> <div class=highlight><pre><span></span><code><span class=c1># Stratified Sampling (Variance Reduction)</span>
<span class=k>def</span><span class=w> </span><span class=nf>stratified_analysis</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>strata_col</span><span class=o>=</span><span class=s1>&#39;country&#39;</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Analyze within strata, then combine&quot;&quot;&quot;</span>
    <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=k>for</span> <span class=n>stratum</span> <span class=ow>in</span> <span class=n>df</span><span class=p>[</span><span class=n>strata_col</span><span class=p>]</span><span class=o>.</span><span class=n>unique</span><span class=p>():</span>
        <span class=n>subset</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>df</span><span class=p>[</span><span class=n>strata_col</span><span class=p>]</span> <span class=o>==</span> <span class=n>stratum</span><span class=p>]</span>
        <span class=n>result</span> <span class=o>=</span> <span class=n>analyze_experiment</span><span class=p>(</span>
            <span class=n>subset</span><span class=p>[</span><span class=n>subset</span><span class=p>[</span><span class=s1>&#39;variant&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;A&#39;</span><span class=p>][</span><span class=s1>&#39;metric&#39;</span><span class=p>],</span>
            <span class=n>subset</span><span class=p>[</span><span class=n>subset</span><span class=p>[</span><span class=s1>&#39;variant&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;B&#39;</span><span class=p>][</span><span class=s1>&#39;metric&#39;</span><span class=p>]</span>
        <span class=p>)</span>
        <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>stratum</span><span class=p>,</span> <span class=n>result</span><span class=p>))</span>
    <span class=k>return</span> <span class=n>results</span>

<span class=c1># Bayesian A/B Testing (Alternative to frequentist)</span>
<span class=k>def</span><span class=w> </span><span class=nf>bayesian_ab_test</span><span class=p>(</span><span class=n>control_conversions</span><span class=p>,</span> <span class=n>control_trials</span><span class=p>,</span>
                     <span class=n>treatment_conversions</span><span class=p>,</span> <span class=n>treatment_trials</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Bayesian approach with Beta priors&quot;&quot;&quot;</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>scipy.stats</span><span class=w> </span><span class=kn>import</span> <span class=n>beta</span>

    <span class=c1># Posterior distributions</span>
    <span class=n>control_posterior</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=n>control_conversions</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>control_trials</span> <span class=o>-</span> <span class=n>control_conversions</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
    <span class=n>treatment_posterior</span> <span class=o>=</span> <span class=n>beta</span><span class=p>(</span><span class=n>treatment_conversions</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>treatment_trials</span> <span class=o>-</span> <span class=n>treatment_conversions</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>

    <span class=c1># Probability treatment &gt; control</span>
    <span class=n>samples_control</span> <span class=o>=</span> <span class=n>control_posterior</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=mi>100000</span><span class=p>)</span>
    <span class=n>samples_treatment</span> <span class=o>=</span> <span class=n>treatment_posterior</span><span class=o>.</span><span class=n>rvs</span><span class=p>(</span><span class=mi>100000</span><span class=p>)</span>
    <span class=n>prob_treatment_better</span> <span class=o>=</span> <span class=p>(</span><span class=n>samples_treatment</span> <span class=o>&gt;</span> <span class=n>samples_control</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>

    <span class=k>return</span> <span class=n>prob_treatment_better</span>
</code></pre></div> <p><strong>Metrics Taxonomy:</strong></p> <table> <thead> <tr> <th>Metric Type</th> <th>Examples</th> <th>Guardrails?</th> </tr> </thead> <tbody> <tr> <td><strong>Primary</strong></td> <td>Conversion rate, Revenue</td> <td>Decision metric</td> </tr> <tr> <td><strong>Secondary</strong></td> <td>CTR, Engagement time</td> <td>Supplementary insights</td> </tr> <tr> <td><strong>Guardrail</strong></td> <td>Page load time, Error rate</td> <td>Must not degrade</td> </tr> <tr> <td><strong>Debugging</strong></td> <td>Feature usage, Funnel steps</td> <td>Understand "why"</td> </tr> </tbody> </table> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p><strong>What they're testing:</strong> Understanding of randomization, statistical power, variance reduction, multiple testing.</p> <p><strong>Strong answer signals:</strong> - Discusses deterministic assignment with hash functions - Mentions Sample Ratio Mismatch (SRM) detection - Knows about CUPED for variance reduction - Talks about multiple testing correction (Bonferroni) - Discusses interaction effects between experiments - Mentions sequential testing for early stopping - Knows about novelty effects and proper experiment duration - Discusses layered experiments for isolation</p> </div> </details> <hr> <h3 id=design-a-data-pipeline-for-ml-google-amazon-interview-question>Design a Data Pipeline for ML - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Data Engineering</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <h2 id=scale-requirements>Scale Requirements</h2> <ul> <li><strong>Data Volume:</strong> 10TB-1PB daily ingestion</li> <li><strong>Throughput:</strong> 100K-1M events/second</li> <li><strong>Latency:</strong> Batch (hourly/daily), Streaming (&lt;1 min end-to-end)</li> <li><strong>Features:</strong> 1K-10K features, 100M-10B rows</li> <li><strong>Pipeline SLA:</strong> 99.9% uptime, &lt;5% data loss tolerance</li> <li><strong>Data Quality:</strong> 99%+ accuracy, &lt;0.1% duplicate rate</li> </ul> <h2 id=architecture>Architecture</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Data Sources                                 ‚îÇ
‚îÇ  [Databases] [APIs] [Event Streams] [Files] [3rd Party]        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Ingestion Layer (Airflow/Prefect)                ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Batch:          CDC:              Streaming:                   ‚îÇ
‚îÇ  Sqoop/Fivetran  Debezium         Kafka Connect                 ‚îÇ
‚îÇ  (hourly/daily)  (real-time)      (real-time)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Raw Data Lake (S3/GCS/ADLS)                     ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  /raw/yyyy/mm/dd/hh/source_name/data.parquet                   ‚îÇ
‚îÇ  - Immutable, append-only                                       ‚îÇ
‚îÇ  - Partitioned by date + source                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Data Quality &amp; Validation Layer                       ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Schema validation ‚Üí Null checks ‚Üí Range checks                 ‚îÇ
‚îÇ  ‚Üí Duplicate detection ‚Üí Anomaly detection                      ‚îÇ
‚îÇ  Great Expectations / Deequ / Custom                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          Processing Layer (Spark/Dask/DBT)                       ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ETL/ELT:                      Feature Engineering:             ‚îÇ
‚îÇ  - Cleaning &amp; deduplication    - Aggregations                   ‚îÇ
‚îÇ  - Schema normalization        - Joins (point-in-time)          ‚îÇ
‚îÇ  - Filtering &amp; sampling        - Transformations                ‚îÇ
‚îÇ  - Enrichment                  - Embeddings                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       Curated Data &amp; Feature Store (Delta Lake/Hudi)            ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Offline Store:            Online Store:                        ‚îÇ
‚îÇ  S3/BigQuery/Snowflake     Redis/DynamoDB/Cassandra             ‚îÇ
‚îÇ  (training data)           (low-latency serving)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   ML Training &amp; Serving                          ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  [Training Jobs] ‚Üê Historical features                          ‚îÇ
‚îÇ  [Inference] ‚Üê Real-time features                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ     Cross-Cutting Concerns         ‚îÇ
        ‚îÇ                                    ‚îÇ
        ‚îÇ  - Metadata &amp; Lineage (DataHub)   ‚îÇ
        ‚îÇ  - Monitoring (Datadog/Grafana)   ‚îÇ
        ‚îÇ  - Versioning (DVC/Delta)         ‚îÇ
        ‚îÇ  - Access Control (IAM/RBAC)      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=production-implementation-320-lines>Production Implementation (320 lines)</h2> <div class=highlight><pre><span></span><code><span class=c1># airflow_ml_pipeline.py</span>
<span class=kn>from</span><span class=w> </span><span class=nn>airflow</span><span class=w> </span><span class=kn>import</span> <span class=n>DAG</span>
<span class=kn>from</span><span class=w> </span><span class=nn>airflow.operators.python</span><span class=w> </span><span class=kn>import</span> <span class=n>PythonOperator</span>
<span class=kn>from</span><span class=w> </span><span class=nn>airflow.providers.apache.spark.operators.spark_submit</span><span class=w> </span><span class=kn>import</span> <span class=n>SparkSubmitOperator</span>
<span class=kn>from</span><span class=w> </span><span class=nn>datetime</span><span class=w> </span><span class=kn>import</span> <span class=n>datetime</span><span class=p>,</span> <span class=n>timedelta</span>
<span class=kn>import</span><span class=w> </span><span class=nn>great_expectations</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>ge</span>
<span class=kn>from</span><span class=w> </span><span class=nn>pyspark.sql</span><span class=w> </span><span class=kn>import</span> <span class=n>SparkSession</span><span class=p>,</span> <span class=n>Window</span>
<span class=kn>from</span><span class=w> </span><span class=nn>pyspark.sql</span><span class=w> </span><span class=kn>import</span> <span class=n>functions</span> <span class=k>as</span> <span class=n>F</span>
<span class=kn>import</span><span class=w> </span><span class=nn>logging</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>List</span><span class=p>,</span> <span class=n>Tuple</span>
<span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span>

<span class=c1># ============= Configuration =============</span>
<span class=nd>@dataclass</span>
<span class=k>class</span><span class=w> </span><span class=nc>PipelineConfig</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Pipeline configuration with all parameters&quot;&quot;&quot;</span>
    <span class=n>raw_data_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;s3://ml-data/raw&quot;</span>
    <span class=n>processed_data_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;s3://ml-data/processed&quot;</span>
    <span class=n>feature_store_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;s3://ml-data/features&quot;</span>
    <span class=n>data_quality_threshold</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.95</span>
    <span class=n>max_null_percentage</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.05</span>
    <span class=n>deduplication_keys</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=k>def</span><span class=w> </span><span class=nf>__post_init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>deduplication_keys</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>deduplication_keys</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;user_id&#39;</span><span class=p>,</span> <span class=s1>&#39;timestamp&#39;</span><span class=p>]</span>

<span class=n>config</span> <span class=o>=</span> <span class=n>PipelineConfig</span><span class=p>()</span>

<span class=c1># ============= Data Quality Checks =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>DataQualityChecker</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Comprehensive data quality validation&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>spark</span><span class=p>:</span> <span class=n>SparkSession</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>spark</span> <span class=o>=</span> <span class=n>spark</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>validate_schema</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>expected_schema</span><span class=p>:</span> <span class=n>Dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=nb>bool</span><span class=p>,</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Validate DataFrame schema against expected&quot;&quot;&quot;</span>
        <span class=n>issues</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=n>df_schema</span> <span class=o>=</span> <span class=p>{</span><span class=n>field</span><span class=o>.</span><span class=n>name</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>field</span><span class=o>.</span><span class=n>dataType</span><span class=p>)</span> <span class=k>for</span> <span class=n>field</span> <span class=ow>in</span> <span class=n>df</span><span class=o>.</span><span class=n>schema</span><span class=p>}</span>

        <span class=k>for</span> <span class=n>col</span><span class=p>,</span> <span class=n>dtype</span> <span class=ow>in</span> <span class=n>expected_schema</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=k>if</span> <span class=n>col</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>df_schema</span><span class=p>:</span>
                <span class=n>issues</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Missing column: </span><span class=si>{</span><span class=n>col</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
            <span class=k>elif</span> <span class=n>df_schema</span><span class=p>[</span><span class=n>col</span><span class=p>]</span> <span class=o>!=</span> <span class=n>dtype</span><span class=p>:</span>
                <span class=n>issues</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Type mismatch for </span><span class=si>{</span><span class=n>col</span><span class=si>}</span><span class=s2>: expected </span><span class=si>{</span><span class=n>dtype</span><span class=si>}</span><span class=s2>, got </span><span class=si>{</span><span class=n>df_schema</span><span class=p>[</span><span class=n>col</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=n>issues</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=n>issues</span>

    <span class=k>def</span><span class=w> </span><span class=nf>check_nulls</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>max_null_pct</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.05</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=nb>bool</span><span class=p>,</span> <span class=n>Dict</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Check null percentage for each column&quot;&quot;&quot;</span>
        <span class=n>total_rows</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>count</span><span class=p>()</span>
        <span class=n>null_stats</span> <span class=o>=</span> <span class=p>{}</span>
        <span class=n>failed_cols</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>for</span> <span class=n>col</span> <span class=ow>in</span> <span class=n>df</span><span class=o>.</span><span class=n>columns</span><span class=p>:</span>
            <span class=n>null_count</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=n>col</span><span class=p>)</span><span class=o>.</span><span class=n>isNull</span><span class=p>())</span><span class=o>.</span><span class=n>count</span><span class=p>()</span>
            <span class=n>null_pct</span> <span class=o>=</span> <span class=n>null_count</span> <span class=o>/</span> <span class=n>total_rows</span>
            <span class=n>null_stats</span><span class=p>[</span><span class=n>col</span><span class=p>]</span> <span class=o>=</span> <span class=n>null_pct</span>

            <span class=k>if</span> <span class=n>null_pct</span> <span class=o>&gt;</span> <span class=n>max_null_pct</span><span class=p>:</span>
                <span class=n>failed_cols</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>col</span><span class=p>)</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Column </span><span class=si>{</span><span class=n>col</span><span class=si>}</span><span class=s2> has </span><span class=si>{</span><span class=n>null_pct</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2> nulls (threshold: </span><span class=si>{</span><span class=n>max_null_pct</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>

        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=n>failed_cols</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=n>null_stats</span>

    <span class=k>def</span><span class=w> </span><span class=nf>detect_duplicates</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>keys</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=nb>float</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Detect and count duplicates based on keys&quot;&quot;&quot;</span>
        <span class=n>total_rows</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>count</span><span class=p>()</span>
        <span class=n>duplicate_count</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>groupBy</span><span class=p>(</span><span class=n>keys</span><span class=p>)</span><span class=o>.</span><span class=n>count</span><span class=p>()</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=s1>&#39;count&#39;</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>count</span><span class=p>()</span>
        <span class=n>duplicate_rate</span> <span class=o>=</span> <span class=n>duplicate_count</span> <span class=o>/</span> <span class=n>total_rows</span> <span class=k>if</span> <span class=n>total_rows</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=k>else</span> <span class=mi>0</span>

        <span class=k>return</span> <span class=n>duplicate_count</span><span class=p>,</span> <span class=n>duplicate_rate</span>

    <span class=k>def</span><span class=w> </span><span class=nf>check_value_ranges</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>range_constraints</span><span class=p>:</span> <span class=n>Dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=nb>bool</span><span class=p>,</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Validate value ranges for numeric columns&quot;&quot;&quot;</span>
        <span class=n>issues</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>for</span> <span class=n>col</span><span class=p>,</span> <span class=p>(</span><span class=n>min_val</span><span class=p>,</span> <span class=n>max_val</span><span class=p>)</span> <span class=ow>in</span> <span class=n>range_constraints</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=n>out_of_range</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span>
                <span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=n>col</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>min_val</span><span class=p>)</span> <span class=o>|</span> <span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=n>col</span><span class=p>)</span> <span class=o>&gt;</span> <span class=n>max_val</span><span class=p>)</span>
            <span class=p>)</span><span class=o>.</span><span class=n>count</span><span class=p>()</span>

            <span class=k>if</span> <span class=n>out_of_range</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
                <span class=n>issues</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>col</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>out_of_range</span><span class=si>}</span><span class=s2> values out of range [</span><span class=si>{</span><span class=n>min_val</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>max_val</span><span class=si>}</span><span class=s2>]&quot;</span><span class=p>)</span>

        <span class=k>return</span> <span class=nb>len</span><span class=p>(</span><span class=n>issues</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=n>issues</span>

    <span class=k>def</span><span class=w> </span><span class=nf>detect_anomalies</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>numeric_cols</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span> <span class=n>std_threshold</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>3.0</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Detect statistical anomalies using z-score&quot;&quot;&quot;</span>
        <span class=k>for</span> <span class=n>col</span> <span class=ow>in</span> <span class=n>numeric_cols</span><span class=p>:</span>
            <span class=n>stats</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>select</span><span class=p>(</span>
                <span class=n>F</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>col</span><span class=p>)</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s1>&#39;mean&#39;</span><span class=p>),</span>
                <span class=n>F</span><span class=o>.</span><span class=n>stddev</span><span class=p>(</span><span class=n>col</span><span class=p>)</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s1>&#39;std&#39;</span><span class=p>)</span>
            <span class=p>)</span><span class=o>.</span><span class=n>first</span><span class=p>()</span>

            <span class=k>if</span> <span class=n>stats</span><span class=o>.</span><span class=n>std</span> <span class=ow>and</span> <span class=n>stats</span><span class=o>.</span><span class=n>std</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
                <span class=n>anomalies</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span>
                    <span class=n>F</span><span class=o>.</span><span class=n>abs</span><span class=p>((</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=n>col</span><span class=p>)</span> <span class=o>-</span> <span class=n>stats</span><span class=o>.</span><span class=n>mean</span><span class=p>)</span> <span class=o>/</span> <span class=n>stats</span><span class=o>.</span><span class=n>std</span><span class=p>)</span> <span class=o>&gt;</span> <span class=n>std_threshold</span>
                <span class=p>)</span><span class=o>.</span><span class=n>count</span><span class=p>()</span>

                <span class=k>if</span> <span class=n>anomalies</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
                    <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>col</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>anomalies</span><span class=si>}</span><span class=s2> anomalies detected (&gt;</span><span class=si>{</span><span class=n>std_threshold</span><span class=si>}</span><span class=s2>œÉ)&quot;</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>run_great_expectations</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>checkpoint_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>bool</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Run Great Expectations validation suite&quot;&quot;&quot;</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=n>context</span> <span class=o>=</span> <span class=n>ge</span><span class=o>.</span><span class=n>data_context</span><span class=o>.</span><span class=n>DataContext</span><span class=p>()</span>
            <span class=n>batch</span> <span class=o>=</span> <span class=n>context</span><span class=o>.</span><span class=n>get_batch</span><span class=p>({</span><span class=s1>&#39;dataset&#39;</span><span class=p>:</span> <span class=n>df</span><span class=p>,</span> <span class=s1>&#39;datasource&#39;</span><span class=p>:</span> <span class=s1>&#39;spark&#39;</span><span class=p>})</span>
            <span class=n>results</span> <span class=o>=</span> <span class=n>context</span><span class=o>.</span><span class=n>run_checkpoint</span><span class=p>(</span><span class=n>checkpoint_name</span><span class=o>=</span><span class=n>checkpoint_name</span><span class=p>)</span>
            <span class=k>return</span> <span class=n>results</span><span class=p>[</span><span class=s1>&#39;success&#39;</span><span class=p>]</span>
        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Great Expectations failed: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
            <span class=k>return</span> <span class=kc>False</span>

<span class=c1># ============= Feature Engineering Pipeline =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>FeatureEngineeringPipeline</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Production feature engineering with point-in-time correctness&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>spark</span><span class=p>:</span> <span class=n>SparkSession</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>spark</span> <span class=o>=</span> <span class=n>spark</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>create_time_features</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>timestamp_col</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s1>&#39;timestamp&#39;</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Extract temporal features&quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=n>df</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span><span class=s1>&#39;hour&#39;</span><span class=p>,</span> <span class=n>F</span><span class=o>.</span><span class=n>hour</span><span class=p>(</span><span class=n>timestamp_col</span><span class=p>))</span> \
                 <span class=o>.</span><span class=n>withColumn</span><span class=p>(</span><span class=s1>&#39;day_of_week&#39;</span><span class=p>,</span> <span class=n>F</span><span class=o>.</span><span class=n>dayofweek</span><span class=p>(</span><span class=n>timestamp_col</span><span class=p>))</span> \
                 <span class=o>.</span><span class=n>withColumn</span><span class=p>(</span><span class=s1>&#39;day_of_month&#39;</span><span class=p>,</span> <span class=n>F</span><span class=o>.</span><span class=n>dayofmonth</span><span class=p>(</span><span class=n>timestamp_col</span><span class=p>))</span> \
                 <span class=o>.</span><span class=n>withColumn</span><span class=p>(</span><span class=s1>&#39;month&#39;</span><span class=p>,</span> <span class=n>F</span><span class=o>.</span><span class=n>month</span><span class=p>(</span><span class=n>timestamp_col</span><span class=p>))</span> \
                 <span class=o>.</span><span class=n>withColumn</span><span class=p>(</span><span class=s1>&#39;is_weekend&#39;</span><span class=p>,</span> <span class=n>F</span><span class=o>.</span><span class=n>dayofweek</span><span class=p>(</span><span class=n>timestamp_col</span><span class=p>)</span><span class=o>.</span><span class=n>isin</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>7</span><span class=p>])</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=s1>&#39;int&#39;</span><span class=p>))</span>

    <span class=k>def</span><span class=w> </span><span class=nf>create_aggregation_features</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>group_keys</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span>
                                   <span class=n>agg_col</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>windows</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Create time-windowed aggregations with point-in-time correctness&quot;&quot;&quot;</span>

        <span class=c1># Define window specifications</span>
        <span class=n>window_specs</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;1h&#39;</span><span class=p>:</span> <span class=mi>3600</span><span class=p>,</span>
            <span class=s1>&#39;24h&#39;</span><span class=p>:</span> <span class=mi>86400</span><span class=p>,</span>
            <span class=s1>&#39;7d&#39;</span><span class=p>:</span> <span class=mi>604800</span><span class=p>,</span>
            <span class=s1>&#39;30d&#39;</span><span class=p>:</span> <span class=mi>2592000</span>
        <span class=p>}</span>

        <span class=n>result_df</span> <span class=o>=</span> <span class=n>df</span>

        <span class=k>for</span> <span class=n>window</span> <span class=ow>in</span> <span class=n>windows</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>window</span> <span class=ow>in</span> <span class=n>window_specs</span><span class=p>:</span>
                <span class=n>seconds</span> <span class=o>=</span> <span class=n>window_specs</span><span class=p>[</span><span class=n>window</span><span class=p>]</span>

                <span class=c1># Sliding window aggregation</span>
                <span class=n>window_spec</span> <span class=o>=</span> <span class=n>Window</span><span class=o>.</span><span class=n>partitionBy</span><span class=p>(</span><span class=n>group_keys</span><span class=p>)</span> \
                                   <span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=s1>&#39;timestamp&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=s1>&#39;long&#39;</span><span class=p>))</span> \
                                   <span class=o>.</span><span class=n>rangeBetween</span><span class=p>(</span><span class=o>-</span><span class=n>seconds</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>

                <span class=n>result_df</span> <span class=o>=</span> <span class=n>result_df</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span>
                    <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>agg_col</span><span class=si>}</span><span class=s1>_sum_</span><span class=si>{</span><span class=n>window</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span>
                    <span class=n>F</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>agg_col</span><span class=p>)</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>window_spec</span><span class=p>)</span>
                <span class=p>)</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span>
                    <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>agg_col</span><span class=si>}</span><span class=s1>_avg_</span><span class=si>{</span><span class=n>window</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span>
                    <span class=n>F</span><span class=o>.</span><span class=n>avg</span><span class=p>(</span><span class=n>agg_col</span><span class=p>)</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>window_spec</span><span class=p>)</span>
                <span class=p>)</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span>
                    <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>agg_col</span><span class=si>}</span><span class=s1>_count_</span><span class=si>{</span><span class=n>window</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span>
                    <span class=n>F</span><span class=o>.</span><span class=n>count</span><span class=p>(</span><span class=n>agg_col</span><span class=p>)</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>window_spec</span><span class=p>)</span>
                <span class=p>)</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span>
                    <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>agg_col</span><span class=si>}</span><span class=s1>_max_</span><span class=si>{</span><span class=n>window</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span>
                    <span class=n>F</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=n>agg_col</span><span class=p>)</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>window_spec</span><span class=p>)</span>
                <span class=p>)</span>

        <span class=k>return</span> <span class=n>result_df</span>

    <span class=k>def</span><span class=w> </span><span class=nf>point_in_time_join</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>events_df</span><span class=p>,</span> <span class=n>features_df</span><span class=p>,</span>
                           <span class=n>join_keys</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span> <span class=n>event_time_col</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s1>&#39;timestamp&#39;</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Point-in-time correct join to prevent data leakage&quot;&quot;&quot;</span>

        <span class=c1># For each event, get the latest feature values BEFORE the event timestamp</span>
        <span class=n>window_spec</span> <span class=o>=</span> <span class=n>Window</span><span class=o>.</span><span class=n>partitionBy</span><span class=p>(</span><span class=n>join_keys</span><span class=p>)</span> \
                            <span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=s1>&#39;feature_timestamp&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=s1>&#39;long&#39;</span><span class=p>))</span> \
                            <span class=o>.</span><span class=n>rowsBetween</span><span class=p>(</span><span class=n>Window</span><span class=o>.</span><span class=n>unboundedPreceding</span><span class=p>,</span> <span class=n>Window</span><span class=o>.</span><span class=n>currentRow</span><span class=p>)</span>

        <span class=c1># Add sequence number to handle ties</span>
        <span class=n>features_with_seq</span> <span class=o>=</span> <span class=n>features_df</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span>
            <span class=s1>&#39;seq&#39;</span><span class=p>,</span> <span class=n>F</span><span class=o>.</span><span class=n>row_number</span><span class=p>()</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>window_spec</span><span class=p>)</span>
        <span class=p>)</span>

        <span class=c1># Join using inequality condition</span>
        <span class=n>joined</span> <span class=o>=</span> <span class=n>events_df</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s1>&#39;e&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>join</span><span class=p>(</span>
            <span class=n>features_with_seq</span><span class=o>.</span><span class=n>alias</span><span class=p>(</span><span class=s1>&#39;f&#39;</span><span class=p>),</span>
            <span class=p>(</span><span class=n>events_df</span><span class=p>[</span><span class=n>join_keys</span><span class=p>[</span><span class=mi>0</span><span class=p>]]</span> <span class=o>==</span> <span class=n>features_df</span><span class=p>[</span><span class=n>join_keys</span><span class=p>[</span><span class=mi>0</span><span class=p>]])</span> <span class=o>&amp;</span>
            <span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=s1>&#39;f.feature_timestamp&#39;</span><span class=p>)</span> <span class=o>&lt;=</span> <span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;e.</span><span class=si>{</span><span class=n>event_time_col</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)),</span>
            <span class=s1>&#39;left&#39;</span>
        <span class=p>)</span>

        <span class=c1># Keep only the latest feature value before each event</span>
        <span class=n>window_latest</span> <span class=o>=</span> <span class=n>Window</span><span class=o>.</span><span class=n>partitionBy</span><span class=p>(</span>
            <span class=p>[</span><span class=sa>f</span><span class=s1>&#39;e.</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s1>&#39;</span> <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>join_keys</span><span class=p>]</span> <span class=o>+</span> <span class=p>[</span><span class=sa>f</span><span class=s1>&#39;e.</span><span class=si>{</span><span class=n>event_time_col</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>]</span>
        <span class=p>)</span><span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=s1>&#39;f.feature_timestamp&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>desc</span><span class=p>())</span>

        <span class=n>result</span> <span class=o>=</span> <span class=n>joined</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span><span class=s1>&#39;rank&#39;</span><span class=p>,</span> <span class=n>F</span><span class=o>.</span><span class=n>row_number</span><span class=p>()</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>window_latest</span><span class=p>))</span> \
                      <span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>col</span><span class=p>(</span><span class=s1>&#39;rank&#39;</span><span class=p>)</span> <span class=o>==</span> <span class=mi>1</span><span class=p>)</span> \
                      <span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s1>&#39;rank&#39;</span><span class=p>,</span> <span class=s1>&#39;seq&#39;</span><span class=p>,</span> <span class=s1>&#39;feature_timestamp&#39;</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>result</span>

    <span class=k>def</span><span class=w> </span><span class=nf>handle_missing_values</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>df</span><span class=p>,</span> <span class=n>strategy</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>str</span><span class=p>]):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Handle missing values with column-specific strategies&quot;&quot;&quot;</span>
        <span class=n>result_df</span> <span class=o>=</span> <span class=n>df</span>

        <span class=k>for</span> <span class=n>col</span><span class=p>,</span> <span class=n>method</span> <span class=ow>in</span> <span class=n>strategy</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
            <span class=k>if</span> <span class=n>method</span> <span class=o>==</span> <span class=s1>&#39;mean&#39;</span><span class=p>:</span>
                <span class=n>mean_val</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>col</span><span class=p>))</span><span class=o>.</span><span class=n>first</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
                <span class=n>result_df</span> <span class=o>=</span> <span class=n>result_df</span><span class=o>.</span><span class=n>fillna</span><span class=p>({</span><span class=n>col</span><span class=p>:</span> <span class=n>mean_val</span><span class=p>})</span>
            <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s1>&#39;median&#39;</span><span class=p>:</span>
                <span class=n>median_val</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>approxQuantile</span><span class=p>(</span><span class=n>col</span><span class=p>,</span> <span class=p>[</span><span class=mf>0.5</span><span class=p>],</span> <span class=mf>0.01</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
                <span class=n>result_df</span> <span class=o>=</span> <span class=n>result_df</span><span class=o>.</span><span class=n>fillna</span><span class=p>({</span><span class=n>col</span><span class=p>:</span> <span class=n>median_val</span><span class=p>})</span>
            <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s1>&#39;mode&#39;</span><span class=p>:</span>
                <span class=n>mode_val</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>groupBy</span><span class=p>(</span><span class=n>col</span><span class=p>)</span><span class=o>.</span><span class=n>count</span><span class=p>()</span><span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=s1>&#39;count&#39;</span><span class=p>,</span> <span class=n>ascending</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span><span class=o>.</span><span class=n>first</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span>
                <span class=n>result_df</span> <span class=o>=</span> <span class=n>result_df</span><span class=o>.</span><span class=n>fillna</span><span class=p>({</span><span class=n>col</span><span class=p>:</span> <span class=n>mode_val</span><span class=p>})</span>
            <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s1>&#39;zero&#39;</span><span class=p>:</span>
                <span class=n>result_df</span> <span class=o>=</span> <span class=n>result_df</span><span class=o>.</span><span class=n>fillna</span><span class=p>({</span><span class=n>col</span><span class=p>:</span> <span class=mi>0</span><span class=p>})</span>
            <span class=k>elif</span> <span class=n>method</span> <span class=o>==</span> <span class=s1>&#39;forward_fill&#39;</span><span class=p>:</span>
                <span class=n>window</span> <span class=o>=</span> <span class=n>Window</span><span class=o>.</span><span class=n>partitionBy</span><span class=p>()</span><span class=o>.</span><span class=n>orderBy</span><span class=p>(</span><span class=s1>&#39;timestamp&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>rowsBetween</span><span class=p>(</span><span class=n>Window</span><span class=o>.</span><span class=n>unboundedPreceding</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
                <span class=n>result_df</span> <span class=o>=</span> <span class=n>result_df</span><span class=o>.</span><span class=n>withColumn</span><span class=p>(</span><span class=n>col</span><span class=p>,</span> <span class=n>F</span><span class=o>.</span><span class=n>last</span><span class=p>(</span><span class=n>col</span><span class=p>,</span> <span class=n>ignorenulls</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>over</span><span class=p>(</span><span class=n>window</span><span class=p>))</span>

        <span class=k>return</span> <span class=n>result_df</span>

<span class=c1># ============= Data Lineage Tracker =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>DataLineageTracker</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Track data lineage for reproducibility and debugging&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>lineage_graph</span> <span class=o>=</span> <span class=p>{}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>record_transformation</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>output_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>input_paths</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span>
                             <span class=n>transformation_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>parameters</span><span class=p>:</span> <span class=n>Dict</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Record a data transformation step&quot;&quot;&quot;</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>lineage_graph</span><span class=p>[</span><span class=n>output_path</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;inputs&#39;</span><span class=p>:</span> <span class=n>input_paths</span><span class=p>,</span>
            <span class=s1>&#39;transformation&#39;</span><span class=p>:</span> <span class=n>transformation_name</span><span class=p>,</span>
            <span class=s1>&#39;parameters&#39;</span><span class=p>:</span> <span class=n>parameters</span><span class=p>,</span>
            <span class=s1>&#39;timestamp&#39;</span><span class=p>:</span> <span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>isoformat</span><span class=p>(),</span>
            <span class=s1>&#39;spark_config&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_spark_config</span><span class=p>()</span>
        <span class=p>}</span>

        <span class=c1># Persist to DataHub or custom metadata store</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_persist_lineage</span><span class=p>(</span><span class=n>output_path</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_get_spark_config</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Capture Spark configuration for reproducibility&quot;&quot;&quot;</span>
        <span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span><span class=o>.</span><span class=n>getActiveSession</span><span class=p>()</span>
        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;spark.version&#39;</span><span class=p>:</span> <span class=n>spark</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
            <span class=s1>&#39;spark.executor.memory&#39;</span><span class=p>:</span> <span class=n>spark</span><span class=o>.</span><span class=n>conf</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;spark.executor.memory&#39;</span><span class=p>),</span>
            <span class=s1>&#39;spark.executor.cores&#39;</span><span class=p>:</span> <span class=n>spark</span><span class=o>.</span><span class=n>conf</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;spark.executor.cores&#39;</span><span class=p>)</span>
        <span class=p>}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_persist_lineage</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>output_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Persist lineage metadata to external system (DataHub, Atlas, etc.)&quot;&quot;&quot;</span>
        <span class=c1># Integration with DataHub/Apache Atlas</span>
        <span class=k>pass</span>

<span class=c1># ============= Airflow DAG Definition =============</span>
<span class=n>default_args</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;owner&#39;</span><span class=p>:</span> <span class=s1>&#39;ml-team&#39;</span><span class=p>,</span>
    <span class=s1>&#39;depends_on_past&#39;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
    <span class=s1>&#39;email&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;ml-alerts@company.com&#39;</span><span class=p>],</span>
    <span class=s1>&#39;email_on_failure&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
    <span class=s1>&#39;email_on_retry&#39;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
    <span class=s1>&#39;retries&#39;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span>
    <span class=s1>&#39;retry_delay&#39;</span><span class=p>:</span> <span class=n>timedelta</span><span class=p>(</span><span class=n>minutes</span><span class=o>=</span><span class=mi>5</span><span class=p>),</span>
<span class=p>}</span>

<span class=n>dag</span> <span class=o>=</span> <span class=n>DAG</span><span class=p>(</span>
    <span class=s1>&#39;ml_feature_pipeline&#39;</span><span class=p>,</span>
    <span class=n>default_args</span><span class=o>=</span><span class=n>default_args</span><span class=p>,</span>
    <span class=n>description</span><span class=o>=</span><span class=s1>&#39;Production ML feature engineering pipeline&#39;</span><span class=p>,</span>
    <span class=n>schedule_interval</span><span class=o>=</span><span class=s1>&#39;0 */1 * * *&#39;</span><span class=p>,</span>  <span class=c1># Hourly</span>
    <span class=n>start_date</span><span class=o>=</span><span class=n>datetime</span><span class=p>(</span><span class=mi>2024</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
    <span class=n>catchup</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
    <span class=n>tags</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;ml&#39;</span><span class=p>,</span> <span class=s1>&#39;features&#39;</span><span class=p>,</span> <span class=s1>&#39;production&#39;</span><span class=p>],</span>
<span class=p>)</span>

<span class=k>def</span><span class=w> </span><span class=nf>ingest_data</span><span class=p>(</span><span class=o>**</span><span class=n>context</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Ingest data from various sources&quot;&quot;&quot;</span>
    <span class=n>execution_date</span> <span class=o>=</span> <span class=n>context</span><span class=p>[</span><span class=s1>&#39;execution_date&#39;</span><span class=p>]</span>

    <span class=c1># Example: Ingest from database, APIs, S3</span>
    <span class=c1># This is a placeholder - replace with actual ingestion logic</span>

    <span class=n>output_path</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>config</span><span class=o>.</span><span class=n>raw_data_path</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>execution_date</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s1>&#39;%Y/%m/</span><span class=si>%d</span><span class=s1>/%H&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span>
    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Ingesting data to </span><span class=si>{</span><span class=n>output_path</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>output_path</span>

<span class=k>def</span><span class=w> </span><span class=nf>validate_data_quality</span><span class=p>(</span><span class=o>**</span><span class=n>context</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Run data quality checks&quot;&quot;&quot;</span>
    <span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span><span class=o>.</span><span class=n>builder</span><span class=o>.</span><span class=n>appName</span><span class=p>(</span><span class=s2>&quot;DataQualityCheck&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>getOrCreate</span><span class=p>()</span>
    <span class=n>input_path</span> <span class=o>=</span> <span class=n>context</span><span class=p>[</span><span class=s1>&#39;task_instance&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>xcom_pull</span><span class=p>(</span><span class=n>task_ids</span><span class=o>=</span><span class=s1>&#39;ingest_data&#39;</span><span class=p>)</span>

    <span class=n>df</span> <span class=o>=</span> <span class=n>spark</span><span class=o>.</span><span class=n>read</span><span class=o>.</span><span class=n>parquet</span><span class=p>(</span><span class=n>input_path</span><span class=p>)</span>
    <span class=n>checker</span> <span class=o>=</span> <span class=n>DataQualityChecker</span><span class=p>(</span><span class=n>spark</span><span class=p>)</span>

    <span class=c1># Run all quality checks</span>
    <span class=n>schema_valid</span><span class=p>,</span> <span class=n>schema_issues</span> <span class=o>=</span> <span class=n>checker</span><span class=o>.</span><span class=n>validate_schema</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>expected_schema</span><span class=o>=</span><span class=p>{</span>
        <span class=s1>&#39;user_id&#39;</span><span class=p>:</span> <span class=s1>&#39;string&#39;</span><span class=p>,</span>
        <span class=s1>&#39;timestamp&#39;</span><span class=p>:</span> <span class=s1>&#39;timestamp&#39;</span><span class=p>,</span>
        <span class=s1>&#39;amount&#39;</span><span class=p>:</span> <span class=s1>&#39;double&#39;</span>
    <span class=p>})</span>

    <span class=n>nulls_valid</span><span class=p>,</span> <span class=n>null_stats</span> <span class=o>=</span> <span class=n>checker</span><span class=o>.</span><span class=n>check_nulls</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>max_null_pct</span><span class=o>=</span><span class=mf>0.05</span><span class=p>)</span>
    <span class=n>dup_count</span><span class=p>,</span> <span class=n>dup_rate</span> <span class=o>=</span> <span class=n>checker</span><span class=o>.</span><span class=n>detect_duplicates</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=p>[</span><span class=s1>&#39;user_id&#39;</span><span class=p>,</span> <span class=s1>&#39;timestamp&#39;</span><span class=p>])</span>

    <span class=c1># Fail if quality below threshold</span>
    <span class=k>if</span> <span class=ow>not</span> <span class=n>schema_valid</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>nulls_valid</span> <span class=ow>or</span> <span class=n>dup_rate</span> <span class=o>&gt;</span> <span class=mf>0.01</span><span class=p>:</span>
        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Data quality check failed: </span><span class=si>{</span><span class=n>schema_issues</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Data quality passed: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>columns</span><span class=p>)</span><span class=si>}</span><span class=s2> columns, </span><span class=si>{</span><span class=n>df</span><span class=o>.</span><span class=n>count</span><span class=p>()</span><span class=si>}</span><span class=s2> rows&quot;</span><span class=p>)</span>
    <span class=n>spark</span><span class=o>.</span><span class=n>stop</span><span class=p>()</span>

<span class=c1># Define Airflow tasks</span>
<span class=n>ingest_task</span> <span class=o>=</span> <span class=n>PythonOperator</span><span class=p>(</span>
    <span class=n>task_id</span><span class=o>=</span><span class=s1>&#39;ingest_data&#39;</span><span class=p>,</span>
    <span class=n>python_callable</span><span class=o>=</span><span class=n>ingest_data</span><span class=p>,</span>
    <span class=n>dag</span><span class=o>=</span><span class=n>dag</span><span class=p>,</span>
<span class=p>)</span>

<span class=n>quality_check_task</span> <span class=o>=</span> <span class=n>PythonOperator</span><span class=p>(</span>
    <span class=n>task_id</span><span class=o>=</span><span class=s1>&#39;validate_data_quality&#39;</span><span class=p>,</span>
    <span class=n>python_callable</span><span class=o>=</span><span class=n>validate_data_quality</span><span class=p>,</span>
    <span class=n>dag</span><span class=o>=</span><span class=n>dag</span><span class=p>,</span>
<span class=p>)</span>

<span class=n>feature_engineering_task</span> <span class=o>=</span> <span class=n>SparkSubmitOperator</span><span class=p>(</span>
    <span class=n>task_id</span><span class=o>=</span><span class=s1>&#39;feature_engineering&#39;</span><span class=p>,</span>
    <span class=n>application</span><span class=o>=</span><span class=s1>&#39;feature_engineering.py&#39;</span><span class=p>,</span>
    <span class=n>conf</span><span class=o>=</span><span class=p>{</span>
        <span class=s1>&#39;spark.executor.memory&#39;</span><span class=p>:</span> <span class=s1>&#39;8g&#39;</span><span class=p>,</span>
        <span class=s1>&#39;spark.executor.cores&#39;</span><span class=p>:</span> <span class=s1>&#39;4&#39;</span><span class=p>,</span>
        <span class=s1>&#39;spark.dynamicAllocation.enabled&#39;</span><span class=p>:</span> <span class=s1>&#39;true&#39;</span>
    <span class=p>},</span>
    <span class=n>dag</span><span class=o>=</span><span class=n>dag</span><span class=p>,</span>
<span class=p>)</span>

<span class=c1># Define task dependencies</span>
<span class=n>ingest_task</span> <span class=o>&gt;&gt;</span> <span class=n>quality_check_task</span> <span class=o>&gt;&gt;</span> <span class=n>feature_engineering_task</span>
</code></pre></div> <h2 id=technology-stack-comparison>Technology Stack Comparison</h2> <table> <thead> <tr> <th>Layer</th> <th>Tool Options</th> <th>When to Use</th> </tr> </thead> <tbody> <tr> <td><strong>Orchestration</strong></td> <td>Airflow, Prefect, Dagster</td> <td>Airflow: mature ecosystem; Prefect: dynamic DAGs; Dagster: asset-based</td> </tr> <tr> <td><strong>Batch Processing</strong></td> <td>Spark, Dask, Ray</td> <td>Spark: PB-scale; Dask: Python-native; Ray: ML workloads</td> </tr> <tr> <td><strong>Stream Processing</strong></td> <td>Flink, Spark Streaming, Kafka Streams</td> <td>Flink: exactly-once, low latency; Spark: batch+stream; Kafka: simple</td> </tr> <tr> <td><strong>Storage</strong></td> <td>S3, GCS, ADLS, HDFS</td> <td>Cloud: S3/GCS/ADLS; On-prem: HDFS</td> </tr> <tr> <td><strong>Format</strong></td> <td>Parquet, ORC, Delta Lake, Hudi</td> <td>Parquet: read-heavy; Delta/Hudi: ACID, time travel</td> </tr> <tr> <td><strong>Data Quality</strong></td> <td>Great Expectations, Deequ, Soda</td> <td>GE: Python; Deequ: Spark/Scala; Soda: SQL-based</td> </tr> <tr> <td><strong>Metadata</strong></td> <td>DataHub, Apache Atlas, Amundsen</td> <td>DataHub: modern; Atlas: Hadoop ecosystem; Amundsen: search-focused</td> </tr> </tbody> </table> <h2 id=common-pitfalls-solutions>Common Pitfalls &amp; Solutions</h2> <table> <thead> <tr> <th>Pitfall</th> <th>Impact</th> <th>Solution</th> </tr> </thead> <tbody> <tr> <td><strong>Data Leakage</strong></td> <td>Train/test contamination</td> <td>Use point-in-time joins, strict temporal splits</td> </tr> <tr> <td><strong>Schema Drift</strong></td> <td>Pipeline failures</td> <td>Schema evolution with backward compatibility</td> </tr> <tr> <td><strong>Late-Arriving Data</strong></td> <td>Incomplete features</td> <td>Watermarks, reprocessing windows</td> </tr> <tr> <td><strong>Duplicate Records</strong></td> <td>Inflated metrics</td> <td>Deduplication with unique keys</td> </tr> <tr> <td><strong>Missing Values</strong></td> <td>Biased models</td> <td>Strategy per column (imputation/drop/flag)</td> </tr> <tr> <td><strong>Skewed Partitions</strong></td> <td>Slow jobs</td> <td>Salting, repartitioning, broadcast joins</td> </tr> <tr> <td><strong>No Data Versioning</strong></td> <td>Irreproducible results</td> <td>DVC, Delta Lake, manifest files</td> </tr> <tr> <td><strong>Insufficient Monitoring</strong></td> <td>Silent failures</td> <td>Data quality alerts, pipeline SLAs</td> </tr> </tbody> </table> <h2 id=real-world-examples>Real-World Examples</h2> <p><strong>Uber's Michelangelo:</strong> - <strong>Scale:</strong> 10K+ features, 100M+ predictions/day - <strong>Architecture:</strong> Kafka ‚Üí Flink ‚Üí Cassandra (online), Hive (offline) - <strong>Feature Store:</strong> Point-in-time correct joins, feature monitoring - <strong>Impact:</strong> Reduced feature engineering time by 70%</p> <p><strong>Netflix's Data Pipeline:</strong> - <strong>Scale:</strong> 500TB+ daily, 1.3PB total - <strong>Tools:</strong> S3 ‚Üí Spark ‚Üí Iceberg ‚Üí Presto - <strong>Features:</strong> Schema evolution, time travel, data quality checks - <strong>Impact:</strong> Powers 800+ data scientists, 100K+ jobs/day</p> <p><strong>Airbnb's Zipline:</strong> - <strong>Scale:</strong> 6K+ features, 10M+ bookings/day - <strong>Architecture:</strong> Airflow ‚Üí Spark ‚Üí Hive (offline), Redis (online) - <strong>Innovation:</strong> Feature freshness SLAs, automatic backfills - <strong>Impact:</strong> 80% reduction in feature development time</p> <h2 id=monitoring-debugging>Monitoring &amp; Debugging</h2> <div class=highlight><pre><span></span><code><span class=c1># Pipeline metrics to track</span>
<span class=n>metrics</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;data_volume&#39;</span><span class=p>:</span> <span class=s1>&#39;Input/output row counts&#39;</span><span class=p>,</span>
    <span class=s1>&#39;latency&#39;</span><span class=p>:</span> <span class=s1>&#39;End-to-end pipeline duration&#39;</span><span class=p>,</span>
    <span class=s1>&#39;data_quality&#39;</span><span class=p>:</span> <span class=s1>&#39;Null rate, duplicate rate, schema violations&#39;</span><span class=p>,</span>
    <span class=s1>&#39;freshness&#39;</span><span class=p>:</span> <span class=s1>&#39;Time from data creation to availability&#39;</span><span class=p>,</span>
    <span class=s1>&#39;resource_usage&#39;</span><span class=p>:</span> <span class=s1>&#39;CPU, memory, disk I/O per stage&#39;</span><span class=p>,</span>
    <span class=s1>&#39;failure_rate&#39;</span><span class=p>:</span> <span class=s1>&#39;Task failures, retries, SLA misses&#39;</span>
<span class=p>}</span>

<span class=c1># Alerting thresholds</span>
<span class=n>alerts</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;data_volume_drop&#39;</span><span class=p>:</span> <span class=s1>&#39;Alert if &lt;80</span><span class=si>% o</span><span class=s1>f expected volume&#39;</span><span class=p>,</span>
    <span class=s1>&#39;latency_spike&#39;</span><span class=p>:</span> <span class=s1>&#39;Alert if p99 &gt; 2x baseline&#39;</span><span class=p>,</span>
    <span class=s1>&#39;quality_drop&#39;</span><span class=p>:</span> <span class=s1>&#39;Alert if quality score &lt; 95%&#39;</span><span class=p>,</span>
    <span class=s1>&#39;freshness_lag&#39;</span><span class=p>:</span> <span class=s1>&#39;Alert if data &gt;4 hours old&#39;</span>
<span class=p>}</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Emphasizes point-in-time correctness, data quality, and lineage tracking. Discusses trade-offs between batch and streaming, shows knowledge of Great Expectations/Deequ, and understands schema evolution. Can explain how Uber/Netflix/Airbnb implement feature stores at scale.</p> </div> </details> <hr> <h3 id=design-a-model-registry-google-amazon-interview-question>Design a Model Registry - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>MLOps</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <h2 id=scale-requirements_1>Scale Requirements</h2> <ul> <li><strong>Models:</strong> 100-10K registered models</li> <li><strong>Versions:</strong> 10-1K versions per model</li> <li><strong>Metadata:</strong> 100KB-10MB per model (metrics, params, artifacts)</li> <li><strong>Throughput:</strong> 1K-100K model queries/day</li> <li><strong>Storage:</strong> 10GB-10TB (model binaries + artifacts)</li> <li><strong>Latency:</strong> &lt;100ms for metadata queries, &lt;1s for model downloads</li> <li><strong>Users:</strong> 10-1K data scientists/engineers</li> </ul> <h2 id=architecture_1>Architecture</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Training Environment                          ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  [Notebook/Script] ‚Üí MLflow Client ‚Üí Model Registry API        ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Logs: model, metrics, params, artifacts, tags                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Model Registry (MLflow Server)                  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ            Metadata Store (PostgreSQL/MySQL)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Model names &amp; versions                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Metrics (accuracy, F1, AUC)                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Parameters (hyperparameters)                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Tags &amp; descriptions                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Stage (None/Staging/Production/Archived)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Lineage (dataset version, code commit)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - User &amp; timestamp                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Artifact Store (S3/GCS/Azure Blob/HDFS)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Model binaries (pickle, ONNX, SavedModel)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Feature preprocessors                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Training/validation datasets (samples)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Plots &amp; visualizations                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Model cards &amp; documentation                            ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Model Lifecycle Management                    ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Stage Transitions:                                             ‚îÇ
‚îÇ  None ‚Üí Staging ‚Üí Production ‚Üí Archived                        ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Approval Workflow:                                             ‚îÇ
‚îÇ  1. Register model (None)                                       ‚îÇ
‚îÇ  2. Validation tests ‚Üí Staging                                  ‚îÇ
‚îÇ  3. A/B test ‚Üí Production (with approval)                       ‚îÇ
‚îÇ  4. Superseded ‚Üí Archived                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Serving &amp; Deployment                           ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  [Model Serving] ‚Üê Load model by stage or version              ‚îÇ
‚îÇ  [CI/CD Pipeline] ‚Üê Trigger deploy on stage change             ‚îÇ
‚îÇ  [Monitoring] ‚Üê Track production model performance              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ      Cross-Cutting Features          ‚îÇ
         ‚îÇ                                      ‚îÇ
         ‚îÇ  - Access Control (RBAC)            ‚îÇ
         ‚îÇ  - Model Comparison (side-by-side)  ‚îÇ
         ‚îÇ  - Search &amp; Discovery               ‚îÇ
         ‚îÇ  - Webhooks (stage change alerts)   ‚îÇ
         ‚îÇ  - Model Card Generation            ‚îÇ
         ‚îÇ  - Reproducibility (env capture)    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=production-implementation-280-lines>Production Implementation (280 lines)</h2> <div class=highlight><pre><span></span><code><span class=c1># model_registry.py</span>
<span class=kn>import</span><span class=w> </span><span class=nn>mlflow</span>
<span class=kn>from</span><span class=w> </span><span class=nn>mlflow.tracking</span><span class=w> </span><span class=kn>import</span> <span class=n>MlflowClient</span>
<span class=kn>from</span><span class=w> </span><span class=nn>mlflow.models.signature</span><span class=w> </span><span class=kn>import</span> <span class=n>infer_signature</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>List</span><span class=p>,</span> <span class=n>Optional</span><span class=p>,</span> <span class=n>Any</span>
<span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>datetime</span><span class=w> </span><span class=kn>import</span> <span class=n>datetime</span>
<span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span>
<span class=kn>import</span><span class=w> </span><span class=nn>json</span>
<span class=kn>import</span><span class=w> </span><span class=nn>logging</span>
<span class=kn>from</span><span class=w> </span><span class=nn>enum</span><span class=w> </span><span class=kn>import</span> <span class=n>Enum</span>

<span class=c1># ============= Configuration =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>ModelStage</span><span class=p>(</span><span class=n>Enum</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Model lifecycle stages&quot;&quot;&quot;</span>
    <span class=n>NONE</span> <span class=o>=</span> <span class=s2>&quot;None&quot;</span>
    <span class=n>STAGING</span> <span class=o>=</span> <span class=s2>&quot;Staging&quot;</span>
    <span class=n>PRODUCTION</span> <span class=o>=</span> <span class=s2>&quot;Production&quot;</span>
    <span class=n>ARCHIVED</span> <span class=o>=</span> <span class=s2>&quot;Archived&quot;</span>

<span class=nd>@dataclass</span>
<span class=k>class</span><span class=w> </span><span class=nc>ModelRegistryConfig</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Model registry configuration&quot;&quot;&quot;</span>
    <span class=n>tracking_uri</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;http://mlflow-server:5000&quot;</span>
    <span class=n>artifact_location</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;s3://ml-models&quot;</span>
    <span class=n>experiment_name</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;default&quot;</span>
    <span class=n>min_accuracy_staging</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.80</span>
    <span class=n>min_accuracy_production</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.90</span>

<span class=n>config</span> <span class=o>=</span> <span class=n>ModelRegistryConfig</span><span class=p>()</span>

<span class=c1># ============= Model Registry Client =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>ModelRegistry</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Production model registry with lifecycle management&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>ModelRegistryConfig</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
        <span class=n>mlflow</span><span class=o>.</span><span class=n>set_tracking_uri</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>tracking_uri</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>client</span> <span class=o>=</span> <span class=n>MlflowClient</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>register_model</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>model</span><span class=p>:</span> <span class=n>Any</span><span class=p>,</span>
        <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>X_sample</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span>
        <span class=n>y_sample</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span>
        <span class=n>metrics</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>],</span>
        <span class=n>params</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
        <span class=n>tags</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>str</span><span class=p>]]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
        <span class=n>artifacts</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>str</span><span class=p>]]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
        <span class=n>description</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;&quot;</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Register a new model with comprehensive metadata</span>

<span class=sd>        Returns: model_version (e.g., &quot;1&quot;, &quot;2&quot;, etc.)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=c1># Start MLflow run</span>
        <span class=k>with</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>start_run</span><span class=p>()</span> <span class=k>as</span> <span class=n>run</span><span class=p>:</span>
            <span class=c1># Log parameters</span>
            <span class=n>mlflow</span><span class=o>.</span><span class=n>log_params</span><span class=p>(</span><span class=n>params</span><span class=p>)</span>

            <span class=c1># Log metrics</span>
            <span class=n>mlflow</span><span class=o>.</span><span class=n>log_metrics</span><span class=p>(</span><span class=n>metrics</span><span class=p>)</span>

            <span class=c1># Log tags</span>
            <span class=k>if</span> <span class=n>tags</span><span class=p>:</span>
                <span class=n>mlflow</span><span class=o>.</span><span class=n>set_tags</span><span class=p>(</span><span class=n>tags</span><span class=p>)</span>

            <span class=c1># Infer model signature for input/output validation</span>
            <span class=n>signature</span> <span class=o>=</span> <span class=n>infer_signature</span><span class=p>(</span><span class=n>X_sample</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_sample</span><span class=p>))</span>

            <span class=c1># Log model with signature</span>
            <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>log_model</span><span class=p>(</span>
                <span class=n>model</span><span class=p>,</span>
                <span class=n>artifact_path</span><span class=o>=</span><span class=s2>&quot;model&quot;</span><span class=p>,</span>
                <span class=n>signature</span><span class=o>=</span><span class=n>signature</span><span class=p>,</span>
                <span class=n>registered_model_name</span><span class=o>=</span><span class=n>model_name</span>
            <span class=p>)</span>

            <span class=c1># Log additional artifacts (plots, datasets, etc.)</span>
            <span class=k>if</span> <span class=n>artifacts</span><span class=p>:</span>
                <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>path</span> <span class=ow>in</span> <span class=n>artifacts</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
                    <span class=n>mlflow</span><span class=o>.</span><span class=n>log_artifact</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>artifact_path</span><span class=o>=</span><span class=n>name</span><span class=p>)</span>

            <span class=c1># Log dataset samples for reproducibility</span>
            <span class=n>train_data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>X_sample</span><span class=p>)</span>
            <span class=n>train_data</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>y_sample</span>
            <span class=n>mlflow</span><span class=o>.</span><span class=n>log_input</span><span class=p>(</span>
                <span class=n>mlflow</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>from_pandas</span><span class=p>(</span><span class=n>train_data</span><span class=p>),</span>
                <span class=n>context</span><span class=o>=</span><span class=s2>&quot;training&quot;</span>
            <span class=p>)</span>

            <span class=n>run_id</span> <span class=o>=</span> <span class=n>run</span><span class=o>.</span><span class=n>info</span><span class=o>.</span><span class=n>run_id</span>

        <span class=c1># Get the registered model version</span>
        <span class=n>model_version</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_latest_version</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>

        <span class=c1># Add model description</span>
        <span class=k>if</span> <span class=n>description</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>update_model_version</span><span class=p>(</span>
                <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
                <span class=n>version</span><span class=o>=</span><span class=n>model_version</span><span class=p>,</span>
                <span class=n>description</span><span class=o>=</span><span class=n>description</span>
            <span class=p>)</span>

        <span class=c1># Log lineage information</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_log_lineage</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>model_version</span><span class=p>,</span> <span class=n>params</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Registered </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2> v</span><span class=si>{</span><span class=n>model_version</span><span class=si>}</span><span class=s2> (run_id: </span><span class=si>{</span><span class=n>run_id</span><span class=si>}</span><span class=s2>)&quot;</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>model_version</span>

    <span class=k>def</span><span class=w> </span><span class=nf>transition_stage</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>version</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>stage</span><span class=p>:</span> <span class=n>ModelStage</span><span class=p>,</span>
        <span class=n>archive_existing</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>bool</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Transition model to a new stage with validation</span>

<span class=sd>        Returns: True if transition successful</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=c1># Validate model meets requirements for the stage</span>
            <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>_validate_for_stage</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>,</span> <span class=n>stage</span><span class=p>):</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Model </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2> v</span><span class=si>{</span><span class=n>version</span><span class=si>}</span><span class=s2> failed validation for </span><span class=si>{</span><span class=n>stage</span><span class=o>.</span><span class=n>value</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
                <span class=k>return</span> <span class=kc>False</span>

            <span class=c1># Archive existing models in target stage if requested</span>
            <span class=k>if</span> <span class=n>archive_existing</span> <span class=ow>and</span> <span class=n>stage</span> <span class=ow>in</span> <span class=p>[</span><span class=n>ModelStage</span><span class=o>.</span><span class=n>STAGING</span><span class=p>,</span> <span class=n>ModelStage</span><span class=o>.</span><span class=n>PRODUCTION</span><span class=p>]:</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>_archive_existing_models</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>stage</span><span class=p>)</span>

            <span class=c1># Transition to new stage</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>transition_model_version_stage</span><span class=p>(</span>
                <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
                <span class=n>version</span><span class=o>=</span><span class=n>version</span><span class=p>,</span>
                <span class=n>stage</span><span class=o>=</span><span class=n>stage</span><span class=o>.</span><span class=n>value</span><span class=p>,</span>
                <span class=n>archive_existing_versions</span><span class=o>=</span><span class=n>archive_existing</span>
            <span class=p>)</span>

            <span class=c1># Send notification (webhook, Slack, email, etc.)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_notify_stage_change</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>,</span> <span class=n>stage</span><span class=p>)</span>

            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Transitioned </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2> v</span><span class=si>{</span><span class=n>version</span><span class=si>}</span><span class=s2> to </span><span class=si>{</span><span class=n>stage</span><span class=o>.</span><span class=n>value</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
            <span class=k>return</span> <span class=kc>True</span>

        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Stage transition failed: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
            <span class=k>return</span> <span class=kc>False</span>

    <span class=k>def</span><span class=w> </span><span class=nf>get_model</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>version</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
        <span class=n>stage</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>ModelStage</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Any</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Load a model by version or stage</span>

<span class=sd>        If both version and stage are None, returns latest production model</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=n>version</span><span class=p>:</span>
            <span class=n>model_uri</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;models:/</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>version</span><span class=si>}</span><span class=s2>&quot;</span>
        <span class=k>elif</span> <span class=n>stage</span><span class=p>:</span>
            <span class=n>model_uri</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;models:/</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>stage</span><span class=o>.</span><span class=n>value</span><span class=si>}</span><span class=s2>&quot;</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>model_uri</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;models:/</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>/Production&quot;</span>

        <span class=k>try</span><span class=p>:</span>
            <span class=n>model</span> <span class=o>=</span> <span class=n>mlflow</span><span class=o>.</span><span class=n>sklearn</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=n>model_uri</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Loaded model from </span><span class=si>{</span><span class=n>model_uri</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
            <span class=k>return</span> <span class=n>model</span>
        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Failed to load model: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
            <span class=k>raise</span>

    <span class=k>def</span><span class=w> </span><span class=nf>compare_models</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>versions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span>
        <span class=n>metrics</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Compare multiple versions of a model side-by-side</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>comparison_data</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=k>for</span> <span class=n>version</span> <span class=ow>in</span> <span class=n>versions</span><span class=p>:</span>
            <span class=k>try</span><span class=p>:</span>
                <span class=c1># Get model version details</span>
                <span class=n>mv</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>get_model_version</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>)</span>

                <span class=c1># Get run metrics</span>
                <span class=n>run</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>get_run</span><span class=p>(</span><span class=n>mv</span><span class=o>.</span><span class=n>run_id</span><span class=p>)</span>
                <span class=n>metrics_data</span> <span class=o>=</span> <span class=p>{</span><span class=n>m</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>m</span><span class=p>)</span> <span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=n>metrics</span><span class=p>}</span>

                <span class=n>comparison_data</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
                    <span class=s1>&#39;version&#39;</span><span class=p>:</span> <span class=n>version</span><span class=p>,</span>
                    <span class=s1>&#39;stage&#39;</span><span class=p>:</span> <span class=n>mv</span><span class=o>.</span><span class=n>current_stage</span><span class=p>,</span>
                    <span class=s1>&#39;created&#39;</span><span class=p>:</span> <span class=n>datetime</span><span class=o>.</span><span class=n>fromtimestamp</span><span class=p>(</span><span class=n>mv</span><span class=o>.</span><span class=n>creation_timestamp</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>),</span>
                    <span class=o>**</span><span class=n>metrics_data</span>
                <span class=p>})</span>
            <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Skipping version </span><span class=si>{</span><span class=n>version</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>comparison_data</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>search_models</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>filter_string</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;&quot;</span><span class=p>,</span>
        <span class=n>max_results</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>100</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=n>Dict</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Search for models using filter syntax</span>

<span class=sd>        Examples:</span>
<span class=sd>        - &quot;name=&#39;fraud_detector&#39;&quot;</span>
<span class=sd>        - &quot;tags.team=&#39;risk&#39;&quot;</span>
<span class=sd>        - &quot;run.metrics.accuracy &gt; 0.9&quot;</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>results</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>search_model_versions</span><span class=p>(</span>
            <span class=n>filter_string</span><span class=o>=</span><span class=n>filter_string</span><span class=p>,</span>
            <span class=n>max_results</span><span class=o>=</span><span class=n>max_results</span>
        <span class=p>)</span>

        <span class=k>return</span> <span class=p>[{</span>
            <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=n>mv</span><span class=o>.</span><span class=n>name</span><span class=p>,</span>
            <span class=s1>&#39;version&#39;</span><span class=p>:</span> <span class=n>mv</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
            <span class=s1>&#39;stage&#39;</span><span class=p>:</span> <span class=n>mv</span><span class=o>.</span><span class=n>current_stage</span><span class=p>,</span>
            <span class=s1>&#39;run_id&#39;</span><span class=p>:</span> <span class=n>mv</span><span class=o>.</span><span class=n>run_id</span><span class=p>,</span>
            <span class=s1>&#39;created&#39;</span><span class=p>:</span> <span class=n>datetime</span><span class=o>.</span><span class=n>fromtimestamp</span><span class=p>(</span><span class=n>mv</span><span class=o>.</span><span class=n>creation_timestamp</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>)</span>
        <span class=p>}</span> <span class=k>for</span> <span class=n>mv</span> <span class=ow>in</span> <span class=n>results</span><span class=p>]</span>

    <span class=k>def</span><span class=w> </span><span class=nf>get_model_lineage</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>version</span><span class=p>:</span> <span class=nb>str</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Get full lineage: dataset, code, dependencies</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>mv</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>get_model_version</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>)</span>
        <span class=n>run</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>get_run</span><span class=p>(</span><span class=n>mv</span><span class=o>.</span><span class=n>run_id</span><span class=p>)</span>

        <span class=n>lineage</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;model&#39;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=n>model_name</span><span class=p>,</span>
                <span class=s1>&#39;version&#39;</span><span class=p>:</span> <span class=n>version</span><span class=p>,</span>
                <span class=s1>&#39;created&#39;</span><span class=p>:</span> <span class=n>datetime</span><span class=o>.</span><span class=n>fromtimestamp</span><span class=p>(</span><span class=n>mv</span><span class=o>.</span><span class=n>creation_timestamp</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>)</span>
            <span class=p>},</span>
            <span class=s1>&#39;training&#39;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s1>&#39;run_id&#39;</span><span class=p>:</span> <span class=n>mv</span><span class=o>.</span><span class=n>run_id</span><span class=p>,</span>
                <span class=s1>&#39;user&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>info</span><span class=o>.</span><span class=n>user_id</span><span class=p>,</span>
                <span class=s1>&#39;start_time&#39;</span><span class=p>:</span> <span class=n>datetime</span><span class=o>.</span><span class=n>fromtimestamp</span><span class=p>(</span><span class=n>run</span><span class=o>.</span><span class=n>info</span><span class=o>.</span><span class=n>start_time</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>)</span>
            <span class=p>},</span>
            <span class=s1>&#39;data&#39;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s1>&#39;dataset_version&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>tags</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;dataset_version&#39;</span><span class=p>),</span>
                <span class=s1>&#39;data_path&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>tags</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;data_path&#39;</span><span class=p>)</span>
            <span class=p>},</span>
            <span class=s1>&#39;code&#39;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s1>&#39;git_commit&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>tags</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;git_commit&#39;</span><span class=p>),</span>
                <span class=s1>&#39;git_branch&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>tags</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;git_branch&#39;</span><span class=p>),</span>
                <span class=s1>&#39;code_version&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>tags</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;code_version&#39;</span><span class=p>)</span>
            <span class=p>},</span>
            <span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>params</span><span class=p>,</span>
            <span class=s1>&#39;metrics&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>metrics</span><span class=p>,</span>
            <span class=s1>&#39;tags&#39;</span><span class=p>:</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>tags</span>
        <span class=p>}</span>

        <span class=k>return</span> <span class=n>lineage</span>

    <span class=k>def</span><span class=w> </span><span class=nf>delete_model_version</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>version</span><span class=p>:</span> <span class=nb>str</span>
    <span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Delete a specific model version (only if not in Production)</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>mv</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>get_model_version</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>mv</span><span class=o>.</span><span class=n>current_stage</span> <span class=o>==</span> <span class=n>ModelStage</span><span class=o>.</span><span class=n>PRODUCTION</span><span class=o>.</span><span class=n>value</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&quot;Cannot delete model in Production stage&quot;</span><span class=p>)</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>delete_model_version</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Deleted </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2> v</span><span class=si>{</span><span class=n>version</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># ============= Private Helper Methods =============</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_get_latest_version</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Get the latest version number for a model&quot;&quot;&quot;</span>
        <span class=n>versions</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>search_model_versions</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;name=&#39;</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#39;&quot;</span><span class=p>)</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>versions</span><span class=p>:</span>
            <span class=k>return</span> <span class=s2>&quot;1&quot;</span>
        <span class=k>return</span> <span class=nb>max</span><span class=p>([</span><span class=nb>int</span><span class=p>(</span><span class=n>v</span><span class=o>.</span><span class=n>version</span><span class=p>)</span> <span class=k>for</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>versions</span><span class=p>])</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_validate_for_stage</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>version</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>stage</span><span class=p>:</span> <span class=n>ModelStage</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>bool</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Validate model meets requirements for stage&quot;&quot;&quot;</span>
        <span class=n>mv</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>get_model_version</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>)</span>
        <span class=n>run</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>get_run</span><span class=p>(</span><span class=n>mv</span><span class=o>.</span><span class=n>run_id</span><span class=p>)</span>

        <span class=n>accuracy</span> <span class=o>=</span> <span class=n>run</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>

        <span class=k>if</span> <span class=n>stage</span> <span class=o>==</span> <span class=n>ModelStage</span><span class=o>.</span><span class=n>STAGING</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>accuracy</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>min_accuracy_staging</span>
        <span class=k>elif</span> <span class=n>stage</span> <span class=o>==</span> <span class=n>ModelStage</span><span class=o>.</span><span class=n>PRODUCTION</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>accuracy</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>min_accuracy_production</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>return</span> <span class=kc>True</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_archive_existing_models</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>stage</span><span class=p>:</span> <span class=n>ModelStage</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Archive all models currently in the target stage&quot;&quot;&quot;</span>
        <span class=n>versions</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>search_model_versions</span><span class=p>(</span>
            <span class=sa>f</span><span class=s2>&quot;name=&#39;</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#39; AND current_stage=&#39;</span><span class=si>{</span><span class=n>stage</span><span class=o>.</span><span class=n>value</span><span class=si>}</span><span class=s2>&#39;&quot;</span>
        <span class=p>)</span>

        <span class=k>for</span> <span class=n>mv</span> <span class=ow>in</span> <span class=n>versions</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>transition_model_version_stage</span><span class=p>(</span>
                <span class=n>name</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
                <span class=n>version</span><span class=o>=</span><span class=n>mv</span><span class=o>.</span><span class=n>version</span><span class=p>,</span>
                <span class=n>stage</span><span class=o>=</span><span class=n>ModelStage</span><span class=o>.</span><span class=n>ARCHIVED</span><span class=o>.</span><span class=n>value</span>
            <span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_log_lineage</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>version</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>params</span><span class=p>:</span> <span class=n>Dict</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Log lineage information to external system (DataHub, etc.)&quot;&quot;&quot;</span>
        <span class=c1># Integration point for lineage tracking systems</span>
        <span class=k>pass</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_notify_stage_change</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>version</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>stage</span><span class=p>:</span> <span class=n>ModelStage</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Send notification about stage change (Slack, PagerDuty, etc.)&quot;&quot;&quot;</span>
        <span class=n>message</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;Model </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2> v</span><span class=si>{</span><span class=n>version</span><span class=si>}</span><span class=s2> transitioned to </span><span class=si>{</span><span class=n>stage</span><span class=o>.</span><span class=n>value</span><span class=si>}</span><span class=s2>&quot;</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Notification: </span><span class=si>{</span><span class=n>message</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=c1># Integration with notification systems</span>

<span class=c1># ============= Usage Example =============</span>
<span class=k>def</span><span class=w> </span><span class=nf>example_workflow</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;End-to-end example of model registry workflow&quot;&quot;&quot;</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>sklearn.ensemble</span><span class=w> </span><span class=kn>import</span> <span class=n>RandomForestClassifier</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>make_classification</span>

    <span class=c1># Initialize registry</span>
    <span class=n>registry</span> <span class=o>=</span> <span class=n>ModelRegistry</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>

    <span class=c1># 1. Train model</span>
    <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>make_classification</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>n_features</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span>
    <span class=n>model</span> <span class=o>=</span> <span class=n>RandomForestClassifier</span><span class=p>(</span><span class=n>n_estimators</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>max_depth</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
    <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>

    <span class=c1># Calculate metrics</span>
    <span class=n>train_accuracy</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>

    <span class=c1># 2. Register model</span>
    <span class=n>version</span> <span class=o>=</span> <span class=n>registry</span><span class=o>.</span><span class=n>register_model</span><span class=p>(</span>
        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
        <span class=n>model_name</span><span class=o>=</span><span class=s2>&quot;fraud_detector&quot;</span><span class=p>,</span>
        <span class=n>X_sample</span><span class=o>=</span><span class=n>X</span><span class=p>[:</span><span class=mi>100</span><span class=p>],</span>
        <span class=n>y_sample</span><span class=o>=</span><span class=n>y</span><span class=p>[:</span><span class=mi>100</span><span class=p>],</span>
        <span class=n>metrics</span><span class=o>=</span><span class=p>{</span>
            <span class=s1>&#39;accuracy&#39;</span><span class=p>:</span> <span class=n>train_accuracy</span><span class=p>,</span>
            <span class=s1>&#39;n_estimators&#39;</span><span class=p>:</span> <span class=mi>100</span>
        <span class=p>},</span>
        <span class=n>params</span><span class=o>=</span><span class=p>{</span>
            <span class=s1>&#39;max_depth&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>,</span>
            <span class=s1>&#39;min_samples_split&#39;</span><span class=p>:</span> <span class=mi>2</span>
        <span class=p>},</span>
        <span class=n>tags</span><span class=o>=</span><span class=p>{</span>
            <span class=s1>&#39;team&#39;</span><span class=p>:</span> <span class=s1>&#39;risk&#39;</span><span class=p>,</span>
            <span class=s1>&#39;git_commit&#39;</span><span class=p>:</span> <span class=s1>&#39;abc123&#39;</span><span class=p>,</span>
            <span class=s1>&#39;dataset_version&#39;</span><span class=p>:</span> <span class=s1>&#39;v1.0&#39;</span>
        <span class=p>},</span>
        <span class=n>description</span><span class=o>=</span><span class=s2>&quot;Fraud detection model using Random Forest&quot;</span>
    <span class=p>)</span>

    <span class=c1># 3. Transition to Staging</span>
    <span class=n>registry</span><span class=o>.</span><span class=n>transition_stage</span><span class=p>(</span>
        <span class=n>model_name</span><span class=o>=</span><span class=s2>&quot;fraud_detector&quot;</span><span class=p>,</span>
        <span class=n>version</span><span class=o>=</span><span class=n>version</span><span class=p>,</span>
        <span class=n>stage</span><span class=o>=</span><span class=n>ModelStage</span><span class=o>.</span><span class=n>STAGING</span>
    <span class=p>)</span>

    <span class=c1># 4. Compare with other versions</span>
    <span class=n>comparison</span> <span class=o>=</span> <span class=n>registry</span><span class=o>.</span><span class=n>compare_models</span><span class=p>(</span>
        <span class=n>model_name</span><span class=o>=</span><span class=s2>&quot;fraud_detector&quot;</span><span class=p>,</span>
        <span class=n>versions</span><span class=o>=</span><span class=p>[</span><span class=n>version</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>version</span><span class=p>)</span><span class=o>-</span><span class=mi>1</span><span class=p>)]</span> <span class=k>if</span> <span class=nb>int</span><span class=p>(</span><span class=n>version</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>1</span> <span class=k>else</span> <span class=p>[</span><span class=n>version</span><span class=p>],</span>
        <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>,</span> <span class=s1>&#39;n_estimators&#39;</span><span class=p>]</span>
    <span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>comparison</span><span class=p>)</span>

    <span class=c1># 5. Promote to Production (after validation)</span>
    <span class=n>registry</span><span class=o>.</span><span class=n>transition_stage</span><span class=p>(</span>
        <span class=n>model_name</span><span class=o>=</span><span class=s2>&quot;fraud_detector&quot;</span><span class=p>,</span>
        <span class=n>version</span><span class=o>=</span><span class=n>version</span><span class=p>,</span>
        <span class=n>stage</span><span class=o>=</span><span class=n>ModelStage</span><span class=o>.</span><span class=n>PRODUCTION</span>
    <span class=p>)</span>

    <span class=c1># 6. Load production model for serving</span>
    <span class=n>prod_model</span> <span class=o>=</span> <span class=n>registry</span><span class=o>.</span><span class=n>get_model</span><span class=p>(</span>
        <span class=n>model_name</span><span class=o>=</span><span class=s2>&quot;fraud_detector&quot;</span><span class=p>,</span>
        <span class=n>stage</span><span class=o>=</span><span class=n>ModelStage</span><span class=o>.</span><span class=n>PRODUCTION</span>
    <span class=p>)</span>

    <span class=c1># 7. Get lineage</span>
    <span class=n>lineage</span> <span class=o>=</span> <span class=n>registry</span><span class=o>.</span><span class=n>get_model_lineage</span><span class=p>(</span><span class=s2>&quot;fraud_detector&quot;</span><span class=p>,</span> <span class=n>version</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>lineage</span><span class=p>,</span> <span class=n>indent</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=nb>str</span><span class=p>))</span>
</code></pre></div> <h2 id=technology-stack-comparison_1>Technology Stack Comparison</h2> <table> <thead> <tr> <th>Tool</th> <th>Strengths</th> <th>Weaknesses</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td><strong>MLflow</strong></td> <td>Open-source, vendor-neutral, rich ecosystem</td> <td>Self-hosted complexity</td> <td>Teams wanting full control</td> </tr> <tr> <td><strong>Weights &amp; Biases</strong></td> <td>Great UI, experiment tracking, collaboration</td> <td>Closed-source, cost</td> <td>Research teams, quick setup</td> </tr> <tr> <td><strong>AWS SageMaker</strong></td> <td>AWS integration, managed service</td> <td>Vendor lock-in</td> <td>AWS-native environments</td> </tr> <tr> <td><strong>Azure ML</strong></td> <td>Azure integration, AutoML</td> <td>Vendor lock-in</td> <td>Azure-native environments</td> </tr> <tr> <td><strong>Databricks MLflow</strong></td> <td>Managed MLflow, Unity Catalog integration</td> <td>Cost, Databricks dependency</td> <td>Databricks users</td> </tr> <tr> <td><strong>Custom</strong></td> <td>Full flexibility</td> <td>High maintenance</td> <td>Very specific requirements</td> </tr> </tbody> </table> <h2 id=common-pitfalls-solutions_1>Common Pitfalls &amp; Solutions</h2> <table> <thead> <tr> <th>Pitfall</th> <th>Impact</th> <th>Solution</th> </tr> </thead> <tbody> <tr> <td><strong>No Model Signature</strong></td> <td>Input/output validation missing</td> <td>Always log signature with <code>infer_signature()</code></td> </tr> <tr> <td><strong>Lost Reproducibility</strong></td> <td>Can't recreate model</td> <td>Log dataset version, git commit, dependencies</td> </tr> <tr> <td><strong>Manual Stage Management</strong></td> <td>Human error, slow releases</td> <td>Automate with CI/CD + validation gates</td> </tr> <tr> <td><strong>No Access Control</strong></td> <td>Security risk</td> <td>Implement RBAC, audit logs</td> </tr> <tr> <td><strong>Stale Models in Prod</strong></td> <td>Performance degradation</td> <td>Auto-archive after 90 days, monitor drift</td> </tr> <tr> <td><strong>Large Model Binaries</strong></td> <td>Slow downloads, storage cost</td> <td>Use model compression, separate artifacts</td> </tr> <tr> <td><strong>Duplicate Models</strong></td> <td>Clutter, confusion</td> <td>Naming conventions, tags, search</td> </tr> <tr> <td><strong>No Model Cards</strong></td> <td>Poor documentation</td> <td>Auto-generate from metadata + manual notes</td> </tr> </tbody> </table> <h2 id=real-world-examples_1>Real-World Examples</h2> <p><strong>Uber's Michelangelo:</strong> - <strong>Scale:</strong> 10K+ models, 1K+ daily registrations - <strong>Features:</strong> Multi-framework support, auto-versioning, stage management - <strong>Architecture:</strong> Custom registry + Hive metadata + S3 artifacts - <strong>Impact:</strong> Reduced model deployment time from weeks to hours</p> <p><strong>Netflix's Model Registry:</strong> - <strong>Scale:</strong> 1K+ registered models, 100+ in production - <strong>Features:</strong> A/B testing integration, canary deployments - <strong>Tools:</strong> Custom registry built on S3 + DynamoDB - <strong>Impact:</strong> 10x faster model iteration cycles</p> <p><strong>Airbnb's ML Platform:</strong> - <strong>Scale:</strong> 800+ models, 150+ teams - <strong>Features:</strong> MLflow + Zipline integration, auto-documentation - <strong>Workflow:</strong> Notebook ‚Üí MLflow ‚Üí CI/CD ‚Üí Production - <strong>Impact:</strong> 5x increase in models deployed/quarter</p> <h2 id=model-card-generation>Model Card Generation</h2> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>generate_model_card</span><span class=p>(</span><span class=n>registry</span><span class=p>:</span> <span class=n>ModelRegistry</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>version</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Auto-generate model card from registry metadata&quot;&quot;&quot;</span>
    <span class=n>lineage</span> <span class=o>=</span> <span class=n>registry</span><span class=o>.</span><span class=n>get_model_lineage</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>)</span>
    <span class=n>mv</span> <span class=o>=</span> <span class=n>registry</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>get_model_version</span><span class=p>(</span><span class=n>model_name</span><span class=p>,</span> <span class=n>version</span><span class=p>)</span>

    <span class=n>card</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;</span>
<span class=s2>    # Model Card: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2> v</span><span class=si>{</span><span class=n>version</span><span class=si>}</span>

<span class=s2>    ## Model Details</span>
<span class=s2>    - **Stage:** </span><span class=si>{</span><span class=n>mv</span><span class=o>.</span><span class=n>current_stage</span><span class=si>}</span>
<span class=s2>    - **Created:** </span><span class=si>{</span><span class=n>lineage</span><span class=p>[</span><span class=s1>&#39;model&#39;</span><span class=p>][</span><span class=s1>&#39;created&#39;</span><span class=p>]</span><span class=si>}</span>
<span class=s2>    - **Owner:** </span><span class=si>{</span><span class=n>lineage</span><span class=p>[</span><span class=s1>&#39;training&#39;</span><span class=p>][</span><span class=s1>&#39;user&#39;</span><span class=p>]</span><span class=si>}</span>

<span class=s2>    ## Intended Use</span>
<span class=s2>    - **Primary Use:** [Fill from tags/description]</span>
<span class=s2>    - **Out-of-Scope:** [Fill from tags/description]</span>

<span class=s2>    ## Training Data</span>
<span class=s2>    - **Dataset Version:** </span><span class=si>{</span><span class=n>lineage</span><span class=p>[</span><span class=s1>&#39;data&#39;</span><span class=p>][</span><span class=s1>&#39;dataset_version&#39;</span><span class=p>]</span><span class=si>}</span>
<span class=s2>    - **Data Path:** </span><span class=si>{</span><span class=n>lineage</span><span class=p>[</span><span class=s1>&#39;data&#39;</span><span class=p>][</span><span class=s1>&#39;data_path&#39;</span><span class=p>]</span><span class=si>}</span>

<span class=s2>    ## Performance</span>
<span class=s2>    </span><span class=si>{</span><span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>lineage</span><span class=p>[</span><span class=s1>&#39;metrics&#39;</span><span class=p>],</span><span class=w> </span><span class=n>indent</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span><span class=si>}</span>

<span class=s2>    ## Ethical Considerations</span>
<span class=s2>    - Bias: [Review required]</span>
<span class=s2>    - Fairness: [Review required]</span>

<span class=s2>    ## Caveats and Recommendations</span>
<span class=s2>    - [Based on model type and metrics]</span>
<span class=s2>    &quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=n>card</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Emphasizes model lifecycle management (None ‚Üí Staging ‚Üí Production), reproducibility through lineage tracking, and automation. Discusses model signatures for input validation, CI/CD integration for automated deployments, and shows knowledge of MLflow internals. Can explain trade-offs between hosted (W&amp;B, SageMaker) vs self-hosted (MLflow) solutions.</p> </div> </details> <hr> <h3 id=design-a-low-latency-inference-service-google-amazon-interview-question>Design a Low-Latency Inference Service - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Performance</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <h2 id=scale-requirements_2>Scale Requirements</h2> <ul> <li><strong>Throughput:</strong> 10K-1M+ RPS (requests per second)</li> <li><strong>Latency:</strong> &lt;50ms p99, &lt;20ms p50, &lt;100ms p99.9</li> <li><strong>Models:</strong> 10-100 models deployed concurrently</li> <li><strong>Model Size:</strong> 10MB-10GB per model</li> <li><strong>Batch Size:</strong> 1-128 requests (dynamic batching)</li> <li><strong>GPU Utilization:</strong> &gt;70% target</li> <li><strong>Availability:</strong> 99.99% SLA</li> </ul> <h2 id=architecture_2>Architecture</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Load Balancer (L7)                          ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  - Round-robin with least-connections                           ‚îÇ
‚îÇ  - Health checks (every 10s)                                    ‚îÇ
‚îÇ  - Request routing by model_id                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Inference Service (FastAPI)                   ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              Request Handler (async)                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  1. Validate input                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  2. Feature lookup (parallel)                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  3. Add to batch queue                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  4. Wait for result (Future)                              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ          Dynamic Batcher (background thread)              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Trigger batching when:                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Queue size ‚â• max_batch_size (e.g., 32)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - OR timeout reached (e.g., 5ms)                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Coalesces requests into single inference call            ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Model Inference Engine                         ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Model Cache (LRU, in-memory)                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Warm models (GPU VRAM)                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Cold models (CPU RAM/Disk)                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Auto-eviction based on usage                           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ          GPU Inference (TensorRT/ONNX)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - FP16/INT8 quantization                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Kernel fusion                                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Dynamic shapes                                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Multi-stream execution                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Feature Store (Redis/Aerospike)                 ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  - Online features (&lt;5ms p99)                                   ‚îÇ
‚îÇ  - Connection pooling                                           ‚îÇ
‚îÇ  - Batch get operations                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ      Cross-Cutting Optimizations     ‚îÇ
         ‚îÇ                                      ‚îÇ
         ‚îÇ  - Response caching (Redis)         ‚îÇ
         ‚îÇ  - Feature caching (TTL: 1min)      ‚îÇ
         ‚îÇ  - Connection pooling               ‚îÇ
         ‚îÇ  - Async I/O (asyncio)              ‚îÇ
         ‚îÇ  - Zero-copy where possible         ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=latency-budget-breakdown>Latency Budget Breakdown</h2> <div class=highlight><pre><span></span><code>Total: 50ms p99 target

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Network (Load Balancer ‚Üí Service)      5ms          ‚îÇ
‚îÇ  2. Request Validation                     1ms          ‚îÇ
‚îÇ  3. Feature Lookup (Redis parallel)       10ms          ‚îÇ
‚îÇ  4. Batching Wait Time                     5ms (max)    ‚îÇ
‚îÇ  5. Model Inference (GPU)                 20ms          ‚îÇ
‚îÇ     - Input preprocessing                  2ms          ‚îÇ
‚îÇ     - GPU compute                         15ms          ‚îÇ
‚îÇ     - Output postprocessing                3ms          ‚îÇ
‚îÇ  6. Result Serialization                   2ms          ‚îÇ
‚îÇ  7. Network (Service ‚Üí Client)             7ms          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Optimization priorities:
1. GPU compute (15ms) ‚Üí quantization, TensorRT
2. Feature lookup (10ms) ‚Üí caching, batch fetch
3. Batching wait (5ms) ‚Üí tuned timeout/batch size
</code></pre></div> <h2 id=production-implementation-300-lines>Production Implementation (300 lines)</h2> <div class=highlight><pre><span></span><code><span class=c1># low_latency_inference.py</span>
<span class=kn>from</span><span class=w> </span><span class=nn>fastapi</span><span class=w> </span><span class=kn>import</span> <span class=n>FastAPI</span><span class=p>,</span> <span class=n>HTTPException</span>
<span class=kn>from</span><span class=w> </span><span class=nn>pydantic</span><span class=w> </span><span class=kn>import</span> <span class=n>BaseModel</span>
<span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
<span class=kn>import</span><span class=w> </span><span class=nn>tensorrt</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>trt</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>Any</span><span class=p>,</span> <span class=n>Optional</span>
<span class=kn>import</span><span class=w> </span><span class=nn>asyncio</span>
<span class=kn>import</span><span class=w> </span><span class=nn>redis.asyncio</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>aioredis</span>
<span class=kn>from</span><span class=w> </span><span class=nn>collections</span><span class=w> </span><span class=kn>import</span> <span class=n>deque</span>
<span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span>
<span class=kn>import</span><span class=w> </span><span class=nn>time</span>
<span class=kn>import</span><span class=w> </span><span class=nn>logging</span>
<span class=kn>from</span><span class=w> </span><span class=nn>concurrent.futures</span><span class=w> </span><span class=kn>import</span> <span class=n>ThreadPoolExecutor</span>
<span class=kn>import</span><span class=w> </span><span class=nn>uvicorn</span>

<span class=c1># ============= Configuration =============</span>
<span class=nd>@dataclass</span>
<span class=k>class</span><span class=w> </span><span class=nc>InferenceConfig</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Low-latency inference configuration&quot;&quot;&quot;</span>
    <span class=n>max_batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>32</span>
    <span class=n>batch_timeout_ms</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span>  <span class=c1># ms</span>
    <span class=n>feature_cache_ttl</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>60</span>  <span class=c1># seconds</span>
    <span class=n>max_queue_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1000</span>
    <span class=n>gpu_device</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=n>num_workers</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>4</span>
    <span class=n>warmup_requests</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>100</span>

<span class=n>config</span> <span class=o>=</span> <span class=n>InferenceConfig</span><span class=p>()</span>

<span class=c1># ============= Request/Response Models =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>InferenceRequest</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Input request schema&quot;&quot;&quot;</span>
    <span class=n>model_id</span><span class=p>:</span> <span class=nb>str</span>
    <span class=n>features</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]]</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=n>feature_keys</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]]</span> <span class=o>=</span> <span class=kc>None</span>  <span class=c1># For feature store lookup</span>
    <span class=n>use_cache</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span>

<span class=k>class</span><span class=w> </span><span class=nc>InferenceResponse</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Output response schema&quot;&quot;&quot;</span>
    <span class=n>predictions</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>float</span><span class=p>]</span>
    <span class=n>model_version</span><span class=p>:</span> <span class=nb>str</span>
    <span class=n>latency_ms</span><span class=p>:</span> <span class=nb>float</span>
    <span class=n>cache_hit</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span>

<span class=c1># ============= Dynamic Batcher =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>DynamicBatcher</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Batches requests dynamically based on size and timeout</span>
<span class=sd>    Inspired by NVIDIA Triton and TensorFlow Serving</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>InferenceConfig</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>:</span> <span class=n>deque</span> <span class=o>=</span> <span class=n>deque</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>pending_futures</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>int</span><span class=p>,</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>Future</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>batch_id</span> <span class=o>=</span> <span class=mi>0</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>lock</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>Lock</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>add_request</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>request</span><span class=p>:</span> <span class=n>InferenceRequest</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Add request to batch queue and wait for result&quot;&quot;&quot;</span>
        <span class=n>request_id</span> <span class=o>=</span> <span class=nb>id</span><span class=p>(</span><span class=n>request</span><span class=p>)</span>
        <span class=n>future</span> <span class=o>=</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>Future</span><span class=p>()</span>

        <span class=k>async</span> <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>lock</span><span class=p>:</span>
            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>)</span> <span class=o>&gt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_queue_size</span><span class=p>:</span>
                <span class=k>raise</span> <span class=n>HTTPException</span><span class=p>(</span><span class=n>status_code</span><span class=o>=</span><span class=mi>503</span><span class=p>,</span> <span class=n>detail</span><span class=o>=</span><span class=s2>&quot;Queue full&quot;</span><span class=p>)</span>

            <span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>request_id</span><span class=p>,</span> <span class=n>request</span><span class=p>))</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>pending_futures</span><span class=p>[</span><span class=n>request_id</span><span class=p>]</span> <span class=o>=</span> <span class=n>future</span>

        <span class=c1># Wait for result with timeout</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>wait_for</span><span class=p>(</span>
                <span class=n>future</span><span class=p>,</span>
                <span class=n>timeout</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>batch_timeout_ms</span> <span class=o>*</span> <span class=mi>10</span> <span class=o>/</span> <span class=mi>1000</span>  <span class=c1># 10x timeout for safety</span>
            <span class=p>)</span>
            <span class=k>return</span> <span class=n>result</span>
        <span class=k>except</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>TimeoutError</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Request </span><span class=si>{</span><span class=n>request_id</span><span class=si>}</span><span class=s2> timed out&quot;</span><span class=p>)</span>
            <span class=k>raise</span> <span class=n>HTTPException</span><span class=p>(</span><span class=n>status_code</span><span class=o>=</span><span class=mi>504</span><span class=p>,</span> <span class=n>detail</span><span class=o>=</span><span class=s2>&quot;Inference timeout&quot;</span><span class=p>)</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>process_batches</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_engine</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Background task to process batches&quot;&quot;&quot;</span>
        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
            <span class=n>batch_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>perf_counter</span><span class=p>()</span>

            <span class=c1># Wait for batch to fill or timeout</span>
            <span class=k>await</span> <span class=n>asyncio</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>batch_timeout_ms</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>)</span>

            <span class=k>async</span> <span class=k>with</span> <span class=bp>self</span><span class=o>.</span><span class=n>lock</span><span class=p>:</span>
                <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>:</span>
                    <span class=k>continue</span>

                <span class=c1># Extract batch (up to max_batch_size)</span>
                <span class=n>batch_size</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_batch_size</span><span class=p>)</span>
                <span class=n>batch</span> <span class=o>=</span> <span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>queue</span><span class=o>.</span><span class=n>popleft</span><span class=p>()</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>batch_size</span><span class=p>)]</span>

            <span class=k>if</span> <span class=ow>not</span> <span class=n>batch</span><span class=p>:</span>
                <span class=k>continue</span>

            <span class=c1># Run inference on batch</span>
            <span class=k>try</span><span class=p>:</span>
                <span class=n>request_ids</span><span class=p>,</span> <span class=n>requests</span> <span class=o>=</span> <span class=nb>zip</span><span class=p>(</span><span class=o>*</span><span class=n>batch</span><span class=p>)</span>
                <span class=n>results</span> <span class=o>=</span> <span class=k>await</span> <span class=n>model_engine</span><span class=o>.</span><span class=n>infer_batch</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>requests</span><span class=p>))</span>

                <span class=c1># Resolve futures with results</span>
                <span class=k>for</span> <span class=n>request_id</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>request_ids</span><span class=p>,</span> <span class=n>results</span><span class=p>):</span>
                    <span class=k>if</span> <span class=n>request_id</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>pending_futures</span><span class=p>:</span>
                        <span class=bp>self</span><span class=o>.</span><span class=n>pending_futures</span><span class=p>[</span><span class=n>request_id</span><span class=p>]</span><span class=o>.</span><span class=n>set_result</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
                        <span class=k>del</span> <span class=bp>self</span><span class=o>.</span><span class=n>pending_futures</span><span class=p>[</span><span class=n>request_id</span><span class=p>]</span>

                <span class=n>batch_latency</span> <span class=o>=</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>perf_counter</span><span class=p>()</span> <span class=o>-</span> <span class=n>batch_start</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Processed batch of </span><span class=si>{</span><span class=n>batch_size</span><span class=si>}</span><span class=s2> in </span><span class=si>{</span><span class=n>batch_latency</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>ms&quot;</span><span class=p>)</span>

            <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Batch inference failed: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
                <span class=c1># Reject all requests in batch</span>
                <span class=k>for</span> <span class=n>request_id</span><span class=p>,</span> <span class=n>_</span> <span class=ow>in</span> <span class=n>batch</span><span class=p>:</span>
                    <span class=k>if</span> <span class=n>request_id</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>pending_futures</span><span class=p>:</span>
                        <span class=bp>self</span><span class=o>.</span><span class=n>pending_futures</span><span class=p>[</span><span class=n>request_id</span><span class=p>]</span><span class=o>.</span><span class=n>set_exception</span><span class=p>(</span><span class=n>e</span><span class=p>)</span>
                        <span class=k>del</span> <span class=bp>self</span><span class=o>.</span><span class=n>pending_futures</span><span class=p>[</span><span class=n>request_id</span><span class=p>]</span>

<span class=c1># ============= Model Engine with TensorRT =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>TensorRTModelEngine</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Optimized model inference using TensorRT</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>InferenceConfig</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>models</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>  <span class=c1># model_id -&gt; TRT engine</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;cuda:</span><span class=si>{</span><span class=n>config</span><span class=o>.</span><span class=n>gpu_device</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>warmup_done</span> <span class=o>=</span> <span class=kc>False</span>

    <span class=k>def</span><span class=w> </span><span class=nf>load_model</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>model_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Load and optimize model with TensorRT&quot;&quot;&quot;</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Loading model </span><span class=si>{</span><span class=n>model_id</span><span class=si>}</span><span class=s2> from </span><span class=si>{</span><span class=n>model_path</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=c1># Load PyTorch model</span>
        <span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>
        <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
        <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>

        <span class=c1># Convert to TensorRT (simplified - actual conversion is more complex)</span>
        <span class=c1># In production, use torch2trt or ONNX ‚Üí TensorRT pipeline</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>models</span><span class=p>[</span><span class=n>model_id</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;model&#39;</span><span class=p>:</span> <span class=n>model</span><span class=p>,</span>
            <span class=s1>&#39;version&#39;</span><span class=p>:</span> <span class=s1>&#39;1.0&#39;</span><span class=p>,</span>
            <span class=s1>&#39;input_shape&#39;</span><span class=p>:</span> <span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=mi>128</span><span class=p>),</span>  <span class=c1># Dynamic batch</span>
            <span class=s1>&#39;warmup_done&#39;</span><span class=p>:</span> <span class=kc>False</span>
        <span class=p>}</span>

        <span class=c1># Warmup</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_warmup_model</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_warmup_model</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Warmup model with dummy requests for kernel optimization&quot;&quot;&quot;</span>
        <span class=n>model_info</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>models</span><span class=p>[</span><span class=n>model_id</span><span class=p>]</span>
        <span class=n>model</span> <span class=o>=</span> <span class=n>model_info</span><span class=p>[</span><span class=s1>&#39;model&#39;</span><span class=p>]</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Warming up model </span><span class=si>{</span><span class=n>model_id</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
            <span class=k>for</span> <span class=n>batch_size</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>32</span><span class=p>]:</span>
                <span class=n>dummy_input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span>
                    <span class=n>batch_size</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span>
                <span class=p>)</span>
                <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
                    <span class=n>_</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>dummy_input</span><span class=p>)</span>

        <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>
        <span class=n>model_info</span><span class=p>[</span><span class=s1>&#39;warmup_done&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>True</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Warmup complete for </span><span class=si>{</span><span class=n>model_id</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>infer_batch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>requests</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>InferenceRequest</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Run inference on a batch of requests&quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>requests</span><span class=p>:</span>
            <span class=k>return</span> <span class=p>[]</span>

        <span class=c1># Assume all requests use same model (can be extended)</span>
        <span class=n>model_id</span> <span class=o>=</span> <span class=n>requests</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>model_id</span>

        <span class=k>if</span> <span class=n>model_id</span> <span class=ow>not</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>models</span><span class=p>:</span>
            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Model </span><span class=si>{</span><span class=n>model_id</span><span class=si>}</span><span class=s2> not loaded&quot;</span><span class=p>)</span>

        <span class=c1># Prepare batch input</span>
        <span class=n>inputs</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>for</span> <span class=n>req</span> <span class=ow>in</span> <span class=n>requests</span><span class=p>:</span>
            <span class=c1># In production, this would fetch from feature store</span>
            <span class=n>input_tensor</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>128</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
            <span class=n>inputs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>input_tensor</span><span class=p>)</span>

        <span class=n>batch_input</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span>
            <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>inputs</span><span class=p>),</span> <span class=n>device</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span>
        <span class=p>)</span>

        <span class=c1># Run inference with torch.cuda.nvtx for profiling</span>
        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
            <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>perf_counter</span><span class=p>()</span>
            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>models</span><span class=p>[</span><span class=n>model_id</span><span class=p>][</span><span class=s1>&#39;model&#39;</span><span class=p>](</span><span class=n>batch_input</span><span class=p>)</span>
            <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>synchronize</span><span class=p>()</span>  <span class=c1># Wait for GPU</span>
            <span class=n>latency</span> <span class=o>=</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>perf_counter</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>debug</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Batch inference: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>requests</span><span class=p>)</span><span class=si>}</span><span class=s2> requests in </span><span class=si>{</span><span class=n>latency</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>ms&quot;</span><span class=p>)</span>

        <span class=c1># Convert to numpy</span>
        <span class=k>return</span> <span class=p>[</span><span class=n>output</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span> <span class=k>for</span> <span class=n>output</span> <span class=ow>in</span> <span class=n>outputs</span><span class=p>]</span>

<span class=c1># ============= Feature Store Client =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>FeatureStoreClient</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Async feature store client with caching</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>redis_url</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;redis://localhost&quot;</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>redis</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>redis_url</span> <span class=o>=</span> <span class=n>redis_url</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>cache</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]</span> <span class=o>=</span> <span class=p>{}</span>  <span class=c1># Local cache</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>cache_ttl</span> <span class=o>=</span> <span class=n>config</span><span class=o>.</span><span class=n>feature_cache_ttl</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>connect</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Initialize Redis connection&quot;&quot;&quot;</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>redis</span> <span class=o>=</span> <span class=k>await</span> <span class=n>aioredis</span><span class=o>.</span><span class=n>from_url</span><span class=p>(</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>redis_url</span><span class=p>,</span>
            <span class=n>encoding</span><span class=o>=</span><span class=s2>&quot;utf-8&quot;</span><span class=p>,</span>
            <span class=n>decode_responses</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
            <span class=n>max_connections</span><span class=o>=</span><span class=mi>50</span>  <span class=c1># Connection pooling</span>
        <span class=p>)</span>

    <span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>get_features</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span> <span class=n>feature_keys</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span> <span class=n>use_cache</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Fetch features with parallel Redis queries and local caching</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=n>use_cache</span><span class=p>:</span>
            <span class=c1># Check local cache first</span>
            <span class=n>cached</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_from_cache</span><span class=p>(</span><span class=n>feature_keys</span><span class=p>)</span>
            <span class=k>if</span> <span class=n>cached</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
                <span class=k>return</span> <span class=n>cached</span>

        <span class=c1># Batch fetch from Redis (pipeline for parallelism)</span>
        <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>perf_counter</span><span class=p>()</span>
        <span class=n>pipeline</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>redis</span><span class=o>.</span><span class=n>pipeline</span><span class=p>()</span>
        <span class=k>for</span> <span class=n>key</span> <span class=ow>in</span> <span class=n>feature_keys</span><span class=p>:</span>
            <span class=n>pipeline</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>key</span><span class=p>)</span>

        <span class=n>results</span> <span class=o>=</span> <span class=k>await</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>execute</span><span class=p>()</span>
        <span class=n>latency</span> <span class=o>=</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>perf_counter</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>debug</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Feature fetch: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>feature_keys</span><span class=p>)</span><span class=si>}</span><span class=s2> keys in </span><span class=si>{</span><span class=n>latency</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>ms&quot;</span><span class=p>)</span>

        <span class=c1># Parse results</span>
        <span class=n>features</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=nb>float</span><span class=p>(</span><span class=n>r</span><span class=p>)</span> <span class=k>if</span> <span class=n>r</span> <span class=k>else</span> <span class=mf>0.0</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>results</span><span class=p>])</span>

        <span class=c1># Update cache</span>
        <span class=k>if</span> <span class=n>use_cache</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>_update_cache</span><span class=p>(</span><span class=n>feature_keys</span><span class=p>,</span> <span class=n>features</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>features</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_get_from_cache</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>keys</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Check local cache for features&quot;&quot;&quot;</span>
        <span class=n>cache_key</span> <span class=o>=</span> <span class=nb>tuple</span><span class=p>(</span><span class=n>keys</span><span class=p>)</span>
        <span class=k>if</span> <span class=n>cache_key</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>cache</span><span class=p>:</span>
            <span class=n>entry</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>cache</span><span class=p>[</span><span class=n>cache_key</span><span class=p>]</span>
            <span class=k>if</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>entry</span><span class=p>[</span><span class=s1>&#39;timestamp&#39;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>cache_ttl</span><span class=p>:</span>
                <span class=k>return</span> <span class=n>entry</span><span class=p>[</span><span class=s1>&#39;value&#39;</span><span class=p>]</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=k>del</span> <span class=bp>self</span><span class=o>.</span><span class=n>cache</span><span class=p>[</span><span class=n>cache_key</span><span class=p>]</span>
        <span class=k>return</span> <span class=kc>None</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_update_cache</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>keys</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span> <span class=n>value</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Update local cache&quot;&quot;&quot;</span>
        <span class=n>cache_key</span> <span class=o>=</span> <span class=nb>tuple</span><span class=p>(</span><span class=n>keys</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>cache</span><span class=p>[</span><span class=n>cache_key</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;value&#39;</span><span class=p>:</span> <span class=n>value</span><span class=p>,</span>
            <span class=s1>&#39;timestamp&#39;</span><span class=p>:</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
        <span class=p>}</span>

<span class=c1># ============= FastAPI Application =============</span>
<span class=n>app</span> <span class=o>=</span> <span class=n>FastAPI</span><span class=p>(</span><span class=n>title</span><span class=o>=</span><span class=s2>&quot;Low-Latency Inference Service&quot;</span><span class=p>)</span>

<span class=c1># Global state</span>
<span class=n>batcher</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>DynamicBatcher</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<span class=n>model_engine</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>TensorRTModelEngine</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<span class=n>feature_store</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>FeatureStoreClient</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>

<span class=nd>@app</span><span class=o>.</span><span class=n>on_event</span><span class=p>(</span><span class=s2>&quot;startup&quot;</span><span class=p>)</span>
<span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>startup</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Initialize services on startup&quot;&quot;&quot;</span>
    <span class=k>global</span> <span class=n>batcher</span><span class=p>,</span> <span class=n>model_engine</span><span class=p>,</span> <span class=n>feature_store</span>

    <span class=c1># Initialize components</span>
    <span class=n>model_engine</span> <span class=o>=</span> <span class=n>TensorRTModelEngine</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
    <span class=n>batcher</span> <span class=o>=</span> <span class=n>DynamicBatcher</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
    <span class=n>feature_store</span> <span class=o>=</span> <span class=n>FeatureStoreClient</span><span class=p>()</span>

    <span class=c1># Load models</span>
    <span class=n>model_engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model_v1&quot;</span><span class=p>,</span> <span class=s2>&quot;models/model_v1.pt&quot;</span><span class=p>)</span>

    <span class=c1># Connect to feature store</span>
    <span class=k>await</span> <span class=n>feature_store</span><span class=o>.</span><span class=n>connect</span><span class=p>()</span>

    <span class=c1># Start background batcher</span>
    <span class=n>asyncio</span><span class=o>.</span><span class=n>create_task</span><span class=p>(</span><span class=n>batcher</span><span class=o>.</span><span class=n>process_batches</span><span class=p>(</span><span class=n>model_engine</span><span class=p>))</span>

    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&quot;Inference service started&quot;</span><span class=p>)</span>

<span class=nd>@app</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=s2>&quot;/predict&quot;</span><span class=p>,</span> <span class=n>response_model</span><span class=o>=</span><span class=n>InferenceResponse</span><span class=p>)</span>
<span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>predict</span><span class=p>(</span><span class=n>request</span><span class=p>:</span> <span class=n>InferenceRequest</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>InferenceResponse</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Low-latency prediction endpoint</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>perf_counter</span><span class=p>()</span>

    <span class=k>try</span><span class=p>:</span>
        <span class=c1># Fetch features if needed</span>
        <span class=k>if</span> <span class=n>request</span><span class=o>.</span><span class=n>feature_keys</span><span class=p>:</span>
            <span class=n>features</span> <span class=o>=</span> <span class=k>await</span> <span class=n>feature_store</span><span class=o>.</span><span class=n>get_features</span><span class=p>(</span>
                <span class=n>request</span><span class=o>.</span><span class=n>feature_keys</span><span class=p>,</span>
                <span class=n>use_cache</span><span class=o>=</span><span class=n>request</span><span class=o>.</span><span class=n>use_cache</span>
            <span class=p>)</span>
            <span class=n>request</span><span class=o>.</span><span class=n>features</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;input&#39;</span><span class=p>:</span> <span class=n>features</span><span class=o>.</span><span class=n>tolist</span><span class=p>()}</span>

        <span class=c1># Add to batch queue</span>
        <span class=n>result</span> <span class=o>=</span> <span class=k>await</span> <span class=n>batcher</span><span class=o>.</span><span class=n>add_request</span><span class=p>(</span><span class=n>request</span><span class=p>)</span>

        <span class=c1># Calculate latency</span>
        <span class=n>latency_ms</span> <span class=o>=</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>perf_counter</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>

        <span class=k>return</span> <span class=n>InferenceResponse</span><span class=p>(</span>
            <span class=n>predictions</span><span class=o>=</span><span class=n>result</span><span class=o>.</span><span class=n>tolist</span><span class=p>(),</span>
            <span class=n>model_version</span><span class=o>=</span><span class=s2>&quot;1.0&quot;</span><span class=p>,</span>
            <span class=n>latency_ms</span><span class=o>=</span><span class=n>latency_ms</span><span class=p>,</span>
            <span class=n>cache_hit</span><span class=o>=</span><span class=kc>False</span>  <span class=c1># Would track actual cache hits</span>
        <span class=p>)</span>

    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
        <span class=n>logging</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Prediction failed: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=k>raise</span> <span class=n>HTTPException</span><span class=p>(</span><span class=n>status_code</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span> <span class=n>detail</span><span class=o>=</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>))</span>

<span class=nd>@app</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;/health&quot;</span><span class=p>)</span>
<span class=k>async</span> <span class=k>def</span><span class=w> </span><span class=nf>health</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Health check endpoint&quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=p>{</span>
        <span class=s2>&quot;status&quot;</span><span class=p>:</span> <span class=s2>&quot;healthy&quot;</span><span class=p>,</span>
        <span class=s2>&quot;models_loaded&quot;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>model_engine</span><span class=o>.</span><span class=n>models</span><span class=p>)</span> <span class=k>if</span> <span class=n>model_engine</span> <span class=k>else</span> <span class=mi>0</span><span class=p>,</span>
        <span class=s2>&quot;queue_size&quot;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>batcher</span><span class=o>.</span><span class=n>queue</span><span class=p>)</span> <span class=k>if</span> <span class=n>batcher</span> <span class=k>else</span> <span class=mi>0</span>
    <span class=p>}</span>

<span class=c1># ============= Main Entry Point =============</span>
<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
    <span class=n>uvicorn</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
        <span class=n>app</span><span class=p>,</span>
        <span class=n>host</span><span class=o>=</span><span class=s2>&quot;0.0.0.0&quot;</span><span class=p>,</span>
        <span class=n>port</span><span class=o>=</span><span class=mi>8000</span><span class=p>,</span>
        <span class=n>workers</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>num_workers</span><span class=p>,</span>
        <span class=n>log_level</span><span class=o>=</span><span class=s2>&quot;info&quot;</span>
    <span class=p>)</span>
</code></pre></div> <h2 id=optimization-techniques-comparison>Optimization Techniques Comparison</h2> <table> <thead> <tr> <th>Technique</th> <th>Speedup</th> <th>Accuracy Impact</th> <th>Complexity</th> <th>When to Use</th> </tr> </thead> <tbody> <tr> <td><strong>FP16 (Half Precision)</strong></td> <td>2-3x</td> <td>Minimal (&lt;0.5%)</td> <td>Low</td> <td>Almost always on modern GPUs</td> </tr> <tr> <td><strong>INT8 Quantization</strong></td> <td>3-4x</td> <td>Small (1-2%)</td> <td>Medium</td> <td>When latency critical, post-training</td> </tr> <tr> <td><strong>Dynamic Batching</strong></td> <td>3-10x throughput</td> <td>None</td> <td>Medium</td> <td>High QPS scenarios</td> </tr> <tr> <td><strong>Model Distillation</strong></td> <td>2-5x</td> <td>Medium (2-5%)</td> <td>High</td> <td>When training new model is ok</td> </tr> <tr> <td><strong>TensorRT Optimization</strong></td> <td>2-5x</td> <td>Minimal</td> <td>Medium</td> <td>NVIDIA GPUs, production deployment</td> </tr> <tr> <td><strong>ONNX Runtime</strong></td> <td>1.5-3x</td> <td>Minimal</td> <td>Low</td> <td>Cross-platform, CPU/GPU</td> </tr> <tr> <td><strong>Model Pruning</strong></td> <td>1.5-3x</td> <td>Medium (2-5%)</td> <td>High</td> <td>When model is overparameterized</td> </tr> <tr> <td><strong>Feature Caching</strong></td> <td>2-5x</td> <td>None</td> <td>Low</td> <td>When features stable (1min+)</td> </tr> <tr> <td><strong>Response Caching</strong></td> <td>10-100x</td> <td>None</td> <td>Low</td> <td>When exact requests repeat</td> </tr> </tbody> </table> <h2 id=common-pitfalls-solutions_2>Common Pitfalls &amp; Solutions</h2> <table> <thead> <tr> <th>Pitfall</th> <th>Impact</th> <th>Solution</th> </tr> </thead> <tbody> <tr> <td><strong>Cold Start</strong></td> <td>5-10s first request</td> <td>Warmup models with dummy requests at startup</td> </tr> <tr> <td><strong>Small Batches</strong></td> <td>Low GPU utilization</td> <td>Dynamic batching with timeout</td> </tr> <tr> <td><strong>CPU Bottleneck</strong></td> <td>GPU idle, high latency</td> <td>Async I/O, multi-threading for preprocessing</td> </tr> <tr> <td><strong>Memory Fragmentation</strong></td> <td>OOM errors</td> <td>Preallocate tensors, use memory pools</td> </tr> <tr> <td><strong>Blocking I/O</strong></td> <td>Queue buildup</td> <td>Use async Redis, async feature fetching</td> </tr> <tr> <td><strong>Large Models</strong></td> <td>High VRAM, slow load</td> <td>Model quantization, layer freezing</td> </tr> <tr> <td><strong>No Request Timeout</strong></td> <td>Unbounded latency</td> <td>Set max wait time (e.g., 100ms)</td> </tr> <tr> <td><strong>Synchronous GPU Calls</strong></td> <td>Underutilized GPU</td> <td>Use CUDA streams for parallelism</td> </tr> </tbody> </table> <h2 id=real-world-examples_2>Real-World Examples</h2> <p><strong>Uber's Real-Time Prediction Service:</strong> - <strong>Scale:</strong> 100K+ RPS, &lt;10ms p99 - <strong>Optimizations:</strong> TensorFlow Serving, TensorRT INT8, batching - <strong>Architecture:</strong> Go service ‚Üí TF Serving ‚Üí GPU cluster - <strong>Impact:</strong> Handles surge pricing, ETA prediction at scale</p> <p><strong>Meta's PyTorch Inference:</strong> - <strong>Scale:</strong> 1M+ RPS, &lt;50ms p99 - <strong>Optimizations:</strong> TorchScript, ONNX, custom CUDA kernels - <strong>Models:</strong> 100+ models, dynamic batching per model - <strong>Impact:</strong> Powers ads ranking, content recommendation</p> <p><strong>Google's TF Serving:</strong> - <strong>Scale:</strong> 10M+ QPS aggregate - <strong>Features:</strong> Dynamic batching, model versioning, multi-model - <strong>Latency:</strong> &lt;1ms for small models (embeddings) - <strong>Impact:</strong> Industry standard for model serving</p> <h2 id=monitoring-metrics>Monitoring Metrics</h2> <div class=highlight><pre><span></span><code><span class=n>metrics_to_track</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;latency&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;p50&#39;</span><span class=p>:</span> <span class=s1>&#39;Median latency&#39;</span><span class=p>,</span>
        <span class=s1>&#39;p95&#39;</span><span class=p>:</span> <span class=s1>&#39;95th percentile&#39;</span><span class=p>,</span>
        <span class=s1>&#39;p99&#39;</span><span class=p>:</span> <span class=s1>&#39;99th percentile&#39;</span><span class=p>,</span>
        <span class=s1>&#39;p99.9&#39;</span><span class=p>:</span> <span class=s1>&#39;99.9th percentile&#39;</span>
    <span class=p>},</span>
    <span class=s1>&#39;throughput&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;rps&#39;</span><span class=p>:</span> <span class=s1>&#39;Requests per second&#39;</span><span class=p>,</span>
        <span class=s1>&#39;batch_size_avg&#39;</span><span class=p>:</span> <span class=s1>&#39;Average batch size&#39;</span><span class=p>,</span>
        <span class=s1>&#39;queue_depth&#39;</span><span class=p>:</span> <span class=s1>&#39;Pending requests&#39;</span>
    <span class=p>},</span>
    <span class=s1>&#39;resource&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;gpu_utilization&#39;</span><span class=p>:</span> <span class=s1>&#39;GPU compute %&#39;</span><span class=p>,</span>
        <span class=s1>&#39;gpu_memory&#39;</span><span class=p>:</span> <span class=s1>&#39;VRAM usage&#39;</span><span class=p>,</span>
        <span class=s1>&#39;cpu_utilization&#39;</span><span class=p>:</span> <span class=s1>&#39;CPU %&#39;</span><span class=p>,</span>
        <span class=s1>&#39;network_bandwidth&#39;</span><span class=p>:</span> <span class=s1>&#39;MB/s&#39;</span>
    <span class=p>},</span>
    <span class=s1>&#39;errors&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;timeout_rate&#39;</span><span class=p>:</span> <span class=s1>&#39;</span><span class=si>% r</span><span class=s1>equests timing out&#39;</span><span class=p>,</span>
        <span class=s1>&#39;error_rate&#39;</span><span class=p>:</span> <span class=s1>&#39;</span><span class=si>% r</span><span class=s1>equests failing&#39;</span><span class=p>,</span>
        <span class=s1>&#39;queue_full_rate&#39;</span><span class=p>:</span> <span class=s1>&#39;</span><span class=si>% r</span><span class=s1>equests rejected&#39;</span>
    <span class=p>}</span>
<span class=p>}</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Emphasizes latency budget breakdown, dynamic batching for GPU efficiency, and multi-level optimization (model, serving, infrastructure). Discusses trade-offs between FP16/INT8 quantization and accuracy. Shows knowledge of TensorRT, async I/O, and production serving patterns from Uber/Meta/Google.</p> </div> </details> <hr> <h3 id=design-a-search-system-google-amazon-interview-question>Design a Search System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Search</code>, <code>Information Retrieval</code> | <strong>Asked by:</strong> Google, Amazon, LinkedIn</p> <details class=success> <summary>View Answer</summary> <h2 id=scale-requirements_3>Scale Requirements</h2> <ul> <li><strong>Index Size:</strong> 1B-1T documents</li> <li><strong>Query Volume:</strong> 10K-1M QPS (queries per second)</li> <li><strong>Latency:</strong> &lt;100ms p99, &lt;50ms p50</li> <li><strong>Index Update:</strong> Real-time (&lt;1s) or near-real-time (&lt;1min)</li> <li><strong>Relevance:</strong> NDCG@10 &gt; 0.75, MRR &gt; 0.80</li> <li><strong>Availability:</strong> 99.99% SLA</li> <li><strong>Storage:</strong> 10TB-10PB (index + documents)</li> </ul> <h2 id=architecture_3>Architecture</h2> <div class=highlight><pre><span></span><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        User Query                                ‚îÇ
‚îÇ                   &quot;machin learning books&quot;                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Query Understanding Layer                           ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  1. Spell Correction: &quot;machine learning books&quot;            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  2. Query Expansion: +[&quot;ML&quot;, &quot;deep learning&quot;, &quot;AI&quot;]       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  3. Intent Classification: [product_search, confidence=0.9]‚îÇ ‚îÇ
‚îÇ  ‚îÇ  4. Entity Extraction: [&quot;machine learning&quot; -&gt; TOPIC]      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Retrieval Layer (Stage 1)                       ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Elasticsearch / Solr (Inverted Index)             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  BM25 Scoring:                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Term frequency (TF)                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Inverse document frequency (IDF)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Document length normalization                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Filters:                                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Category, price range, rating                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Availability, location                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Retrieve top 1000 candidates (~10-20ms)                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Ranking Layer (Stage 2)                         ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ          Learning-to-Rank (LambdaMART / Neural)           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Features (100-1000 features):                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Text relevance: BM25, TF-IDF, exact match              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Quality signals: CTR, conversion rate, ratings         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Freshness: recency, update time                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - User context: location, device, history                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Item popularity: views, sales, trending                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Model: GBDT (e.g., LightGBM) or DNN                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Re-rank top 100 results (~30-50ms)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Personalization Layer (Stage 3)                 ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  - User preferences (past clicks, purchases)                    ‚îÇ
‚îÇ  - Collaborative filtering (users like you bought...)           ‚îÇ
‚îÇ  - Diversity &amp; exploration (avoid filter bubble)                ‚îÇ
‚îÇ  - Business rules (promotions, ads, editorial picks)            ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  Final top 20 results (~10ms)                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Search Results                              ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  1. &quot;Hands-On Machine Learning&quot; ‚≠ê4.8 $39.99                   ‚îÇ
‚îÇ  2. &quot;Deep Learning&quot; by Goodfellow ‚≠ê4.9 $49.99                 ‚îÇ
‚îÇ  3. ...                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ      Supporting Components           ‚îÇ
         ‚îÇ                                      ‚îÇ
         ‚îÇ  - Indexing Pipeline (Kafka ‚Üí ES)   ‚îÇ
         ‚îÇ  - Query Logs (click tracking)      ‚îÇ
         ‚îÇ  - A/B Testing Framework            ‚îÇ
         ‚îÇ  - Ranking Model Training           ‚îÇ
         ‚îÇ  - Autocomplete / Suggestions       ‚îÇ
         ‚îÇ  - Synonym Management               ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div> <h2 id=production-implementation-310-lines>Production Implementation (310 lines)</h2> <div class=highlight><pre><span></span><code><span class=c1># search_system.py</span>
<span class=kn>from</span><span class=w> </span><span class=nn>elasticsearch</span><span class=w> </span><span class=kn>import</span> <span class=n>Elasticsearch</span><span class=p>,</span> <span class=n>helpers</span>
<span class=kn>from</span><span class=w> </span><span class=nn>typing</span><span class=w> </span><span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>Any</span><span class=p>,</span> <span class=n>Optional</span>
<span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<span class=kn>from</span><span class=w> </span><span class=nn>dataclasses</span><span class=w> </span><span class=kn>import</span> <span class=n>dataclass</span>
<span class=kn>import</span><span class=w> </span><span class=nn>re</span>
<span class=kn>from</span><span class=w> </span><span class=nn>collections</span><span class=w> </span><span class=kn>import</span> <span class=n>defaultdict</span>
<span class=kn>import</span><span class=w> </span><span class=nn>lightgbm</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>lgb</span>
<span class=kn>from</span><span class=w> </span><span class=nn>scipy.spatial.distance</span><span class=w> </span><span class=kn>import</span> <span class=n>cosine</span>
<span class=kn>import</span><span class=w> </span><span class=nn>logging</span>
<span class=kn>from</span><span class=w> </span><span class=nn>datetime</span><span class=w> </span><span class=kn>import</span> <span class=n>datetime</span>
<span class=kn>import</span><span class=w> </span><span class=nn>hashlib</span>

<span class=c1># ============= Configuration =============</span>
<span class=nd>@dataclass</span>
<span class=k>class</span><span class=w> </span><span class=nc>SearchConfig</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Search system configuration&quot;&quot;&quot;</span>
    <span class=n>es_hosts</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=n>index_name</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;products&quot;</span>
    <span class=n>max_candidates</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1000</span>
    <span class=n>max_results</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>20</span>
    <span class=n>ltr_model_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;models/ranker.txt&quot;</span>
    <span class=n>min_score_threshold</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.1</span>

    <span class=k>def</span><span class=w> </span><span class=nf>__post_init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>es_hosts</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>es_hosts</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;localhost:9200&quot;</span><span class=p>]</span>

<span class=n>config</span> <span class=o>=</span> <span class=n>SearchConfig</span><span class=p>()</span>

<span class=c1># ============= Query Understanding =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>QueryUnderstanding</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Query preprocessing and understanding&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
        <span class=c1># Load spell correction dictionary (simplified)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>spelling_corrections</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;machin&#39;</span><span class=p>:</span> <span class=s1>&#39;machine&#39;</span><span class=p>,</span>
            <span class=s1>&#39;lerning&#39;</span><span class=p>:</span> <span class=s1>&#39;learning&#39;</span><span class=p>,</span>
            <span class=s1>&#39;python&#39;</span><span class=p>:</span> <span class=s1>&#39;python&#39;</span><span class=p>,</span>
            <span class=s1>&#39;javascrpit&#39;</span><span class=p>:</span> <span class=s1>&#39;javascript&#39;</span>
        <span class=p>}</span>
        <span class=c1># Synonym expansion</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>synonyms</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s1>&#39;ml&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;machine learning&#39;</span><span class=p>,</span> <span class=s1>&#39;ML&#39;</span><span class=p>],</span>
            <span class=s1>&#39;ai&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;artificial intelligence&#39;</span><span class=p>,</span> <span class=s1>&#39;AI&#39;</span><span class=p>],</span>
            <span class=s1>&#39;dl&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;deep learning&#39;</span><span class=p>,</span> <span class=s1>&#39;DL&#39;</span><span class=p>]</span>
        <span class=p>}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>process_query</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Process raw query through multiple stages</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=c1># 1. Normalize</span>
        <span class=n>normalized</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_normalize</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>

        <span class=c1># 2. Spell correction</span>
        <span class=n>corrected</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_spell_correct</span><span class=p>(</span><span class=n>normalized</span><span class=p>)</span>

        <span class=c1># 3. Tokenize</span>
        <span class=n>tokens</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_tokenize</span><span class=p>(</span><span class=n>corrected</span><span class=p>)</span>

        <span class=c1># 4. Expand with synonyms</span>
        <span class=n>expanded_tokens</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_expand_synonyms</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>

        <span class=c1># 5. Extract entities (simplified NER)</span>
        <span class=n>entities</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_extract_entities</span><span class=p>(</span><span class=n>corrected</span><span class=p>)</span>

        <span class=c1># 6. Classify intent</span>
        <span class=n>intent</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_classify_intent</span><span class=p>(</span><span class=n>corrected</span><span class=p>)</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;original&#39;</span><span class=p>:</span> <span class=n>query</span><span class=p>,</span>
            <span class=s1>&#39;normalized&#39;</span><span class=p>:</span> <span class=n>normalized</span><span class=p>,</span>
            <span class=s1>&#39;corrected&#39;</span><span class=p>:</span> <span class=n>corrected</span><span class=p>,</span>
            <span class=s1>&#39;tokens&#39;</span><span class=p>:</span> <span class=n>tokens</span><span class=p>,</span>
            <span class=s1>&#39;expanded_tokens&#39;</span><span class=p>:</span> <span class=n>expanded_tokens</span><span class=p>,</span>
            <span class=s1>&#39;entities&#39;</span><span class=p>:</span> <span class=n>entities</span><span class=p>,</span>
            <span class=s1>&#39;intent&#39;</span><span class=p>:</span> <span class=n>intent</span>
        <span class=p>}</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_normalize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Lowercase, trim, remove special chars&quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=s1>&#39; &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>query</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span><span class=o>.</span><span class=n>split</span><span class=p>())</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_spell_correct</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Simple spell correction using dictionary&quot;&quot;&quot;</span>
        <span class=n>words</span> <span class=o>=</span> <span class=n>query</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
        <span class=n>corrected</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=n>words</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>word</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>spelling_corrections</span><span class=p>:</span>
                <span class=n>corrected</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>spelling_corrections</span><span class=p>[</span><span class=n>word</span><span class=p>])</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Spell correction: </span><span class=si>{</span><span class=n>word</span><span class=si>}</span><span class=s2> ‚Üí </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>spelling_corrections</span><span class=p>[</span><span class=n>word</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
            <span class=k>else</span><span class=p>:</span>
                <span class=n>corrected</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>word</span><span class=p>)</span>
        <span class=k>return</span> <span class=s1>&#39; &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>corrected</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_tokenize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Simple whitespace tokenization&quot;&quot;&quot;</span>
        <span class=k>return</span> <span class=n>query</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_expand_synonyms</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tokens</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Expand tokens with synonyms&quot;&quot;&quot;</span>
        <span class=n>expanded</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
        <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>tokens</span><span class=p>:</span>
            <span class=k>if</span> <span class=n>token</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>synonyms</span><span class=p>:</span>
                <span class=n>expanded</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>synonyms</span><span class=p>[</span><span class=n>token</span><span class=p>])</span>
        <span class=k>return</span> <span class=n>expanded</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_extract_entities</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>]]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Extract named entities (simplified)&quot;&quot;&quot;</span>
        <span class=n>entities</span> <span class=o>=</span> <span class=n>defaultdict</span><span class=p>(</span><span class=nb>list</span><span class=p>)</span>
        <span class=c1># Pattern matching for common entities</span>
        <span class=k>if</span> <span class=s1>&#39;python&#39;</span> <span class=ow>in</span> <span class=n>query</span><span class=p>:</span>
            <span class=n>entities</span><span class=p>[</span><span class=s1>&#39;language&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s1>&#39;Python&#39;</span><span class=p>)</span>
        <span class=k>if</span> <span class=s1>&#39;machine learning&#39;</span> <span class=ow>in</span> <span class=n>query</span> <span class=ow>or</span> <span class=s1>&#39;ml&#39;</span> <span class=ow>in</span> <span class=n>query</span><span class=p>:</span>
            <span class=n>entities</span><span class=p>[</span><span class=s1>&#39;topic&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s1>&#39;Machine Learning&#39;</span><span class=p>)</span>
        <span class=k>return</span> <span class=nb>dict</span><span class=p>(</span><span class=n>entities</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_classify_intent</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Classify user intent (simplified)&quot;&quot;&quot;</span>
        <span class=c1># In production, use a trained classifier</span>
        <span class=k>if</span> <span class=nb>any</span><span class=p>(</span><span class=n>word</span> <span class=ow>in</span> <span class=n>query</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>&#39;buy&#39;</span><span class=p>,</span> <span class=s1>&#39;purchase&#39;</span><span class=p>,</span> <span class=s1>&#39;price&#39;</span><span class=p>]):</span>
            <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;transactional&#39;</span><span class=p>,</span> <span class=s1>&#39;confidence&#39;</span><span class=p>:</span> <span class=mf>0.9</span><span class=p>}</span>
        <span class=k>elif</span> <span class=nb>any</span><span class=p>(</span><span class=n>word</span> <span class=ow>in</span> <span class=n>query</span> <span class=k>for</span> <span class=n>word</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>&#39;how to&#39;</span><span class=p>,</span> <span class=s1>&#39;what is&#39;</span><span class=p>,</span> <span class=s1>&#39;tutorial&#39;</span><span class=p>]):</span>
            <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;informational&#39;</span><span class=p>,</span> <span class=s1>&#39;confidence&#39;</span><span class=p>:</span> <span class=mf>0.85</span><span class=p>}</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;navigational&#39;</span><span class=p>,</span> <span class=s1>&#39;confidence&#39;</span><span class=p>:</span> <span class=mf>0.7</span><span class=p>}</span>

<span class=c1># ============= Elasticsearch Retrieval =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>ElasticsearchRetriever</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;BM25-based retrieval using Elasticsearch&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>SearchConfig</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>es</span> <span class=o>=</span> <span class=n>Elasticsearch</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>es_hosts</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>create_index</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Create Elasticsearch index with custom mapping&quot;&quot;&quot;</span>
        <span class=n>mapping</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s2>&quot;mappings&quot;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s2>&quot;properties&quot;</span><span class=p>:</span> <span class=p>{</span>
                    <span class=s2>&quot;title&quot;</span><span class=p>:</span> <span class=p>{</span>
                        <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;text&quot;</span><span class=p>,</span>
                        <span class=s2>&quot;analyzer&quot;</span><span class=p>:</span> <span class=s2>&quot;standard&quot;</span><span class=p>,</span>
                        <span class=s2>&quot;fields&quot;</span><span class=p>:</span> <span class=p>{</span>
                            <span class=s2>&quot;keyword&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;keyword&quot;</span><span class=p>},</span>
                            <span class=s2>&quot;ngram&quot;</span><span class=p>:</span> <span class=p>{</span>
                                <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;text&quot;</span><span class=p>,</span>
                                <span class=s2>&quot;analyzer&quot;</span><span class=p>:</span> <span class=s2>&quot;ngram_analyzer&quot;</span>
                            <span class=p>}</span>
                        <span class=p>}</span>
                    <span class=p>},</span>
                    <span class=s2>&quot;description&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;text&quot;</span><span class=p>,</span> <span class=s2>&quot;analyzer&quot;</span><span class=p>:</span> <span class=s2>&quot;standard&quot;</span><span class=p>},</span>
                    <span class=s2>&quot;category&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;keyword&quot;</span><span class=p>},</span>
                    <span class=s2>&quot;price&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;float&quot;</span><span class=p>},</span>
                    <span class=s2>&quot;rating&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;float&quot;</span><span class=p>},</span>
                    <span class=s2>&quot;num_reviews&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;integer&quot;</span><span class=p>},</span>
                    <span class=s2>&quot;created_at&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;date&quot;</span><span class=p>},</span>
                    <span class=s2>&quot;tags&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;keyword&quot;</span><span class=p>}</span>
                <span class=p>}</span>
            <span class=p>},</span>
            <span class=s2>&quot;settings&quot;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s2>&quot;analysis&quot;</span><span class=p>:</span> <span class=p>{</span>
                    <span class=s2>&quot;analyzer&quot;</span><span class=p>:</span> <span class=p>{</span>
                        <span class=s2>&quot;ngram_analyzer&quot;</span><span class=p>:</span> <span class=p>{</span>
                            <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;custom&quot;</span><span class=p>,</span>
                            <span class=s2>&quot;tokenizer&quot;</span><span class=p>:</span> <span class=s2>&quot;standard&quot;</span><span class=p>,</span>
                            <span class=s2>&quot;filter&quot;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&quot;lowercase&quot;</span><span class=p>,</span> <span class=s2>&quot;ngram_filter&quot;</span><span class=p>]</span>
                        <span class=p>}</span>
                    <span class=p>},</span>
                    <span class=s2>&quot;filter&quot;</span><span class=p>:</span> <span class=p>{</span>
                        <span class=s2>&quot;ngram_filter&quot;</span><span class=p>:</span> <span class=p>{</span>
                            <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;ngram&quot;</span><span class=p>,</span>
                            <span class=s2>&quot;min_gram&quot;</span><span class=p>:</span> <span class=mi>3</span><span class=p>,</span>
                            <span class=s2>&quot;max_gram&quot;</span><span class=p>:</span> <span class=mi>4</span>
                        <span class=p>}</span>
                    <span class=p>}</span>
                <span class=p>}</span>
            <span class=p>}</span>
        <span class=p>}</span>

        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>es</span><span class=o>.</span><span class=n>indices</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>index_name</span><span class=p>):</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>es</span><span class=o>.</span><span class=n>indices</span><span class=o>.</span><span class=n>create</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>index_name</span><span class=p>,</span> <span class=n>body</span><span class=o>=</span><span class=n>mapping</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Created index: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>index_name</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>index_documents</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>documents</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]]):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Bulk index documents&quot;&quot;&quot;</span>
        <span class=n>actions</span> <span class=o>=</span> <span class=p>[</span>
            <span class=p>{</span>
                <span class=s2>&quot;_index&quot;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>index_name</span><span class=p>,</span>
                <span class=s2>&quot;_id&quot;</span><span class=p>:</span> <span class=n>doc</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;id&#39;</span><span class=p>,</span> <span class=n>hashlib</span><span class=o>.</span><span class=n>md5</span><span class=p>(</span><span class=n>doc</span><span class=p>[</span><span class=s1>&#39;title&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>encode</span><span class=p>())</span><span class=o>.</span><span class=n>hexdigest</span><span class=p>()),</span>
                <span class=s2>&quot;_source&quot;</span><span class=p>:</span> <span class=n>doc</span>
            <span class=p>}</span>
            <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>documents</span>
        <span class=p>]</span>
        <span class=n>helpers</span><span class=o>.</span><span class=n>bulk</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>es</span><span class=p>,</span> <span class=n>actions</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Indexed </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span><span class=si>}</span><span class=s2> documents&quot;</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>search</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>query_info</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
        <span class=n>filters</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
        <span class=n>size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1000</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Execute BM25 search with filters</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=c1># Build Elasticsearch query</span>
        <span class=n>must_clauses</span> <span class=o>=</span> <span class=p>[</span>
            <span class=p>{</span>
                <span class=s2>&quot;multi_match&quot;</span><span class=p>:</span> <span class=p>{</span>
                    <span class=s2>&quot;query&quot;</span><span class=p>:</span> <span class=n>query_info</span><span class=p>[</span><span class=s1>&#39;corrected&#39;</span><span class=p>],</span>
                    <span class=s2>&quot;fields&quot;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&quot;title^3&quot;</span><span class=p>,</span> <span class=s2>&quot;description&quot;</span><span class=p>,</span> <span class=s2>&quot;tags^2&quot;</span><span class=p>],</span>
                    <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;best_fields&quot;</span><span class=p>,</span>
                    <span class=s2>&quot;tie_breaker&quot;</span><span class=p>:</span> <span class=mf>0.3</span>
                <span class=p>}</span>
            <span class=p>}</span>
        <span class=p>]</span>

        <span class=c1># Add expanded query terms with lower weight</span>
        <span class=k>if</span> <span class=n>query_info</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;expanded_tokens&#39;</span><span class=p>):</span>
            <span class=n>expanded_query</span> <span class=o>=</span> <span class=s1>&#39; &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>query_info</span><span class=p>[</span><span class=s1>&#39;expanded_tokens&#39;</span><span class=p>])</span>
            <span class=n>must_clauses</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
                <span class=s2>&quot;multi_match&quot;</span><span class=p>:</span> <span class=p>{</span>
                    <span class=s2>&quot;query&quot;</span><span class=p>:</span> <span class=n>expanded_query</span><span class=p>,</span>
                    <span class=s2>&quot;fields&quot;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&quot;title&quot;</span><span class=p>,</span> <span class=s2>&quot;description&quot;</span><span class=p>],</span>
                    <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;phrase&quot;</span><span class=p>,</span>
                    <span class=s2>&quot;boost&quot;</span><span class=p>:</span> <span class=mf>0.5</span>
                <span class=p>}</span>
            <span class=p>})</span>

        <span class=c1># Build filter clauses</span>
        <span class=n>filter_clauses</span> <span class=o>=</span> <span class=p>[]</span>
        <span class=k>if</span> <span class=n>filters</span><span class=p>:</span>
            <span class=k>if</span> <span class=s1>&#39;category&#39;</span> <span class=ow>in</span> <span class=n>filters</span><span class=p>:</span>
                <span class=n>filter_clauses</span><span class=o>.</span><span class=n>append</span><span class=p>({</span><span class=s2>&quot;term&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;category&quot;</span><span class=p>:</span> <span class=n>filters</span><span class=p>[</span><span class=s1>&#39;category&#39;</span><span class=p>]}})</span>
            <span class=k>if</span> <span class=s1>&#39;min_price&#39;</span> <span class=ow>in</span> <span class=n>filters</span> <span class=ow>or</span> <span class=s1>&#39;max_price&#39;</span> <span class=ow>in</span> <span class=n>filters</span><span class=p>:</span>
                <span class=n>range_filter</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;range&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;price&quot;</span><span class=p>:</span> <span class=p>{}}}</span>
                <span class=k>if</span> <span class=s1>&#39;min_price&#39;</span> <span class=ow>in</span> <span class=n>filters</span><span class=p>:</span>
                    <span class=n>range_filter</span><span class=p>[</span><span class=s1>&#39;range&#39;</span><span class=p>][</span><span class=s1>&#39;price&#39;</span><span class=p>][</span><span class=s1>&#39;gte&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>filters</span><span class=p>[</span><span class=s1>&#39;min_price&#39;</span><span class=p>]</span>
                <span class=k>if</span> <span class=s1>&#39;max_price&#39;</span> <span class=ow>in</span> <span class=n>filters</span><span class=p>:</span>
                    <span class=n>range_filter</span><span class=p>[</span><span class=s1>&#39;range&#39;</span><span class=p>][</span><span class=s1>&#39;price&#39;</span><span class=p>][</span><span class=s1>&#39;lte&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>filters</span><span class=p>[</span><span class=s1>&#39;max_price&#39;</span><span class=p>]</span>
                <span class=n>filter_clauses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>range_filter</span><span class=p>)</span>

        <span class=n>query</span> <span class=o>=</span> <span class=p>{</span>
            <span class=s2>&quot;query&quot;</span><span class=p>:</span> <span class=p>{</span>
                <span class=s2>&quot;bool&quot;</span><span class=p>:</span> <span class=p>{</span>
                    <span class=s2>&quot;must&quot;</span><span class=p>:</span> <span class=n>must_clauses</span><span class=p>,</span>
                    <span class=s2>&quot;filter&quot;</span><span class=p>:</span> <span class=n>filter_clauses</span>
                <span class=p>}</span>
            <span class=p>},</span>
            <span class=s2>&quot;size&quot;</span><span class=p>:</span> <span class=n>size</span><span class=p>,</span>
            <span class=s2>&quot;_source&quot;</span><span class=p>:</span> <span class=kc>True</span>
        <span class=p>}</span>

        <span class=n>response</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>es</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>index</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>index_name</span><span class=p>,</span> <span class=n>body</span><span class=o>=</span><span class=n>query</span><span class=p>)</span>
        <span class=n>results</span> <span class=o>=</span> <span class=p>[</span>
            <span class=p>{</span>
                <span class=o>**</span><span class=n>hit</span><span class=p>[</span><span class=s1>&#39;_source&#39;</span><span class=p>],</span>
                <span class=s1>&#39;doc_id&#39;</span><span class=p>:</span> <span class=n>hit</span><span class=p>[</span><span class=s1>&#39;_id&#39;</span><span class=p>],</span>
                <span class=s1>&#39;bm25_score&#39;</span><span class=p>:</span> <span class=n>hit</span><span class=p>[</span><span class=s1>&#39;_score&#39;</span><span class=p>]</span>
            <span class=p>}</span>
            <span class=k>for</span> <span class=n>hit</span> <span class=ow>in</span> <span class=n>response</span><span class=p>[</span><span class=s1>&#39;hits&#39;</span><span class=p>][</span><span class=s1>&#39;hits&#39;</span><span class=p>]</span>
        <span class=p>]</span>

        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Retrieved </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>)</span><span class=si>}</span><span class=s2> candidates&quot;</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>results</span>

<span class=c1># ============= Learning-to-Rank =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>LearningToRank</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;LTR re-ranking using LightGBM&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>SearchConfig</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=kc>None</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>_load_model</span><span class=p>()</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_load_model</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Load pre-trained LightGBM ranker&quot;&quot;&quot;</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>lgb</span><span class=o>.</span><span class=n>Booster</span><span class=p>(</span><span class=n>model_file</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>ltr_model_path</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&quot;Loaded LTR model&quot;</span><span class=p>)</span>
        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>warning</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Could not load LTR model: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=k>def</span><span class=w> </span><span class=nf>extract_features</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>query_info</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
        <span class=n>document</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
        <span class=n>user_context</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Extract ranking features for query-document pair</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=n>features</span> <span class=o>=</span> <span class=p>[]</span>

        <span class=c1># 1. Text relevance features</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>document</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;bm25_score&#39;</span><span class=p>,</span> <span class=mi>0</span><span class=p>))</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_exact_match_score</span><span class=p>(</span><span class=n>query_info</span><span class=p>[</span><span class=s1>&#39;corrected&#39;</span><span class=p>],</span> <span class=n>document</span><span class=p>[</span><span class=s1>&#39;title&#39;</span><span class=p>]))</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_query_coverage</span><span class=p>(</span><span class=n>query_info</span><span class=p>[</span><span class=s1>&#39;tokens&#39;</span><span class=p>],</span> <span class=n>document</span><span class=p>[</span><span class=s1>&#39;title&#39;</span><span class=p>]))</span>

        <span class=c1># 2. Quality signals</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>document</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;rating&#39;</span><span class=p>,</span> <span class=mi>0</span><span class=p>))</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>log1p</span><span class=p>(</span><span class=n>document</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;num_reviews&#39;</span><span class=p>,</span> <span class=mi>0</span><span class=p>)))</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>document</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;conversion_rate&#39;</span><span class=p>,</span> <span class=mi>0</span><span class=p>))</span>

        <span class=c1># 3. Freshness</span>
        <span class=n>days_old</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_days_since_creation</span><span class=p>(</span><span class=n>document</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;created_at&#39;</span><span class=p>))</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=mf>1.0</span> <span class=o>/</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>+</span> <span class=n>days_old</span><span class=p>))</span>  <span class=c1># Decay with age</span>

        <span class=c1># 4. Popularity</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>log1p</span><span class=p>(</span><span class=n>document</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;view_count&#39;</span><span class=p>,</span> <span class=mi>0</span><span class=p>)))</span>
        <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>log1p</span><span class=p>(</span><span class=n>document</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;sales_count&#39;</span><span class=p>,</span> <span class=mi>0</span><span class=p>)))</span>

        <span class=c1># 5. User personalization (if available)</span>
        <span class=k>if</span> <span class=n>user_context</span><span class=p>:</span>
            <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>_user_affinity</span><span class=p>(</span><span class=n>user_context</span><span class=p>,</span> <span class=n>document</span><span class=p>))</span>
        <span class=k>else</span><span class=p>:</span>
            <span class=n>features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>

        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>features</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_exact_match_score</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>text</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Score for exact query match in text&quot;&quot;&quot;</span>
        <span class=n>text_lower</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
        <span class=n>query_lower</span> <span class=o>=</span> <span class=n>query</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
        <span class=k>if</span> <span class=n>query_lower</span> <span class=ow>in</span> <span class=n>text_lower</span><span class=p>:</span>
            <span class=c1># Bonus for match at beginning</span>
            <span class=k>if</span> <span class=n>text_lower</span><span class=o>.</span><span class=n>startswith</span><span class=p>(</span><span class=n>query_lower</span><span class=p>):</span>
                <span class=k>return</span> <span class=mf>2.0</span>
            <span class=k>return</span> <span class=mf>1.0</span>
        <span class=k>return</span> <span class=mf>0.0</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_query_coverage</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query_tokens</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=nb>str</span><span class=p>],</span> <span class=n>text</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Fraction of query tokens found in text&quot;&quot;&quot;</span>
        <span class=n>text_lower</span> <span class=o>=</span> <span class=n>text</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span>
        <span class=n>matches</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=mi>1</span> <span class=k>for</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>query_tokens</span> <span class=k>if</span> <span class=n>token</span> <span class=ow>in</span> <span class=n>text_lower</span><span class=p>)</span>
        <span class=k>return</span> <span class=n>matches</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>query_tokens</span><span class=p>)</span> <span class=k>if</span> <span class=n>query_tokens</span> <span class=k>else</span> <span class=mi>0</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_days_since_creation</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>created_at</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>str</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>int</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;Calculate days since document creation&quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=n>created_at</span><span class=p>:</span>
            <span class=k>return</span> <span class=mi>365</span>  <span class=c1># Default to 1 year old</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=n>created</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>fromisoformat</span><span class=p>(</span><span class=n>created_at</span><span class=p>)</span>
            <span class=k>return</span> <span class=p>(</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span> <span class=o>-</span> <span class=n>created</span><span class=p>)</span><span class=o>.</span><span class=n>days</span>
        <span class=k>except</span><span class=p>:</span>
            <span class=k>return</span> <span class=mi>365</span>

    <span class=k>def</span><span class=w> </span><span class=nf>_user_affinity</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>user_context</span><span class=p>:</span> <span class=n>Dict</span><span class=p>,</span> <span class=n>document</span><span class=p>:</span> <span class=n>Dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;User-document affinity score&quot;&quot;&quot;</span>
        <span class=c1># Simplified - in production, use collaborative filtering</span>
        <span class=n>user_categories</span> <span class=o>=</span> <span class=n>user_context</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;preferred_categories&#39;</span><span class=p>,</span> <span class=p>[])</span>
        <span class=n>doc_category</span> <span class=o>=</span> <span class=n>document</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;category&#39;</span><span class=p>,</span> <span class=s1>&#39;&#39;</span><span class=p>)</span>
        <span class=k>return</span> <span class=mf>1.0</span> <span class=k>if</span> <span class=n>doc_category</span> <span class=ow>in</span> <span class=n>user_categories</span> <span class=k>else</span> <span class=mf>0.0</span>

    <span class=k>def</span><span class=w> </span><span class=nf>rank</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>query_info</span><span class=p>:</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>],</span>
        <span class=n>candidates</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]],</span>
        <span class=n>user_context</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
        <span class=n>top_k</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>20</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>List</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        Re-rank candidates using LTR model</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>candidates</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>candidates</span><span class=p>[:</span><span class=n>top_k</span><span class=p>]</span>

        <span class=c1># Extract features for all candidates</span>
        <span class=n>feature_matrix</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
            <span class=bp>self</span><span class=o>.</span><span class=n>extract_features</span><span class=p>(</span><span class=n>query_info</span><span class=p>,</span> <span class=n>doc</span><span class=p>,</span> <span class=n>user_context</span><span class=p>)</span>
            <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>candidates</span>
        <span class=p>])</span>

        <span class=c1># Predict scores</span>
        <span class=n>scores</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>feature_matrix</span><span class=p>)</span>

        <span class=c1># Sort by score</span>
        <span class=n>ranked_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=n>scores</span><span class=p>)[::</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
        <span class=n>ranked_results</span> <span class=o>=</span> <span class=p>[</span>
            <span class=p>{</span><span class=o>**</span><span class=n>candidates</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=s1>&#39;ltr_score&#39;</span><span class=p>:</span> <span class=nb>float</span><span class=p>(</span><span class=n>scores</span><span class=p>[</span><span class=n>i</span><span class=p>])}</span>
            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>ranked_indices</span><span class=p>[:</span><span class=n>top_k</span><span class=p>]</span>
        <span class=p>]</span>

        <span class=k>return</span> <span class=n>ranked_results</span>

<span class=c1># ============= Search Service =============</span>
<span class=k>class</span><span class=w> </span><span class=nc>SearchService</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Main search service orchestrating all components&quot;&quot;&quot;</span>

    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config</span><span class=p>:</span> <span class=n>SearchConfig</span><span class=p>):</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>query_understanding</span> <span class=o>=</span> <span class=n>QueryUnderstanding</span><span class=p>()</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>retriever</span> <span class=o>=</span> <span class=n>ElasticsearchRetriever</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>ranker</span> <span class=o>=</span> <span class=n>LearningToRank</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>

    <span class=k>def</span><span class=w> </span><span class=nf>search</span><span class=p>(</span>
        <span class=bp>self</span><span class=p>,</span>
        <span class=n>query</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>
        <span class=n>filters</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>
        <span class=n>user_context</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]:</span>
<span class=w>        </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>        End-to-end search pipeline</span>
<span class=sd>        &quot;&quot;&quot;</span>
        <span class=kn>import</span><span class=w> </span><span class=nn>time</span>
        <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>

        <span class=c1># 1. Query understanding</span>
        <span class=n>query_info</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>query_understanding</span><span class=o>.</span><span class=n>process_query</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Understood query: </span><span class=si>{</span><span class=n>query_info</span><span class=p>[</span><span class=s1>&#39;corrected&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=c1># 2. Retrieval (Stage 1)</span>
        <span class=n>candidates</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>retriever</span><span class=o>.</span><span class=n>search</span><span class=p>(</span>
            <span class=n>query_info</span><span class=p>,</span>
            <span class=n>filters</span><span class=o>=</span><span class=n>filters</span><span class=p>,</span>
            <span class=n>size</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_candidates</span>
        <span class=p>)</span>

        <span class=c1># 3. Ranking (Stage 2)</span>
        <span class=n>ranked_results</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ranker</span><span class=o>.</span><span class=n>rank</span><span class=p>(</span>
            <span class=n>query_info</span><span class=p>,</span>
            <span class=n>candidates</span><span class=p>,</span>
            <span class=n>user_context</span><span class=o>=</span><span class=n>user_context</span><span class=p>,</span>
            <span class=n>top_k</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>max_results</span>
        <span class=p>)</span>

        <span class=n>latency_ms</span> <span class=o>=</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>

        <span class=k>return</span> <span class=p>{</span>
            <span class=s1>&#39;query&#39;</span><span class=p>:</span> <span class=n>query_info</span><span class=p>[</span><span class=s1>&#39;corrected&#39;</span><span class=p>],</span>
            <span class=s1>&#39;results&#39;</span><span class=p>:</span> <span class=n>ranked_results</span><span class=p>,</span>
            <span class=s1>&#39;total_candidates&#39;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>candidates</span><span class=p>),</span>
            <span class=s1>&#39;latency_ms&#39;</span><span class=p>:</span> <span class=n>latency_ms</span><span class=p>,</span>
            <span class=s1>&#39;spelling_corrected&#39;</span><span class=p>:</span> <span class=n>query</span> <span class=o>!=</span> <span class=n>query_info</span><span class=p>[</span><span class=s1>&#39;corrected&#39;</span><span class=p>]</span>
        <span class=p>}</span>

<span class=c1># ============= Usage Example =============</span>
<span class=k>def</span><span class=w> </span><span class=nf>example_usage</span><span class=p>():</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Example search workflow&quot;&quot;&quot;</span>
    <span class=n>service</span> <span class=o>=</span> <span class=n>SearchService</span><span class=p>(</span><span class=n>config</span><span class=p>)</span>

    <span class=c1># Create index</span>
    <span class=n>service</span><span class=o>.</span><span class=n>retriever</span><span class=o>.</span><span class=n>create_index</span><span class=p>()</span>

    <span class=c1># Index sample documents</span>
    <span class=n>documents</span> <span class=o>=</span> <span class=p>[</span>
        <span class=p>{</span>
            <span class=s1>&#39;id&#39;</span><span class=p>:</span> <span class=s1>&#39;1&#39;</span><span class=p>,</span>
            <span class=s1>&#39;title&#39;</span><span class=p>:</span> <span class=s1>&#39;Hands-On Machine Learning&#39;</span><span class=p>,</span>
            <span class=s1>&#39;description&#39;</span><span class=p>:</span> <span class=s1>&#39;Practical ML with Scikit-Learn and TensorFlow&#39;</span><span class=p>,</span>
            <span class=s1>&#39;category&#39;</span><span class=p>:</span> <span class=s1>&#39;Books&#39;</span><span class=p>,</span>
            <span class=s1>&#39;price&#39;</span><span class=p>:</span> <span class=mf>39.99</span><span class=p>,</span>
            <span class=s1>&#39;rating&#39;</span><span class=p>:</span> <span class=mf>4.8</span><span class=p>,</span>
            <span class=s1>&#39;num_reviews&#39;</span><span class=p>:</span> <span class=mi>2500</span><span class=p>,</span>
            <span class=s1>&#39;created_at&#39;</span><span class=p>:</span> <span class=s1>&#39;2023-01-15&#39;</span><span class=p>,</span>
            <span class=s1>&#39;tags&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;machine learning&#39;</span><span class=p>,</span> <span class=s1>&#39;python&#39;</span><span class=p>,</span> <span class=s1>&#39;AI&#39;</span><span class=p>]</span>
        <span class=p>},</span>
        <span class=p>{</span>
            <span class=s1>&#39;id&#39;</span><span class=p>:</span> <span class=s1>&#39;2&#39;</span><span class=p>,</span>
            <span class=s1>&#39;title&#39;</span><span class=p>:</span> <span class=s1>&#39;Deep Learning&#39;</span><span class=p>,</span>
            <span class=s1>&#39;description&#39;</span><span class=p>:</span> <span class=s1>&#39;Comprehensive guide to deep learning by Goodfellow&#39;</span><span class=p>,</span>
            <span class=s1>&#39;category&#39;</span><span class=p>:</span> <span class=s1>&#39;Books&#39;</span><span class=p>,</span>
            <span class=s1>&#39;price&#39;</span><span class=p>:</span> <span class=mf>49.99</span><span class=p>,</span>
            <span class=s1>&#39;rating&#39;</span><span class=p>:</span> <span class=mf>4.9</span><span class=p>,</span>
            <span class=s1>&#39;num_reviews&#39;</span><span class=p>:</span> <span class=mi>1800</span><span class=p>,</span>
            <span class=s1>&#39;created_at&#39;</span><span class=p>:</span> <span class=s1>&#39;2023-03-20&#39;</span><span class=p>,</span>
            <span class=s1>&#39;tags&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;deep learning&#39;</span><span class=p>,</span> <span class=s1>&#39;neural networks&#39;</span><span class=p>,</span> <span class=s1>&#39;AI&#39;</span><span class=p>]</span>
        <span class=p>}</span>
    <span class=p>]</span>
    <span class=n>service</span><span class=o>.</span><span class=n>retriever</span><span class=o>.</span><span class=n>index_documents</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>

    <span class=c1># Execute search</span>
    <span class=n>results</span> <span class=o>=</span> <span class=n>service</span><span class=o>.</span><span class=n>search</span><span class=p>(</span>
        <span class=n>query</span><span class=o>=</span><span class=s2>&quot;machin learning books&quot;</span><span class=p>,</span>  <span class=c1># Typo intentional</span>
        <span class=n>filters</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;category&#39;</span><span class=p>:</span> <span class=s1>&#39;Books&#39;</span><span class=p>},</span>
        <span class=n>user_context</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;preferred_categories&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;Books&#39;</span><span class=p>,</span> <span class=s1>&#39;Technology&#39;</span><span class=p>]}</span>
    <span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Query: </span><span class=si>{</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;query&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Latency: </span><span class=si>{</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;latency_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>ms&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Results: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;results&#39;</span><span class=p>])</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>results</span><span class=p>[</span><span class=s1>&#39;results&#39;</span><span class=p>][:</span><span class=mi>3</span><span class=p>],</span> <span class=mi>1</span><span class=p>):</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>. </span><span class=si>{</span><span class=n>result</span><span class=p>[</span><span class=s1>&#39;title&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> - $</span><span class=si>{</span><span class=n>result</span><span class=p>[</span><span class=s1>&#39;price&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> ‚≠ê</span><span class=si>{</span><span class=n>result</span><span class=p>[</span><span class=s1>&#39;rating&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <h2 id=ranking-stage-comparison>Ranking Stage Comparison</h2> <table> <thead> <tr> <th>Stage</th> <th>Algorithm</th> <th>Candidates</th> <th>Latency</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td><strong>Stage 1: Retrieval</strong></td> <td>BM25, TF-IDF</td> <td>1M ‚Üí 1K</td> <td>&lt;20ms</td> <td>Fast pruning from large corpus</td> </tr> <tr> <td><strong>Stage 2: Re-ranking</strong></td> <td>LightGBM, BERT</td> <td>1K ‚Üí 100</td> <td>&lt;50ms</td> <td>Feature-rich scoring</td> </tr> <tr> <td><strong>Stage 3: Personalization</strong></td> <td>Collaborative Filtering</td> <td>100 ‚Üí 20</td> <td>&lt;10ms</td> <td>User-specific adjustments</td> </tr> </tbody> </table> <h2 id=common-pitfalls-solutions_3>Common Pitfalls &amp; Solutions</h2> <table> <thead> <tr> <th>Pitfall</th> <th>Impact</th> <th>Solution</th> </tr> </thead> <tbody> <tr> <td><strong>No Spell Correction</strong></td> <td>Miss ~10% queries</td> <td>Use Levenshtein distance, context-aware correction</td> </tr> <tr> <td><strong>Single-Stage Ranking</strong></td> <td>Slow or poor relevance</td> <td>Multi-stage: fast retrieval ‚Üí expensive re-ranking</td> </tr> <tr> <td><strong>No Query Expansion</strong></td> <td>Miss synonyms/variations</td> <td>Synonym dictionaries, word embeddings</td> </tr> <tr> <td><strong>Static Ranking</strong></td> <td>Stale results</td> <td>Incorporate real-time signals (CTR, freshness)</td> </tr> <tr> <td><strong>No Personalization</strong></td> <td>Generic results</td> <td>User history, collaborative filtering</td> </tr> <tr> <td><strong>Index Hotspots</strong></td> <td>Uneven load</td> <td>Shard by hash, avoid temporal sharding</td> </tr> <tr> <td><strong>No Diversity</strong></td> <td>Filter bubble</td> <td>MMR (Maximal Marginal Relevance), genre mixing</td> </tr> <tr> <td><strong>Ignoring Long Tail</strong></td> <td>Miss niche queries</td> <td>Fuzzy matching, relaxed filters for 0 results</td> </tr> </tbody> </table> <h2 id=real-world-examples_3>Real-World Examples</h2> <p><strong>Google Search:</strong> - <strong>Scale:</strong> Billions of documents, 100K+ QPS - <strong>Architecture:</strong> Multi-tiered serving (L1: memory, L2: SSD, L3: disk) - <strong>Ranking:</strong> 200+ signals, PageRank + BERT embeddings + user signals - <strong>Latency:</strong> &lt;200ms p99 with global query routing - <strong>Impact:</strong> Gold standard for search relevance</p> <p><strong>Amazon Product Search:</strong> - <strong>Scale:</strong> 600M+ products, 1M+ QPS - <strong>Architecture:</strong> Elasticsearch + custom ranking service - <strong>Ranking:</strong> 150+ features (text, behavior, business metrics) - <strong>Personalization:</strong> Purchase history, browsing, collaborative filtering - <strong>Impact:</strong> 35% of revenue from search-driven purchases</p> <p><strong>LinkedIn Talent Search:</strong> - <strong>Scale:</strong> 800M+ profiles, 100K+ QPS - <strong>Architecture:</strong> Galene (custom search engine) + LTR - <strong>Ranking:</strong> 50+ features (skills, experience, network, activity) - <strong>Innovation:</strong> Standardization (normalize titles, skills) - <strong>Impact:</strong> 70% of hires go through search</p> <h2 id=evaluation-metrics>Evaluation Metrics</h2> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>evaluate_search_quality</span><span class=p>(</span><span class=n>predicted_rankings</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>]],</span>
                             <span class=n>ground_truth</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>List</span><span class=p>[</span><span class=nb>int</span><span class=p>]])</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=nb>float</span><span class=p>]:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Evaluate search quality using standard IR metrics</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>ndcg_score</span>

    <span class=n>metrics</span> <span class=o>=</span> <span class=p>{}</span>

    <span class=c1># NDCG@K (Normalized Discounted Cumulative Gain)</span>
    <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>]:</span>
        <span class=n>ndcg</span> <span class=o>=</span> <span class=n>ndcg_score</span><span class=p>(</span><span class=n>ground_truth</span><span class=p>,</span> <span class=n>predicted_rankings</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=n>k</span><span class=p>)</span>
        <span class=n>metrics</span><span class=p>[</span><span class=sa>f</span><span class=s1>&#39;ndcg@</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>ndcg</span>

    <span class=c1># MRR (Mean Reciprocal Rank)</span>
    <span class=n>mrr</span> <span class=o>=</span> <span class=mi>0</span>
    <span class=k>for</span> <span class=n>pred</span><span class=p>,</span> <span class=n>truth</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>predicted_rankings</span><span class=p>,</span> <span class=n>ground_truth</span><span class=p>):</span>
        <span class=k>for</span> <span class=n>rank</span><span class=p>,</span> <span class=n>item</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>pred</span><span class=p>,</span> <span class=mi>1</span><span class=p>):</span>
            <span class=k>if</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>truth</span><span class=p>:</span>
                <span class=n>mrr</span> <span class=o>+=</span> <span class=mf>1.0</span> <span class=o>/</span> <span class=n>rank</span>
                <span class=k>break</span>
    <span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;mrr&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>mrr</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>predicted_rankings</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>metrics</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Emphasizes multi-stage ranking (BM25 ‚Üí LTR ‚Üí personalization) for latency-quality trade-off, query understanding for handling typos/synonyms, and learning-to-rank with 100+ features. Discusses inverted index structure, sharding strategies, and evaluation metrics (NDCG, MRR). Can explain how Google/Amazon/LinkedIn implement search at scale with specific architectural choices.</p> </div> </details> <hr> <h3 id=design-a-data-warehouse-amazon-google-interview-question>Design a Data Warehouse - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Data Engineering</code> | <strong>Asked by:</strong> Amazon, Google, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Schema Design:</strong> - Star schema (fact + dimension tables) - Slowly changing dimensions (SCD Type &frac12;)</p> <p><strong>Technology Stack:</strong> - Storage: S3, GCS - Processing: Spark, DBT - Query: BigQuery, Snowflake, Redshift</p> <p><strong>Partitioning:</strong> By date for time-series data.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Knows star vs snowflake schema and partitioning.</p> </div> </details> <hr> <h3 id=design-a-stream-processing-system-uber-netflix-interview-question>Design a Stream Processing System - Uber, Netflix Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Streaming</code> | <strong>Asked by:</strong> Uber, Netflix, LinkedIn</p> <details class=success> <summary>View Answer</summary> <div class=highlight><pre><span></span><code>[Events] ‚Üí [Kafka] ‚Üí [Flink/Spark] ‚Üí [Feature Store] ‚Üí [Model]
                            ‚Üì
                     [Aggregations]
</code></pre></div> <p><strong>Key Concepts:</strong> - Windowing (tumbling, sliding, session) - Watermarks for late data - Exactly-once semantics - State management</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Handles late data and stateful processing.</p> </div> </details> <hr> <h3 id=design-an-ml-labeling-pipeline-google-amazon-interview-question>Design an ML Labeling Pipeline - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Data Quality</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Components:</strong> 1. <strong>Label UI:</strong> Annotation interface 2. <strong>Quality assurance:</strong> Multiple annotators, consensus 3. <strong>Active learning:</strong> Prioritize uncertain samples 4. <strong>Version control:</strong> Track label changes</p> <p><strong>Tools:</strong> Label Studio, Scale AI, Labelbox.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Includes quality control and active learning.</p> </div> </details> <hr> <h3 id=design-a-neural-network-optimizer-google-meta-interview-question>Design a Neural Network Optimizer - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Deep Learning</code> | <strong>Asked by:</strong> Google, Meta, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>Hyperparameter Search:</strong> - Grid search ‚Üí Random search ‚Üí Bayesian - Neural Architecture Search (NAS)</p> <p><strong>Infrastructure:</strong> - Ray Tune, Optuna - Distributed trials - Early stopping - Checkpoint management</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses Bayesian optimization for efficiency.</p> </div> </details> <hr> <h3 id=design-a-model-retraining-system-google-amazon-interview-question>Design a Model Retraining System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>MLOps</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Triggers:</strong> - Scheduled (daily/weekly) - Drift-based (data/concept drift) - Performance-based (accuracy drop)</p> <p><strong>Pipeline:</strong> <div class=highlight><pre><span></span><code>[Trigger] ‚Üí [Data] ‚Üí [Train] ‚Üí [Validate] ‚Üí [Deploy]
                                    ‚Üì
                          [Shadow Mode/Canary]
</code></pre></div></p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses drift detection for smart retraining.</p> </div> </details> <hr> <h3 id=design-a-vector-search-system-google-meta-interview-question>Design a Vector Search System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Embeddings</code>, <code>Search</code> | <strong>Asked by:</strong> Google, Meta, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>ANN (Approximate Nearest Neighbor) Options:</strong></p> <table> <thead> <tr> <th>Algorithm</th> <th>Pros</th> <th>Cons</th> </tr> </thead> <tbody> <tr> <td>HNSW</td> <td>Fast, good recall</td> <td>Memory</td> </tr> <tr> <td>IVF</td> <td>Scalable</td> <td>Slower</td> </tr> <tr> <td>PQ</td> <td>Memory efficient</td> <td>Lower recall</td> </tr> </tbody> </table> <p><strong>Systems:</strong> Faiss, Pinecone, Weaviate, Milvus.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Knows HNSW vs IVF tradeoffs.</p> </div> </details> <hr> <h3 id=design-an-embedding-service-google-meta-interview-question>Design an Embedding Service - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Embeddings</code> | <strong>Asked by:</strong> Google, Meta, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>Requirements:</strong> - Low latency (&lt; 50ms) - High throughput - Batching for efficiency</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Request] ‚Üí [Batch Collector] ‚Üí [GPU Inference] ‚Üí [Cache]
</code></pre></div></p> <p><strong>Optimization:</strong> Model quantization, TensorRT.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses batching and caching for efficiency.</p> </div> </details> <hr> <h3 id=design-a-content-moderation-system-meta-youtube-interview-question>Design a Content Moderation System - Meta, YouTube Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Trust &amp; Safety</code> | <strong>Asked by:</strong> Meta, YouTube, TikTok</p> <details class=success> <summary>View Answer</summary> <p><strong>Multi-stage Pipeline:</strong> 1. <strong>Fast filters:</strong> Hashes, blocklists 2. <strong>ML classifiers:</strong> Text, image, video 3. <strong>Human review:</strong> Edge cases 4. <strong>Appeals:</strong> User feedback loop</p> <p><strong>Metrics:</strong> Precision (avoid false positives), latency.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Balances automation with human review.</p> </div> </details> <hr> <h3 id=design-a-notification-system-google-amazon-interview-question>Design a Notification System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>System Design</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Components:</strong> - Event ingestion (Kafka) - User preferences store - Rate limiting - Multi-channel delivery (push, email, SMS)</p> <p><strong>ML Integration:</strong> Optimal send time, relevance scoring.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses ML for send time optimization.</p> </div> </details> <hr> <h3 id=design-a-cache-invalidation-strategy-google-meta-interview-question>Design a Cache Invalidation Strategy - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Caching</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Strategies:</strong></p> <table> <thead> <tr> <th>Strategy</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td>TTL</td> <td>Time-based expiry</td> </tr> <tr> <td>Write-through</td> <td>Consistent, slower writes</td> </tr> <tr> <td>Write-behind</td> <td>Fast writes, eventual consistency</td> </tr> <tr> <td>Event-based</td> <td>Data change triggers</td> </tr> </tbody> </table> <p><strong>ML Context:</strong> Model version changes, feature updates.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Chooses strategy based on consistency needs.</p> </div> </details> <hr> <h3 id=design-a-feature-flag-system-netflix-meta-interview-question>Design a Feature Flag System - Netflix, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>DevOps</code> | <strong>Asked by:</strong> Netflix, Meta, Uber</p> <details class=success> <summary>View Answer</summary> <p><strong>Capabilities:</strong> - User targeting (percentage, segments) - Kill switches - Experiment integration - Audit logging</p> <p><strong>ML Use Cases:</strong> Model rollouts, shadow testing.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Integrates with experiment platform.</p> </div> </details> <hr> <h3 id=design-a-rate-limiter-google-amazon-interview-question>Design a Rate Limiter - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>System Design</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Algorithms:</strong> - Token bucket - Sliding window - Fixed window counter</p> <p><strong>ML API Context:</strong> - Per-user limits - Tiered pricing - Burst handling</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses sliding window for smooth limiting.</p> </div> </details> <hr> <h3 id=design-a-batch-prediction-system-google-amazon-interview-question>Design a Batch Prediction System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Inference</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Scheduler] ‚Üí [Data Fetch] ‚Üí [Batch Inference] ‚Üí [Store Results]
</code></pre></div></p> <p><strong>Considerations:</strong> - Parallelization - Checkpointing - Error handling - Result storage (BigQuery, S3)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Designs for resumability and monitoring.</p> </div> </details> <hr> <h3 id=design-a-cicd-pipeline-for-ml-google-amazon-interview-question>Design a CI/CD Pipeline for ML - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>MLOps</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Stages:</strong> 1. Code/data validation 2. Unit tests + integration tests 3. Model training 4. Evaluation against holdout 5. Shadow deployment 6. Canary rollout</p> <p><strong>Tools:</strong> GitHub Actions, MLflow, Kubeflow.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Includes model evaluation in pipeline.</p> </div> </details> <hr> <h3 id=design-a-time-series-forecasting-system-amazon-google-interview-question>Design a Time Series Forecasting System - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Forecasting</code>, <code>Time Series</code> | <strong>Asked by:</strong> Amazon, Google, Uber</p> <details class=success> <summary>View Answer</summary> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Historical Data] ‚Üí [Feature Engineering] ‚Üí [Model] ‚Üí [Forecast] ‚Üí [Monitoring]
       ‚Üì
[Seasonality Detection]
</code></pre></div></p> <p><strong>Key Components:</strong></p> <table> <thead> <tr> <th>Component</th> <th>Techniques</th> </tr> </thead> <tbody> <tr> <td>Feature Engineering</td> <td>Lags, rolling stats, seasonality</td> </tr> <tr> <td>Models</td> <td>ARIMA, Prophet, LSTM, Transformers</td> </tr> <tr> <td>Validation</td> <td>Time-based cross-validation</td> </tr> <tr> <td>Monitoring</td> <td>Forecast accuracy, drift detection</td> </tr> </tbody> </table> <p><strong>Scale Considerations:</strong> - Hierarchical forecasting (product ‚Üí category ‚Üí total) - Parallel training for multiple series - Cold-start handling for new products</p> <div class=highlight><pre><span></span><code><span class=kn>from</span><span class=w> </span><span class=nn>prophet</span><span class=w> </span><span class=kn>import</span> <span class=n>Prophet</span>

<span class=c1># Hierarchical forecasting</span>
<span class=k>def</span><span class=w> </span><span class=nf>forecast_hierarchy</span><span class=p>(</span><span class=n>data</span><span class=p>):</span>
    <span class=c1># Bottom-up: sum leaf forecasts</span>
    <span class=c1># Top-down: distribute total forecast</span>
    <span class=c1># Middle-out: reconciliation</span>
    <span class=k>return</span> <span class=n>reconciled_forecasts</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses backtesting strategy and handling seasonality at scale.</p> </div> </details> <hr> <h3 id=design-a-computer-vision-pipeline-google-meta-interview-question>Design a Computer Vision Pipeline - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Computer Vision</code>, <code>Deep Learning</code> | <strong>Asked by:</strong> Google, Meta, Tesla</p> <details class=success> <summary>View Answer</summary> <p><strong>End-to-End Pipeline:</strong> <div class=highlight><pre><span></span><code>[Image/Video] ‚Üí [Preprocessing] ‚Üí [Model Inference] ‚Üí [Post-processing] ‚Üí [Results]
                     ‚Üì
               [Data Augmentation]
</code></pre></div></p> <p><strong>Components:</strong> 1. <strong>Data Ingestion:</strong> Handle images, videos, streams 2. <strong>Preprocessing:</strong> Resize, normalize, batch 3. <strong>Model:</strong> ResNet, EfficientNet, ViT 4. <strong>Post-processing:</strong> NMS, filtering, tracking</p> <p><strong>Optimization:</strong> - TensorRT for GPU inference - ONNX for portability - Quantization (INT8) for edge devices</p> <p><strong>Scale:</strong> Process 1M+ images/day with &lt;100ms latency.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses model selection based on accuracy vs latency tradeoffs.</p> </div> </details> <hr> <h3 id=design-an-nlp-pipeline-for-production-google-amazon-interview-question>Design an NLP Pipeline for Production - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>NLP</code>, <code>Transformers</code> | <strong>Asked by:</strong> Google, Amazon, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Text] ‚Üí [Tokenization] ‚Üí [Embedding] ‚Üí [Model] ‚Üí [Post-process] ‚Üí [Output]
              ‚Üì
        [Text Cleaning]
</code></pre></div></p> <p><strong>Key Decisions:</strong></p> <table> <thead> <tr> <th>Stage</th> <th>Options</th> </tr> </thead> <tbody> <tr> <td>Tokenization</td> <td>BPE, WordPiece, SentencePiece</td> </tr> <tr> <td>Model</td> <td>BERT, RoBERTa, GPT, T5</td> </tr> <tr> <td>Serving</td> <td>ONNX, TorchServe, Triton</td> </tr> <tr> <td>Latency</td> <td>Distillation, quantization</td> </tr> </tbody> </table> <p><strong>Challenges:</strong> - Long context handling (16K+ tokens) - Multi-lingual support - Domain adaptation</p> <div class=highlight><pre><span></span><code><span class=c1># Model distillation for faster inference</span>
<span class=n>student_model</span> <span class=o>=</span> <span class=n>distill</span><span class=p>(</span><span class=n>teacher_model</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
<span class=c1># 10x faster, 95% accuracy retained</span>
</code></pre></div> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Knows when to use fine-tuning vs prompt engineering.</p> </div> </details> <hr> <h3 id=design-a-graph-neural-network-system-google-meta-interview-question>Design a Graph Neural Network System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Graph ML</code>, <code>GNN</code> | <strong>Asked by:</strong> Google, Meta, LinkedIn</p> <details class=success> <summary>View Answer</summary> <p><strong>Use Cases:</strong> - Social network analysis - Fraud detection (transaction graphs) - Recommendation (user-item graphs) - Knowledge graphs</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Graph Data] ‚Üí [Graph Construction] ‚Üí [GNN] ‚Üí [Node/Edge Predictions]
                      ‚Üì
              [Sampling Strategy]
</code></pre></div></p> <p><strong>Key Components:</strong> - Graph sampling (GraphSAGE, neighbor sampling) - Message passing (GCN, GAT, GraphTransformer) - Distributed training (DGL, PyG)</p> <p><strong>Scale:</strong> Billion-node graphs with mini-batch training.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses sampling strategies for large-scale graphs.</p> </div> </details> <hr> <h3 id=design-a-reinforcement-learning-system-google-deepmind-interview-question>Design a Reinforcement Learning System - Google, DeepMind Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>RL</code>, <code>Online Learning</code> | <strong>Asked by:</strong> Google, DeepMind, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>Components:</strong> 1. <strong>Environment:</strong> Simulator or real-world 2. <strong>Agent:</strong> Policy network 3. <strong>Experience Replay:</strong> Store (s, a, r, s') 4. <strong>Training:</strong> Off-policy or on-policy</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Agent] ‚Üî [Environment]
   ‚Üì
[Replay Buffer] ‚Üí [Training] ‚Üí [Updated Policy]
</code></pre></div></p> <p><strong>Algorithms:</strong> - DQN, A3C, PPO, SAC - Model-based RL for sample efficiency</p> <p><strong>Challenges:</strong> - Exploration vs exploitation - Reward shaping - Sim-to-real transfer</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses reward engineering and safety constraints.</p> </div> </details> <hr> <h3 id=design-a-model-explainability-system-google-amazon-interview-question>Design a Model Explainability System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Interpretability</code>, <code>XAI</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Techniques:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Use Case</th> <th>Complexity</th> </tr> </thead> <tbody> <tr> <td>SHAP</td> <td>Feature importance</td> <td>Medium</td> </tr> <tr> <td>LIME</td> <td>Local explanations</td> <td>Low</td> </tr> <tr> <td>Attention Viz</td> <td>Transformers</td> <td>Low</td> </tr> <tr> <td>Counterfactuals</td> <td>What-if analysis</td> <td>High</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Prediction] ‚Üí [Explanation Generator] ‚Üí [Visualization] ‚Üí [User]
                      ‚Üì
              [Explanation Store]
</code></pre></div></p> <p><strong>Requirements:</strong> - Real-time explanations (&lt;100ms) - Human-readable outputs - Regulatory compliance (GDPR, FCRA)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Balances explanation quality with computational cost.</p> </div> </details> <hr> <h3 id=design-a-federated-learning-system-google-apple-interview-question>Design a Federated Learning System - Google, Apple Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Privacy</code>, <code>Distributed ML</code> | <strong>Asked by:</strong> Google, Apple, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Privacy-Preserving ML:</strong> <div class=highlight><pre><span></span><code>[Edge Devices] ‚Üí [Local Training] ‚Üí [Encrypted Updates] ‚Üí [Central Server]
                                          ‚Üì
                                [Aggregation (FedAvg)]
</code></pre></div></p> <p><strong>Key Concepts:</strong> 1. <strong>Local Training:</strong> Data never leaves device 2. <strong>Secure Aggregation:</strong> Encrypted model updates 3. <strong>Differential Privacy:</strong> Add noise to updates 4. <strong>Communication Efficiency:</strong> Compression, quantization</p> <p><strong>Challenges:</strong> - Non-IID data distribution - Stragglers (slow devices) - Byzantine attacks</p> <p><strong>Tools:</strong> TensorFlow Federated, PySyft.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses communication efficiency and privacy guarantees.</p> </div> </details> <hr> <h3 id=design-a-multi-tenant-ml-platform-amazon-microsoft-interview-question>Design a Multi-Tenant ML Platform - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Platform</code>, <code>Multi-tenancy</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Requirements:</strong> - Isolation (data, compute, models) - Resource quotas - Cost tracking per tenant - Shared infrastructure efficiency</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[API Gateway] ‚Üí [Tenant Router] ‚Üí [Isolated Namespaces]
                      ‚Üì
                [Shared Resources]
</code></pre></div></p> <p><strong>Implementation:</strong> - Kubernetes namespaces - Resource limits (CPU, GPU, memory) - Data encryption at rest/transit - Audit logging</p> <p><strong>Scaling:</strong> Support 1000+ tenants efficiently.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Balances isolation with resource efficiency.</p> </div> </details> <hr> <h3 id=design-a-cost-optimization-system-for-ml-amazon-google-interview-question>Design a Cost Optimization System for ML - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Cost Optimization</code>, <code>FinOps</code> | <strong>Asked by:</strong> Amazon, Google, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Cost Levers:</strong></p> <table> <thead> <tr> <th>Component</th> <th>Optimization</th> </tr> </thead> <tbody> <tr> <td>Compute</td> <td>Spot instances, right-sizing</td> </tr> <tr> <td>Storage</td> <td>Data lifecycle, compression</td> </tr> <tr> <td>Inference</td> <td>Batching, autoscaling</td> </tr> <tr> <td>Training</td> <td>Early stopping, efficient architectures</td> </tr> </tbody> </table> <p><strong>Monitoring:</strong> <div class=highlight><pre><span></span><code>[Usage Metrics] ‚Üí [Cost Analysis] ‚Üí [Recommendations] ‚Üí [Auto-actions]
</code></pre></div></p> <p><strong>Strategies:</strong> - Schedule training during off-peak hours - Use cheaper storage tiers for old data - Implement model caching - Optimize batch sizes for GPU utilization</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Provides cost breakdown by experiment/model/team.</p> </div> </details> <hr> <h3 id=design-an-automl-system-google-amazon-interview-question>Design an AutoML System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>AutoML</code>, <code>Meta-learning</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Components:</strong> 1. <strong>Data Preprocessing:</strong> Auto feature engineering 2. <strong>Model Selection:</strong> Search over architectures 3. <strong>Hyperparameter Optimization:</strong> Bayesian optimization 4. <strong>Ensemble:</strong> Combine top models</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Dataset] ‚Üí [AutoML Engine] ‚Üí [Model Zoo] ‚Üí [Best Model]
                 ‚Üì
          [Search Space]
</code></pre></div></p> <p><strong>Techniques:</strong> - Neural Architecture Search (NAS) - Meta-learning for warm starts - Progressive training (ASHA)</p> <p><strong>Tools:</strong> Google AutoML, H2O.ai, Auto-sklearn.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses search space design and computational budget.</p> </div> </details> <hr> <h3 id=design-an-active-learning-system-google-meta-interview-question>Design an Active Learning System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Active Learning</code>, <code>Data Efficiency</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Goal:</strong> Minimize labeling cost by selecting most informative samples.</p> <p><strong>Strategies:</strong></p> <table> <thead> <tr> <th>Strategy</th> <th>When to Use</th> </tr> </thead> <tbody> <tr> <td>Uncertainty Sampling</td> <td>Classification confidence</td> </tr> <tr> <td>Query-by-Committee</td> <td>Ensemble disagreement</td> </tr> <tr> <td>Expected Model Change</td> <td>Impact on model</td> </tr> <tr> <td>Diversity Sampling</td> <td>Cover feature space</td> </tr> </tbody> </table> <p><strong>Pipeline:</strong> <div class=highlight><pre><span></span><code>[Model] ‚Üí [Uncertainty Estimation] ‚Üí [Sample Selection] ‚Üí [Labeling] ‚Üí [Retrain]
</code></pre></div></p> <p><strong>Metrics:</strong> Accuracy vs number of labeled samples.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Combines uncertainty with diversity for better coverage.</p> </div> </details> <hr> <h3 id=design-an-online-learning-system-netflix-uber-interview-question>Design an Online Learning System - Netflix, Uber Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Online Learning</code>, <code>Streaming</code> | <strong>Asked by:</strong> Netflix, Uber, LinkedIn</p> <details class=success> <summary>View Answer</summary> <p><strong>Characteristics:</strong> - Learn from streaming data - Update model incrementally - Adapt to changing distributions</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Stream] ‚Üí [Feature Extraction] ‚Üí [Online Model] ‚Üí [Prediction]
                 ‚Üì                      ‚Üì
          [Feature Store]        [Model Update]
</code></pre></div></p> <p><strong>Algorithms:</strong> - Stochastic Gradient Descent (SGD) - Online gradient descent - Vowpal Wabbit, River</p> <p><strong>Challenges:</strong> - Concept drift detection - Catastrophic forgetting - Model stability</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses when online learning is preferred over batch retraining.</p> </div> </details> <hr> <h3 id=design-a-knowledge-graph-for-ml-google-amazon-interview-question>Design a Knowledge Graph for ML - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Knowledge Graphs</code>, <code>Graph ML</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Use Cases:</strong> - Enhanced search (semantic understanding) - Recommendation (entity relationships) - Question answering - Feature enrichment for ML</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Data Sources] ‚Üí [Entity Extraction] ‚Üí [Knowledge Graph] ‚Üí [Graph Embeddings]
                       ‚Üì
                [Relation Extraction]
</code></pre></div></p> <p><strong>Components:</strong> - Entity resolution and linking - Relation extraction (distant supervision) - Graph storage (Neo4j, Neptune) - Embedding (TransE, ComplEx, RotatE)</p> <p><strong>Scale:</strong> Billions of entities and relations.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses entity disambiguation and knowledge graph completion.</p> </div> </details> <hr> <h3 id=design-an-ml-system-for-edge-devices-apple-tesla-interview-question>Design an ML System for Edge Devices - Apple, Tesla Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Edge Computing</code>, <code>Mobile ML</code> | <strong>Asked by:</strong> Apple, Tesla, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Constraints:</strong> - Limited compute (mobile CPU/GPU) - Memory constraints (&lt;100MB models) - Battery efficiency - No/intermittent connectivity</p> <p><strong>Optimization Techniques:</strong></p> <table> <thead> <tr> <th>Technique</th> <th>Benefit</th> <th>Trade-off</th> </tr> </thead> <tbody> <tr> <td>Quantization</td> <td>4x smaller</td> <td>Slight accuracy drop</td> </tr> <tr> <td>Pruning</td> <td>Faster inference</td> <td>More training needed</td> </tr> <tr> <td>Knowledge Distillation</td> <td>Smaller model</td> <td>Requires teacher</td> </tr> <tr> <td>Mobile architectures</td> <td>Optimized for edge</td> <td>Different training</td> </tr> </tbody> </table> <p><strong>Tools:</strong> TensorFlow Lite, Core ML, ONNX Runtime Mobile.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Balances model size, accuracy, and latency for edge constraints.</p> </div> </details> <hr> <h3 id=design-a-containerization-strategy-for-ml-google-amazon-interview-question>Design a Containerization Strategy for ML - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>DevOps</code>, <code>Containers</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Model Code] ‚Üí [Dockerfile] ‚Üí [Container Image] ‚Üí [Container Registry]
                    ‚Üì
              [Orchestration (K8s)]
</code></pre></div></p> <p><strong>Best Practices:</strong> 1. <strong>Reproducibility:</strong> Pin all dependencies 2. <strong>Caching:</strong> Layer Docker images efficiently 3. <strong>Security:</strong> Scan for vulnerabilities 4. <strong>Size:</strong> Multi-stage builds to reduce size</p> <div class=highlight><pre><span></span><code><span class=k>FROM</span><span class=w> </span><span class=s>python:3.9-slim</span>
<span class=k>COPY</span><span class=w> </span>requirements.txt<span class=w> </span>.
<span class=k>RUN</span><span class=w> </span>pip<span class=w> </span>install<span class=w> </span>-r<span class=w> </span>requirements.txt
<span class=k>COPY</span><span class=w> </span>model.pkl<span class=w> </span>app.py<span class=w> </span>./
<span class=k>CMD</span><span class=w> </span><span class=p>[</span><span class=s2>&quot;python&quot;</span><span class=p>,</span><span class=w> </span><span class=s2>&quot;app.py&quot;</span><span class=p>]</span>
</code></pre></div> <p><strong>Tools:</strong> Docker, Kubernetes, Helm.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses multi-stage builds and proper dependency management.</p> </div> </details> <hr> <h3 id=design-a-data-quality-framework-amazon-google-interview-question>Design a Data Quality Framework - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Data Quality</code>, <code>Data Engineering</code> | <strong>Asked by:</strong> Amazon, Google, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Quality Dimensions:</strong></p> <table> <thead> <tr> <th>Dimension</th> <th>Checks</th> </tr> </thead> <tbody> <tr> <td>Completeness</td> <td>Missing values, null rates</td> </tr> <tr> <td>Consistency</td> <td>Schema validation, referential integrity</td> </tr> <tr> <td>Accuracy</td> <td>Statistical tests, anomaly detection</td> </tr> <tr> <td>Timeliness</td> <td>Data freshness, SLA compliance</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Data Pipeline] ‚Üí [Quality Checks] ‚Üí [Alerts] ‚Üí [Dashboard]
                       ‚Üì
                [Remediation]
</code></pre></div></p> <p><strong>Tools:</strong> Great Expectations, Deequ, Monte Carlo.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Implements automated data quality checks in pipeline.</p> </div> </details> <hr> <h3 id=design-a-model-compression-system-google-meta-interview-question>Design a Model Compression System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Model Compression</code>, <code>Optimization</code> | <strong>Asked by:</strong> Google, Meta, Apple</p> <details class=success> <summary>View Answer</summary> <p><strong>Techniques:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Compression Ratio</th> <th>Accuracy Impact</th> </tr> </thead> <tbody> <tr> <td>Quantization (INT8)</td> <td>4x</td> <td>&lt;1% drop</td> </tr> <tr> <td>Pruning</td> <td>2-5x</td> <td>1-3% drop</td> </tr> <tr> <td>Knowledge Distillation</td> <td>10x</td> <td>2-5% drop</td> </tr> <tr> <td>Low-rank Factorization</td> <td>2-3x</td> <td>&lt;1% drop</td> </tr> </tbody> </table> <p><strong>Pipeline:</strong> <div class=highlight><pre><span></span><code>[Trained Model] ‚Üí [Compression] ‚Üí [Fine-tuning] ‚Üí [Validation] ‚Üí [Deployment]
</code></pre></div></p> <p><strong>Workflow:</strong> 1. Quantization-aware training 2. Structured pruning 3. Distillation with teacher-student 4. Validation on representative data</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Combines multiple compression techniques for maximum efficiency.</p> </div> </details> <hr> <h3 id=design-a-transfer-learning-system-google-amazon-interview-question>Design a Transfer Learning System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Transfer Learning</code>, <code>Fine-tuning</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Strategy:</strong> 1. <strong>Pretrain:</strong> Large dataset (ImageNet, WebText) 2. <strong>Fine-tune:</strong> Target domain with smaller dataset 3. <strong>Adapt:</strong> Layer freezing, learning rate scheduling</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Pretrained Model] ‚Üí [Feature Extractor] ‚Üí [Task-specific Head] ‚Üí [Fine-tune]
</code></pre></div></p> <p><strong>Best Practices:</strong> - Freeze early layers, fine-tune later layers - Use lower learning rate for pretrained weights - Data augmentation for small datasets - Regularization to prevent overfitting</p> <p><strong>Domain Adaptation:</strong> Handle distribution shift between source and target.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses layer-wise learning rates and progressive unfreezing.</p> </div> </details> <hr> <h3 id=design-a-model-ensembling-system-netflix-uber-interview-question>Design a Model Ensembling System - Netflix, Uber Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Ensemble Learning</code> | <strong>Asked by:</strong> Netflix, Uber, Airbnb</p> <details class=success> <summary>View Answer</summary> <p><strong>Ensemble Methods:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Approach</th> <th>Benefit</th> </tr> </thead> <tbody> <tr> <td>Bagging</td> <td>Bootstrap samples</td> <td>Reduce variance</td> </tr> <tr> <td>Boosting</td> <td>Sequential learning</td> <td>Reduce bias</td> </tr> <tr> <td>Stacking</td> <td>Meta-model</td> <td>Best of both</td> </tr> <tr> <td>Voting</td> <td>Majority/average</td> <td>Simple, effective</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Input] ‚Üí [Model 1, Model 2, ..., Model N] ‚Üí [Aggregation] ‚Üí [Final Prediction]
</code></pre></div></p> <p><strong>Considerations:</strong> - Model diversity (different architectures, features) - Calibration for probability outputs - Computational cost vs accuracy gain</p> <p><strong>Netflix example:</strong> Ensembles 100+ models for recommendations.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Ensures diversity in base models for effective ensembling.</p> </div> </details> <hr> <h3 id=design-a-synthetic-data-generation-system-google-amazon-interview-question>Design a Synthetic Data Generation System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Data Augmentation</code>, <code>Synthetic Data</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Use Cases:</strong> - Privacy-preserving ML (replace sensitive data) - Rare event augmentation - Testing and validation - Cold-start problems</p> <p><strong>Techniques:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td>GANs</td> <td>Image/video generation</td> </tr> <tr> <td>VAEs</td> <td>Controlled generation</td> </tr> <tr> <td>SMOTE</td> <td>Imbalanced classification</td> </tr> <tr> <td>Statistical sampling</td> <td>Tabular data</td> </tr> </tbody> </table> <p><strong>Pipeline:</strong> <div class=highlight><pre><span></span><code>[Real Data] ‚Üí [Generative Model] ‚Üí [Synthetic Data] ‚Üí [Quality Checks] ‚Üí [Mix with Real]
</code></pre></div></p> <p><strong>Validation:</strong> Statistical similarity, downstream task performance.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Validates synthetic data quality with statistical tests and model performance.</p> </div> </details> <hr> <h3 id=design-a-data-augmentation-pipeline-google-meta-interview-question>Design a Data Augmentation Pipeline - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Data Augmentation</code>, <code>Training</code> | <strong>Asked by:</strong> Google, Meta, Tesla</p> <details class=success> <summary>View Answer</summary> <p><strong>Image Augmentation:</strong> - Geometric: Rotation, flip, crop, resize - Color: Brightness, contrast, saturation - Advanced: Mixup, CutMix, AutoAugment</p> <p><strong>Text Augmentation:</strong> - Synonym replacement - Back-translation - Paraphrasing with LLMs</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Training Data] ‚Üí [Augmentation Pipeline] ‚Üí [Augmented Batch] ‚Üí [Model]
</code></pre></div></p> <p><strong>Best Practices:</strong> - Apply augmentation on-the-fly during training - Use task-specific augmentations - Test time augmentation (TTA) for inference</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses domain-specific augmentation strategies and AutoAugment.</p> </div> </details> <hr> <h3 id=design-a-model-testing-framework-google-amazon-interview-question>Design a Model Testing Framework - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Testing</code>, <code>QA</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Testing Levels:</strong></p> <table> <thead> <tr> <th>Level</th> <th>Focus</th> <th>Examples</th> </tr> </thead> <tbody> <tr> <td>Unit</td> <td>Individual functions</td> <td>Data preprocessing logic</td> </tr> <tr> <td>Integration</td> <td>Component interactions</td> <td>Feature pipeline ‚Üí model</td> </tr> <tr> <td>System</td> <td>End-to-end</td> <td>Full prediction pipeline</td> </tr> <tr> <td>Performance</td> <td>Model quality</td> <td>Accuracy, latency, fairness</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Code] ‚Üí [Unit Tests] ‚Üí [Integration Tests] ‚Üí [Model Tests] ‚Üí [CI/CD]
</code></pre></div></p> <p><strong>ML-Specific Tests:</strong> - Data validation tests - Model performance tests (accuracy, bias) - Invariance tests (predictions shouldn't change for certain inputs) - Metamorphic testing</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Includes behavioral testing and model-specific test cases.</p> </div> </details> <hr> <h3 id=design-a-shadow-testing-system-netflix-amazon-interview-question>Design a Shadow Testing System - Netflix, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Testing</code>, <code>Deployment</code> | <strong>Asked by:</strong> Netflix, Amazon, Uber</p> <details class=success> <summary>View Answer</summary> <p><strong>Concept:</strong> Run new model in parallel with production model without affecting users.</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[User Request] ‚Üí [Production Model] ‚Üí [Response to User]
                      ‚Üì
                [Shadow Model] ‚Üí [Logging &amp; Analysis]
</code></pre></div></p> <p><strong>Benefits:</strong> - Compare model performance in production traffic - Detect issues before full rollout - A/B test without risk</p> <p><strong>Metrics to Compare:</strong> - Prediction differences - Latency - Error rates - Business metrics</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses shadow mode before canary deployment for risk mitigation.</p> </div> </details> <hr> <h3 id=design-a-blue-green-deployment-for-ml-google-amazon-interview-question>Design a Blue-Green Deployment for ML - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Deployment</code>, <code>DevOps</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Strategy:</strong> - Blue: Current production model - Green: New model version - Switch traffic from blue to green after validation - Keep blue as rollback option</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Load Balancer] ‚Üí [Blue Environment (v1)]
              ‚Üò   [Green Environment (v2)]
</code></pre></div></p> <p><strong>Deployment Steps:</strong> 1. Deploy new model to green environment 2. Run smoke tests on green 3. Route small % of traffic to green 4. Monitor metrics 5. Full cutover if successful 6. Keep blue for 24h, then decommission</p> <p><strong>Rollback:</strong> Instant by switching load balancer back to blue.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Combines blue-green with canary for gradual rollout.</p> </div> </details> <hr> <h3 id=design-a-model-governance-system-google-microsoft-interview-question>Design a Model Governance System - Google, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Governance</code>, <code>Compliance</code> | <strong>Asked by:</strong> Google, Microsoft, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Governance Requirements:</strong></p> <table> <thead> <tr> <th>Aspect</th> <th>Implementation</th> </tr> </thead> <tbody> <tr> <td>Audit Trail</td> <td>Track all model changes</td> </tr> <tr> <td>Access Control</td> <td>RBAC for models/data</td> </tr> <tr> <td>Compliance</td> <td>GDPR, CCPA, industry regulations</td> </tr> <tr> <td>Risk Assessment</td> <td>Model risk tiering</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Model Registry] ‚Üí [Governance Layer] ‚Üí [Compliance Checks] ‚Üí [Approval Workflow]
                          ‚Üì
                    [Audit Logs]
</code></pre></div></p> <p><strong>Key Features:</strong> - Model approval workflows - Automated compliance checks - Lineage tracking (data ‚Üí features ‚Üí model ‚Üí predictions) - Documentation requirements</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Implements automated compliance checks and approval workflows.</p> </div> </details> <hr> <h3 id=design-an-experiment-tracking-system-google-amazon-interview-question>Design an Experiment Tracking System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>MLOps</code>, <code>Experiment Management</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Requirements:</strong> - Track hyperparameters, metrics, artifacts - Compare experiments - Reproducibility - Collaboration</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Experiment] ‚Üí [Logging] ‚Üí [Tracking Server] ‚Üí [UI Dashboard]
                   ‚Üì
            [Artifact Store]
</code></pre></div></p> <p><strong>Track:</strong> - Code version (git commit) - Data version - Hyperparameters - Metrics (training + validation) - Model artifacts - Environment (dependencies)</p> <p><strong>Tools:</strong> MLflow, Weights &amp; Biases, Neptune.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Ensures reproducibility by tracking all experiment components.</p> </div> </details> <hr> <h3 id=design-a-hyperparameter-optimization-service-google-amazon-interview-question>Design a Hyperparameter Optimization Service - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Optimization</code>, <code>AutoML</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Algorithms:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Efficiency</th> <th>Use Case</th> </tr> </thead> <tbody> <tr> <td>Grid Search</td> <td>Low</td> <td>Small spaces</td> </tr> <tr> <td>Random Search</td> <td>Medium</td> <td>Baseline</td> </tr> <tr> <td>Bayesian Optimization</td> <td>High</td> <td>Expensive evaluations</td> </tr> <tr> <td>Hyperband/ASHA</td> <td>Very High</td> <td>Large-scale</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Search Space] ‚Üí [Optimization Algorithm] ‚Üí [Trial Scheduler] ‚Üí [Best Config]
                        ‚Üì
                [Resource Manager]
</code></pre></div></p> <p><strong>Key Features:</strong> - Parallel trial execution - Early stopping of poor trials - Resource allocation optimization - Warm start from previous runs</p> <p><strong>Scale:</strong> 1000s of parallel trials.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses multi-fidelity optimization (ASHA) for efficiency.</p> </div> </details> <hr> <h3 id=design-a-feature-selection-system-amazon-google-interview-question>Design a Feature Selection System - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Feature Engineering</code>, <code>Model Optimization</code> | <strong>Asked by:</strong> Amazon, Google, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Methods:</strong></p> <table> <thead> <tr> <th>Category</th> <th>Techniques</th> <th>When to Use</th> </tr> </thead> <tbody> <tr> <td>Filter</td> <td>Correlation, mutual information</td> <td>Fast, model-agnostic</td> </tr> <tr> <td>Wrapper</td> <td>Forward/backward selection</td> <td>Accurate, expensive</td> </tr> <tr> <td>Embedded</td> <td>L1 regularization, tree importance</td> <td>Model-specific</td> </tr> </tbody> </table> <p><strong>Pipeline:</strong> <div class=highlight><pre><span></span><code>[All Features] ‚Üí [Feature Selection] ‚Üí [Reduced Features] ‚Üí [Model Training]
                        ‚Üì
                [Validation Score]
</code></pre></div></p> <p><strong>Benefits:</strong> - Reduce overfitting - Faster training and inference - Better interpretability - Lower costs</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Combines multiple methods and validates on holdout set.</p> </div> </details> <hr> <h3 id=design-a-data-drift-detection-system-netflix-uber-interview-question>Design a Data Drift Detection System - Netflix, Uber Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Monitoring</code>, <code>Drift Detection</code> | <strong>Asked by:</strong> Netflix, Uber, Airbnb</p> <details class=success> <summary>View Answer</summary> <p><strong>Drift Types:</strong></p> <table> <thead> <tr> <th>Type</th> <th>Description</th> <th>Detection</th> </tr> </thead> <tbody> <tr> <td>Covariate Shift</td> <td>Input distribution changes</td> <td>PSI, KS test</td> </tr> <tr> <td>Concept Drift</td> <td>Input-output relationship changes</td> <td>Model performance drop</td> </tr> <tr> <td>Label Drift</td> <td>Output distribution changes</td> <td>Label statistics</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Production Data] ‚Üí [Drift Detector] ‚Üí [Alert] ‚Üí [Retrain Trigger]
                          ‚Üì
                [Reference Distribution]
</code></pre></div></p> <p><strong>Metrics:</strong> - Population Stability Index (PSI) - Kolmogorov-Smirnov test - KL divergence</p> <p><strong>Action:</strong> Trigger model retraining when drift detected.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Sets appropriate thresholds and monitors both data and model drift.</p> </div> </details> <hr> <h3 id=design-a-model-performance-degradation-detection-system-amazon-google-interview-question>Design a Model Performance Degradation Detection System - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Monitoring</code>, <code>Performance</code> | <strong>Asked by:</strong> Amazon, Google, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Monitoring:</strong></p> <table> <thead> <tr> <th>Metric Type</th> <th>Examples</th> </tr> </thead> <tbody> <tr> <td>Model Metrics</td> <td>Accuracy, AUC, precision, recall</td> </tr> <tr> <td>Business Metrics</td> <td>Revenue, conversion, engagement</td> </tr> <tr> <td>Operational</td> <td>Latency, error rate, throughput</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Predictions] ‚Üí [Ground Truth (delayed)] ‚Üí [Metric Calculation] ‚Üí [Alerting]
                                                  ‚Üì
                                          [Historical Baseline]
</code></pre></div></p> <p><strong>Challenges:</strong> - Delayed ground truth labels - Seasonality in metrics - Statistical significance testing</p> <p><strong>Proxy Metrics:</strong> Use prediction confidence, data drift as early signals.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses proxy metrics when ground truth is delayed.</p> </div> </details> <hr> <h3 id=design-a-real-time-analytics-dashboard-netflix-uber-interview-question>Design a Real-Time Analytics Dashboard - Netflix, Uber Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Analytics</code>, <code>Visualization</code> | <strong>Asked by:</strong> Netflix, Uber, Airbnb</p> <details class=success> <summary>View Answer</summary> <p><strong>Requirements:</strong> - Real-time data ingestion - Interactive visualizations - Drill-down capabilities - Alerting</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Events] ‚Üí [Stream Processing] ‚Üí [Aggregation] ‚Üí [Time-series DB] ‚Üí [Dashboard]
                                                        ‚Üì
                                                [Materialized Views]
</code></pre></div></p> <p><strong>Components:</strong> - Data ingestion: Kafka, Kinesis - Processing: Flink, Spark Streaming - Storage: InfluxDB, TimescaleDB - Visualization: Grafana, Tableau, Custom UI</p> <p><strong>Optimizations:</strong> Pre-aggregation, caching, sampling for scale.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses materialized views and caching for low-latency queries.</p> </div> </details> <hr> <h3 id=design-an-ml-model-marketplace-google-amazon-interview-question>Design an ML Model Marketplace - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Platform</code>, <code>Marketplace</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Features:</strong> - Model discovery and search - Model versioning and hosting - API access with rate limiting - Usage tracking and billing - Model quality indicators</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Model Provider] ‚Üí [Upload] ‚Üí [Model Registry] ‚Üí [API Gateway] ‚Üí [Consumers]
                                    ‚Üì
                              [Hosting Service]
</code></pre></div></p> <p><strong>Challenges:</strong> - Model evaluation and benchmarking - Licensing and IP protection - Fair pricing models - Quality assurance</p> <p><strong>Examples:</strong> Hugging Face Hub, AWS Marketplace, Replicate.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Includes standardized evaluation benchmarks and clear licensing.</p> </div> </details> <hr> <h3 id=design-a-neural-architecture-search-system-google-meta-interview-question>Design a Neural Architecture Search System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>AutoML</code>, <code>NAS</code> | <strong>Asked by:</strong> Google, Meta, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>Approaches:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Search Strategy</th> <th>Efficiency</th> </tr> </thead> <tbody> <tr> <td>Random Search</td> <td>Random sampling</td> <td>Baseline</td> </tr> <tr> <td>Reinforcement Learning</td> <td>Controller RNN</td> <td>Medium</td> </tr> <tr> <td>Evolutionary</td> <td>Genetic algorithms</td> <td>Medium</td> </tr> <tr> <td>Gradient-based</td> <td>DARTS</td> <td>High</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Search Space] ‚Üí [NAS Algorithm] ‚Üí [Architecture] ‚Üí [Train &amp; Evaluate]
                      ‚Üë                                    ‚Üì
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[Feedback]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</code></pre></div></p> <p><strong>Optimizations:</strong> - Weight sharing (ENAS) - Early stopping - Proxy tasks (train on subset) - Transfer from related tasks</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses efficient methods like DARTS or weight sharing to reduce search cost.</p> </div> </details> <hr> <h3 id=design-a-model-debugging-system-google-amazon-interview-question>Design a Model Debugging System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Debugging</code>, <code>Interpretability</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Debugging Tools:</strong></p> <table> <thead> <tr> <th>Tool</th> <th>Purpose</th> </tr> </thead> <tbody> <tr> <td>Error Analysis</td> <td>Identify failure modes</td> </tr> <tr> <td>Slice Analysis</td> <td>Performance by subgroups</td> </tr> <tr> <td>Visualization</td> <td>Attention maps, embeddings</td> </tr> <tr> <td>Counterfactuals</td> <td>What-if scenarios</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Model] ‚Üí [Predictions] ‚Üí [Debug Tools] ‚Üí [Insights] ‚Üí [Model Improvements]
              ‚Üì
        [Error Cases]
</code></pre></div></p> <p><strong>Workflow:</strong> 1. Identify systematic errors 2. Analyze error patterns 3. Generate hypotheses 4. Test fixes (more data, features, architecture)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Systematically analyzes errors by slice and creates targeted improvements.</p> </div> </details> <hr> <h3 id=design-an-ml-observability-platform-netflix-uber-interview-question>Design an ML Observability Platform - Netflix, Uber Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Observability</code>, <code>Monitoring</code> | <strong>Asked by:</strong> Netflix, Uber, Airbnb</p> <details class=success> <summary>View Answer</summary> <p><strong>Three Pillars:</strong> 1. <strong>Metrics:</strong> Model performance, system health 2. <strong>Logs:</strong> Prediction logs, error logs 3. <strong>Traces:</strong> Request flow through system</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[ML Services] ‚Üí [Telemetry] ‚Üí [Observability Platform] ‚Üí [Dashboards/Alerts]
                    ‚Üì
            [Time-series DB]
</code></pre></div></p> <p><strong>Key Features:</strong> - Distributed tracing (OpenTelemetry) - Anomaly detection on metrics - Log aggregation and search - SLI/SLO tracking - Root cause analysis</p> <p><strong>Tools:</strong> Prometheus, Grafana, ELK stack, Jaeger.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Correlates metrics, logs, and traces for effective debugging.</p> </div> </details> <hr> <h3 id=design-a-data-catalog-system-google-amazon-interview-question>Design a Data Catalog System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Data Discovery</code>, <code>Metadata</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Capabilities:</strong> - Data discovery and search - Metadata management - Data lineage - Schema evolution tracking - Access control information</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Data Sources] ‚Üí [Metadata Extraction] ‚Üí [Catalog] ‚Üí [Search/Browse UI]
                        ‚Üì
                [Lineage Tracker]
</code></pre></div></p> <p><strong>Metadata:</strong> - Technical: Schema, size, location - Business: Ownership, description, tags - Operational: Freshness, quality scores - Lineage: Upstream/downstream dependencies</p> <p><strong>Tools:</strong> DataHub, Amundsen, Apache Atlas.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Includes automated metadata extraction and lineage tracking.</p> </div> </details> <hr> <h3 id=design-a-metadata-management-system-amazon-microsoft-interview-question>Design a Metadata Management System - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Metadata</code>, <code>Governance</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Metadata Types:</strong></p> <table> <thead> <tr> <th>Type</th> <th>Examples</th> </tr> </thead> <tbody> <tr> <td>Business</td> <td>Glossary, ownership, definitions</td> </tr> <tr> <td>Technical</td> <td>Schema, types, constraints</td> </tr> <tr> <td>Operational</td> <td>SLAs, quality metrics, usage stats</td> </tr> <tr> <td>Lineage</td> <td>Data flow, transformations</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Systems] ‚Üí [Metadata Extraction] ‚Üí [Central Repository] ‚Üí [APIs/UI]
                    ‚Üì
            [Lineage Graph]
</code></pre></div></p> <p><strong>Features:</strong> - Automated discovery - Impact analysis - Search and recommendations - Change management</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Automates metadata collection and maintains lineage graph.</p> </div> </details> <hr> <h3 id=design-an-ml-platform-for-multi-cloud-amazon-google-interview-question>Design an ML Platform for Multi-Cloud - Amazon, Google Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Multi-Cloud</code>, <code>Platform</code> | <strong>Asked by:</strong> Amazon, Google, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Requirements:</strong> - Cloud-agnostic APIs - Cost optimization across clouds - Data portability - Vendor lock-in avoidance</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Abstraction Layer] ‚Üí [Cloud Provider A]
                  ‚Üí [Cloud Provider B]
                  ‚Üí [Cloud Provider C]
</code></pre></div></p> <p><strong>Components:</strong> - Unified ML APIs (training, serving, monitoring) - Cross-cloud data transfer - Workload placement optimization - Centralized monitoring</p> <p><strong>Challenges:</strong> - Network latency between clouds - Data gravity - Different service capabilities</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses abstraction layer but allows cloud-specific optimizations.</p> </div> </details> <hr> <h3 id=design-a-disaster-recovery-system-for-ml-google-amazon-interview-question>Design a Disaster Recovery System for ML - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Reliability</code>, <code>DR</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Requirements:</strong> - Recovery Time Objective (RTO): &lt; 1 hour - Recovery Point Objective (RPO): &lt; 15 minutes - Multi-region deployment - Automated failover</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Primary Region] ‚Üê‚Üí [Replication] ‚Üê‚Üí [DR Region]
      ‚Üì                                    ‚Üì
[Data Backup]                        [Data Backup]
</code></pre></div></p> <p><strong>Components:</strong> - Model replication to DR region - Data replication (async/sync) - Health checks and failover logic - Regular DR testing</p> <p><strong>Scenarios:</strong> Region outage, data corruption, security incident.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Regularly tests DR procedures and monitors replication lag.</p> </div> </details> <hr> <h3 id=design-a-model-security-and-adversarial-robustness-system-google-meta-interview-question>Design a Model Security and Adversarial Robustness System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Security</code>, <code>Adversarial ML</code> | <strong>Asked by:</strong> Google, Meta, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>Threats:</strong></p> <table> <thead> <tr> <th>Attack Type</th> <th>Description</th> <th>Defense</th> </tr> </thead> <tbody> <tr> <td>Evasion</td> <td>Adversarial examples</td> <td>Adversarial training</td> </tr> <tr> <td>Poisoning</td> <td>Corrupt training data</td> <td>Data validation</td> </tr> <tr> <td>Model Stealing</td> <td>Extract model via queries</td> <td>Rate limiting, watermarking</td> </tr> <tr> <td>Backdoors</td> <td>Trigger malicious behavior</td> <td>Input sanitization</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Input] ‚Üí [Validation] ‚Üí [Adversarial Detection] ‚Üí [Model] ‚Üí [Output Sanitization]
</code></pre></div></p> <p><strong>Defenses:</strong> - Adversarial training (PGD, FGSM) - Input sanitization and validation - Model watermarking - Anomaly detection on queries</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Combines multiple defense layers and monitors for attacks.</p> </div> </details> <hr> <h3 id=design-an-ml-compliance-and-audit-system-microsoft-amazon-interview-question>Design an ML Compliance and Audit System - Microsoft, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Compliance</code>, <code>Audit</code> | <strong>Asked by:</strong> Microsoft, Amazon, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Regulatory Requirements:</strong> - GDPR: Right to explanation, data deletion - CCPA: Data access and deletion - Industry-specific: HIPAA, SOC 2, PCI-DSS</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[ML System] ‚Üí [Audit Logger] ‚Üí [Audit Trail] ‚Üí [Compliance Dashboard]
                    ‚Üì
            [Policy Engine]
</code></pre></div></p> <p><strong>Audit Trail:</strong> - All data access events - Model training and deployment - Predictions and explanations - Data deletions</p> <p><strong>Features:</strong> - Immutable audit logs - Retention policies - Compliance reporting - Automated alerts for violations</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Implements privacy-by-design and maintains comprehensive audit trails.</p> </div> </details> <hr> <h3 id=design-a-real-time-feature-computation-system-netflix-uber-interview-question>Design a Real-Time Feature Computation System - Netflix, Uber Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Real-Time</code>, <code>Feature Engineering</code> | <strong>Asked by:</strong> Netflix, Uber, LinkedIn</p> <details class=success> <summary>View Answer</summary> <p><strong>Requirements:</strong> - &lt;10ms feature computation - Handle 100K+ QPS - Consistent with training features</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Events] ‚Üí [Stream Processing] ‚Üí [Feature Store] ‚Üí [Model Serving]
                 ‚Üì
          [Windowed Aggregations]
</code></pre></div></p> <p><strong>Features:</strong> - Real-time aggregations (last 5 min, 1 hour, 1 day) - User/item embeddings - Context features</p> <p><strong>Challenges:</strong> - Training/serving skew - Low-latency requirements - State management for aggregations</p> <p><strong>Tools:</strong> Flink, ksqlDB, Materialize.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Ensures feature consistency between training and serving.</p> </div> </details> <hr> <h3 id=design-a-streaming-feature-engineering-system-uber-netflix-interview-question>Design a Streaming Feature Engineering System - Uber, Netflix Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Streaming</code>, <code>Feature Engineering</code> | <strong>Asked by:</strong> Uber, Netflix, LinkedIn</p> <details class=success> <summary>View Answer</summary> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Event Stream] ‚Üí [Stateful Processing] ‚Üí [Feature Store] ‚Üí [Online Serving]
                       ‚Üì
              [Tumbling/Sliding Windows]
</code></pre></div></p> <p><strong>Features to Compute:</strong> - Count/sum over time windows - Average, percentiles - Distinct counts (HyperLogLog) - Session-based features</p> <p><strong>Challenges:</strong> - Late-arriving data (watermarks) - State management at scale - Exactly-once semantics - Feature freshness vs latency</p> <p><strong>Example:</strong> <div class=highlight><pre><span></span><code><span class=c1>-- ksqlDB example</span>
<span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>user_clicks_5min</span><span class=w> </span><span class=k>AS</span>
<span class=k>SELECT</span><span class=w> </span><span class=n>user_id</span><span class=p>,</span><span class=w> </span><span class=k>COUNT</span><span class=p>(</span><span class=o>*</span><span class=p>)</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>click_count</span>
<span class=k>FROM</span><span class=w> </span><span class=n>clicks_stream</span>
<span class=n>WINDOW</span><span class=w> </span><span class=n>TUMBLING</span><span class=w> </span><span class=p>(</span><span class=k>SIZE</span><span class=w> </span><span class=mi>5</span><span class=w> </span><span class=n>MINUTES</span><span class=p>)</span>
<span class=k>GROUP</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>user_id</span><span class=p>;</span>
</code></pre></div></p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Uses watermarks for late data and manages state efficiently.</p> </div> </details> <hr> <h3 id=design-a-model-lifecycle-management-system-amazon-microsoft-interview-question>Design a Model Lifecycle Management System - Amazon, Microsoft Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>MLOps</code>, <code>Lifecycle</code> | <strong>Asked by:</strong> Amazon, Microsoft, Google</p> <details class=success> <summary>View Answer</summary> <p><strong>Lifecycle Stages:</strong></p> <table> <thead> <tr> <th>Stage</th> <th>Activities</th> </tr> </thead> <tbody> <tr> <td>Development</td> <td>Experimentation, prototyping</td> </tr> <tr> <td>Staging</td> <td>Validation, integration testing</td> </tr> <tr> <td>Production</td> <td>Serving, monitoring</td> </tr> <tr> <td>Retired</td> <td>Archival, decommissioning</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Development] ‚Üí [Staging] ‚Üí [Production] ‚Üí [Monitoring] ‚Üí [Retrain/Retire]
                    ‚Üì
            [Model Registry]
</code></pre></div></p> <p><strong>Key Features:</strong> - Stage promotion workflows - Approval gates - Automated testing between stages - Rollback capabilities - Sunset policies for old models</p> <p><strong>Tools:</strong> MLflow, Kubeflow, SageMaker.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Implements automated testing and approval workflows between stages.</p> </div> </details> <hr> <h3 id=design-a-chatbotconversational-ai-system-google-amazon-interview-question>Design a Chatbot/Conversational AI System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>NLP</code>, <code>Dialogue Systems</code> | <strong>Asked by:</strong> Google, Amazon, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Components:</strong> 1. <strong>Intent Classification:</strong> Identify user intent 2. <strong>Entity Extraction:</strong> Extract key information 3. <strong>Dialogue Management:</strong> Track conversation state 4. <strong>Response Generation:</strong> Generate or retrieve response 5. <strong>Context Management:</strong> Multi-turn understanding</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[User Input] ‚Üí [NLU] ‚Üí [Dialogue Manager] ‚Üí [Response Gen] ‚Üí [User]
                  ‚Üì
            [Context Store]
</code></pre></div></p> <p><strong>Techniques:</strong> - Transformer-based models (BERT, GPT) - Retrieval-augmented generation (RAG) - Reinforcement learning for policy - Personalization layer</p> <p><strong>Scale:</strong> Handle 1M+ conversations/day with &lt;500ms latency.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses context management and handling multi-turn conversations.</p> </div> </details> <hr> <h3 id=design-a-document-processing-system-google-amazon-interview-question>Design a Document Processing System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>OCR</code>, <code>Document AI</code> | <strong>Asked by:</strong> Google, Amazon, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Pipeline:</strong> <div class=highlight><pre><span></span><code>[Document] ‚Üí [OCR] ‚Üí [Layout Analysis] ‚Üí [Entity Extraction] ‚Üí [Structured Output]
               ‚Üì
        [Document Classification]
</code></pre></div></p> <p><strong>Components:</strong> - <strong>OCR:</strong> Tesseract, Cloud Vision API - <strong>Layout:</strong> Detect tables, forms, sections - <strong>NER:</strong> Extract names, dates, amounts - <strong>Classification:</strong> Invoice, receipt, contract</p> <p><strong>Challenges:</strong> - Multiple languages - Poor quality scans - Complex layouts - Privacy (PII redaction)</p> <p><strong>Tools:</strong> AWS Textract, Google Document AI, Azure Form Recognizer.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Handles multi-modal inputs (text, tables, images) and ensures PII compliance.</p> </div> </details> <hr> <h3 id=design-a-video-understanding-system-google-youtube-interview-question>Design a Video Understanding System - Google, YouTube Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Computer Vision</code>, <code>Video</code> | <strong>Asked by:</strong> Google, YouTube, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Tasks:</strong> - Video classification - Action recognition - Object tracking - Scene understanding - Content moderation</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Video] ‚Üí [Frame Sampling] ‚Üí [Feature Extraction] ‚Üí [Temporal Model] ‚Üí [Output]
                ‚Üì
          [Optical Flow]
</code></pre></div></p> <p><strong>Models:</strong> - 3D CNNs (C3D, I3D) - Two-stream networks - Transformers (TimeSformer, ViViT)</p> <p><strong>Optimization:</strong> - Keyframe extraction to reduce compute - Efficient architectures (MobileNet-based) - Distributed processing</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses temporal modeling and efficient video processing at scale.</p> </div> </details> <hr> <h3 id=design-an-audiospeech-processing-system-google-amazon-interview-question>Design an Audio/Speech Processing System - Google, Amazon Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Speech Recognition</code>, <code>Audio</code> | <strong>Asked by:</strong> Google, Amazon, Apple</p> <details class=success> <summary>View Answer</summary> <p><strong>Use Cases:</strong> - Speech-to-text (ASR) - Speaker identification - Emotion recognition - Audio classification</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Audio] ‚Üí [Preprocessing] ‚Üí [Feature Extraction] ‚Üí [Model] ‚Üí [Post-process] ‚Üí [Text]
              ‚Üì
        [Mel Spectrogram]
</code></pre></div></p> <p><strong>Models:</strong> - RNN/LSTM, Transformers (Wav2Vec, Whisper) - CTC loss for sequence alignment - Language models for correction</p> <p><strong>Challenges:</strong> - Noisy environments - Accents and dialects - Real-time processing - Speaker diarization</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses handling accents, noise, and real-time constraints.</p> </div> </details> <hr> <h3 id=design-a-multimodal-fusion-system-google-meta-interview-question>Design a Multimodal Fusion System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Multimodal</code>, <code>Fusion</code> | <strong>Asked by:</strong> Google, Meta, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>Use Cases:</strong> - Visual question answering - Image captioning - Video + text understanding - Audio-visual learning</p> <p><strong>Fusion Strategies:</strong></p> <table> <thead> <tr> <th>Strategy</th> <th>When</th> <th>Complexity</th> </tr> </thead> <tbody> <tr> <td>Early Fusion</td> <td>Concat inputs</td> <td>Low</td> </tr> <tr> <td>Late Fusion</td> <td>Concat outputs</td> <td>Low</td> </tr> <tr> <td>Cross-attention</td> <td>Learn interactions</td> <td>High</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Image] ‚Üí [Vision Encoder] ‚Üò
                             [Fusion Layer] ‚Üí [Output]
[Text] ‚Üí [Text Encoder]    ‚Üó
</code></pre></div></p> <p><strong>Models:</strong> CLIP, ALIGN, Flamingo, GPT-4V.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses cross-modal attention and alignment between modalities.</p> </div> </details> <hr> <h3 id=design-a-few-shot-learning-system-google-meta-interview-question>Design a Few-Shot Learning System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Few-Shot</code>, <code>Meta-Learning</code> | <strong>Asked by:</strong> Google, Meta, DeepMind</p> <details class=success> <summary>View Answer</summary> <p><strong>Goal:</strong> Learn from few labeled examples (1-10 per class).</p> <p><strong>Approaches:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Strategy</th> </tr> </thead> <tbody> <tr> <td>Meta-learning</td> <td>MAML, Prototypical Networks</td> </tr> <tr> <td>Transfer Learning</td> <td>Fine-tune pretrained models</td> </tr> <tr> <td>Data Augmentation</td> <td>Synthesize more examples</td> </tr> <tr> <td>Prompt Engineering</td> <td>For LLMs</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Support Set] ‚Üí [Meta-Learner] ‚Üí [Adapted Model] ‚Üí [Query Prediction]
</code></pre></div></p> <p><strong>Applications:</strong> New product categories, rare diseases, personalization.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses when few-shot learning is preferred over traditional supervised learning.</p> </div> </details> <hr> <h3 id=design-a-zero-shot-learning-system-google-openai-interview-question>Design a Zero-Shot Learning System - Google, OpenAI Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Zero-Shot</code>, <code>Generalization</code> | <strong>Asked by:</strong> Google, OpenAI, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Goal:</strong> Classify unseen classes without training examples.</p> <p><strong>Approaches:</strong> 1. <strong>Semantic Embeddings:</strong> Map classes to embedding space 2. <strong>Attribute-based:</strong> Describe classes by attributes 3. <strong>Prompt-based:</strong> Use LLMs with natural language descriptions</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Input] ‚Üí [Encoder] ‚Üí [Embedding Space] ‚Üí [Similarity] ‚Üí [Class]
                          ‚Üì
                  [Class Descriptions]
</code></pre></div></p> <p><strong>Example:</strong> CLIP for zero-shot image classification.</p> <p><strong>Challenges:</strong> Requires good semantic representations.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses using semantic embeddings and language models for zero-shot tasks.</p> </div> </details> <hr> <h3 id=design-a-continual-learning-system-google-deepmind-interview-question>Design a Continual Learning System - Google, DeepMind Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Continual Learning</code>, <code>Lifelong Learning</code> | <strong>Asked by:</strong> Google, DeepMind, Meta</p> <details class=success> <summary>View Answer</summary> <p><strong>Goal:</strong> Learn new tasks without forgetting old ones (avoid catastrophic forgetting).</p> <p><strong>Strategies:</strong></p> <table> <thead> <tr> <th>Approach</th> <th>Method</th> </tr> </thead> <tbody> <tr> <td>Regularization</td> <td>EWC (Elastic Weight Consolidation)</td> </tr> <tr> <td>Replay</td> <td>Store examples from old tasks</td> </tr> <tr> <td>Dynamic Architectures</td> <td>Add capacity for new tasks</td> </tr> <tr> <td>Meta-learning</td> <td>Learn to learn continually</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Task 1] ‚Üí [Model] ‚Üí [Task 2] ‚Üí [Updated Model] ‚Üí [Task 3]
              ‚Üì
        [Memory Buffer]
</code></pre></div></p> <p><strong>Evaluation:</strong> Average accuracy across all tasks over time.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses strategies to prevent catastrophic forgetting.</p> </div> </details> <hr> <h3 id=design-a-model-fairness-and-bias-detection-system-google-meta-interview-question>Design a Model Fairness and Bias Detection System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Fairness</code>, <code>Bias</code> | <strong>Asked by:</strong> Google, Meta, Microsoft</p> <details class=success> <summary>View Answer</summary> <p><strong>Fairness Metrics:</strong></p> <table> <thead> <tr> <th>Metric</th> <th>Definition</th> </tr> </thead> <tbody> <tr> <td>Demographic Parity</td> <td>Equal positive rate across groups</td> </tr> <tr> <td>Equal Opportunity</td> <td>Equal TPR across groups</td> </tr> <tr> <td>Equalized Odds</td> <td>Equal TPR and FPR across groups</td> </tr> <tr> <td>Calibration</td> <td>Predicted probabilities match actual rates</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Model] ‚Üí [Predictions] ‚Üí [Bias Detection] ‚Üí [Mitigation] ‚Üí [Fair Model]
                                ‚Üì
                        [Protected Attributes]
</code></pre></div></p> <p><strong>Mitigation:</strong> - Pre-processing: Balance training data - In-processing: Fairness constraints during training - Post-processing: Adjust thresholds per group</p> <p><strong>Tools:</strong> Fairlearn, AI Fairness 360.</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses trade-offs between different fairness metrics.</p> </div> </details> <hr> <h3 id=design-a-model-watermarking-system-google-meta-interview-question>Design a Model Watermarking System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üü° Medium | <strong>Tags:</strong> <code>Security</code>, <code>IP Protection</code> | <strong>Asked by:</strong> Google, Meta, OpenAI</p> <details class=success> <summary>View Answer</summary> <p><strong>Goal:</strong> Embed verifiable signature in model to prove ownership.</p> <p><strong>Techniques:</strong> 1. <strong>Backdoor Watermarking:</strong> Train model to output specific pattern for trigger inputs 2. <strong>Parameter Watermarking:</strong> Encode signature in model weights 3. <strong>Output-based:</strong> Statistical properties of outputs</p> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Model Training] ‚Üí [Watermark Embedding] ‚Üí [Watermarked Model]
                          ‚Üì
                [Verification Trigger Set]
</code></pre></div></p> <p><strong>Requirements:</strong> - Undetectable (doesn't degrade performance) - Robust (survives fine-tuning, pruning) - Verifiable (can prove ownership)</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses robustness to model extraction and fine-tuning attacks.</p> </div> </details> <hr> <h3 id=design-a-cross-lingual-ml-system-google-meta-interview-question>Design a Cross-Lingual ML System - Google, Meta Interview Question</h3> <p><strong>Difficulty:</strong> üî¥ Hard | <strong>Tags:</strong> <code>Multilingual</code>, <code>NLP</code> | <strong>Asked by:</strong> Google, Meta, Amazon</p> <details class=success> <summary>View Answer</summary> <p><strong>Challenges:</strong> - Limited labeled data for low-resource languages - Different scripts and tokenization - Cultural context differences</p> <p><strong>Approaches:</strong></p> <table> <thead> <tr> <th>Method</th> <th>Strategy</th> </tr> </thead> <tbody> <tr> <td>Multilingual Models</td> <td>Train on many languages jointly (mBERT, XLM-R)</td> </tr> <tr> <td>Cross-lingual Transfer</td> <td>Train on high-resource, transfer to low-resource</td> </tr> <tr> <td>Machine Translation</td> <td>Translate to English, process, translate back</td> </tr> <tr> <td>Zero-shot</td> <td>Use multilingual embeddings</td> </tr> </tbody> </table> <p><strong>Architecture:</strong> <div class=highlight><pre><span></span><code>[Text (any language)] ‚Üí [Multilingual Encoder] ‚Üí [Task Head] ‚Üí [Output]
</code></pre></div></p> <p><strong>Best Practices:</strong> - Use language-agnostic tokenization (SentencePiece) - Balance training data across languages - Evaluate on diverse language families</p> <div class="admonition tip"> <p class=admonition-title>Interviewer's Insight</p> <p>Discusses handling low-resource languages and script variations.</p> </div> </details> <hr> <h2 id=quick-reference-30-system-design-questions>Quick Reference: 30 System Design Questions</h2> <table> <thead> <tr> <th>Sno</th> <th>Question Title</th> <th>Practice Links</th> <th>Companies Asking</th> <th>Difficulty</th> <th>Topics</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>Design an End-to-End Machine Learning Pipeline</td> <td><a href=https://towardsdatascience.com/designing-end-to-end-machine-learning-pipelines-3d2a5eabc123>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>ML Pipeline, MLOps</td> </tr> <tr> <td>2</td> <td>Design a Scalable Data Ingestion &amp; Processing System for ML</td> <td><a href=https://medium.com/@example/scalable-data-ingestion-for-ml-abc123>Medium</a></td> <td>Amazon, Google, Microsoft</td> <td>Hard</td> <td>Data Engineering, Scalability</td> </tr> <tr> <td>3</td> <td>Design a Recommendation System</td> <td><a href=https://towardsdatascience.com/building-recommendation-systems-456def>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Recommender Systems, Personalization</td> </tr> <tr> <td>4</td> <td>Design a Fraud Detection System</td> <td><a href=https://medium.com/@example/fraud-detection-system-design-789ghi>Medium</a></td> <td>Amazon, Facebook, PayPal</td> <td>Hard</td> <td>Real-Time Analytics, Anomaly Detection</td> </tr> <tr> <td>5</td> <td>Design a Feature Store for Machine Learning</td> <td><a href=https://towardsdatascience.com/feature-stores-in-machine-learning-123jkl>Towards Data Science</a></td> <td>Google, Amazon, Microsoft</td> <td>Medium</td> <td>Data Preprocessing, Feature Engineering</td> </tr> <tr> <td>6</td> <td>Design an Online ML Model Serving Architecture</td> <td><a href=https://towardsdatascience.com/deploying-machine-learning-models-987mno>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Hard</td> <td>Model Deployment, Real-Time Serving</td> </tr> <tr> <td>7</td> <td>Design a Continuous Model Retraining and Monitoring System</td> <td><a href=https://medium.com/@example/continuous-training-and-monitoring-for-ml-456stu>Medium</a></td> <td>Google, Microsoft, Amazon</td> <td>Hard</td> <td>MLOps, Automation</td> </tr> <tr> <td>8</td> <td>Design an A/B Testing Framework for ML Models</td> <td><a href=https://towardsdatascience.com/ab-testing-for-machine-learning-789pqr>Towards Data Science</a></td> <td>Google, Facebook, Amazon</td> <td>Medium</td> <td>Experimentation, Evaluation</td> </tr> <tr> <td>9</td> <td>Design a Distributed ML Training System</td> <td><a href=https://towardsdatascience.com/distributed-training-for-deep-learning-234vwx>Towards Data Science</a></td> <td>Google, Amazon, Microsoft</td> <td>Hard</td> <td>Distributed Systems, Deep Learning</td> </tr> <tr> <td>10</td> <td>Design a Real-Time Prediction Serving System</td> <td><a href=https://towardsdatascience.com/real-time-ml-model-serving-123abc>Towards Data Science</a></td> <td>Amazon, Google, Facebook</td> <td>Hard</td> <td>Model Serving, Real-Time Processing</td> </tr> <tr> <td>11</td> <td>Design a System for Anomaly Detection in Streaming Data</td> <td><a href=https://medium.com/@example/anomaly-detection-in-streaming-data-567def>Medium</a></td> <td>Amazon, Google, Facebook</td> <td>Hard</td> <td>Streaming Data, Anomaly Detection</td> </tr> <tr> <td>12</td> <td>Design a Real-Time Personalization System for E-Commerce</td> <td><a href=https://medium.com/@example/designing-real-time-personalization-890ghi>Medium</a></td> <td>Amazon, Facebook, Uber</td> <td>Medium</td> <td>Personalization, Real-Time Analytics</td> </tr> <tr> <td>13</td> <td>Design a Data Versioning and Model Versioning System</td> <td><a href=https://towardsdatascience.com/data-and-model-versioning-456jkl>Towards Data Science</a></td> <td>Google, Amazon, Microsoft</td> <td>Medium</td> <td>MLOps, Version Control</td> </tr> <tr> <td>14</td> <td>Design a System to Ensure Fairness and Transparency in ML Predictions</td> <td><a href=https://medium.com/@example/fairness-transparency-in-ml-system-design-123stu>Medium</a></td> <td>Google, Facebook, Amazon</td> <td>Hard</td> <td>Ethics, Model Interpretability</td> </tr> <tr> <td>15</td> <td>Design a Data Governance and Compliance System for ML</td> <td><a href=https://towardsdatascience.com/data-governance-for-machine-learning-789mno>Towards Data Science</a></td> <td>Microsoft, Google, Amazon</td> <td>Hard</td> <td>Data Governance, Compliance</td> </tr> <tr> <td>16</td> <td>Design an MLOps Pipeline for End-to-End Automation</td> <td><a href=https://towardsdatascience.com/mlops-pipelines-design-234vwx>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Hard</td> <td>MLOps, Automation</td> </tr> <tr> <td>17</td> <td>Design a System for Real-Time Prediction Serving with Low Latency</td> <td><a href=https://medium.com/@example/real-time-low-latency-model-serving-567def>Medium</a></td> <td>Google, Amazon, Microsoft</td> <td>Hard</td> <td>Model Serving, Scalability</td> </tr> <tr> <td>18</td> <td>Design a Scalable Data Warehouse for ML-Driven Analytics</td> <td><a href=https://towardsdatascience.com/designing-data-warehouses-for-ml-345abc>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Data Warehousing, Analytics</td> </tr> <tr> <td>19</td> <td>Design a System for Hyperparameter Tuning at Scale</td> <td><a href=https://medium.com/@example/hyperparameter-tuning-system-design-789ghi>Medium</a></td> <td>Google, Amazon, Microsoft</td> <td>Hard</td> <td>Optimization, Automation</td> </tr> <tr> <td>20</td> <td>Design an Event-Driven Architecture for ML Pipelines</td> <td><a href=https://towardsdatascience.com/event-driven-architecture-for-ml-567jkl>Towards Data Science</a></td> <td>Amazon, Google, Facebook</td> <td>Medium</td> <td>Event-Driven, Real-Time Processing</td> </tr> <tr> <td>21</td> <td>Design a System for Multimodal Data Processing in Machine Learning</td> <td><a href=https://towardsdatascience.com/multimodal-data-processing-for-ml-123stu>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Hard</td> <td>Data Integration, Deep Learning</td> </tr> <tr> <td>22</td> <td>Design a System to Handle High-Volume Streaming Data for ML</td> <td><a href=https://towardsdatascience.com/high-volume-streaming-data-for-ml-456vwx>Towards Data Science</a></td> <td>Amazon, Google, Microsoft</td> <td>Hard</td> <td>Streaming, Scalability</td> </tr> <tr> <td>23</td> <td>Design a Secure and Scalable ML Infrastructure</td> <td><a href=https://towardsdatascience.com/secure-scalable-ml-infrastructure-789pqr>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Hard</td> <td>Security, Scalability</td> </tr> <tr> <td>24</td> <td>Design a Scalable Feature Engineering Pipeline</td> <td><a href=https://towardsdatascience.com/scalable-feature-engineering-345abc>Towards Data Science</a></td> <td>Google, Amazon, Microsoft</td> <td>Medium</td> <td>Feature Engineering, Scalability</td> </tr> <tr> <td>25</td> <td>Design a System for Experimentation and A/B Testing in Data Science</td> <td><a href=https://towardsdatascience.com/ab-testing-for-data-science-567jkl>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Experimentation, Analytics</td> </tr> <tr> <td>26</td> <td>Design an Architecture for a Data Lake Tailored for ML Applications</td> <td><a href=https://towardsdatascience.com/data-lakes-for-ml-123abc>Towards Data Science</a></td> <td>Amazon, Google, Microsoft</td> <td>Medium</td> <td>Data Lakes, Data Engineering</td> </tr> <tr> <td>27</td> <td>Design a Fault-Tolerant Machine Learning System</td> <td><a href=https://medium.com/@example/fault-tolerant-ml-system-design-890ghi>Medium</a></td> <td>Google, Amazon, Facebook</td> <td>Hard</td> <td>Reliability, Distributed Systems</td> </tr> <tr> <td>28</td> <td>Design a System for Scalable Deep Learning Inference</td> <td><a href=https://towardsdatascience.com/scalable-deep-learning-inference-234vwx>Towards Data Science</a></td> <td>Google, Amazon, Microsoft</td> <td>Hard</td> <td>Deep Learning, Inference</td> </tr> <tr> <td>29</td> <td>Design a Collaborative Platform for Data Science Projects</td> <td><a href=https://towardsdatascience.com/collaborative-platforms-for-data-science-456def>Towards Data Science</a></td> <td>Google, Amazon, Facebook</td> <td>Medium</td> <td>Collaboration, Platform Design</td> </tr> <tr> <td>30</td> <td>Design a System for Model Monitoring and Logging</td> <td><a href=https://towardsdatascience.com/model-monitoring-for-machine-learning-789mno>Towards Data Science</a></td> <td>Google, Amazon, Microsoft</td> <td>Medium</td> <td>MLOps, Monitoring</td> </tr> </tbody> </table> <hr> <h2 id=questions-asked-in-google-interview>Questions asked in Google interview</h2> <ul> <li>Design an End-to-End Machine Learning Pipeline </li> <li>Design a Real-Time Prediction Serving System </li> <li>Design a Continuous Model Retraining and Monitoring System </li> <li>Design a System for Hyperparameter Tuning at Scale </li> <li>Design a Secure and Scalable ML Infrastructure </li> </ul> <h2 id=questions-asked-in-amazon-interview>Questions asked in Amazon interview</h2> <ul> <li>Design a Scalable Data Ingestion &amp; Processing System for ML </li> <li>Design a Recommendation System </li> <li>Design a Fraud Detection System </li> <li>Design an MLOps Pipeline for End-to-End Automation </li> <li>Design a System to Handle High-Volume Streaming Data for ML </li> </ul> <h2 id=questions-asked-in-facebook-interview>Questions asked in Facebook interview</h2> <ul> <li>Design an End-to-End Machine Learning Pipeline </li> <li>Design an Online ML Model Serving Architecture </li> <li>Design a Real-Time Personalization System for E-Commerce </li> <li>Design a System for Model Monitoring and Logging </li> <li>Design a System for Multimodal Data Processing in ML </li> </ul> <h2 id=questions-asked-in-microsoft-interview>Questions asked in Microsoft interview</h2> <ul> <li>Design a Data Versioning and Model Versioning System </li> <li>Design a Scalable Data Warehouse for ML-Driven Analytics </li> <li>Design a Distributed ML Training System </li> <li>Design a System for Real-Time Prediction Serving with Low Latency </li> <li>Design a System for Secure and Scalable ML Infrastructure </li> </ul> <hr> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2020 - <script>document.write(/\d{4}/.exec(Date())[0])</script> ‚Ä¢ <strong>Kuldeep Singh Sidhu</strong> ‚Ä¢ <u><a href=https://choosealicense.com/licenses/agpl-3.0/ target=‚Äù_blank‚Äù>License</a></u> ‚Ä¢ <u><a href=/privacy>Privacy Policy</a></u> ‚Ä¢ <u><a href=/contact>Contact</a></u> ‚Ä¢ </div> </div> <div class=md-social> <a href=https://github.com/singhsidhukuldeep/ target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M8 0c4.42 0 8 3.58 8 8a8.01 8.01 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27s-1.36.09-2 .27c-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8"/></svg> </a> <a href=https://linkedin.com/in/singhsidhukuldeep target=_blank rel=noopener title=linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href=https://twitter.com/kuldeep_s_s target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> <a href=https://stackoverflow.com/u/7182350/ target=_blank rel=noopener title=stackoverflow.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 384 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M290.7 311 95 269.7 86.8 309l195.7 41zm51-87L188.2 95.7l-25.5 30.8 153.5 128.3zm-31.2 39.7L129.2 179l-16.7 36.5L293.7 300zM262 32l-32 24 119.3 160.3 32-24zm20.5 328h-200v39.7h200zm39.7 80H42.7V320h-40v160h359.5V320h-40z"/></svg> </a> <a href=https://huggingface.co/singhsidhukuldeep target=_blank rel=noopener title=huggingface.co class=md-social__link> <svg width=500 height=463 viewbox="0 0 500 463" fill=none xmlns=http://www.w3.org/2000/svg> <path fill=white d="M496.592 369.699C500.563 381.093 499.61 393.227 494.315 403.778C490.503 411.48 485.05 417.441 478.379 422.769C470.331 429.099 460.324 434.48 448.253 439.65C433.852 445.77 416.274 451.52 408.226 453.63C387.63 458.958 367.829 462.334 347.762 462.493C319.066 462.756 294.34 456.004 276.762 438.753C267.656 439.861 258.443 440.494 249.178 440.494C240.389 440.494 231.706 439.967 223.076 438.912C205.445 456.057 180.825 462.756 152.234 462.493C132.168 462.334 112.366 458.958 91.7177 453.63C83.7229 451.52 66.145 445.77 51.7439 439.65C39.6723 434.48 29.6656 429.099 21.6708 422.769C14.9467 417.441 9.49334 411.48 5.68127 403.778C0.439661 393.227 -0.566304 381.093 3.45755 369.699C-0.248631 360.994 -1.20165 351.024 1.71035 339.998C3.03399 334.987 5.20476 330.344 7.95792 326.229C7.37552 324.067 6.89901 321.851 6.58134 319.424C4.56941 304.97 9.59923 291.781 19.0765 281.547C23.7357 276.43 28.7655 272.895 34.0071 270.627C30.1421 254.273 28.1302 237.445 28.1302 220.247C28.1302 98.5969 127.085 0 249.178 0C291.111 0 330.343 11.6058 363.805 31.8633C369.84 35.5561 375.77 39.5126 381.436 43.7329C384.242 45.8431 387.048 48.006 389.748 50.2744C392.501 52.49 395.201 54.8112 397.796 57.1851C405.632 64.3069 412.991 71.9562 419.715 80.133C421.992 82.8235 424.163 85.6194 426.28 88.4681C430.569 94.1128 434.54 99.9685 438.193 106.035C443.752 115.109 448.623 124.604 452.859 134.469C455.665 141.064 458.101 147.816 460.271 154.727C463.501 165.067 465.99 175.723 467.684 186.696C468.213 190.336 468.69 194.028 469.06 197.721C469.802 205.107 470.225 212.598 470.225 220.247C470.225 237.234 468.213 253.904 464.454 269.994C470.278 272.262 475.784 275.955 480.92 281.547C490.397 291.781 495.427 305.022 493.415 319.477C493.098 321.851 492.621 324.067 492.039 326.229C494.792 330.344 496.963 334.987 498.286 339.998C501.198 351.024 500.245 360.994 496.592 369.699Z"/> <path fill=black d="M433.839 221.75C433.839 120.838 351.531 39.0323 250 39.0323C148.469 39.0323 66.1613 120.838 66.1613 221.75C66.1613 322.662 148.469 404.468 250 404.468C351.531 404.468 433.839 322.662 433.839 221.75ZM45 221.75C45 109.222 136.782 18 250 18C363.218 18 455 109.222 455 221.75C455 334.278 363.218 425.5 250 425.5C136.782 425.5 45 334.278 45 221.75Z"/> <path fill=white d="M250 405.5C352.173 405.5 435 323.232 435 221.75C435 120.268 352.173 38 250 38C147.827 38 65 120.268 65 221.75C65 323.232 147.827 405.5 250 405.5Z"/> <path fill=white d="M202.198 404.174C216.789 383.118 215.755 367.316 195.735 347.627C175.715 327.943 164.062 299.145 164.062 299.145C164.062 299.145 159.709 282.419 149.794 283.958C139.88 285.497 132.6 310.492 153.368 325.783C174.135 341.069 149.232 351.456 141.242 337.099C133.252 322.741 111.435 285.831 100.121 278.772C88.8117 271.713 80.8483 275.668 83.5151 290.218C86.182 304.769 133.48 340.036 128.878 347.668C124.276 355.296 108.058 338.7 108.058 338.7C108.058 338.7 57.3079 293.255 46.2587 305.097C35.2096 316.94 54.641 326.863 82.3328 343.359C110.03 359.85 112.177 364.206 108.248 370.446C104.314 376.685 43.1836 325.971 37.4417 347.47C31.705 368.969 99.8291 375.209 95.6247 390.051C91.4203 404.899 47.6372 361.958 38.6823 378.689C29.7221 395.425 100.465 415.088 101.038 415.234C123.889 421.067 181.924 433.426 202.198 404.174Z"/> <path fill=black d="M90.9935 255C82.4744 255 74.8603 258.477 69.551 264.784C66.2675 268.69 62.8367 274.986 62.5578 284.414C58.985 283.394 55.5489 282.824 52.3391 282.824C44.183 282.824 36.8163 285.93 31.6069 291.573C24.9137 298.815 21.9407 307.715 23.2351 316.62C23.8508 320.861 25.2768 324.663 27.4079 328.182C22.9142 331.795 19.6044 336.826 18.0047 342.876C16.7524 347.619 15.4685 357.497 22.1722 367.673C21.746 368.337 21.3461 369.027 20.9725 369.733C16.9418 377.336 16.684 385.927 20.2411 393.928C25.6346 406.054 39.0368 415.608 65.0625 425.863C81.2536 432.242 96.0661 436.321 96.1976 436.357C117.603 441.874 136.962 444.677 153.721 444.677C184.525 444.677 206.578 435.301 219.27 416.811C239.697 387.036 236.776 359.803 210.346 333.552C195.717 319.026 185.993 297.607 183.967 292.906C179.884 278.986 169.086 263.513 151.138 263.513H151.133C149.622 263.513 148.096 263.633 146.592 263.869C138.73 265.097 131.858 269.595 126.949 276.361C121.65 269.814 116.504 264.606 111.847 261.667C104.827 257.243 97.813 255 90.9935 255ZM90.9935 275.917C93.6771 275.917 96.9553 277.051 100.57 279.331C111.794 286.406 133.452 323.403 141.382 337.793C144.039 342.614 148.581 344.654 152.669 344.654C160.783 344.654 167.118 336.638 153.411 326.451C132.8 311.124 140.03 286.072 149.87 284.529C150.301 284.461 150.727 284.43 151.138 284.43C160.083 284.43 164.03 299.751 164.03 299.751C164.03 299.751 175.595 328.616 195.465 348.346C215.334 368.08 216.36 383.919 201.879 405.024C192.002 419.415 173.096 421.292 153.721 421.292C133.626 421.292 112.99 417.772 101.445 414.796C100.877 414.65 30.7019 396.255 39.5946 379.48C41.089 376.661 43.5516 375.532 46.6509 375.532C59.1744 375.532 81.9535 394.054 91.746 394.054C93.935 394.054 95.5662 392.371 96.1976 390.112C100.555 374.522 32.6646 369.738 38.3633 348.189C39.3683 344.377 42.094 342.829 45.9248 342.834C62.4737 342.834 99.6021 371.756 107.385 371.756C107.979 371.756 108.405 371.584 108.637 371.218C112.536 364.964 110.74 359.872 83.257 343.343C55.7738 326.808 36.1428 317.588 47.114 305.718C48.3768 304.347 50.1659 303.741 52.3391 303.741C69.0248 303.746 108.447 339.398 108.447 339.398C108.447 339.398 119.087 350.395 125.523 350.395C127.001 350.395 128.259 349.815 129.111 348.382C133.673 340.737 86.7366 305.388 84.0898 290.804C82.2955 280.921 85.3474 275.917 90.9935 275.917Z"/> <path fill=white d="M296.9 404.174C282.31 383.118 283.343 367.316 303.363 347.627C323.383 327.943 335.037 299.145 335.037 299.145C335.037 299.145 339.39 282.419 349.304 283.958C359.219 285.497 366.498 310.492 345.731 325.783C324.963 341.069 349.866 351.456 357.856 337.099C365.846 322.741 387.663 285.831 398.978 278.772C410.287 271.713 418.25 275.668 415.583 290.218C412.916 304.769 365.618 340.036 370.22 347.668C374.822 355.296 391.041 338.7 391.041 338.7C391.041 338.7 441.791 293.255 452.84 305.097C463.889 316.94 444.457 326.863 416.766 343.359C389.068 359.85 386.921 364.206 390.85 370.446C394.784 376.685 455.915 325.971 461.657 347.47C467.393 368.969 399.269 375.209 403.474 390.051C407.678 404.899 451.461 361.958 460.416 378.689C469.376 395.425 398.633 415.088 398.06 415.234C375.209 421.067 317.175 433.426 296.9 404.174Z"/> <path fill=black d="M408.105 255C416.624 255 424.238 258.477 429.547 264.784C432.831 268.69 436.262 274.986 436.541 284.414C440.113 283.394 443.549 282.824 446.759 282.824C454.915 282.824 462.282 285.93 467.491 291.573C474.185 298.815 477.158 307.715 475.863 316.62C475.248 320.861 473.822 324.663 471.69 328.182C476.184 331.795 479.494 336.826 481.094 342.876C482.346 347.619 483.63 357.497 476.926 367.673C477.352 368.337 477.752 369.027 478.126 369.733C482.157 377.336 482.414 385.927 478.857 393.928C473.464 406.054 460.062 415.608 434.036 425.863C417.845 432.242 403.032 436.321 402.901 436.357C381.495 441.874 362.136 444.677 345.377 444.677C314.573 444.677 292.52 435.301 279.829 416.811C259.402 387.036 262.322 359.803 288.753 333.552C303.381 319.026 313.105 297.607 315.131 292.906C319.214 278.986 330.012 263.513 347.961 263.513H347.966C349.476 263.513 351.002 263.633 352.507 263.869C360.368 265.097 367.24 269.595 372.15 276.361C377.449 269.814 382.595 264.606 387.252 261.667C394.271 257.243 401.285 255 408.105 255ZM408.105 275.917C405.421 275.917 402.143 277.051 398.528 279.331C387.304 286.406 365.646 323.403 357.716 337.793C355.059 342.614 350.518 344.654 346.429 344.654C338.315 344.654 331.98 336.638 345.687 326.451C366.299 311.124 359.069 286.072 349.229 284.529C348.797 284.461 348.371 284.43 347.961 284.43C339.015 284.43 335.069 299.751 335.069 299.751C335.069 299.751 323.503 328.616 303.634 348.346C283.764 368.08 282.738 383.919 297.219 405.024C307.096 419.415 326.002 421.292 345.377 421.292C365.472 421.292 386.108 417.772 397.653 414.796C398.221 414.65 468.397 396.255 459.504 379.48C458.009 376.661 455.547 375.532 452.447 375.532C439.924 375.532 417.145 394.054 407.352 394.054C405.163 394.054 403.532 392.371 402.901 390.112C398.543 374.522 466.434 369.738 460.735 348.189C459.73 344.377 457.004 342.829 453.174 342.834C436.625 342.834 399.496 371.756 391.714 371.756C391.119 371.756 390.693 371.584 390.461 371.218C386.562 364.964 388.358 359.872 415.841 343.343C443.325 326.808 462.956 317.588 451.984 305.718C450.722 304.347 448.932 303.741 446.759 303.741C430.074 303.746 390.651 339.398 390.651 339.398C390.651 339.398 380.011 350.395 373.576 350.395C372.097 350.395 370.84 349.815 369.987 348.382C365.425 340.737 412.362 305.388 415.009 290.804C416.803 280.921 413.751 275.917 408.105 275.917Z"/> <path fill=#0E1116 d="M319.277 228.901C319.277 205.236 288.585 241.304 250.637 241.465C212.692 241.306 182 205.238 182 228.901C182 244.591 189.507 270.109 209.669 285.591C213.681 271.787 235.726 260.729 238.877 262.317C243.364 264.578 243.112 270.844 250.637 276.365C258.163 270.844 257.911 264.58 262.398 262.317C265.551 260.729 287.594 271.787 291.605 285.591C311.767 270.109 319.275 244.591 319.275 228.903L319.277 228.901Z"/> <path fill=#FF323D d="M262.4 262.315C257.913 264.576 258.165 270.842 250.639 276.363C243.114 270.842 243.366 264.578 238.879 262.315C235.726 260.727 213.683 271.785 209.672 285.589C219.866 293.417 233.297 298.678 250.627 298.806C250.631 298.806 250.635 298.806 250.641 298.806C250.646 298.806 250.65 298.806 250.656 298.806C267.986 298.68 281.417 293.417 291.611 285.589C287.6 271.785 265.555 260.727 262.404 262.315H262.4Z"/> <path fill=black d="M373 196C382.389 196 390 188.389 390 179C390 169.611 382.389 162 373 162C363.611 162 356 169.611 356 179C356 188.389 363.611 196 373 196Z"/> <path fill=black d="M128 196C137.389 196 145 188.389 145 179C145 169.611 137.389 162 128 162C118.611 162 111 169.611 111 179C111 188.389 118.611 196 128 196Z"/> <path fill=#0E1116 d="M313.06 171.596C319.796 173.968 322.476 187.779 329.281 184.171C342.167 177.337 347.06 161.377 340.208 148.524C333.356 135.671 317.354 130.792 304.467 137.626C291.58 144.46 286.688 160.419 293.54 173.272C296.774 179.339 307.039 169.475 313.06 171.596Z"/> <path fill=#0E1116 d="M188.554 171.596C181.818 173.968 179.138 187.779 172.334 184.171C159.447 177.337 154.555 161.377 161.407 148.524C168.259 135.671 184.26 130.792 197.147 137.626C210.034 144.46 214.926 160.419 208.074 173.272C204.84 179.339 194.575 169.475 188.554 171.596Z"/> </svg> </a> <a href=http://kuldeepsinghsidhu.com target=_blank rel=noopener title=kuldeepsinghsidhu.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 16 16"><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0M5.78 8.75a9.64 9.64 0 0 0 1.363 4.177q.383.64.857 1.215c.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a10 10 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.51 6.51 0 0 0 4.666 5.5q-.184-.271-.352-.552c-.715-1.192-1.437-2.874-1.581-4.948m-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948q.18-.295.353-.552a6.51 6.51 0 0 0-4.666 5.5m10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948q-.18.296-.353.552a6.51 6.51 0 0 0 4.666-5.5Zm2.733-1.5a6.51 6.51 0 0 0-4.666-5.5q.184.272.353.552c.714 1.192 1.436 2.874 1.58 4.948Z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "search.highlight", "search.share", "search.suggest", "content.tooltips", "navigation.instant.progress", "navigation.path", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.60a45f97.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> <script src=../../javascripts/xfile.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>